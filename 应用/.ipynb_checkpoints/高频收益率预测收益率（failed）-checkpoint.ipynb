{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上证指数已实现波动率计算\n",
    "df_fminSZZS = pd.read_csv(r'C:\\Users\\jxjsj\\Desktop\\JupyterHome\\Data\\SZZS_five_min080101-181201.csv',index_col=0,header=0)\n",
    "\n",
    "df_fminSZZS['time'] = list(df_fminSZZS.index)\n",
    "\n",
    "df_fminSZZS['date'] = list(df_fminSZZS['time'].apply(lambda x: str(x)[:10]))\n",
    "\n",
    "df_fminSZZS['close-1'] = df_fminSZZS['close'].shift(1)\n",
    "\n",
    "df_fminSZZS_lnR_temp = pd.DataFrame(np.log(df_fminSZZS['close'])-np.log(df_fminSZZS['close-1']),index=df_fminSZZS.index,columns=['lnR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fminSZZS_lnR = pd.concat([df_fminSZZS_lnR_temp,pd.DataFrame(list(df_fminSZZS['date']),columns=['date'],index=df_fminSZZS.index)],axis=1).dropna(axis=0,how='any')\n",
    "\n",
    "df_fminSZZS_lnR['lnR^2'] = df_fminSZZS_lnR['lnR'].apply(lambda x: x*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t天预测t+1天\n",
    "save_array = np.zeros(shape=(int((len(df_fminSZZS_lnR)-47)/48-21),48))\n",
    "column_n = 0\n",
    "row_n = -1\n",
    "date_record = 0\n",
    "for index in df_fminSZZS_lnR.index[47:-21*48]:\n",
    "    if date_record == str(index)[:10]:\n",
    "        save_array[row_n,column_n] = df_fminSZZS_lnR['lnR'][index]\n",
    "        column_n += 1\n",
    "    else:\n",
    "        date_record = str(index)[:10]\n",
    "        row_n += 1\n",
    "        column_n = 0\n",
    "        save_array[row_n,column_n] = df_fminSZZS_lnR['lnR'][index]\n",
    "        column_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t天上半天预测t天全天\n",
    "save_array = np.zeros(shape=(int((len(df_fminSZZS_lnR)-47)/48-21),24))\n",
    "column_n = 0\n",
    "row_n = -1\n",
    "date_record = 0\n",
    "for index in df_fminSZZS_lnR.index[47:-21*48]:\n",
    "    try:\n",
    "        if date_record == str(index)[:10]:\n",
    "            save_array[row_n,column_n] = df_fminSZZS_lnR['lnR'][index]\n",
    "            column_n += 1\n",
    "        else:\n",
    "            date_record = str(index)[:10]\n",
    "            row_n += 1\n",
    "            column_n = 0\n",
    "            save_array[row_n,column_n] = df_fminSZZS_lnR['lnR'][index]\n",
    "            column_n += 1\n",
    "    except:\n",
    "        column_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def positive_negative(x):\n",
    "#     if x>=0.009364169774957184:\n",
    "#         return 2\n",
    "#     if x>=0.002597620432019096 and x<0.009364169774957184:\n",
    "#         return 1\n",
    "#     if x<-0.009043426461761683:\n",
    "#         return -2\n",
    "#     if x>=-0.009043426461761683 and x<-0.001910275079918831:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "def positive_negative(x):\n",
    "    if x>=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data = pd.read_csv('C:/Users/jxjsj/Desktop/JupyterHome/Data/SZZS_lnr_rv_w_m_ntd_080101-181101.csv',index_col=0,header=0)\n",
    "lnR = pd.DataFrame(data['lnR'])\n",
    "# lnR['lnR'] = lnR['lnR'].apply(lambda x: positive_negative(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lnR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>0.008883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>0.007810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>0.005908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <td>-0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-09</th>\n",
       "      <td>0.009106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-10</th>\n",
       "      <td>0.003807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-11</th>\n",
       "      <td>0.005143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-14</th>\n",
       "      <td>0.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-15</th>\n",
       "      <td>-0.009891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-16</th>\n",
       "      <td>-0.028543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-17</th>\n",
       "      <td>-0.026620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-18</th>\n",
       "      <td>0.005592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-21</th>\n",
       "      <td>-0.052727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-22</th>\n",
       "      <td>-0.074909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-23</th>\n",
       "      <td>0.030943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-24</th>\n",
       "      <td>0.003118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-25</th>\n",
       "      <td>0.009274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-28</th>\n",
       "      <td>-0.074622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-29</th>\n",
       "      <td>0.008708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-30</th>\n",
       "      <td>-0.009035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-31</th>\n",
       "      <td>-0.007830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-01</th>\n",
       "      <td>-0.014390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-04</th>\n",
       "      <td>0.078191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-05</th>\n",
       "      <td>-0.015633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-13</th>\n",
       "      <td>-0.023977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-14</th>\n",
       "      <td>0.013623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-15</th>\n",
       "      <td>-0.012197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-18</th>\n",
       "      <td>0.015670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-19</th>\n",
       "      <td>0.020828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-20</th>\n",
       "      <td>-0.021074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13</th>\n",
       "      <td>0.011406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-14</th>\n",
       "      <td>-0.001840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-17</th>\n",
       "      <td>-0.011194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-18</th>\n",
       "      <td>0.017998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19</th>\n",
       "      <td>0.011380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-20</th>\n",
       "      <td>-0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-21</th>\n",
       "      <td>0.024696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-25</th>\n",
       "      <td>-0.005858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-26</th>\n",
       "      <td>0.009188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-27</th>\n",
       "      <td>-0.005373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-28</th>\n",
       "      <td>0.010540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-08</th>\n",
       "      <td>-0.037868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-09</th>\n",
       "      <td>0.001655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-10</th>\n",
       "      <td>0.001774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-11</th>\n",
       "      <td>-0.053647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-12</th>\n",
       "      <td>0.009036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-15</th>\n",
       "      <td>-0.014999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-16</th>\n",
       "      <td>-0.008513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-17</th>\n",
       "      <td>0.005983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-18</th>\n",
       "      <td>-0.029792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19</th>\n",
       "      <td>0.025434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-22</th>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-23</th>\n",
       "      <td>-0.022878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-24</th>\n",
       "      <td>0.003259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-25</th>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-26</th>\n",
       "      <td>-0.001903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-29</th>\n",
       "      <td>-0.022079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-30</th>\n",
       "      <td>0.010156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-31</th>\n",
       "      <td>0.013433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>0.001328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2635 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lnR\n",
       "2008-01-03  0.008883\n",
       "2008-01-04  0.007810\n",
       "2008-01-07  0.005908\n",
       "2008-01-08 -0.001264\n",
       "2008-01-09  0.009106\n",
       "2008-01-10  0.003807\n",
       "2008-01-11  0.005143\n",
       "2008-01-14  0.002408\n",
       "2008-01-15 -0.009891\n",
       "2008-01-16 -0.028543\n",
       "2008-01-17 -0.026620\n",
       "2008-01-18  0.005592\n",
       "2008-01-21 -0.052727\n",
       "2008-01-22 -0.074909\n",
       "2008-01-23  0.030943\n",
       "2008-01-24  0.003118\n",
       "2008-01-25  0.009274\n",
       "2008-01-28 -0.074622\n",
       "2008-01-29  0.008708\n",
       "2008-01-30 -0.009035\n",
       "2008-01-31 -0.007830\n",
       "2008-02-01 -0.014390\n",
       "2008-02-04  0.078191\n",
       "2008-02-05 -0.015633\n",
       "2008-02-13 -0.023977\n",
       "2008-02-14  0.013623\n",
       "2008-02-15 -0.012197\n",
       "2008-02-18  0.015670\n",
       "2008-02-19  0.020828\n",
       "2008-02-20 -0.021074\n",
       "...              ...\n",
       "2018-09-13  0.011406\n",
       "2018-09-14 -0.001840\n",
       "2018-09-17 -0.011194\n",
       "2018-09-18  0.017998\n",
       "2018-09-19  0.011380\n",
       "2018-09-20 -0.000590\n",
       "2018-09-21  0.024696\n",
       "2018-09-25 -0.005858\n",
       "2018-09-26  0.009188\n",
       "2018-09-27 -0.005373\n",
       "2018-09-28  0.010540\n",
       "2018-10-08 -0.037868\n",
       "2018-10-09  0.001655\n",
       "2018-10-10  0.001774\n",
       "2018-10-11 -0.053647\n",
       "2018-10-12  0.009036\n",
       "2018-10-15 -0.014999\n",
       "2018-10-16 -0.008513\n",
       "2018-10-17  0.005983\n",
       "2018-10-18 -0.029792\n",
       "2018-10-19  0.025434\n",
       "2018-10-22  0.040122\n",
       "2018-10-23 -0.022878\n",
       "2018-10-24  0.003259\n",
       "2018-10-25  0.000192\n",
       "2018-10-26 -0.001903\n",
       "2018-10-29 -0.022079\n",
       "2018-10-30  0.010156\n",
       "2018-10-31  0.013433\n",
       "2018-11-01  0.001328\n",
       "\n",
       "[2635 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [pd.DataFrame(save_array),pd.DataFrame(list(lnR['lnR']))],\n",
    "    axis=1).to_csv('C:/Users/jxjsj/Desktop/JupyterHome/Data/SZZSlnrlnR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array = save_array[:2634]\n",
    "lnR = lnR[1:2635]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09034457846970413"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(lnR, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(save_array, lnR, random_state=1, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 0.7666034155597723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      1004\n",
      "           1       0.76      0.80      0.78      1104\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      2108\n",
      "   macro avg       0.77      0.76      0.77      2108\n",
      "weighted avg       0.77      0.77      0.77      2108\n",
      "\n",
      "testAccracy: 0.7476280834914611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       247\n",
      "           1       0.74      0.82      0.77       280\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       527\n",
      "   macro avg       0.75      0.74      0.74       527\n",
      "weighted avg       0.75      0.75      0.75       527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 运用原非平衡样本-训练\n",
    "realvolEvaluation = MLPClassifier(activation='tanh', \n",
    "                    solver='lbfgs',\n",
    "                    alpha=1e-5,\n",
    "                    hidden_layer_sizes=(len(x_train[0])*5+1,),\n",
    "                    random_state=1, \n",
    "                   )\n",
    "realvolEvaluation.fit(x_train,y_train)\n",
    "\n",
    "# 运用原非平衡样本-评估\n",
    "y_train_predict = realvolEvaluation.predict(x_train)\n",
    "y_test_predict = realvolEvaluation.predict(x_test)\n",
    "\n",
    "print('trainAccracy:',realvolEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict)) #真实数据在前 训练结果在后！\n",
    "print('testAccracy:',realvolEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 0.6133776091081594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.25      0.38      1004\n",
      "           1       0.58      0.94      0.72      1104\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      2108\n",
      "   macro avg       0.69      0.60      0.55      2108\n",
      "weighted avg       0.68      0.61      0.56      2108\n",
      "\n",
      "testAccracy: 0.6053130929791272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.22      0.34       247\n",
      "           1       0.58      0.95      0.72       280\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       527\n",
      "   macro avg       0.68      0.58      0.53       527\n",
      "weighted avg       0.67      0.61      0.54       527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "realvolEvaluation = svm.SVC(C=10, kernel='linear', decision_function_shape='ovr',class_weight = \"balanced\")\n",
    "\n",
    "realvolEvaluation.fit(x_train,y_train)\n",
    "# 运用原非平衡样本-评估\n",
    "y_train_predict = realvolEvaluation.predict(x_train)\n",
    "y_test_predict = realvolEvaluation.predict(x_test)\n",
    "\n",
    "print('trainAccracy:',realvolEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict)) #真实数据在前 训练结果在后！\n",
    "print('testAccracy:',realvolEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 0.6475332068311196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.41      0.53      1004\n",
      "           1       0.62      0.86      0.72      1104\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      2108\n",
      "   macro avg       0.67      0.64      0.62      2108\n",
      "weighted avg       0.67      0.65      0.63      2108\n",
      "\n",
      "testAccracy: 0.6451612903225806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.38      0.50       247\n",
      "           1       0.62      0.88      0.72       280\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       527\n",
      "   macro avg       0.68      0.63      0.61       527\n",
      "weighted avg       0.67      0.65      0.62       527\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "realvolEvaluation = GaussianNB()\n",
    "\n",
    "realvolEvaluation.fit(x_train,y_train)\n",
    "# 运用原非平衡样本-评估\n",
    "y_train_predict = realvolEvaluation.predict(x_train)\n",
    "y_test_predict = realvolEvaluation.predict(x_test)\n",
    "\n",
    "print('trainAccracy:',realvolEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict)) #真实数据在前 训练结果在后！\n",
    "print('testAccracy:',realvolEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 0.9169829222011385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1004\n",
      "           1       0.92      0.92      0.92      1104\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      2108\n",
      "   macro avg       0.92      0.92      0.92      2108\n",
      "weighted avg       0.92      0.92      0.92      2108\n",
      "\n",
      "testAccracy: 0.6546489563567363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       247\n",
      "           1       0.67      0.68      0.68       280\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       527\n",
      "   macro avg       0.65      0.65      0.65       527\n",
      "weighted avg       0.65      0.65      0.65       527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "realvolEvaluation = tree.DecisionTreeClassifier(criterion='gini', \n",
    "                                                max_depth=10, \n",
    "                                                min_samples_split=10, \n",
    "                                                min_samples_leaf =1, \n",
    "                                                min_weight_fraction_leaf=0.0, \n",
    "                                                max_features=None, \n",
    "                                                random_state=1, \n",
    "                                                max_leaf_nodes=None, \n",
    "                                                class_weight='balanced', \n",
    "                                                presort=False)\n",
    "\n",
    "realvolEvaluation.fit(x_train,y_train)\n",
    "# 运用原非平衡样本-评估\n",
    "y_train_predict = realvolEvaluation.predict(x_train)\n",
    "y_test_predict = realvolEvaluation.predict(x_test)\n",
    "\n",
    "print('trainAccracy:',realvolEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict)) #真实数据在前 训练结果在后！\n",
    "print('testAccracy:',realvolEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
