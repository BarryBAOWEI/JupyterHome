{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jqdatasdk as jq\n",
    "import statsmodels.api as sm\n",
    "import time,datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auth success （JQData现有流量增加活动，详情请咨询JQData管理员，微信号：JQData01）\n"
     ]
    }
   ],
   "source": [
    "jq.auth('13918852005','960312Lsc')\n",
    "# jq.auth('15821912507','912507')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先分组，5因子分组：市值2组，其余3组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成分组标识\n",
    "bin_df = pd.read_csv('E:/Stock_Data/bin_data.csv',index_col=0)\n",
    "for col in ['B_M', 'OP','pe_ratio']:\n",
    "    if isinstance(bin_df[col][0],float):\n",
    "        bin_df[col] = bin_df[col].apply(lambda x : np.nan if x<0 else x)\n",
    "bin_df = bin_df.dropna(how='any',axis=0)\n",
    "\n",
    "## 分组组数\n",
    "bin_num = 3\n",
    "\n",
    "for i in range(8):\n",
    "    \n",
    "    year = str(2010+i)+'-12-31'\n",
    "    temp_df_0 = bin_df[bin_df.date==year]\n",
    "    \n",
    "    # 计算当年总行数\n",
    "    stock_num = len(temp_df_0)\n",
    "    \n",
    "    for bin_kind in ['B_M','OP','Inv']:\n",
    "        \n",
    "        # 生成分组标识\n",
    "        bin_lst = []\n",
    "        for i in range(bin_num):\n",
    "            bin_lst += [bin_kind+str(i+1)]*int(stock_num/bin_num)\n",
    "        if len(bin_lst) != stock_num:\n",
    "            bin_lst += [bin_kind+str(i+1)]*(stock_num-len(bin_lst))\n",
    "        \n",
    "        temp_df_0 = temp_df_0.sort_values(bin_kind)\n",
    "        temp_df_0[bin_kind] = bin_lst\n",
    "            \n",
    "    for bin_kind in ['Size']:\n",
    "        \n",
    "        # Size只分两组\n",
    "        bin_num_size = 2\n",
    "        # 生成分组标识\n",
    "        bin_lst = []\n",
    "        for i in range(bin_num_size):\n",
    "            bin_lst += [bin_kind+str(i+1)]*int(stock_num/bin_num_size)\n",
    "        if len(bin_lst) != stock_num:\n",
    "            bin_lst += [bin_kind+str(i+1)]*(stock_num-len(bin_lst))\n",
    "        \n",
    "        temp_df_0 = temp_df_0.sort_values(bin_kind)\n",
    "        temp_df_0[bin_kind] = bin_lst    \n",
    "    \n",
    "    temp_df_1 = bin_df[bin_df.date==year]\n",
    "    temp_df_1 = temp_df_1.sort_values('Size') # 和df_0对齐，最后一次是按照Size排序的\n",
    "    temp_df_0['S']=temp_df_1['Size']\n",
    "    temp_df_0.to_csv('E:/Stock_Data/factor_portfolio/bin_data'+year+'.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按要求生成投资组合\n",
    "\n",
    "# 保存在字典：除Size以外的另一个组别 -> 年份 -> bin2 -> 组合，stock code list\n",
    "\n",
    "portfolio={}\n",
    "\n",
    "for bin2 in ['B_M','OP','Inv','Size']:\n",
    "    portfolio[bin2] = {}\n",
    "    \n",
    "    for i in range(8):\n",
    "        year = str(2010+i)+'-12-31'\n",
    "        portfolio[bin2][str(2011+i)]={}\n",
    "        \n",
    "        temp_df_0 = pd.read_csv('E:/Stock_Data/factor_portfolio/bin_data'+year+'.csv',index_col=0)\n",
    "        bin2_lst = list(set(temp_df_0[bin2]))\n",
    "        \n",
    "        for bin2_ in bin2_lst:\n",
    "            temp_df_1 = temp_df_0[temp_df_0[bin2]==bin2_]\n",
    "            list_code_value = [list(temp_df_1[['code','S']].iloc[i,:]) for i in range(len(temp_df_1))]\n",
    "            portfolio[bin2][str(2011+i)][bin2_] = list_code_value\n",
    "            \n",
    "# 保存字典\n",
    "f = open('E:/Stock_Data/factor_portfolio/portfolio.txt','w')\n",
    "f.write(str(portfolio))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取字典\n",
    "f = open('E:/Stock_Data/factor_portfolio/portfolio.txt','r')\n",
    "a = f.read()\n",
    "portfolio = eval(a)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_download_return_temp = os.listdir('E:/Stock_Data/stock_return_data/')\n",
    "stock_download_return = [x[:-4] for x in stock_download_return_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000001.XSHE',\n",
       " '000002.XSHE',\n",
       " '000004.XSHE',\n",
       " '000005.XSHE',\n",
       " '000006.XSHE',\n",
       " '000008.XSHE',\n",
       " '000009.XSHE',\n",
       " '000011.XSHE',\n",
       " '000012.XSHE',\n",
       " '000014.XSHE',\n",
       " '000016.XSHE',\n",
       " '000017.XSHE',\n",
       " '000018.XSHE',\n",
       " '000019.XSHE',\n",
       " '000020.XSHE',\n",
       " '000021.XSHE',\n",
       " '000022.XSHE',\n",
       " '000023.XSHE',\n",
       " '000024.XSHE',\n",
       " '000025.XSHE',\n",
       " '000026.XSHE',\n",
       " '000027.XSHE',\n",
       " '000028.XSHE',\n",
       " '000030.XSHE',\n",
       " '000031.XSHE',\n",
       " '000032.XSHE',\n",
       " '000034.XSHE',\n",
       " '000036.XSHE',\n",
       " '000037.XSHE',\n",
       " '000039.XSHE',\n",
       " '000040.XSHE',\n",
       " '000042.XSHE',\n",
       " '000043.XSHE',\n",
       " '000045.XSHE',\n",
       " '000046.XSHE',\n",
       " '000048.XSHE',\n",
       " '000049.XSHE',\n",
       " '000050.XSHE',\n",
       " '000055.XSHE',\n",
       " '000056.XSHE',\n",
       " '000058.XSHE',\n",
       " '000059.XSHE',\n",
       " '000060.XSHE',\n",
       " '000061.XSHE',\n",
       " '000062.XSHE',\n",
       " '000063.XSHE',\n",
       " '000065.XSHE',\n",
       " '000066.XSHE',\n",
       " '000069.XSHE',\n",
       " '000070.XSHE',\n",
       " '000078.XSHE',\n",
       " '000088.XSHE',\n",
       " '000089.XSHE',\n",
       " '000090.XSHE',\n",
       " '000096.XSHE',\n",
       " '000099.XSHE',\n",
       " '000100.XSHE',\n",
       " '000150.XSHE',\n",
       " '000151.XSHE',\n",
       " '000153.XSHE',\n",
       " '000157.XSHE',\n",
       " '000158.XSHE',\n",
       " '000159.XSHE',\n",
       " '000301.XSHE',\n",
       " '000338.XSHE',\n",
       " '000400.XSHE',\n",
       " '000401.XSHE',\n",
       " '000402.XSHE',\n",
       " '000404.XSHE',\n",
       " '000407.XSHE',\n",
       " '000408.XSHE',\n",
       " '000409.XSHE',\n",
       " '000410.XSHE',\n",
       " '000411.XSHE',\n",
       " '000413.XSHE',\n",
       " '000416.XSHE',\n",
       " '000417.XSHE',\n",
       " '000418.XSHE',\n",
       " '000419.XSHE',\n",
       " '000420.XSHE',\n",
       " '000421.XSHE',\n",
       " '000422.XSHE',\n",
       " '000423.XSHE',\n",
       " '000425.XSHE',\n",
       " '000426.XSHE',\n",
       " '000428.XSHE',\n",
       " '000429.XSHE',\n",
       " '000430.XSHE',\n",
       " '000488.XSHE',\n",
       " '000501.XSHE',\n",
       " '000502.XSHE',\n",
       " '000503.XSHE',\n",
       " '000504.XSHE',\n",
       " '000505.XSHE',\n",
       " '000506.XSHE',\n",
       " '000507.XSHE',\n",
       " '000509.XSHE',\n",
       " '000510.XSHE',\n",
       " '000513.XSHE',\n",
       " '000514.XSHE',\n",
       " '000516.XSHE',\n",
       " '000517.XSHE',\n",
       " '000518.XSHE',\n",
       " '000519.XSHE',\n",
       " '000521.XSHE',\n",
       " '000523.XSHE',\n",
       " '000524.XSHE',\n",
       " '000525.XSHE',\n",
       " '000528.XSHE',\n",
       " '000529.XSHE',\n",
       " '000530.XSHE',\n",
       " '000531.XSHE',\n",
       " '000532.XSHE',\n",
       " '000533.XSHE',\n",
       " '000534.XSHE',\n",
       " '000536.XSHE',\n",
       " '000537.XSHE',\n",
       " '000538.XSHE',\n",
       " '000539.XSHE',\n",
       " '000541.XSHE',\n",
       " '000543.XSHE',\n",
       " '000544.XSHE',\n",
       " '000546.XSHE',\n",
       " '000547.XSHE',\n",
       " '000548.XSHE',\n",
       " '000550.XSHE',\n",
       " '000551.XSHE',\n",
       " '000552.XSHE',\n",
       " '000553.XSHE',\n",
       " '000554.XSHE',\n",
       " '000555.XSHE',\n",
       " '000558.XSHE',\n",
       " '000559.XSHE',\n",
       " '000560.XSHE',\n",
       " '000561.XSHE',\n",
       " '000563.XSHE',\n",
       " '000565.XSHE',\n",
       " '000566.XSHE',\n",
       " '000567.XSHE',\n",
       " '000568.XSHE',\n",
       " '000570.XSHE',\n",
       " '000571.XSHE',\n",
       " '000572.XSHE',\n",
       " '000573.XSHE',\n",
       " '000576.XSHE',\n",
       " '000581.XSHE',\n",
       " '000582.XSHE',\n",
       " '000584.XSHE',\n",
       " '000585.XSHE',\n",
       " '000586.XSHE',\n",
       " '000587.XSHE',\n",
       " '000589.XSHE',\n",
       " '000590.XSHE',\n",
       " '000591.XSHE',\n",
       " '000592.XSHE',\n",
       " '000593.XSHE',\n",
       " '000594.XSHE',\n",
       " '000595.XSHE',\n",
       " '000596.XSHE',\n",
       " '000597.XSHE',\n",
       " '000598.XSHE',\n",
       " '000599.XSHE',\n",
       " '000600.XSHE',\n",
       " '000601.XSHE',\n",
       " '000603.XSHE',\n",
       " '000605.XSHE',\n",
       " '000606.XSHE',\n",
       " '000607.XSHE',\n",
       " '000608.XSHE',\n",
       " '000609.XSHE',\n",
       " '000610.XSHE',\n",
       " '000611.XSHE',\n",
       " '000612.XSHE',\n",
       " '000613.XSHE',\n",
       " '000615.XSHE',\n",
       " '000616.XSHE',\n",
       " '000617.XSHE',\n",
       " '000619.XSHE',\n",
       " '000620.XSHE',\n",
       " '000623.XSHE',\n",
       " '000625.XSHE',\n",
       " '000626.XSHE',\n",
       " '000627.XSHE',\n",
       " '000628.XSHE',\n",
       " '000630.XSHE',\n",
       " '000631.XSHE',\n",
       " '000632.XSHE',\n",
       " '000633.XSHE',\n",
       " '000635.XSHE',\n",
       " '000636.XSHE',\n",
       " '000637.XSHE',\n",
       " '000638.XSHE',\n",
       " '000639.XSHE',\n",
       " '000650.XSHE',\n",
       " '000651.XSHE',\n",
       " '000652.XSHE',\n",
       " '000655.XSHE',\n",
       " '000656.XSHE',\n",
       " '000659.XSHE',\n",
       " '000661.XSHE',\n",
       " '000662.XSHE',\n",
       " '000663.XSHE',\n",
       " '000665.XSHE',\n",
       " '000666.XSHE',\n",
       " '000667.XSHE',\n",
       " '000668.XSHE',\n",
       " '000669.XSHE',\n",
       " '000671.XSHE',\n",
       " '000673.XSHE',\n",
       " '000676.XSHE',\n",
       " '000678.XSHE',\n",
       " '000679.XSHE',\n",
       " '000680.XSHE',\n",
       " '000682.XSHE',\n",
       " '000683.XSHE',\n",
       " '000685.XSHE',\n",
       " '000686.XSHE',\n",
       " '000687.XSHE',\n",
       " '000690.XSHE',\n",
       " '000691.XSHE',\n",
       " '000692.XSHE',\n",
       " '000695.XSHE',\n",
       " '000697.XSHE',\n",
       " '000698.XSHE',\n",
       " '000700.XSHE',\n",
       " '000701.XSHE',\n",
       " '000702.XSHE',\n",
       " '000703.XSHE',\n",
       " '000705.XSHE',\n",
       " '000707.XSHE',\n",
       " '000708.XSHE',\n",
       " '000709.XSHE',\n",
       " '000710.XSHE',\n",
       " '000712.XSHE',\n",
       " '000713.XSHE',\n",
       " '000715.XSHE',\n",
       " '000716.XSHE',\n",
       " '000717.XSHE',\n",
       " '000718.XSHE',\n",
       " '000719.XSHE',\n",
       " '000720.XSHE',\n",
       " '000721.XSHE',\n",
       " '000722.XSHE',\n",
       " '000723.XSHE',\n",
       " '000725.XSHE',\n",
       " '000726.XSHE',\n",
       " '000727.XSHE',\n",
       " '000728.XSHE',\n",
       " '000729.XSHE',\n",
       " '000731.XSHE',\n",
       " '000732.XSHE',\n",
       " '000733.XSHE',\n",
       " '000735.XSHE',\n",
       " '000736.XSHE',\n",
       " '000737.XSHE',\n",
       " '000738.XSHE',\n",
       " '000739.XSHE',\n",
       " '000748.XSHE',\n",
       " '000750.XSHE',\n",
       " '000751.XSHE',\n",
       " '000752.XSHE',\n",
       " '000753.XSHE',\n",
       " '000755.XSHE',\n",
       " '000756.XSHE',\n",
       " '000758.XSHE',\n",
       " '000759.XSHE',\n",
       " '000760.XSHE',\n",
       " '000761.XSHE',\n",
       " '000762.XSHE',\n",
       " '000766.XSHE',\n",
       " '000767.XSHE',\n",
       " '000768.XSHE',\n",
       " '000776.XSHE',\n",
       " '000777.XSHE',\n",
       " '000778.XSHE',\n",
       " '000779.XSHE',\n",
       " '000780.XSHE',\n",
       " '000782.XSHE',\n",
       " '000783.XSHE',\n",
       " '000785.XSHE',\n",
       " '000786.XSHE',\n",
       " '000788.XSHE',\n",
       " '000789.XSHE',\n",
       " '000790.XSHE',\n",
       " '000791.XSHE',\n",
       " '000792.XSHE',\n",
       " '000793.XSHE',\n",
       " '000795.XSHE',\n",
       " '000797.XSHE',\n",
       " '000798.XSHE',\n",
       " '000799.XSHE',\n",
       " '000800.XSHE',\n",
       " '000801.XSHE',\n",
       " '000802.XSHE',\n",
       " '000803.XSHE',\n",
       " '000806.XSHE',\n",
       " '000807.XSHE',\n",
       " '000809.XSHE',\n",
       " '000810.XSHE',\n",
       " '000811.XSHE',\n",
       " '000812.XSHE',\n",
       " '000813.XSHE',\n",
       " '000815.XSHE',\n",
       " '000816.XSHE',\n",
       " '000818.XSHE',\n",
       " '000819.XSHE',\n",
       " '000821.XSHE',\n",
       " '000822.XSHE',\n",
       " '000823.XSHE',\n",
       " '000825.XSHE',\n",
       " '000826.XSHE',\n",
       " '000828.XSHE',\n",
       " '000829.XSHE',\n",
       " '000830.XSHE',\n",
       " '000831.XSHE',\n",
       " '000833.XSHE',\n",
       " '000835.XSHE',\n",
       " '000836.XSHE',\n",
       " '000837.XSHE',\n",
       " '000838.XSHE',\n",
       " '000839.XSHE',\n",
       " '000848.XSHE',\n",
       " '000850.XSHE',\n",
       " '000851.XSHE',\n",
       " '000852.XSHE',\n",
       " '000856.XSHE',\n",
       " '000858.XSHE',\n",
       " '000859.XSHE',\n",
       " '000860.XSHE',\n",
       " '000861.XSHE',\n",
       " '000862.XSHE',\n",
       " '000868.XSHE',\n",
       " '000869.XSHE',\n",
       " '000875.XSHE',\n",
       " '000876.XSHE',\n",
       " '000877.XSHE',\n",
       " '000878.XSHE',\n",
       " '000880.XSHE',\n",
       " '000881.XSHE',\n",
       " '000882.XSHE',\n",
       " '000883.XSHE',\n",
       " '000885.XSHE',\n",
       " '000886.XSHE',\n",
       " '000887.XSHE',\n",
       " '000888.XSHE',\n",
       " '000889.XSHE',\n",
       " '000890.XSHE',\n",
       " '000892.XSHE',\n",
       " '000893.XSHE',\n",
       " '000895.XSHE',\n",
       " '000897.XSHE',\n",
       " '000898.XSHE',\n",
       " '000899.XSHE',\n",
       " '000900.XSHE',\n",
       " '000901.XSHE',\n",
       " '000902.XSHE',\n",
       " '000903.XSHE',\n",
       " '000905.XSHE',\n",
       " '000906.XSHE',\n",
       " '000908.XSHE',\n",
       " '000909.XSHE',\n",
       " '000910.XSHE',\n",
       " '000911.XSHE',\n",
       " '000912.XSHE',\n",
       " '000913.XSHE',\n",
       " '000915.XSHE',\n",
       " '000916.XSHE',\n",
       " '000917.XSHE',\n",
       " '000918.XSHE',\n",
       " '000919.XSHE',\n",
       " '000920.XSHE',\n",
       " '000921.XSHE',\n",
       " '000922.XSHE',\n",
       " '000923.XSHE',\n",
       " '000925.XSHE',\n",
       " '000926.XSHE',\n",
       " '000927.XSHE',\n",
       " '000928.XSHE',\n",
       " '000929.XSHE',\n",
       " '000930.XSHE',\n",
       " '000931.XSHE',\n",
       " '000932.XSHE',\n",
       " '000933.XSHE',\n",
       " '000935.XSHE',\n",
       " '000936.XSHE',\n",
       " '000937.XSHE',\n",
       " '000938.XSHE',\n",
       " '000939.XSHE',\n",
       " '000948.XSHE',\n",
       " '000949.XSHE',\n",
       " '000951.XSHE',\n",
       " '000952.XSHE',\n",
       " '000953.XSHE',\n",
       " '000955.XSHE',\n",
       " '000957.XSHE',\n",
       " '000958.XSHE',\n",
       " '000959.XSHE',\n",
       " '000960.XSHE',\n",
       " '000961.XSHE',\n",
       " '000962.XSHE',\n",
       " '000963.XSHE',\n",
       " '000965.XSHE',\n",
       " '000966.XSHE',\n",
       " '000967.XSHE',\n",
       " '000968.XSHE',\n",
       " '000969.XSHE',\n",
       " '000970.XSHE',\n",
       " '000971.XSHE',\n",
       " '000972.XSHE',\n",
       " '000973.XSHE',\n",
       " '000975.XSHE',\n",
       " '000976.XSHE',\n",
       " '000977.XSHE',\n",
       " '000978.XSHE',\n",
       " '000980.XSHE',\n",
       " '000983.XSHE',\n",
       " '000985.XSHE',\n",
       " '000987.XSHE',\n",
       " '000988.XSHE',\n",
       " '000989.XSHE',\n",
       " '000990.XSHE',\n",
       " '000993.XSHE',\n",
       " '000995.XSHE',\n",
       " '000996.XSHE',\n",
       " '000997.XSHE',\n",
       " '000998.XSHE',\n",
       " '000999.XSHE',\n",
       " '001696.XSHE',\n",
       " '001872.XSHE',\n",
       " '001896.XSHE',\n",
       " '002001.XSHE',\n",
       " '002002.XSHE',\n",
       " '002003.XSHE',\n",
       " '002004.XSHE',\n",
       " '002005.XSHE',\n",
       " '002006.XSHE',\n",
       " '002007.XSHE',\n",
       " '002008.XSHE',\n",
       " '002009.XSHE',\n",
       " '002010.XSHE',\n",
       " '002011.XSHE',\n",
       " '002012.XSHE',\n",
       " '002013.XSHE',\n",
       " '002014.XSHE',\n",
       " '002016.XSHE',\n",
       " '002017.XSHE',\n",
       " '002018.XSHE',\n",
       " '002019.XSHE',\n",
       " '002020.XSHE',\n",
       " '002021.XSHE',\n",
       " '002022.XSHE',\n",
       " '002023.XSHE',\n",
       " '002024.XSHE',\n",
       " '002025.XSHE',\n",
       " '002026.XSHE',\n",
       " '002027.XSHE',\n",
       " '002028.XSHE',\n",
       " '002029.XSHE',\n",
       " '002030.XSHE',\n",
       " '002031.XSHE',\n",
       " '002032.XSHE',\n",
       " '002033.XSHE',\n",
       " '002034.XSHE',\n",
       " '002035.XSHE',\n",
       " '002036.XSHE',\n",
       " '002037.XSHE',\n",
       " '002038.XSHE',\n",
       " '002039.XSHE',\n",
       " '002040.XSHE',\n",
       " '002041.XSHE',\n",
       " '002042.XSHE',\n",
       " '002043.XSHE',\n",
       " '002044.XSHE',\n",
       " '002045.XSHE',\n",
       " '002046.XSHE',\n",
       " '002047.XSHE',\n",
       " '002048.XSHE',\n",
       " '002049.XSHE',\n",
       " '002050.XSHE',\n",
       " '002051.XSHE',\n",
       " '002052.XSHE',\n",
       " '002053.XSHE',\n",
       " '002054.XSHE',\n",
       " '002055.XSHE',\n",
       " '002056.XSHE',\n",
       " '002057.XSHE',\n",
       " '002058.XSHE',\n",
       " '002059.XSHE',\n",
       " '002060.XSHE',\n",
       " '002061.XSHE',\n",
       " '002062.XSHE',\n",
       " '002063.XSHE',\n",
       " '002064.XSHE',\n",
       " '002065.XSHE',\n",
       " '002066.XSHE',\n",
       " '002067.XSHE',\n",
       " '002068.XSHE',\n",
       " '002069.XSHE',\n",
       " '002071.XSHE',\n",
       " '002073.XSHE',\n",
       " '002074.XSHE',\n",
       " '002076.XSHE',\n",
       " '002077.XSHE',\n",
       " '002078.XSHE',\n",
       " '002079.XSHE',\n",
       " '002080.XSHE',\n",
       " '002081.XSHE',\n",
       " '002082.XSHE',\n",
       " '002083.XSHE',\n",
       " '002084.XSHE',\n",
       " '002085.XSHE',\n",
       " '002086.XSHE',\n",
       " '002087.XSHE',\n",
       " '002088.XSHE',\n",
       " '002089.XSHE',\n",
       " '002090.XSHE',\n",
       " '002091.XSHE',\n",
       " '002092.XSHE',\n",
       " '002093.XSHE',\n",
       " '002094.XSHE',\n",
       " '002095.XSHE',\n",
       " '002096.XSHE',\n",
       " '002097.XSHE',\n",
       " '002098.XSHE',\n",
       " '002099.XSHE',\n",
       " '002100.XSHE',\n",
       " '002101.XSHE',\n",
       " '002102.XSHE',\n",
       " '002103.XSHE',\n",
       " '002104.XSHE',\n",
       " '002105.XSHE',\n",
       " '002106.XSHE',\n",
       " '002107.XSHE',\n",
       " '002108.XSHE',\n",
       " '002109.XSHE',\n",
       " '002110.XSHE',\n",
       " '002111.XSHE',\n",
       " '002112.XSHE',\n",
       " '002114.XSHE',\n",
       " '002115.XSHE',\n",
       " '002116.XSHE',\n",
       " '002117.XSHE',\n",
       " '002118.XSHE',\n",
       " '002119.XSHE',\n",
       " '002120.XSHE',\n",
       " '002121.XSHE',\n",
       " '002122.XSHE',\n",
       " '002123.XSHE',\n",
       " '002124.XSHE',\n",
       " '002125.XSHE',\n",
       " '002126.XSHE',\n",
       " '002127.XSHE',\n",
       " '002128.XSHE',\n",
       " '002130.XSHE',\n",
       " '002131.XSHE',\n",
       " '002132.XSHE',\n",
       " '002133.XSHE',\n",
       " '002134.XSHE',\n",
       " '002135.XSHE',\n",
       " '002136.XSHE',\n",
       " '002137.XSHE',\n",
       " '002138.XSHE',\n",
       " '002139.XSHE',\n",
       " '002140.XSHE',\n",
       " '002141.XSHE',\n",
       " '002142.XSHE',\n",
       " '002143.XSHE',\n",
       " '002144.XSHE',\n",
       " '002145.XSHE',\n",
       " '002146.XSHE',\n",
       " '002147.XSHE',\n",
       " '002148.XSHE',\n",
       " '002149.XSHE',\n",
       " '002150.XSHE',\n",
       " '002151.XSHE',\n",
       " '002152.XSHE',\n",
       " '002153.XSHE',\n",
       " '002154.XSHE',\n",
       " '002155.XSHE',\n",
       " '002156.XSHE',\n",
       " '002157.XSHE',\n",
       " '002158.XSHE',\n",
       " '002159.XSHE',\n",
       " '002160.XSHE',\n",
       " '002161.XSHE',\n",
       " '002162.XSHE',\n",
       " '002163.XSHE',\n",
       " '002164.XSHE',\n",
       " '002165.XSHE',\n",
       " '002166.XSHE',\n",
       " '002167.XSHE',\n",
       " '002168.XSHE',\n",
       " '002169.XSHE',\n",
       " '002170.XSHE',\n",
       " '002171.XSHE',\n",
       " '002172.XSHE',\n",
       " '002173.XSHE',\n",
       " '002174.XSHE',\n",
       " '002175.XSHE',\n",
       " '002176.XSHE',\n",
       " '002177.XSHE',\n",
       " '002178.XSHE',\n",
       " '002179.XSHE',\n",
       " '002180.XSHE',\n",
       " '002181.XSHE',\n",
       " '002182.XSHE',\n",
       " '002183.XSHE',\n",
       " '002184.XSHE',\n",
       " '002185.XSHE',\n",
       " '002186.XSHE',\n",
       " '002187.XSHE',\n",
       " '002188.XSHE',\n",
       " '002189.XSHE',\n",
       " '002190.XSHE',\n",
       " '002191.XSHE',\n",
       " '002192.XSHE',\n",
       " '002193.XSHE',\n",
       " '002194.XSHE',\n",
       " '002195.XSHE',\n",
       " '002196.XSHE',\n",
       " '002197.XSHE',\n",
       " '002198.XSHE',\n",
       " '002199.XSHE',\n",
       " '002200.XSHE',\n",
       " '002201.XSHE',\n",
       " '002202.XSHE',\n",
       " '002203.XSHE',\n",
       " '002204.XSHE',\n",
       " '002205.XSHE',\n",
       " '002206.XSHE',\n",
       " '002207.XSHE',\n",
       " '002208.XSHE',\n",
       " '002209.XSHE',\n",
       " '002210.XSHE',\n",
       " '002211.XSHE',\n",
       " '002212.XSHE',\n",
       " '002213.XSHE',\n",
       " '002214.XSHE',\n",
       " '002215.XSHE',\n",
       " '002216.XSHE',\n",
       " '002217.XSHE',\n",
       " '002218.XSHE',\n",
       " '002220.XSHE',\n",
       " '002221.XSHE',\n",
       " '002222.XSHE',\n",
       " '002223.XSHE',\n",
       " '002224.XSHE',\n",
       " '002225.XSHE',\n",
       " '002226.XSHE',\n",
       " '002227.XSHE',\n",
       " '002228.XSHE',\n",
       " '002229.XSHE',\n",
       " '002230.XSHE',\n",
       " '002231.XSHE',\n",
       " '002232.XSHE',\n",
       " '002233.XSHE',\n",
       " '002234.XSHE',\n",
       " '002235.XSHE',\n",
       " '002236.XSHE',\n",
       " '002237.XSHE',\n",
       " '002238.XSHE',\n",
       " '002240.XSHE',\n",
       " '002241.XSHE',\n",
       " '002242.XSHE',\n",
       " '002243.XSHE',\n",
       " '002244.XSHE',\n",
       " '002245.XSHE',\n",
       " '002246.XSHE',\n",
       " '002247.XSHE',\n",
       " '002248.XSHE',\n",
       " '002249.XSHE',\n",
       " '002250.XSHE',\n",
       " '002251.XSHE',\n",
       " '002253.XSHE',\n",
       " '002254.XSHE',\n",
       " '002255.XSHE',\n",
       " '002258.XSHE',\n",
       " '002259.XSHE',\n",
       " '002260.XSHE',\n",
       " '002261.XSHE',\n",
       " '002262.XSHE',\n",
       " '002264.XSHE',\n",
       " '002265.XSHE',\n",
       " '002266.XSHE',\n",
       " '002267.XSHE',\n",
       " '002268.XSHE',\n",
       " '002269.XSHE',\n",
       " '002270.XSHE',\n",
       " '002271.XSHE',\n",
       " '002272.XSHE',\n",
       " '002273.XSHE',\n",
       " '002274.XSHE',\n",
       " '002275.XSHE',\n",
       " '002276.XSHE',\n",
       " '002277.XSHE',\n",
       " '002278.XSHE',\n",
       " '002279.XSHE',\n",
       " '002280.XSHE',\n",
       " '002281.XSHE',\n",
       " '002282.XSHE',\n",
       " '002283.XSHE',\n",
       " '002284.XSHE',\n",
       " '002285.XSHE',\n",
       " '002286.XSHE',\n",
       " '002287.XSHE',\n",
       " '002288.XSHE',\n",
       " '002289.XSHE',\n",
       " '002290.XSHE',\n",
       " '002291.XSHE',\n",
       " '002292.XSHE',\n",
       " '002293.XSHE',\n",
       " '002294.XSHE',\n",
       " '002295.XSHE',\n",
       " '002296.XSHE',\n",
       " '002297.XSHE',\n",
       " '002298.XSHE',\n",
       " '002299.XSHE',\n",
       " '002300.XSHE',\n",
       " '002301.XSHE',\n",
       " '002302.XSHE',\n",
       " '002303.XSHE',\n",
       " '002304.XSHE',\n",
       " '002305.XSHE',\n",
       " '002306.XSHE',\n",
       " '002307.XSHE',\n",
       " '002308.XSHE',\n",
       " '002309.XSHE',\n",
       " '002310.XSHE',\n",
       " '002311.XSHE',\n",
       " '002312.XSHE',\n",
       " '002313.XSHE',\n",
       " '002314.XSHE',\n",
       " '002315.XSHE',\n",
       " '002316.XSHE',\n",
       " '002317.XSHE',\n",
       " '002318.XSHE',\n",
       " '002319.XSHE',\n",
       " '002320.XSHE',\n",
       " '002321.XSHE',\n",
       " '002322.XSHE',\n",
       " '002323.XSHE',\n",
       " '002324.XSHE',\n",
       " '002325.XSHE',\n",
       " '002326.XSHE',\n",
       " '002327.XSHE',\n",
       " '002328.XSHE',\n",
       " '002329.XSHE',\n",
       " '002330.XSHE',\n",
       " '002331.XSHE',\n",
       " '002332.XSHE',\n",
       " '002333.XSHE',\n",
       " '002334.XSHE',\n",
       " '002335.XSHE',\n",
       " '002336.XSHE',\n",
       " '002337.XSHE',\n",
       " '002338.XSHE',\n",
       " '002339.XSHE',\n",
       " '002340.XSHE',\n",
       " '002341.XSHE',\n",
       " '002342.XSHE',\n",
       " '002343.XSHE',\n",
       " '002344.XSHE',\n",
       " '002345.XSHE',\n",
       " '002346.XSHE',\n",
       " '002347.XSHE',\n",
       " '002348.XSHE',\n",
       " '002349.XSHE',\n",
       " '002350.XSHE',\n",
       " '002351.XSHE',\n",
       " '002352.XSHE',\n",
       " '002353.XSHE',\n",
       " '002354.XSHE',\n",
       " '002355.XSHE',\n",
       " '002356.XSHE',\n",
       " '002357.XSHE',\n",
       " '002358.XSHE',\n",
       " '002359.XSHE',\n",
       " '002360.XSHE',\n",
       " '002361.XSHE',\n",
       " '002362.XSHE',\n",
       " '002363.XSHE',\n",
       " '002364.XSHE',\n",
       " '002365.XSHE',\n",
       " '002366.XSHE',\n",
       " '002367.XSHE',\n",
       " '002368.XSHE',\n",
       " '002369.XSHE',\n",
       " '002370.XSHE',\n",
       " '002371.XSHE',\n",
       " '002372.XSHE',\n",
       " '002373.XSHE',\n",
       " '002374.XSHE',\n",
       " '002375.XSHE',\n",
       " '002376.XSHE',\n",
       " '002377.XSHE',\n",
       " '002378.XSHE',\n",
       " '002379.XSHE',\n",
       " '002380.XSHE',\n",
       " '002381.XSHE',\n",
       " '002382.XSHE',\n",
       " '002383.XSHE',\n",
       " '002384.XSHE',\n",
       " '002385.XSHE',\n",
       " '002386.XSHE',\n",
       " '002387.XSHE',\n",
       " '002388.XSHE',\n",
       " '002389.XSHE',\n",
       " '002390.XSHE',\n",
       " '002391.XSHE',\n",
       " '002392.XSHE',\n",
       " '002393.XSHE',\n",
       " '002394.XSHE',\n",
       " '002395.XSHE',\n",
       " '002396.XSHE',\n",
       " '002397.XSHE',\n",
       " '002398.XSHE',\n",
       " '002399.XSHE',\n",
       " '002400.XSHE',\n",
       " '002401.XSHE',\n",
       " '002402.XSHE',\n",
       " '002403.XSHE',\n",
       " '002404.XSHE',\n",
       " '002405.XSHE',\n",
       " '002406.XSHE',\n",
       " '002407.XSHE',\n",
       " '002408.XSHE',\n",
       " '002409.XSHE',\n",
       " '002410.XSHE',\n",
       " '002411.XSHE',\n",
       " '002412.XSHE',\n",
       " '002413.XSHE',\n",
       " '002414.XSHE',\n",
       " '002415.XSHE',\n",
       " '002416.XSHE',\n",
       " '002417.XSHE',\n",
       " '002418.XSHE',\n",
       " '002419.XSHE',\n",
       " '002420.XSHE',\n",
       " '002421.XSHE',\n",
       " '002422.XSHE',\n",
       " '002423.XSHE',\n",
       " '002424.XSHE',\n",
       " '002425.XSHE',\n",
       " '002426.XSHE',\n",
       " '002427.XSHE',\n",
       " '002428.XSHE',\n",
       " '002429.XSHE',\n",
       " '002430.XSHE',\n",
       " '002431.XSHE',\n",
       " '002432.XSHE',\n",
       " '002433.XSHE',\n",
       " '002434.XSHE',\n",
       " '002435.XSHE',\n",
       " '002436.XSHE',\n",
       " '002437.XSHE',\n",
       " '002438.XSHE',\n",
       " '002439.XSHE',\n",
       " '002440.XSHE',\n",
       " '002441.XSHE',\n",
       " '002442.XSHE',\n",
       " '002443.XSHE',\n",
       " '002444.XSHE',\n",
       " '002445.XSHE',\n",
       " '002446.XSHE',\n",
       " '002447.XSHE',\n",
       " '002448.XSHE',\n",
       " '002449.XSHE',\n",
       " '002450.XSHE',\n",
       " '002451.XSHE',\n",
       " '002452.XSHE',\n",
       " '002453.XSHE',\n",
       " '002454.XSHE',\n",
       " '002455.XSHE',\n",
       " '002456.XSHE',\n",
       " '002457.XSHE',\n",
       " '002458.XSHE',\n",
       " '002459.XSHE',\n",
       " '002460.XSHE',\n",
       " '002461.XSHE',\n",
       " '002462.XSHE',\n",
       " '002463.XSHE',\n",
       " '002465.XSHE',\n",
       " '002466.XSHE',\n",
       " '002467.XSHE',\n",
       " '002468.XSHE',\n",
       " '002469.XSHE',\n",
       " '002470.XSHE',\n",
       " '002471.XSHE',\n",
       " '002472.XSHE',\n",
       " '002473.XSHE',\n",
       " '002474.XSHE',\n",
       " '002475.XSHE',\n",
       " '002476.XSHE',\n",
       " '002477.XSHE',\n",
       " '002478.XSHE',\n",
       " '002479.XSHE',\n",
       " '002480.XSHE',\n",
       " '002481.XSHE',\n",
       " '002482.XSHE',\n",
       " '002483.XSHE',\n",
       " '002484.XSHE',\n",
       " '002485.XSHE',\n",
       " '002486.XSHE',\n",
       " '002487.XSHE',\n",
       " '002488.XSHE',\n",
       " '002489.XSHE',\n",
       " '002490.XSHE',\n",
       " '002491.XSHE',\n",
       " '002492.XSHE',\n",
       " '002493.XSHE',\n",
       " '002494.XSHE',\n",
       " '002495.XSHE',\n",
       " '002496.XSHE',\n",
       " '002497.XSHE',\n",
       " '002498.XSHE',\n",
       " '002499.XSHE',\n",
       " '002500.XSHE',\n",
       " '002501.XSHE',\n",
       " '002502.XSHE',\n",
       " '002503.XSHE',\n",
       " '002504.XSHE',\n",
       " '002505.XSHE',\n",
       " '002507.XSHE',\n",
       " '002508.XSHE',\n",
       " '002510.XSHE',\n",
       " '002511.XSHE',\n",
       " '002512.XSHE',\n",
       " '002513.XSHE',\n",
       " '002514.XSHE',\n",
       " '002515.XSHE',\n",
       " '002516.XSHE',\n",
       " '002517.XSHE',\n",
       " '002518.XSHE',\n",
       " '002519.XSHE',\n",
       " '002520.XSHE',\n",
       " '002521.XSHE',\n",
       " '002522.XSHE',\n",
       " '002523.XSHE',\n",
       " '002524.XSHE',\n",
       " '002526.XSHE',\n",
       " '002527.XSHE',\n",
       " '002528.XSHE',\n",
       " '002529.XSHE',\n",
       " '002530.XSHE',\n",
       " '002531.XSHE',\n",
       " '002532.XSHE',\n",
       " '002533.XSHE',\n",
       " '300001.XSHE',\n",
       " '300002.XSHE',\n",
       " '300003.XSHE',\n",
       " '300004.XSHE',\n",
       " '300005.XSHE',\n",
       " '300006.XSHE',\n",
       " '300007.XSHE',\n",
       " '300008.XSHE',\n",
       " '300009.XSHE',\n",
       " '300010.XSHE',\n",
       " '300011.XSHE',\n",
       " '300012.XSHE',\n",
       " '300013.XSHE',\n",
       " '300014.XSHE',\n",
       " '300015.XSHE',\n",
       " '300016.XSHE',\n",
       " '300017.XSHE',\n",
       " '300018.XSHE',\n",
       " '300019.XSHE',\n",
       " '300020.XSHE',\n",
       " '300021.XSHE',\n",
       " '300022.XSHE',\n",
       " '300023.XSHE',\n",
       " '300024.XSHE',\n",
       " '300025.XSHE',\n",
       " '300026.XSHE',\n",
       " '300027.XSHE',\n",
       " '300029.XSHE',\n",
       " '300030.XSHE',\n",
       " '300031.XSHE',\n",
       " '300032.XSHE',\n",
       " '300033.XSHE',\n",
       " '300034.XSHE',\n",
       " '300035.XSHE',\n",
       " '300036.XSHE',\n",
       " '300037.XSHE',\n",
       " '300038.XSHE',\n",
       " '300039.XSHE',\n",
       " '300040.XSHE',\n",
       " '300041.XSHE',\n",
       " '300042.XSHE',\n",
       " '300043.XSHE',\n",
       " '300044.XSHE',\n",
       " '300045.XSHE',\n",
       " '300046.XSHE',\n",
       " '300047.XSHE',\n",
       " '300048.XSHE',\n",
       " '300049.XSHE',\n",
       " '300050.XSHE',\n",
       " '300051.XSHE',\n",
       " '300052.XSHE',\n",
       " '300053.XSHE',\n",
       " '300054.XSHE',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_download_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 对于某一投资组合 bin2 计算所有收益率序列\n",
    "address = 'E:/Stock_Data/stock_return_data/'\n",
    "bin2s = ['B_M','OP','Inv','Size']\n",
    "return_inf_used_stock = list(pd.read_csv('E:/Stock_Data/return_inf_used_stock.csv').iloc[:,0])\n",
    "stock_download_return_temp = os.listdir('E:/Stock_Data/stock_return_data/')\n",
    "stock_download_return = [x[:-4] for x in stock_download_return_temp]\n",
    "\n",
    "## 第一层，分组依据\n",
    "for bin2 in bin2s:\n",
    "    portfolio_0 = portfolio[bin2]\n",
    "    \n",
    "    ## 第二层，不同年份\n",
    "    for i in range(8):\n",
    "        year = str(2011+i)\n",
    "        portfolio_1 = portfolio_0[year]\n",
    "        cnt_bin = 0\n",
    "        \n",
    "        ## 第三层，不同小组\n",
    "        for bin1_bin2_type in portfolio_1.keys():\n",
    "            cnt = 0\n",
    "            tol_weight = 0\n",
    "            portfolio_2 = portfolio_1[bin1_bin2_type]\n",
    "            for code_weight in portfolio_2:\n",
    "                \n",
    "                code = code_weight[0]\n",
    "                weight = code_weight[1]\n",
    "                \n",
    "                # 股票由于停牌时间过长被剔除\n",
    "                if code not in stock_download_return:\n",
    "                    continue\n",
    "                \n",
    "                file_name = address+code+'.csv'\n",
    "                r = pd.read_csv(file_name,index_col=0)\n",
    "                \n",
    "                # 读取到的序列过短，剔除\n",
    "                if len(r)<1943:\n",
    "                    continue\n",
    "                \n",
    "                if cnt == 0:\n",
    "                    r_sigma = r*weight\n",
    "                else:\n",
    "                    r_sigma = r_sigma+r*weight\n",
    "                \n",
    "                tol_weight += weight       \n",
    "                cnt+=1  \n",
    "            \n",
    "            ### 求加权平均数，得到一小组的收益率序列\n",
    "            r_mean = r_sigma/tol_weight\n",
    "            r_mean.columns = [bin1_bin2_type]\n",
    "            if cnt_bin == 0:\n",
    "                r_save = r_mean\n",
    "            else:\n",
    "                r_save = pd.concat([r_save,r_mean],axis=1)\n",
    "            cnt_bin += 1\n",
    "        ### 删选当年的数据\n",
    "        r_save_0 = r_save[r_save.index< str(int(year)+1)+'-01-01']\n",
    "        r_save_1 = r_save_0[r_save_0.index> str(int(year)-1)+'-12-31']\n",
    "        ### 每一年拼接\n",
    "        if i == 0:\n",
    "            r_save_year = r_save_1\n",
    "        else:\n",
    "            r_save_year = pd.concat([r_save_year,r_save_1],axis=0)\n",
    "    \n",
    "    ### 完成一个大组的每一年计算后，保存\n",
    "    r_save_year.to_csv('E:/Stock_Data/factor_portfolio/'+bin2+'.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因子计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMB small minus big - Size\n",
    "Size = pd.read_csv('E:/Stock_Data/factor_portfolio/Size.csv',index_col=0).iloc[:1943,:]\n",
    "SMB = Size['Size1'] - Size['Size2']\n",
    "SMB = pd.DataFrame(SMB,columns=['SMB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HML high minus low - B_M\n",
    "B_M = pd.read_csv('E:/Stock_Data/factor_portfolio/B_M.csv',index_col=0).iloc[:1943,:]\n",
    "HML = B_M['B_M3'] - B_M['B_M1']\n",
    "HML = pd.DataFrame(HML,columns=['HML'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMW robust minus weak - OP\n",
    "OP = pd.read_csv('E:/Stock_Data/factor_portfolio/OP.csv',index_col=0).iloc[:1943,:]\n",
    "RMW = OP['OP3'] - OP['OP1']\n",
    "RMW.columns = ['RMW']\n",
    "RMW = pd.DataFrame(RMW,columns=['RMW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMA conservative minus aggressive - Inv\n",
    "Inv = pd.read_csv('E:/Stock_Data/factor_portfolio/Inv.csv',index_col=0).iloc[:1943,:]\n",
    "CMA = Inv['Inv1'] - Inv['Inv3']\n",
    "CMA = pd.DataFrame(CMA,columns=['CMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# market risk，读取投资组合，选取一个标准的全部样本（全样本），计算加权均值，即 Rm\n",
    "\n",
    "# 读取字典\n",
    "f = open('E:/Stock_Data/factor_portfolio/portfolio.txt','r')\n",
    "a = f.read()\n",
    "portfolio = eval(a)\n",
    "f.close()\n",
    "portfolio_0 = portfolio['Size']\n",
    "## 第二层，不同年份\n",
    "for i in range(8):\n",
    "    year = str(2011+i)\n",
    "    portfolio_1 = portfolio_0[year]\n",
    "    tol_weight = 0 # 把总权重放置年份后，对每小组不再单独求和，即Size1+Size2=全股票\n",
    "    cnt = 0 # 进对每一年清零计数\n",
    "\n",
    "    ## 第三层，不同小组\n",
    "    for bin1_bin2_type in portfolio_1.keys():\n",
    "\n",
    "\n",
    "        portfolio_2 = portfolio_1[bin1_bin2_type]\n",
    "        for code_weight in portfolio_2:\n",
    "\n",
    "            code = code_weight[0]\n",
    "            weight = code_weight[1]\n",
    "\n",
    "            # 股票由于停牌时间过长被剔除\n",
    "            if code not in stock_download_return:\n",
    "                continue\n",
    "\n",
    "            file_name = address+code+'.csv'\n",
    "            r = pd.read_csv(file_name,index_col=0)\n",
    "\n",
    "            # 读取到的序列过短，剔除\n",
    "            if len(r)<1943:\n",
    "                continue\n",
    "\n",
    "            if cnt == 0:\n",
    "                r_sigma = r*weight\n",
    "            else:\n",
    "                r_sigma = r_sigma+r*weight\n",
    "\n",
    "            tol_weight += weight       \n",
    "            cnt+=1  \n",
    "\n",
    "    ### 求加权平均数，得到一年的收益率序列\n",
    "    r_mean = r_sigma/tol_weight\n",
    "    r_save = r_mean\n",
    "\n",
    "    ### 删选当年的数据\n",
    "    r_save_0 = r_save[r_save.index< str(int(year)+1)+'-01-01']\n",
    "    r_save_1 = r_save_0[r_save_0.index> str(int(year)-1)+'-12-31']\n",
    "    ### 每一年拼接\n",
    "    if i == 0:\n",
    "        r_save_year = r_save_1\n",
    "    else:\n",
    "        r_save_year = pd.concat([r_save_year,r_save_1],axis=0)\n",
    "\n",
    "### 完成一个大组的每一年计算后，保存\n",
    "r_save_year.columns = ['return']\n",
    "r_save_year.to_csv('E:/Stock_Data/factor_portfolio/MarketRisk.csv',index=True)\n",
    "\n",
    "MKT = r_save_year.iloc[:1943,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rf\n",
    "import re\n",
    "rf_temp_0 = pd.read_csv('E:/Stock_Data/t_bill_one_year.csv')[['日期','收盘']]\n",
    "rf_temp_0.index = rf_temp_0['日期'].apply(lambda x: x[:4]+'-'+re.findall('(.*?)年(.*?)月(.*?)日',x)[0][1].zfill(2)+'-'+re.findall('(.*?)年(.*?)月(.*?)日',x)[0][2].zfill(2))\n",
    "rf_temp_1 = pd.merge(left = MKT,right = rf_temp_0,left_index = True,right_index=True,how='left')[['收盘']]\n",
    "rf_temp_2 = rf_temp_1.fillna(rf_temp_1.mean())\n",
    "rf_temp_2.columns = ['return']\n",
    "rf = rf_temp_2/252/100\n",
    "rf.to_csv('E:/Stock_Data/rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MKTF\n",
    "MKTF = MKT - rf\n",
    "MKTF.columns = ['MKTF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入日历效应哑变量 - 星期\n",
    "sample_df = pd.read_csv('E:/Stock_Data/stock_return_data/001896.XSHE.csv',index_col=0)\n",
    "trade_day_serises = list(sample_df.index)\n",
    "\n",
    "trade_day_df = pd.DataFrame(trade_day_serises)\n",
    "trade_day_df.columns = ['weekday']\n",
    "trade_day_df['weekday'] = trade_day_df['weekday'].apply(lambda x : datetime.datetime.strptime(x, \"%Y-%m-%d\").weekday()+1)\n",
    "\n",
    "dummy_df = pd.get_dummies(trade_day_df['weekday'])\n",
    "dummy_df = dummy_df[[1,2,3,4,5]]\n",
    "dummy_df.index = sample_df.index\n",
    "\n",
    "X = dummy_df.iloc[:1943,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   MKTF   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     1.992\n",
      "Date:                Wed, 10 Apr 2019   Prob (F-statistic):             0.0932\n",
      "Time:                        23:27:37   Log-Likelihood:                 5590.7\n",
      "No. Observations:                1943   AIC:                        -1.117e+04\n",
      "Df Residuals:                    1938   BIC:                        -1.114e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "1             -0.0005      0.001     -0.689      0.491      -0.002       0.001\n",
      "2              0.0005      0.001      0.677      0.499      -0.001       0.002\n",
      "3           9.928e-05      0.001      0.145      0.885      -0.001       0.001\n",
      "4             -0.0018      0.001     -2.566      0.010      -0.003      -0.000\n",
      "5              0.0006      0.001      0.936      0.349      -0.001       0.002\n",
      "==============================================================================\n",
      "Omnibus:                      488.205   Durbin-Watson:                   1.950\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3897.035\n",
      "Skew:                          -0.954   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.671   Cond. No.                         1.03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    SMB   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     1.434\n",
      "Date:                Wed, 10 Apr 2019   Prob (F-statistic):              0.220\n",
      "Time:                        23:27:37   Log-Likelihood:                 5935.6\n",
      "No. Observations:                1943   AIC:                        -1.186e+04\n",
      "Df Residuals:                    1938   BIC:                        -1.183e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "1          -5.564e-05      0.001     -0.094      0.925      -0.001       0.001\n",
      "2              0.0006      0.001      1.109      0.268      -0.000       0.002\n",
      "3              0.0008      0.001      1.333      0.183      -0.000       0.002\n",
      "4             -0.0008      0.001     -1.323      0.186      -0.002       0.000\n",
      "5             -0.0006      0.001     -0.986      0.324      -0.002       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      769.393   Durbin-Watson:                   1.614\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9576.925\n",
      "Skew:                          -1.505   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.451   Cond. No.                         1.03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    HML   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     1.297\n",
      "Date:                Wed, 10 Apr 2019   Prob (F-statistic):              0.269\n",
      "Time:                        23:27:37   Log-Likelihood:                 5928.3\n",
      "No. Observations:                1943   AIC:                        -1.185e+04\n",
      "Df Residuals:                    1938   BIC:                        -1.182e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "1              0.0009      0.001      1.542      0.123      -0.000       0.002\n",
      "2             -0.0002      0.001     -0.395      0.693      -0.001       0.001\n",
      "3          -3.852e-05      0.001     -0.067      0.947      -0.001       0.001\n",
      "4              0.0012      0.001      2.068      0.039    6.16e-05       0.002\n",
      "5              0.0010      0.001      1.799      0.072    -9.4e-05       0.002\n",
      "==============================================================================\n",
      "Omnibus:                      525.917   Durbin-Watson:                   1.691\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3690.044\n",
      "Skew:                           1.084   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.394   Cond. No.                         1.03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    CMA   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     1.611\n",
      "Date:                Wed, 10 Apr 2019   Prob (F-statistic):              0.169\n",
      "Time:                        23:27:37   Log-Likelihood:                 7350.4\n",
      "No. Observations:                1943   AIC:                        -1.469e+04\n",
      "Df Residuals:                    1938   BIC:                        -1.466e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "1              0.0006      0.000      2.087      0.037    3.58e-05       0.001\n",
      "2             -0.0003      0.000     -0.994      0.320      -0.001       0.000\n",
      "3              0.0003      0.000      0.914      0.361      -0.000       0.001\n",
      "4           7.669e-05      0.000      0.275      0.783      -0.000       0.001\n",
      "5             -0.0002      0.000     -0.787      0.431      -0.001       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      211.077   Durbin-Watson:                   1.969\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1651.994\n",
      "Skew:                           0.156   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.506   Cond. No.                         1.03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    RMW   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     1.621\n",
      "Date:                Wed, 10 Apr 2019   Prob (F-statistic):              0.166\n",
      "Time:                        23:27:37   Log-Likelihood:                 6092.1\n",
      "No. Observations:                1943   AIC:                        -1.217e+04\n",
      "Df Residuals:                    1938   BIC:                        -1.215e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "1             -0.0003      0.001     -0.601      0.548      -0.001       0.001\n",
      "2           8.229e-05      0.001      0.154      0.877      -0.001       0.001\n",
      "3             -0.0003      0.001     -0.548      0.584      -0.001       0.001\n",
      "4              0.0011      0.001      2.153      0.031       0.000       0.002\n",
      "5              0.0009      0.001      1.667      0.096      -0.000       0.002\n",
      "==============================================================================\n",
      "Omnibus:                      824.588   Durbin-Watson:                   1.659\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            13882.655\n",
      "Skew:                           1.550   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.723   Cond. No.                         1.03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 检验各因子的周四效应\n",
    "\n",
    "for factor in [MKTF,SMB,HML,CMA,RMW]:\n",
    "    y = factor\n",
    "\n",
    "    est = sm.OLS(y,X)\n",
    "    result = est.fit()\n",
    "    print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依照回归结果分组，B_M以及OP单独分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成分组标识\n",
    "bin_df = pd.read_csv('E:/Stock_Data/bin_data.csv',index_col=0)\n",
    "for col in ['B_M', 'OP','pe_ratio']:\n",
    "    if isinstance(bin_df[col][0],float):\n",
    "        bin_df[col] = bin_df[col].apply(lambda x : np.nan if x<0 else x)\n",
    "bin_df = bin_df.dropna(how='any',axis=0)\n",
    "\n",
    "## 分组组数\n",
    "bin_num = 8\n",
    "\n",
    "for i in range(8):\n",
    "    \n",
    "    year = str(2010+i)+'-12-31'\n",
    "    temp_df_0 = bin_df[bin_df.date==year]\n",
    "    \n",
    "    # 计算当年总行数\n",
    "    stock_num = len(temp_df_0)\n",
    "    \n",
    "    for bin_kind in ['B_M','OP']:\n",
    "        \n",
    "        # 生成分组标识\n",
    "        bin_lst = []\n",
    "        for i in range(bin_num):\n",
    "            bin_lst += [bin_kind+str(i+1)]*int(stock_num/bin_num)\n",
    "        if len(bin_lst) != stock_num:\n",
    "            bin_lst += [bin_kind+str(i+1)]*(stock_num-len(bin_lst))\n",
    "        \n",
    "        temp_df_0 = temp_df_0.sort_values(bin_kind)\n",
    "        temp_df_0[bin_kind] = bin_lst\n",
    "    \n",
    "    temp_df_1 = bin_df[bin_df.date==year]\n",
    "    temp_df_1 = temp_df_1.sort_values('OP') # 和df_0对齐，最后一次是按照Size排序的\n",
    "    temp_df_0['S']=temp_df_1['Size']\n",
    "    temp_df_0.to_csv('E:/Stock_Data/factor_portfolio/B_M&OP'+year+'.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按要求生成投资组合\n",
    "\n",
    "# 保存在字典：除B_M以外的另一个组别 -> 年份 -> bin1 与 bin2 单独！ -> 组合，stock code list\n",
    "\n",
    "portfolio={}\n",
    "\n",
    "for bin2 in ['B_M','OP']:\n",
    "    portfolio[bin2] = {}\n",
    "    \n",
    "    for i in range(8):\n",
    "        year = str(2010+i)+'-12-31'\n",
    "        portfolio[bin2][str(2011+i)]={}\n",
    "        \n",
    "        temp_df_0 = pd.read_csv('E:/Stock_Data/factor_portfolio/B_M&OP'+year+'.csv',index_col=0)\n",
    "        bin2_lst = list(set(temp_df_0[bin2]))\n",
    "        \n",
    "        for bin2_ in bin2_lst:  \n",
    "            temp_df_2 = temp_df_0[temp_df_0[bin2]==bin2_]\n",
    "            list_code_value = [list(temp_df_2[['code','S']].iloc[i,:]) for i in range(len(temp_df_2))]\n",
    "            portfolio[bin2][str(2011+i)][bin2_] = list_code_value\n",
    "# 保存字典\n",
    "f = open('E:/Stock_Data/factor_portfolio/B_M_OPportfolio.txt','w')\n",
    "f.write(str(portfolio))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取字典\n",
    "f = open('E:/Stock_Data/factor_portfolio/B_M_OPportfolio.txt','r')\n",
    "a = f.read()\n",
    "portfolio = eval(a)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 对于某一投资组合 bin2 计算所有收益率序列\n",
    "address = 'E:/Stock_Data/stock_return_data/'\n",
    "\n",
    "bin2s = ['B_M','OP']\n",
    "return_inf_used_stock = list(pd.read_csv('E:/Stock_Data/return_inf_used_stock.csv').iloc[:,0])\n",
    "\n",
    "## 第一层，分组依据\n",
    "for bin2 in bin2s:\n",
    "    portfolio_0 = portfolio[bin2]\n",
    "    \n",
    "    ## 第二层，不同年份\n",
    "    for i in range(8):\n",
    "        year = str(2011+i)\n",
    "        portfolio_1 = portfolio_0[year]\n",
    "        cnt_bin = 0\n",
    "        \n",
    "        ## 第三层，不同小组\n",
    "        for bin1_bin2_type in portfolio_1.keys():\n",
    "            cnt = 0\n",
    "            tol_weight = 0\n",
    "            portfolio_2 = portfolio_1[bin1_bin2_type]\n",
    "            for code_weight in portfolio_2:\n",
    "                \n",
    "                code = code_weight[0]\n",
    "                weight = code_weight[1]\n",
    "                \n",
    "                # 股票由于停牌时间过长被剔除\n",
    "                if code not in stock_download_return:\n",
    "                    continue\n",
    "                \n",
    "                file_name = address+code+'.csv'\n",
    "                r = pd.read_csv(file_name,index_col=0)\n",
    "                \n",
    "                # 读取到的序列过短，剔除\n",
    "                if len(r)<1943:\n",
    "                    continue\n",
    "                \n",
    "                if cnt == 0:\n",
    "                    r_sigma = r*weight\n",
    "                else:\n",
    "                    r_sigma = r_sigma+r*weight\n",
    "                \n",
    "                tol_weight += weight       \n",
    "                cnt+=1  \n",
    "            \n",
    "            ### 求加权平均数，得到一小组的收益率序列\n",
    "            r_mean = r_sigma/tol_weight\n",
    "            r_mean.columns = [bin1_bin2_type]\n",
    "            if cnt_bin == 0:\n",
    "                r_save = r_mean\n",
    "            else:\n",
    "                r_save = pd.concat([r_save,r_mean],axis=1)\n",
    "            cnt_bin += 1\n",
    "        ### 删选当年的数据\n",
    "        r_save_0 = r_save[r_save.index< str(int(year)+1)+'-01-01']\n",
    "        r_save_1 = r_save_0[r_save_0.index> str(int(year)-1)+'-12-31']\n",
    "        ### 每一年拼接\n",
    "        if i == 0:\n",
    "            r_save_year = r_save_1\n",
    "        else:\n",
    "            r_save_year = pd.concat([r_save_year,r_save_1],axis=0)\n",
    "    \n",
    "    ### 完成一个大组的每一年计算后，保存\n",
    "    r_save_year.to_csv('E:/Stock_Data/factor_portfolio/singlebin_'+bin2+'.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bin2s = ['B_M','OP']\n",
    "\n",
    "for bin2 in bin2s:\n",
    "    return_df = pd.read_csv('E:/Stock_Data/factor_portfolio/singlebin_'+bin2+'.csv',index_col=0)\n",
    "    return_df = return_df.dropna(how=\"any\",axis=0)\n",
    "    bin2_list = [bin2+str(i+1) for i in range(8)]\n",
    "    bin1_bin2_save_df = pd.DataFrame(index=[''],columns=bin2_list)\n",
    "    \n",
    "    col = 0\n",
    "    for bin2_ in bin2_list:\n",
    "        bin1_bin2_ = bin2_\n",
    "        # y减去无风险收益率\n",
    "        y_temp = return_df.iloc[:1943,:]\n",
    "        y = y_temp[bin1_bin2_]\n",
    "        X = dummy_df.iloc[:1943,:]\n",
    "\n",
    "#             # 用Garch\n",
    "#             reg = arch_model(y, x=X, mean='HARX', lags=0, vol='Garch', p=1, o=0, q=1, power=1.0, dist='ged', hold_back=None)\n",
    "#             result = reg.fit()\n",
    "\n",
    "        # 用OLS\n",
    "#             X = sm.add_constant(X)\n",
    "        est = sm.OLS(y,X)\n",
    "        result = est.fit()           \n",
    "\n",
    "        calandar_effect = list(result.params)[3]\n",
    "\n",
    "        # 测试 - 结果矩阵形式保存\n",
    "        bin1_bin2_save_df.iloc[0,col] = calandar_effect\n",
    "\n",
    "        col += 1\n",
    "    # 保存\n",
    "    bin1_bin2_save_df.to_csv('E:/Stock_Data/factor_portfolio/'+ bin2 +'3bin_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-bff556679afd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    815\u001b[0m                  **kwargs):\n\u001b[0;32m    816\u001b[0m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[1;32m--> 817\u001b[1;33m                                   hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[0;32m    818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"weights\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weights\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[1;32m--> 663\u001b[1;33m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[0;32m    664\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \"\"\"\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pinv_wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wendog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasconst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[1;32m---> 64\u001b[1;33m                                       **kwargs)\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[1;32m--> 633\u001b[1;33m                  **kwargs)\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_endog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_exog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# this has side-effects, attaches k_constant and const_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m_convert_endog_exog\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;31m#TODO: remove this when we handle dtype systematically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[0mendog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m         \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1602\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1603\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1605\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.values_from_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4682\u001b[0m                [nan,  3.]])\n\u001b[0;32m   4683\u001b[0m         \"\"\"\n\u001b[1;32m-> 4684\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4686\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_dtype_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4626\u001b[0m         \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mRetrieving\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4627\u001b[0m         \"\"\"\n\u001b[1;32m-> 4628\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4629\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4433\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4435\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4437\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   4422\u001b[0m         \"\"\"\n\u001b[0;32m   4423\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4424\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4426\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4432\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4433\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4435\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4096\u001b[0m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4097\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4098\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4099\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4103\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4104\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   5067\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5068\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[1;32m-> 5069\u001b[1;33m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[0;32m   5070\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5071\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[0;32m   5087\u001b[0m         \u001b[1;31m# combination of those slices is a slice, too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5088\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5089\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_vstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5091\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_vstack\u001b[1;34m(to_stack, dtype)\u001b[0m\n\u001b[0;32m   5133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5134\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5135\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_stack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \"\"\"\n\u001b[0;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 5因子回归 - 得系数，用以下一步回归 + 日历效应检验回归，得负周四效应（周四平均超额收益率）\n",
    "rf = pd.read_csv('E:/Stock_Data/rf.csv',index_col=0)\n",
    "\n",
    "code_lst = os.listdir('E:/Stock_Data/stock_return_data')\n",
    "result_save_dct = {1:0,2:0,3:0,4:0,5:0}\n",
    "cnt = 0\n",
    "\n",
    "f_pvalue = 0\n",
    "Thu_mean_r = []\n",
    "for code_csv in code_lst:\n",
    "    y_temp = pd.read_csv('E:/Stock_Data/stock_return_data/'+code_csv,index_col = 0)\n",
    "    if len(y_temp)<1943:\n",
    "        continue\n",
    "    y = y_temp.iloc[:1943,:]\n",
    "    X = pd.concat([MKTF,SMB,HML,CMA,RMW],axis=1)\n",
    "    \n",
    "    # 用OLS - 1\n",
    "    X = sm.add_constant(X)\n",
    "    # 是否使用超额收益率\n",
    "    y = y - rf\n",
    "\n",
    "    est = sm.OLS(y,X)\n",
    "    result = est.fit()\n",
    "    \n",
    "    Const = list(result.params)[0]\n",
    "    MKTF_beta = list(result.params)[1]\n",
    "    SMB_beta = list(result.params)[2]\n",
    "    HML_beta = list(result.params)[3]\n",
    "    CMA_beta = list(result.params)[4]\n",
    "    RMW_beta = list(result.params)[5]\n",
    "    \n",
    "    # 用OLS - 2\n",
    "    # 是否使用超额收益率\n",
    "    X = dummy_df.iloc[:1943,]\n",
    "\n",
    "    est = sm.OLS(y,X)\n",
    "    result = est.fit()\n",
    "    \n",
    "    Thu = list(result.params)[3]\n",
    "    Thu_Pvalue = list(result.pvalues)[3]\n",
    "    \n",
    "    if cnt == 0:\n",
    "        initial_df = pd.DataFrame(columns=['Code','Thu','Thu_Pvalue','C','MKTF_beta','SMB_beta','HML_beta','CMA_beta','RMW_beta'],index=range(9999))\n",
    "        initial_df.iloc[cnt,:] = [code_csv[:-4],Thu,Thu_Pvalue,Const,MKTF_beta,SMB_beta,HML_beta,CMA_beta,RMW_beta]\n",
    "    else:\n",
    "        initial_df.iloc[cnt,:] = [code_csv[:-4],Thu,Thu_Pvalue,Const,MKTF_beta,SMB_beta,HML_beta,CMA_beta,RMW_beta]\n",
    "    \n",
    "    cnt += 1\n",
    "initial_df = initial_df.dropna()\n",
    "initial_df.to_csv('E:/Stock_Data/Fama_beta_Thu.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = pd.read_csv('E:/Stock_Data/Fama_beta_Thu.csv')\n",
    "initial_df['isThu'] = initial_df['Thu_Pvalue'].apply(lambda x: 1 if x<0.01 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    Thu   R-squared:                       0.855\n",
      "Model:                            OLS   Adj. R-squared:                  0.854\n",
      "Method:                 Least Squares   F-statistic:                     1892.\n",
      "Date:                Thu, 11 Apr 2019   Prob (F-statistic):               0.00\n",
      "Time:                        01:52:47   Log-Likelihood:                 10593.\n",
      "No. Observations:                1934   AIC:                        -2.117e+04\n",
      "Df Residuals:                    1928   BIC:                        -2.114e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "C              1.0171      0.076     13.372      0.000       0.868       1.166\n",
      "MKTF_beta     -0.0020    6.4e-05    -30.931      0.000      -0.002      -0.002\n",
      "SMB_beta      -0.0006    7.2e-05     -7.729      0.000      -0.001      -0.000\n",
      "HML_beta       0.0010      0.000      8.264      0.000       0.001       0.001\n",
      "CMA_beta      -0.0003      0.000     -2.306      0.021      -0.000   -4.04e-05\n",
      "RMW_beta       0.0005      0.000      4.514      0.000       0.000       0.001\n",
      "==============================================================================\n",
      "Omnibus:                        5.976   Durbin-Watson:                   1.917\n",
      "Prob(Omnibus):                  0.050   Jarque-Bera (JB):                6.688\n",
      "Skew:                          -0.065   Prob(JB):                       0.0353\n",
      "Kurtosis:                       3.257   Cond. No.                     4.08e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.08e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "y = initial_df[['Thu']]\n",
    "y.index=initial_df['Code']\n",
    "X = initial_df[['C','MKTF_beta','SMB_beta','HML_beta','CMA_beta','RMW_beta']]\n",
    "X.index=initial_df['Code']\n",
    "# X = sm.add_constant(X)\n",
    "\n",
    "est = sm.OLS(y,X)\n",
    "result = est.fit()\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5因子回归\n",
    "\n",
    "rf = pd.read_csv('E:/Stock_Data/rf.csv',index_col=0)\n",
    "\n",
    "bin1 = 'Size'\n",
    "bin2s = ['B_M','OP','Inv']\n",
    "# bin2s = ['B_M','OP','Inv','pe_ratio','industry']\n",
    "for bin2 in bin2s:\n",
    "    file_name = 'E:/Stock_Data/'+bin1+'_'+bin2+'.csv'\n",
    "    return_df = pd.read_csv('E:/Stock_Data/'+bin1+'_'+bin2+'.csv',index_col=0)\n",
    "    return_df = return_df.dropna(how=\"any\",axis=0)\n",
    "    bin1_list = [bin1+str(i+1) for i in range(5)]\n",
    "    \n",
    "    bin2_list = [bin2+str(i+1) for i in range(5)]\n",
    "    bin1_bin2_save_df = pd.DataFrame(index=bin1_list,columns=bin2_list)\n",
    "    \n",
    "    row = 0\n",
    "    for bin1_ in bin1_list:\n",
    "        col = 0\n",
    "        for bin2_ in bin2_list:\n",
    "            bin1_bin2_ = bin1_+bin2_\n",
    "            # y减去无风险收益率\n",
    "            y_temp = return_df.iloc[:1943,:]\n",
    "            y_temp_0 = y_temp[[bin1_bin2_]]\n",
    "            y_temp_0.columns=['return']\n",
    "            y = y_temp_0 - rf\n",
    "\n",
    "#             # 用Garch\n",
    "#             reg = arch_model(y, x=X, mean='HARX', lags=0, vol='Garch', p=1, o=0, q=1, power=1.0, dist='ged', hold_back=None)\n",
    "#             result = reg.fit()\n",
    "            \n",
    "            # 用OLS\n",
    "            X = pd.concat([MKTF,SMB,HML,CMA,RMW],axis=1)\n",
    "            X = sm.add_constant(X)\n",
    "            est = sm.OLS(y,X)\n",
    "            result = est.fit()           \n",
    "            \n",
    "            save1 = result.rsquared_adj\n",
    "            save2 = list(result.pvalues)[0]\n",
    "\n",
    "            # 测试 - 结果矩阵形式保存\n",
    "            bin1_bin2_save_df.iloc[row,col] = 'adjR2%.2f a_pvalue%.2f'%(save1*100,save2)\n",
    "            \n",
    "            col += 1\n",
    "        row += 1\n",
    "    # 保存\n",
    "    bin1_bin2_save_df.to_csv('E:/Stock_Data/calander_effect_adj/'+bin1+'_'+bin2+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5因子回归修正\n",
    "\n",
    "# 引入日历效应哑变量 - 星期\n",
    "sample_df = pd.read_csv('E:/Stock_Data/stock_return_data/001896.XSHE.csv',index_col=0)\n",
    "trade_day_serises = list(sample_df.index)\n",
    "\n",
    "trade_day_df = pd.DataFrame(trade_day_serises)\n",
    "trade_day_df.columns = ['weekday']\n",
    "trade_day_df['weekday'] = trade_day_df['weekday'].apply(lambda x : datetime.datetime.strptime(x, \"%Y-%m-%d\").weekday()+1)\n",
    "\n",
    "dummy_df = pd.get_dummies(trade_day_df['weekday'])\n",
    "dummy_df = dummy_df[[4]]\n",
    "dummy_df.index = sample_df.index\n",
    "dummy_df = dummy_df.iloc[:1943,:]\n",
    "\n",
    "rf = pd.read_csv('E:/Stock_Data/rf.csv',index_col=0)\n",
    "\n",
    "bin1 = 'Size'\n",
    "bin2s = ['B_M','OP','Inv']\n",
    "# bin2s = ['B_M','OP','Inv','pe_ratio','industry']\n",
    "for bin2 in bin2s:\n",
    "    file_name = 'E:/Stock_Data/'+bin1+'_'+bin2+'.csv'\n",
    "    return_df = pd.read_csv('E:/Stock_Data/'+bin1+'_'+bin2+'.csv',index_col=0)\n",
    "    return_df = return_df.dropna(how=\"any\",axis=0)\n",
    "    bin1_list = [bin1+str(i+1) for i in range(5)]\n",
    "    \n",
    "    bin2_list = [bin2+str(i+1) for i in range(5)]\n",
    "    bin1_bin2_save_df = pd.DataFrame(index=bin1_list,columns=bin2_list)\n",
    "    \n",
    "    row = 0\n",
    "    for bin1_ in bin1_list:\n",
    "        col = 0\n",
    "        for bin2_ in bin2_list:\n",
    "            bin1_bin2_ = bin1_+bin2_\n",
    "            # y减去无风险收益率\n",
    "            y_temp = return_df.iloc[:1943,:]\n",
    "            y_temp_0 = y_temp[[bin1_bin2_]]\n",
    "            y_temp_0.columns=['return']\n",
    "            y = y_temp_0 - rf\n",
    "\n",
    "#             # 用Garch\n",
    "#             reg = arch_model(y, x=X, mean='HARX', lags=0, vol='Garch', p=1, o=0, q=1, power=1.0, dist='ged', hold_back=None)\n",
    "#             result = reg.fit()\n",
    "            \n",
    "            # 用OLS\n",
    "            X = pd.concat([MKTF,SMB,HML,CMA,RMW,dummy_df],axis=1)\n",
    "            X = sm.add_constant(X)\n",
    "            est = sm.OLS(y,X)\n",
    "            result = est.fit()           \n",
    "            \n",
    "            save1 = result.rsquared_adj\n",
    "            save2 = list(result.pvalues)[0]\n",
    "            save3 = list(result.params)[6]\n",
    "            save4 = list(result.pvalues)[6]\n",
    "\n",
    "            # 测试 - 结果矩阵形式保存\n",
    "            bin1_bin2_save_df.iloc[row,col] = 'adjR2%.2f a_pvalue%.2f Thu%.2f Thu_pvalue%.2f' % (save1*100,save2,save3*100,save4)\n",
    "            \n",
    "            col += 1\n",
    "        row += 1\n",
    "    # 保存\n",
    "    bin1_bin2_save_df.to_csv('E:/Stock_Data/calander_effect_adj/'+bin1+'_'+bin2+'adj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 return   R-squared:                       0.752\n",
      "Model:                            OLS   Adj. R-squared:                  0.751\n",
      "Method:                 Least Squares   F-statistic:                     978.6\n",
      "Date:                Tue, 02 Apr 2019   Prob (F-statistic):               0.00\n",
      "Time:                        00:00:22   Log-Likelihood:                 6556.3\n",
      "No. Observations:                1943   AIC:                        -1.310e+04\n",
      "Df Residuals:                    1936   BIC:                        -1.306e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -4.806e-05      0.000     -0.228      0.820      -0.000       0.000\n",
      "MKTF           0.9939      0.015     66.659      0.000       0.965       1.023\n",
      "SMB            0.2954      0.018     16.386      0.000       0.260       0.331\n",
      "HML           -0.2639      0.018    -14.566      0.000      -0.299      -0.228\n",
      "CMA           -0.0315      0.018     -1.739      0.082      -0.067       0.004\n",
      "RMW           -0.0071      0.019     -0.382      0.702      -0.044       0.029\n",
      "4             -0.0008      0.000     -1.695      0.090      -0.002       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      202.645   Durbin-Watson:                   1.882\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1627.725\n",
      "Skew:                           0.027   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.484   Cond. No.                         124.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    8.198361e-01\n",
       "MKTF     0.000000e+00\n",
       "SMB      1.309001e-56\n",
       "HML      1.095246e-45\n",
       "CMA      8.225096e-02\n",
       "RMW      7.022682e-01\n",
       "4        9.014270e-02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
