{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import jqdatasdk as jq\n",
    "import statsmodels.api as sm\n",
    "import time,datetime\n",
    "import os\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auth success （JQData现有流量增加活动，详情请咨询JQData管理员，微信号：JQData01）\n"
     ]
    }
   ],
   "source": [
    "# jq.auth('13918852005','960312Lsc')\n",
    "# jq.auth('15821912507','912507')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先分组，5因子分组：市值2组，其余3组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成分组标识\n",
    "bin_df = pd.read_csv('E:/Stock_Data/bin_data.csv',index_col=0)\n",
    "for col in ['B_M', 'OP','pe_ratio']:\n",
    "    if isinstance(bin_df[col][0],float):\n",
    "        bin_df[col] = bin_df[col].apply(lambda x : np.nan if x<0 else x)\n",
    "bin_df = bin_df.dropna(how='any',axis=0)\n",
    "\n",
    "## 分组组数\n",
    "bin_num = 3\n",
    "\n",
    "for i in range(8):\n",
    "    \n",
    "    year = str(2010+i)+'-12-31'\n",
    "    temp_df_0 = bin_df[bin_df.date==year]\n",
    "    \n",
    "    # 计算当年总行数\n",
    "    stock_num = len(temp_df_0)\n",
    "    \n",
    "    for bin_kind in ['B_M','OP','Inv']:\n",
    "        \n",
    "        # 生成分组标识\n",
    "        bin_lst = []\n",
    "        for i in range(bin_num):\n",
    "            bin_lst += [bin_kind+str(i+1)]*int(stock_num/bin_num)\n",
    "        if len(bin_lst) != stock_num:\n",
    "            bin_lst += [bin_kind+str(i+1)]*(stock_num-len(bin_lst))\n",
    "        \n",
    "        temp_df_0 = temp_df_0.sort_values(bin_kind)\n",
    "        temp_df_0[bin_kind] = bin_lst\n",
    "            \n",
    "    for bin_kind in ['Size']:\n",
    "        \n",
    "        # Size只分两组\n",
    "        bin_num_size = 2\n",
    "        # 生成分组标识\n",
    "        bin_lst = []\n",
    "        for i in range(bin_num_size):\n",
    "            bin_lst += [bin_kind+str(i+1)]*int(stock_num/bin_num_size)\n",
    "        if len(bin_lst) != stock_num:\n",
    "            bin_lst += [bin_kind+str(i+1)]*(stock_num-len(bin_lst))\n",
    "        \n",
    "        temp_df_0 = temp_df_0.sort_values(bin_kind)\n",
    "        temp_df_0[bin_kind] = bin_lst    \n",
    "    \n",
    "    temp_df_1 = bin_df[bin_df.date==year]\n",
    "    temp_df_1 = temp_df_1.sort_values('Size') # 和df_0对齐，最后一次是按照Size排序的\n",
    "    temp_df_0['S']=temp_df_1['Size']\n",
    "    temp_df_0.to_csv('E:/Stock_Data/factor_portfolio/bin_data'+year+'.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按要求生成投资组合\n",
    "\n",
    "# 保存在字典：除Size以外的另一个组别 -> 年份 -> bin2 -> 组合，stock code list\n",
    "\n",
    "portfolio={}\n",
    "\n",
    "for bin2 in ['B_M','OP','Inv','Size']:\n",
    "    portfolio[bin2] = {}\n",
    "    \n",
    "    for i in range(8):\n",
    "        year = str(2010+i)+'-12-31'\n",
    "        portfolio[bin2][str(2011+i)]={}\n",
    "        \n",
    "        temp_df_0 = pd.read_csv('E:/Stock_Data/factor_portfolio/bin_data'+year+'.csv',index_col=0)\n",
    "        bin2_lst = list(set(temp_df_0[bin2]))\n",
    "        \n",
    "        for bin2_ in bin2_lst:\n",
    "            temp_df_1 = temp_df_0[temp_df_0[bin2]==bin2_]\n",
    "            list_code_value = [list(temp_df_1[['code','S']].iloc[i,:]) for i in range(len(temp_df_1))]\n",
    "            portfolio[bin2][str(2011+i)][bin2_] = list_code_value\n",
    "            \n",
    "# 保存字典\n",
    "f = open('E:/Stock_Data/factor_portfolio/portfolio.txt','w')\n",
    "f.write(str(portfolio))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取字典\n",
    "f = open('E:/Stock_Data/factor_portfolio/portfolio.txt','r')\n",
    "a = f.read()\n",
    "portfolio = eval(a)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_download_return_temp = os.listdir('E:/Stock_Data/stock_return_data/')\n",
    "stock_download_return = [x[:-4] for x in stock_download_return_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000001.XSHE',\n",
       " '000002.XSHE',\n",
       " '000004.XSHE',\n",
       " '000005.XSHE',\n",
       " '000006.XSHE',\n",
       " '000008.XSHE',\n",
       " '000009.XSHE',\n",
       " '000011.XSHE',\n",
       " '000012.XSHE',\n",
       " '000014.XSHE',\n",
       " '000016.XSHE',\n",
       " '000017.XSHE',\n",
       " '000018.XSHE',\n",
       " '000019.XSHE',\n",
       " '000020.XSHE',\n",
       " '000021.XSHE',\n",
       " '000022.XSHE',\n",
       " '000023.XSHE',\n",
       " '000024.XSHE',\n",
       " '000025.XSHE',\n",
       " '000026.XSHE',\n",
       " '000027.XSHE',\n",
       " '000028.XSHE',\n",
       " '000030.XSHE',\n",
       " '000031.XSHE',\n",
       " '000032.XSHE',\n",
       " '000034.XSHE',\n",
       " '000036.XSHE',\n",
       " '000037.XSHE',\n",
       " '000039.XSHE',\n",
       " '000040.XSHE',\n",
       " '000042.XSHE',\n",
       " '000043.XSHE',\n",
       " '000045.XSHE',\n",
       " '000046.XSHE',\n",
       " '000048.XSHE',\n",
       " '000049.XSHE',\n",
       " '000050.XSHE',\n",
       " '000055.XSHE',\n",
       " '000056.XSHE',\n",
       " '000058.XSHE',\n",
       " '000059.XSHE',\n",
       " '000060.XSHE',\n",
       " '000061.XSHE',\n",
       " '000062.XSHE',\n",
       " '000063.XSHE',\n",
       " '000065.XSHE',\n",
       " '000066.XSHE',\n",
       " '000069.XSHE',\n",
       " '000070.XSHE',\n",
       " '000078.XSHE',\n",
       " '000088.XSHE',\n",
       " '000089.XSHE',\n",
       " '000090.XSHE',\n",
       " '000096.XSHE',\n",
       " '000099.XSHE',\n",
       " '000100.XSHE',\n",
       " '000150.XSHE',\n",
       " '000151.XSHE',\n",
       " '000153.XSHE',\n",
       " '000157.XSHE',\n",
       " '000158.XSHE',\n",
       " '000159.XSHE',\n",
       " '000301.XSHE',\n",
       " '000338.XSHE',\n",
       " '000400.XSHE',\n",
       " '000401.XSHE',\n",
       " '000402.XSHE',\n",
       " '000404.XSHE',\n",
       " '000407.XSHE',\n",
       " '000408.XSHE',\n",
       " '000409.XSHE',\n",
       " '000410.XSHE',\n",
       " '000411.XSHE',\n",
       " '000413.XSHE',\n",
       " '000416.XSHE',\n",
       " '000417.XSHE',\n",
       " '000418.XSHE',\n",
       " '000419.XSHE',\n",
       " '000420.XSHE',\n",
       " '000421.XSHE',\n",
       " '000422.XSHE',\n",
       " '000423.XSHE',\n",
       " '000425.XSHE',\n",
       " '000426.XSHE',\n",
       " '000428.XSHE',\n",
       " '000429.XSHE',\n",
       " '000430.XSHE',\n",
       " '000488.XSHE',\n",
       " '000501.XSHE',\n",
       " '000502.XSHE',\n",
       " '000503.XSHE',\n",
       " '000504.XSHE',\n",
       " '000505.XSHE',\n",
       " '000506.XSHE',\n",
       " '000507.XSHE',\n",
       " '000509.XSHE',\n",
       " '000510.XSHE',\n",
       " '000513.XSHE',\n",
       " '000514.XSHE',\n",
       " '000516.XSHE',\n",
       " '000517.XSHE',\n",
       " '000518.XSHE',\n",
       " '000519.XSHE',\n",
       " '000521.XSHE',\n",
       " '000523.XSHE',\n",
       " '000524.XSHE',\n",
       " '000525.XSHE',\n",
       " '000528.XSHE',\n",
       " '000529.XSHE',\n",
       " '000530.XSHE',\n",
       " '000531.XSHE',\n",
       " '000532.XSHE',\n",
       " '000533.XSHE',\n",
       " '000534.XSHE',\n",
       " '000536.XSHE',\n",
       " '000537.XSHE',\n",
       " '000538.XSHE',\n",
       " '000539.XSHE',\n",
       " '000541.XSHE',\n",
       " '000543.XSHE',\n",
       " '000544.XSHE',\n",
       " '000546.XSHE',\n",
       " '000547.XSHE',\n",
       " '000548.XSHE',\n",
       " '000550.XSHE',\n",
       " '000551.XSHE',\n",
       " '000552.XSHE',\n",
       " '000553.XSHE',\n",
       " '000554.XSHE',\n",
       " '000555.XSHE',\n",
       " '000558.XSHE',\n",
       " '000559.XSHE',\n",
       " '000560.XSHE',\n",
       " '000561.XSHE',\n",
       " '000563.XSHE',\n",
       " '000565.XSHE',\n",
       " '000566.XSHE',\n",
       " '000567.XSHE',\n",
       " '000568.XSHE',\n",
       " '000570.XSHE',\n",
       " '000571.XSHE',\n",
       " '000572.XSHE',\n",
       " '000573.XSHE',\n",
       " '000576.XSHE',\n",
       " '000581.XSHE',\n",
       " '000582.XSHE',\n",
       " '000584.XSHE',\n",
       " '000585.XSHE',\n",
       " '000586.XSHE',\n",
       " '000587.XSHE',\n",
       " '000589.XSHE',\n",
       " '000590.XSHE',\n",
       " '000591.XSHE',\n",
       " '000592.XSHE',\n",
       " '000593.XSHE',\n",
       " '000594.XSHE',\n",
       " '000595.XSHE',\n",
       " '000596.XSHE',\n",
       " '000597.XSHE',\n",
       " '000598.XSHE',\n",
       " '000599.XSHE',\n",
       " '000600.XSHE',\n",
       " '000601.XSHE',\n",
       " '000603.XSHE',\n",
       " '000605.XSHE',\n",
       " '000606.XSHE',\n",
       " '000607.XSHE',\n",
       " '000608.XSHE',\n",
       " '000609.XSHE',\n",
       " '000610.XSHE',\n",
       " '000611.XSHE',\n",
       " '000612.XSHE',\n",
       " '000613.XSHE',\n",
       " '000615.XSHE',\n",
       " '000616.XSHE',\n",
       " '000617.XSHE',\n",
       " '000619.XSHE',\n",
       " '000620.XSHE',\n",
       " '000623.XSHE',\n",
       " '000625.XSHE',\n",
       " '000626.XSHE',\n",
       " '000627.XSHE',\n",
       " '000628.XSHE',\n",
       " '000630.XSHE',\n",
       " '000631.XSHE',\n",
       " '000632.XSHE',\n",
       " '000633.XSHE',\n",
       " '000635.XSHE',\n",
       " '000636.XSHE',\n",
       " '000637.XSHE',\n",
       " '000638.XSHE',\n",
       " '000639.XSHE',\n",
       " '000650.XSHE',\n",
       " '000651.XSHE',\n",
       " '000652.XSHE',\n",
       " '000655.XSHE',\n",
       " '000656.XSHE',\n",
       " '000659.XSHE',\n",
       " '000661.XSHE',\n",
       " '000662.XSHE',\n",
       " '000663.XSHE',\n",
       " '000665.XSHE',\n",
       " '000666.XSHE',\n",
       " '000667.XSHE',\n",
       " '000668.XSHE',\n",
       " '000669.XSHE',\n",
       " '000671.XSHE',\n",
       " '000673.XSHE',\n",
       " '000676.XSHE',\n",
       " '000678.XSHE',\n",
       " '000679.XSHE',\n",
       " '000680.XSHE',\n",
       " '000682.XSHE',\n",
       " '000683.XSHE',\n",
       " '000685.XSHE',\n",
       " '000686.XSHE',\n",
       " '000687.XSHE',\n",
       " '000690.XSHE',\n",
       " '000691.XSHE',\n",
       " '000692.XSHE',\n",
       " '000695.XSHE',\n",
       " '000697.XSHE',\n",
       " '000698.XSHE',\n",
       " '000700.XSHE',\n",
       " '000701.XSHE',\n",
       " '000702.XSHE',\n",
       " '000703.XSHE',\n",
       " '000705.XSHE',\n",
       " '000707.XSHE',\n",
       " '000708.XSHE',\n",
       " '000709.XSHE',\n",
       " '000710.XSHE',\n",
       " '000712.XSHE',\n",
       " '000713.XSHE',\n",
       " '000715.XSHE',\n",
       " '000716.XSHE',\n",
       " '000717.XSHE',\n",
       " '000718.XSHE',\n",
       " '000719.XSHE',\n",
       " '000720.XSHE',\n",
       " '000721.XSHE',\n",
       " '000722.XSHE',\n",
       " '000723.XSHE',\n",
       " '000725.XSHE',\n",
       " '000726.XSHE',\n",
       " '000727.XSHE',\n",
       " '000728.XSHE',\n",
       " '000729.XSHE',\n",
       " '000731.XSHE',\n",
       " '000732.XSHE',\n",
       " '000733.XSHE',\n",
       " '000735.XSHE',\n",
       " '000736.XSHE',\n",
       " '000737.XSHE',\n",
       " '000738.XSHE',\n",
       " '000739.XSHE',\n",
       " '000748.XSHE',\n",
       " '000750.XSHE',\n",
       " '000751.XSHE',\n",
       " '000752.XSHE',\n",
       " '000753.XSHE',\n",
       " '000755.XSHE',\n",
       " '000756.XSHE',\n",
       " '000758.XSHE',\n",
       " '000759.XSHE',\n",
       " '000760.XSHE',\n",
       " '000761.XSHE',\n",
       " '000762.XSHE',\n",
       " '000766.XSHE',\n",
       " '000767.XSHE',\n",
       " '000768.XSHE',\n",
       " '000776.XSHE',\n",
       " '000777.XSHE',\n",
       " '000778.XSHE',\n",
       " '000779.XSHE',\n",
       " '000780.XSHE',\n",
       " '000782.XSHE',\n",
       " '000783.XSHE',\n",
       " '000785.XSHE',\n",
       " '000786.XSHE',\n",
       " '000788.XSHE',\n",
       " '000789.XSHE',\n",
       " '000790.XSHE',\n",
       " '000791.XSHE',\n",
       " '000792.XSHE',\n",
       " '000793.XSHE',\n",
       " '000795.XSHE',\n",
       " '000797.XSHE',\n",
       " '000798.XSHE',\n",
       " '000799.XSHE',\n",
       " '000800.XSHE',\n",
       " '000801.XSHE',\n",
       " '000802.XSHE',\n",
       " '000803.XSHE',\n",
       " '000806.XSHE',\n",
       " '000807.XSHE',\n",
       " '000809.XSHE',\n",
       " '000810.XSHE',\n",
       " '000811.XSHE',\n",
       " '000812.XSHE',\n",
       " '000813.XSHE',\n",
       " '000815.XSHE',\n",
       " '000816.XSHE',\n",
       " '000818.XSHE',\n",
       " '000819.XSHE',\n",
       " '000821.XSHE',\n",
       " '000822.XSHE',\n",
       " '000823.XSHE',\n",
       " '000825.XSHE',\n",
       " '000826.XSHE',\n",
       " '000828.XSHE',\n",
       " '000829.XSHE',\n",
       " '000830.XSHE',\n",
       " '000831.XSHE',\n",
       " '000833.XSHE',\n",
       " '000835.XSHE',\n",
       " '000836.XSHE',\n",
       " '000837.XSHE',\n",
       " '000838.XSHE',\n",
       " '000839.XSHE',\n",
       " '000848.XSHE',\n",
       " '000850.XSHE',\n",
       " '000851.XSHE',\n",
       " '000852.XSHE',\n",
       " '000856.XSHE',\n",
       " '000858.XSHE',\n",
       " '000859.XSHE',\n",
       " '000860.XSHE',\n",
       " '000861.XSHE',\n",
       " '000862.XSHE',\n",
       " '000868.XSHE',\n",
       " '000869.XSHE',\n",
       " '000875.XSHE',\n",
       " '000876.XSHE',\n",
       " '000877.XSHE',\n",
       " '000878.XSHE',\n",
       " '000880.XSHE',\n",
       " '000881.XSHE',\n",
       " '000882.XSHE',\n",
       " '000883.XSHE',\n",
       " '000885.XSHE',\n",
       " '000886.XSHE',\n",
       " '000887.XSHE',\n",
       " '000888.XSHE',\n",
       " '000889.XSHE',\n",
       " '000890.XSHE',\n",
       " '000892.XSHE',\n",
       " '000893.XSHE',\n",
       " '000895.XSHE',\n",
       " '000897.XSHE',\n",
       " '000898.XSHE',\n",
       " '000899.XSHE',\n",
       " '000900.XSHE',\n",
       " '000901.XSHE',\n",
       " '000902.XSHE',\n",
       " '000903.XSHE',\n",
       " '000905.XSHE',\n",
       " '000906.XSHE',\n",
       " '000908.XSHE',\n",
       " '000909.XSHE',\n",
       " '000910.XSHE',\n",
       " '000911.XSHE',\n",
       " '000912.XSHE',\n",
       " '000913.XSHE',\n",
       " '000915.XSHE',\n",
       " '000916.XSHE',\n",
       " '000917.XSHE',\n",
       " '000918.XSHE',\n",
       " '000919.XSHE',\n",
       " '000920.XSHE',\n",
       " '000921.XSHE',\n",
       " '000922.XSHE',\n",
       " '000923.XSHE',\n",
       " '000925.XSHE',\n",
       " '000926.XSHE',\n",
       " '000927.XSHE',\n",
       " '000928.XSHE',\n",
       " '000929.XSHE',\n",
       " '000930.XSHE',\n",
       " '000931.XSHE',\n",
       " '000932.XSHE',\n",
       " '000933.XSHE',\n",
       " '000935.XSHE',\n",
       " '000936.XSHE',\n",
       " '000937.XSHE',\n",
       " '000938.XSHE',\n",
       " '000939.XSHE',\n",
       " '000948.XSHE',\n",
       " '000949.XSHE',\n",
       " '000951.XSHE',\n",
       " '000952.XSHE',\n",
       " '000953.XSHE',\n",
       " '000955.XSHE',\n",
       " '000957.XSHE',\n",
       " '000958.XSHE',\n",
       " '000959.XSHE',\n",
       " '000960.XSHE',\n",
       " '000961.XSHE',\n",
       " '000962.XSHE',\n",
       " '000963.XSHE',\n",
       " '000965.XSHE',\n",
       " '000966.XSHE',\n",
       " '000967.XSHE',\n",
       " '000968.XSHE',\n",
       " '000969.XSHE',\n",
       " '000970.XSHE',\n",
       " '000971.XSHE',\n",
       " '000972.XSHE',\n",
       " '000973.XSHE',\n",
       " '000975.XSHE',\n",
       " '000976.XSHE',\n",
       " '000977.XSHE',\n",
       " '000978.XSHE',\n",
       " '000980.XSHE',\n",
       " '000983.XSHE',\n",
       " '000985.XSHE',\n",
       " '000987.XSHE',\n",
       " '000988.XSHE',\n",
       " '000989.XSHE',\n",
       " '000990.XSHE',\n",
       " '000993.XSHE',\n",
       " '000995.XSHE',\n",
       " '000996.XSHE',\n",
       " '000997.XSHE',\n",
       " '000998.XSHE',\n",
       " '000999.XSHE',\n",
       " '001696.XSHE',\n",
       " '001872.XSHE',\n",
       " '001896.XSHE',\n",
       " '002001.XSHE',\n",
       " '002002.XSHE',\n",
       " '002003.XSHE',\n",
       " '002004.XSHE',\n",
       " '002005.XSHE',\n",
       " '002006.XSHE',\n",
       " '002007.XSHE',\n",
       " '002008.XSHE',\n",
       " '002009.XSHE',\n",
       " '002010.XSHE',\n",
       " '002011.XSHE',\n",
       " '002012.XSHE',\n",
       " '002013.XSHE',\n",
       " '002014.XSHE',\n",
       " '002016.XSHE',\n",
       " '002017.XSHE',\n",
       " '002018.XSHE',\n",
       " '002019.XSHE',\n",
       " '002020.XSHE',\n",
       " '002021.XSHE',\n",
       " '002022.XSHE',\n",
       " '002023.XSHE',\n",
       " '002024.XSHE',\n",
       " '002025.XSHE',\n",
       " '002026.XSHE',\n",
       " '002027.XSHE',\n",
       " '002028.XSHE',\n",
       " '002029.XSHE',\n",
       " '002030.XSHE',\n",
       " '002031.XSHE',\n",
       " '002032.XSHE',\n",
       " '002033.XSHE',\n",
       " '002034.XSHE',\n",
       " '002035.XSHE',\n",
       " '002036.XSHE',\n",
       " '002037.XSHE',\n",
       " '002038.XSHE',\n",
       " '002039.XSHE',\n",
       " '002040.XSHE',\n",
       " '002041.XSHE',\n",
       " '002042.XSHE',\n",
       " '002043.XSHE',\n",
       " '002044.XSHE',\n",
       " '002045.XSHE',\n",
       " '002046.XSHE',\n",
       " '002047.XSHE',\n",
       " '002048.XSHE',\n",
       " '002049.XSHE',\n",
       " '002050.XSHE',\n",
       " '002051.XSHE',\n",
       " '002052.XSHE',\n",
       " '002053.XSHE',\n",
       " '002054.XSHE',\n",
       " '002055.XSHE',\n",
       " '002056.XSHE',\n",
       " '002057.XSHE',\n",
       " '002058.XSHE',\n",
       " '002059.XSHE',\n",
       " '002060.XSHE',\n",
       " '002061.XSHE',\n",
       " '002062.XSHE',\n",
       " '002063.XSHE',\n",
       " '002064.XSHE',\n",
       " '002065.XSHE',\n",
       " '002066.XSHE',\n",
       " '002067.XSHE',\n",
       " '002068.XSHE',\n",
       " '002069.XSHE',\n",
       " '002071.XSHE',\n",
       " '002073.XSHE',\n",
       " '002074.XSHE',\n",
       " '002076.XSHE',\n",
       " '002077.XSHE',\n",
       " '002078.XSHE',\n",
       " '002079.XSHE',\n",
       " '002080.XSHE',\n",
       " '002081.XSHE',\n",
       " '002082.XSHE',\n",
       " '002083.XSHE',\n",
       " '002084.XSHE',\n",
       " '002085.XSHE',\n",
       " '002086.XSHE',\n",
       " '002087.XSHE',\n",
       " '002088.XSHE',\n",
       " '002089.XSHE',\n",
       " '002090.XSHE',\n",
       " '002091.XSHE',\n",
       " '002092.XSHE',\n",
       " '002093.XSHE',\n",
       " '002094.XSHE',\n",
       " '002095.XSHE',\n",
       " '002096.XSHE',\n",
       " '002097.XSHE',\n",
       " '002098.XSHE',\n",
       " '002099.XSHE',\n",
       " '002100.XSHE',\n",
       " '002101.XSHE',\n",
       " '002102.XSHE',\n",
       " '002103.XSHE',\n",
       " '002104.XSHE',\n",
       " '002105.XSHE',\n",
       " '002106.XSHE',\n",
       " '002107.XSHE',\n",
       " '002108.XSHE',\n",
       " '002109.XSHE',\n",
       " '002110.XSHE',\n",
       " '002111.XSHE',\n",
       " '002112.XSHE',\n",
       " '002114.XSHE',\n",
       " '002115.XSHE',\n",
       " '002116.XSHE',\n",
       " '002117.XSHE',\n",
       " '002118.XSHE',\n",
       " '002119.XSHE',\n",
       " '002120.XSHE',\n",
       " '002121.XSHE',\n",
       " '002122.XSHE',\n",
       " '002123.XSHE',\n",
       " '002124.XSHE',\n",
       " '002125.XSHE',\n",
       " '002126.XSHE',\n",
       " '002127.XSHE',\n",
       " '002128.XSHE',\n",
       " '002130.XSHE',\n",
       " '002131.XSHE',\n",
       " '002132.XSHE',\n",
       " '002133.XSHE',\n",
       " '002134.XSHE',\n",
       " '002135.XSHE',\n",
       " '002136.XSHE',\n",
       " '002137.XSHE',\n",
       " '002138.XSHE',\n",
       " '002139.XSHE',\n",
       " '002140.XSHE',\n",
       " '002141.XSHE',\n",
       " '002142.XSHE',\n",
       " '002143.XSHE',\n",
       " '002144.XSHE',\n",
       " '002145.XSHE',\n",
       " '002146.XSHE',\n",
       " '002147.XSHE',\n",
       " '002148.XSHE',\n",
       " '002149.XSHE',\n",
       " '002150.XSHE',\n",
       " '002151.XSHE',\n",
       " '002152.XSHE',\n",
       " '002153.XSHE',\n",
       " '002154.XSHE',\n",
       " '002155.XSHE',\n",
       " '002156.XSHE',\n",
       " '002157.XSHE',\n",
       " '002158.XSHE',\n",
       " '002159.XSHE',\n",
       " '002160.XSHE',\n",
       " '002161.XSHE',\n",
       " '002162.XSHE',\n",
       " '002163.XSHE',\n",
       " '002164.XSHE',\n",
       " '002165.XSHE',\n",
       " '002166.XSHE',\n",
       " '002167.XSHE',\n",
       " '002168.XSHE',\n",
       " '002169.XSHE',\n",
       " '002170.XSHE',\n",
       " '002171.XSHE',\n",
       " '002172.XSHE',\n",
       " '002173.XSHE',\n",
       " '002174.XSHE',\n",
       " '002175.XSHE',\n",
       " '002176.XSHE',\n",
       " '002177.XSHE',\n",
       " '002178.XSHE',\n",
       " '002179.XSHE',\n",
       " '002180.XSHE',\n",
       " '002181.XSHE',\n",
       " '002182.XSHE',\n",
       " '002183.XSHE',\n",
       " '002184.XSHE',\n",
       " '002185.XSHE',\n",
       " '002186.XSHE',\n",
       " '002187.XSHE',\n",
       " '002188.XSHE',\n",
       " '002189.XSHE',\n",
       " '002190.XSHE',\n",
       " '002191.XSHE',\n",
       " '002192.XSHE',\n",
       " '002193.XSHE',\n",
       " '002194.XSHE',\n",
       " '002195.XSHE',\n",
       " '002196.XSHE',\n",
       " '002197.XSHE',\n",
       " '002198.XSHE',\n",
       " '002199.XSHE',\n",
       " '002200.XSHE',\n",
       " '002201.XSHE',\n",
       " '002202.XSHE',\n",
       " '002203.XSHE',\n",
       " '002204.XSHE',\n",
       " '002205.XSHE',\n",
       " '002206.XSHE',\n",
       " '002207.XSHE',\n",
       " '002208.XSHE',\n",
       " '002209.XSHE',\n",
       " '002210.XSHE',\n",
       " '002211.XSHE',\n",
       " '002212.XSHE',\n",
       " '002213.XSHE',\n",
       " '002214.XSHE',\n",
       " '002215.XSHE',\n",
       " '002216.XSHE',\n",
       " '002217.XSHE',\n",
       " '002218.XSHE',\n",
       " '002220.XSHE',\n",
       " '002221.XSHE',\n",
       " '002222.XSHE',\n",
       " '002223.XSHE',\n",
       " '002224.XSHE',\n",
       " '002225.XSHE',\n",
       " '002226.XSHE',\n",
       " '002227.XSHE',\n",
       " '002228.XSHE',\n",
       " '002229.XSHE',\n",
       " '002230.XSHE',\n",
       " '002231.XSHE',\n",
       " '002232.XSHE',\n",
       " '002233.XSHE',\n",
       " '002234.XSHE',\n",
       " '002235.XSHE',\n",
       " '002236.XSHE',\n",
       " '002237.XSHE',\n",
       " '002238.XSHE',\n",
       " '002240.XSHE',\n",
       " '002241.XSHE',\n",
       " '002242.XSHE',\n",
       " '002243.XSHE',\n",
       " '002244.XSHE',\n",
       " '002245.XSHE',\n",
       " '002246.XSHE',\n",
       " '002247.XSHE',\n",
       " '002248.XSHE',\n",
       " '002249.XSHE',\n",
       " '002250.XSHE',\n",
       " '002251.XSHE',\n",
       " '002253.XSHE',\n",
       " '002254.XSHE',\n",
       " '002255.XSHE',\n",
       " '002258.XSHE',\n",
       " '002259.XSHE',\n",
       " '002260.XSHE',\n",
       " '002261.XSHE',\n",
       " '002262.XSHE',\n",
       " '002264.XSHE',\n",
       " '002265.XSHE',\n",
       " '002266.XSHE',\n",
       " '002267.XSHE',\n",
       " '002268.XSHE',\n",
       " '002269.XSHE',\n",
       " '002270.XSHE',\n",
       " '002271.XSHE',\n",
       " '002272.XSHE',\n",
       " '002273.XSHE',\n",
       " '002274.XSHE',\n",
       " '002275.XSHE',\n",
       " '002276.XSHE',\n",
       " '002277.XSHE',\n",
       " '002278.XSHE',\n",
       " '002279.XSHE',\n",
       " '002280.XSHE',\n",
       " '002281.XSHE',\n",
       " '002282.XSHE',\n",
       " '002283.XSHE',\n",
       " '002284.XSHE',\n",
       " '002285.XSHE',\n",
       " '002286.XSHE',\n",
       " '002287.XSHE',\n",
       " '002288.XSHE',\n",
       " '002289.XSHE',\n",
       " '002290.XSHE',\n",
       " '002291.XSHE',\n",
       " '002292.XSHE',\n",
       " '002293.XSHE',\n",
       " '002294.XSHE',\n",
       " '002295.XSHE',\n",
       " '002296.XSHE',\n",
       " '002297.XSHE',\n",
       " '002298.XSHE',\n",
       " '002299.XSHE',\n",
       " '002300.XSHE',\n",
       " '002301.XSHE',\n",
       " '002302.XSHE',\n",
       " '002303.XSHE',\n",
       " '002304.XSHE',\n",
       " '002305.XSHE',\n",
       " '002306.XSHE',\n",
       " '002307.XSHE',\n",
       " '002308.XSHE',\n",
       " '002309.XSHE',\n",
       " '002310.XSHE',\n",
       " '002311.XSHE',\n",
       " '002312.XSHE',\n",
       " '002313.XSHE',\n",
       " '002314.XSHE',\n",
       " '002315.XSHE',\n",
       " '002316.XSHE',\n",
       " '002317.XSHE',\n",
       " '002318.XSHE',\n",
       " '002319.XSHE',\n",
       " '002320.XSHE',\n",
       " '002321.XSHE',\n",
       " '002322.XSHE',\n",
       " '002323.XSHE',\n",
       " '002324.XSHE',\n",
       " '002325.XSHE',\n",
       " '002326.XSHE',\n",
       " '002327.XSHE',\n",
       " '002328.XSHE',\n",
       " '002329.XSHE',\n",
       " '002330.XSHE',\n",
       " '002331.XSHE',\n",
       " '002332.XSHE',\n",
       " '002333.XSHE',\n",
       " '002334.XSHE',\n",
       " '002335.XSHE',\n",
       " '002336.XSHE',\n",
       " '002337.XSHE',\n",
       " '002338.XSHE',\n",
       " '002339.XSHE',\n",
       " '002340.XSHE',\n",
       " '002341.XSHE',\n",
       " '002342.XSHE',\n",
       " '002343.XSHE',\n",
       " '002344.XSHE',\n",
       " '002345.XSHE',\n",
       " '002346.XSHE',\n",
       " '002347.XSHE',\n",
       " '002348.XSHE',\n",
       " '002349.XSHE',\n",
       " '002350.XSHE',\n",
       " '002351.XSHE',\n",
       " '002352.XSHE',\n",
       " '002353.XSHE',\n",
       " '002354.XSHE',\n",
       " '002355.XSHE',\n",
       " '002356.XSHE',\n",
       " '002357.XSHE',\n",
       " '002358.XSHE',\n",
       " '002359.XSHE',\n",
       " '002360.XSHE',\n",
       " '002361.XSHE',\n",
       " '002362.XSHE',\n",
       " '002363.XSHE',\n",
       " '002364.XSHE',\n",
       " '002365.XSHE',\n",
       " '002366.XSHE',\n",
       " '002367.XSHE',\n",
       " '002368.XSHE',\n",
       " '002369.XSHE',\n",
       " '002370.XSHE',\n",
       " '002371.XSHE',\n",
       " '002372.XSHE',\n",
       " '002373.XSHE',\n",
       " '002374.XSHE',\n",
       " '002375.XSHE',\n",
       " '002376.XSHE',\n",
       " '002377.XSHE',\n",
       " '002378.XSHE',\n",
       " '002379.XSHE',\n",
       " '002380.XSHE',\n",
       " '002381.XSHE',\n",
       " '002382.XSHE',\n",
       " '002383.XSHE',\n",
       " '002384.XSHE',\n",
       " '002385.XSHE',\n",
       " '002386.XSHE',\n",
       " '002387.XSHE',\n",
       " '002388.XSHE',\n",
       " '002389.XSHE',\n",
       " '002390.XSHE',\n",
       " '002391.XSHE',\n",
       " '002392.XSHE',\n",
       " '002393.XSHE',\n",
       " '002394.XSHE',\n",
       " '002395.XSHE',\n",
       " '002396.XSHE',\n",
       " '002397.XSHE',\n",
       " '002398.XSHE',\n",
       " '002399.XSHE',\n",
       " '002400.XSHE',\n",
       " '002401.XSHE',\n",
       " '002402.XSHE',\n",
       " '002403.XSHE',\n",
       " '002404.XSHE',\n",
       " '002405.XSHE',\n",
       " '002406.XSHE',\n",
       " '002407.XSHE',\n",
       " '002408.XSHE',\n",
       " '002409.XSHE',\n",
       " '002410.XSHE',\n",
       " '002411.XSHE',\n",
       " '002412.XSHE',\n",
       " '002413.XSHE',\n",
       " '002414.XSHE',\n",
       " '002415.XSHE',\n",
       " '002416.XSHE',\n",
       " '002417.XSHE',\n",
       " '002418.XSHE',\n",
       " '002419.XSHE',\n",
       " '002420.XSHE',\n",
       " '002421.XSHE',\n",
       " '002422.XSHE',\n",
       " '002423.XSHE',\n",
       " '002424.XSHE',\n",
       " '002425.XSHE',\n",
       " '002426.XSHE',\n",
       " '002427.XSHE',\n",
       " '002428.XSHE',\n",
       " '002429.XSHE',\n",
       " '002430.XSHE',\n",
       " '002431.XSHE',\n",
       " '002432.XSHE',\n",
       " '002433.XSHE',\n",
       " '002434.XSHE',\n",
       " '002435.XSHE',\n",
       " '002436.XSHE',\n",
       " '002437.XSHE',\n",
       " '002438.XSHE',\n",
       " '002439.XSHE',\n",
       " '002440.XSHE',\n",
       " '002441.XSHE',\n",
       " '002442.XSHE',\n",
       " '002443.XSHE',\n",
       " '002444.XSHE',\n",
       " '002445.XSHE',\n",
       " '002446.XSHE',\n",
       " '002447.XSHE',\n",
       " '002448.XSHE',\n",
       " '002449.XSHE',\n",
       " '002450.XSHE',\n",
       " '002451.XSHE',\n",
       " '002452.XSHE',\n",
       " '002453.XSHE',\n",
       " '002454.XSHE',\n",
       " '002455.XSHE',\n",
       " '002456.XSHE',\n",
       " '002457.XSHE',\n",
       " '002458.XSHE',\n",
       " '002459.XSHE',\n",
       " '002460.XSHE',\n",
       " '002461.XSHE',\n",
       " '002462.XSHE',\n",
       " '002463.XSHE',\n",
       " '002465.XSHE',\n",
       " '002466.XSHE',\n",
       " '002467.XSHE',\n",
       " '002468.XSHE',\n",
       " '002469.XSHE',\n",
       " '002470.XSHE',\n",
       " '002471.XSHE',\n",
       " '002472.XSHE',\n",
       " '002473.XSHE',\n",
       " '002474.XSHE',\n",
       " '002475.XSHE',\n",
       " '002476.XSHE',\n",
       " '002477.XSHE',\n",
       " '002478.XSHE',\n",
       " '002479.XSHE',\n",
       " '002480.XSHE',\n",
       " '002481.XSHE',\n",
       " '002482.XSHE',\n",
       " '002483.XSHE',\n",
       " '002484.XSHE',\n",
       " '002485.XSHE',\n",
       " '002486.XSHE',\n",
       " '002487.XSHE',\n",
       " '002488.XSHE',\n",
       " '002489.XSHE',\n",
       " '002490.XSHE',\n",
       " '002491.XSHE',\n",
       " '002492.XSHE',\n",
       " '002493.XSHE',\n",
       " '002494.XSHE',\n",
       " '002495.XSHE',\n",
       " '002496.XSHE',\n",
       " '002497.XSHE',\n",
       " '002498.XSHE',\n",
       " '002499.XSHE',\n",
       " '002500.XSHE',\n",
       " '002501.XSHE',\n",
       " '002502.XSHE',\n",
       " '002503.XSHE',\n",
       " '002504.XSHE',\n",
       " '002505.XSHE',\n",
       " '002507.XSHE',\n",
       " '002508.XSHE',\n",
       " '002510.XSHE',\n",
       " '002511.XSHE',\n",
       " '002512.XSHE',\n",
       " '002513.XSHE',\n",
       " '002514.XSHE',\n",
       " '002515.XSHE',\n",
       " '002516.XSHE',\n",
       " '002517.XSHE',\n",
       " '002518.XSHE',\n",
       " '002519.XSHE',\n",
       " '002520.XSHE',\n",
       " '002521.XSHE',\n",
       " '002522.XSHE',\n",
       " '002523.XSHE',\n",
       " '002524.XSHE',\n",
       " '002526.XSHE',\n",
       " '002527.XSHE',\n",
       " '002528.XSHE',\n",
       " '002529.XSHE',\n",
       " '002530.XSHE',\n",
       " '002531.XSHE',\n",
       " '002532.XSHE',\n",
       " '002533.XSHE',\n",
       " '300001.XSHE',\n",
       " '300002.XSHE',\n",
       " '300003.XSHE',\n",
       " '300004.XSHE',\n",
       " '300005.XSHE',\n",
       " '300006.XSHE',\n",
       " '300007.XSHE',\n",
       " '300008.XSHE',\n",
       " '300009.XSHE',\n",
       " '300010.XSHE',\n",
       " '300011.XSHE',\n",
       " '300012.XSHE',\n",
       " '300013.XSHE',\n",
       " '300014.XSHE',\n",
       " '300015.XSHE',\n",
       " '300016.XSHE',\n",
       " '300017.XSHE',\n",
       " '300018.XSHE',\n",
       " '300019.XSHE',\n",
       " '300020.XSHE',\n",
       " '300021.XSHE',\n",
       " '300022.XSHE',\n",
       " '300023.XSHE',\n",
       " '300024.XSHE',\n",
       " '300025.XSHE',\n",
       " '300026.XSHE',\n",
       " '300027.XSHE',\n",
       " '300029.XSHE',\n",
       " '300030.XSHE',\n",
       " '300031.XSHE',\n",
       " '300032.XSHE',\n",
       " '300033.XSHE',\n",
       " '300034.XSHE',\n",
       " '300035.XSHE',\n",
       " '300036.XSHE',\n",
       " '300037.XSHE',\n",
       " '300038.XSHE',\n",
       " '300039.XSHE',\n",
       " '300040.XSHE',\n",
       " '300041.XSHE',\n",
       " '300042.XSHE',\n",
       " '300043.XSHE',\n",
       " '300044.XSHE',\n",
       " '300045.XSHE',\n",
       " '300046.XSHE',\n",
       " '300047.XSHE',\n",
       " '300048.XSHE',\n",
       " '300049.XSHE',\n",
       " '300050.XSHE',\n",
       " '300051.XSHE',\n",
       " '300052.XSHE',\n",
       " '300053.XSHE',\n",
       " '300054.XSHE',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_download_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 对于某一投资组合 bin2 计算所有收益率序列\n",
    "address = 'E:/Stock_Data/stock_return_data/'\n",
    "bin2s = ['B_M','OP','Inv','Size']\n",
    "return_inf_used_stock = list(pd.read_csv('E:/Stock_Data/return_inf_used_stock.csv').iloc[:,0])\n",
    "stock_download_return_temp = os.listdir('E:/Stock_Data/stock_return_data/')\n",
    "stock_download_return = [x[:-4] for x in stock_download_return_temp]\n",
    "\n",
    "## 第一层，分组依据\n",
    "for bin2 in bin2s:\n",
    "    portfolio_0 = portfolio[bin2]\n",
    "    \n",
    "    ## 第二层，不同年份\n",
    "    for i in range(8):\n",
    "        year = str(2011+i)\n",
    "        portfolio_1 = portfolio_0[year]\n",
    "        cnt_bin = 0\n",
    "        \n",
    "        ## 第三层，不同小组\n",
    "        for bin1_bin2_type in portfolio_1.keys():\n",
    "            cnt = 0\n",
    "            tol_weight = 0\n",
    "            portfolio_2 = portfolio_1[bin1_bin2_type]\n",
    "            for code_weight in portfolio_2:\n",
    "                \n",
    "                code = code_weight[0]\n",
    "                weight = code_weight[1]\n",
    "                \n",
    "                # 股票由于停牌时间过长被剔除\n",
    "                if code not in stock_download_return:\n",
    "                    continue\n",
    "                \n",
    "                file_name = address+code+'.csv'\n",
    "                r = pd.read_csv(file_name,index_col=0)\n",
    "                \n",
    "                # 读取到的序列过短，剔除\n",
    "                if len(r)<1943:\n",
    "                    continue\n",
    "                \n",
    "                if cnt == 0:\n",
    "                    r_sigma = r*weight\n",
    "                else:\n",
    "                    r_sigma = r_sigma+r*weight\n",
    "                \n",
    "                tol_weight += weight       \n",
    "                cnt+=1  \n",
    "            \n",
    "            ### 求加权平均数，得到一小组的收益率序列\n",
    "            r_mean = r_sigma/tol_weight\n",
    "            r_mean.columns = [bin1_bin2_type]\n",
    "            if cnt_bin == 0:\n",
    "                r_save = r_mean\n",
    "            else:\n",
    "                r_save = pd.concat([r_save,r_mean],axis=1)\n",
    "            cnt_bin += 1\n",
    "        ### 删选当年的数据\n",
    "        r_save_0 = r_save[r_save.index< str(int(year)+1)+'-01-01']\n",
    "        r_save_1 = r_save_0[r_save_0.index> str(int(year)-1)+'-12-31']\n",
    "        ### 每一年拼接\n",
    "        if i == 0:\n",
    "            r_save_year = r_save_1\n",
    "        else:\n",
    "            r_save_year = pd.concat([r_save_year,r_save_1],axis=0)\n",
    "    \n",
    "    ### 完成一个大组的每一年计算后，保存\n",
    "    r_save_year.to_csv('E:/Stock_Data/factor_portfolio/'+bin2+'.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因子计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMB small minus big - Size\n",
    "Size = pd.read_csv('E:/Stock_Data/factor_portfolio/Size.csv',index_col=0).iloc[:1943,:]\n",
    "SMB = Size['Size1'] - Size['Size2']\n",
    "SMB = pd.DataFrame(SMB,columns=['SMB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HML high minus low - B_M\n",
    "B_M = pd.read_csv('E:/Stock_Data/factor_portfolio/B_M.csv',index_col=0).iloc[:1943,:]\n",
    "HML = B_M['B_M3'] - B_M['B_M1']\n",
    "HML = pd.DataFrame(HML,columns=['HML'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMW robust minus weak - OP\n",
    "OP = pd.read_csv('E:/Stock_Data/factor_portfolio/OP.csv',index_col=0).iloc[:1943,:]\n",
    "RMW = OP['OP3'] - OP['OP1']\n",
    "RMW.columns = ['RMW']\n",
    "RMW = pd.DataFrame(RMW,columns=['RMW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMA conservative minus aggressive - Inv\n",
    "Inv = pd.read_csv('E:/Stock_Data/factor_portfolio/Inv.csv',index_col=0).iloc[:1943,:]\n",
    "CMA = Inv['Inv1'] - Inv['Inv3']\n",
    "CMA = pd.DataFrame(CMA,columns=['CMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# market risk，读取投资组合，选取一个标准的全部样本（全样本），计算加权均值，即 Rm\n",
    "\n",
    "# 读取字典\n",
    "f = open('E:/Stock_Data/factor_portfolio/portfolio.txt','r')\n",
    "a = f.read()\n",
    "portfolio = eval(a)\n",
    "f.close()\n",
    "portfolio_0 = portfolio['Size']\n",
    "## 第二层，不同年份\n",
    "for i in range(8):\n",
    "    year = str(2011+i)\n",
    "    portfolio_1 = portfolio_0[year]\n",
    "    tol_weight = 0 # 把总权重放置年份后，对每小组不再单独求和，即Size1+Size2=全股票\n",
    "    cnt = 0 # 进对每一年清零计数\n",
    "\n",
    "    ## 第三层，不同小组\n",
    "    for bin1_bin2_type in portfolio_1.keys():\n",
    "\n",
    "\n",
    "        portfolio_2 = portfolio_1[bin1_bin2_type]\n",
    "        for code_weight in portfolio_2:\n",
    "\n",
    "            code = code_weight[0]\n",
    "            weight = code_weight[1]\n",
    "\n",
    "            # 股票由于停牌时间过长被剔除\n",
    "            if code not in stock_download_return:\n",
    "                continue\n",
    "\n",
    "            file_name = address+code+'.csv'\n",
    "            r = pd.read_csv(file_name,index_col=0)\n",
    "\n",
    "            # 读取到的序列过短，剔除\n",
    "            if len(r)<1943:\n",
    "                continue\n",
    "\n",
    "            if cnt == 0:\n",
    "                r_sigma = r*weight\n",
    "            else:\n",
    "                r_sigma = r_sigma+r*weight\n",
    "\n",
    "            tol_weight += weight       \n",
    "            cnt+=1  \n",
    "\n",
    "    ### 求加权平均数，得到一年的收益率序列\n",
    "    r_mean = r_sigma/tol_weight\n",
    "    r_save = r_mean\n",
    "\n",
    "    ### 删选当年的数据\n",
    "    r_save_0 = r_save[r_save.index< str(int(year)+1)+'-01-01']\n",
    "    r_save_1 = r_save_0[r_save_0.index> str(int(year)-1)+'-12-31']\n",
    "    ### 每一年拼接\n",
    "    if i == 0:\n",
    "        r_save_year = r_save_1\n",
    "    else:\n",
    "        r_save_year = pd.concat([r_save_year,r_save_1],axis=0)\n",
    "\n",
    "### 完成一个大组的每一年计算后，保存\n",
    "r_save_year.columns = ['return']\n",
    "r_save_year.to_csv('E:/Stock_Data/factor_portfolio/MarketRisk.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MKTF\n",
    "MKT = pd.read_csv('E:/Stock_Data/factor_portfolio/MarketRisk.csv',index_col=0).iloc[:1943,:]\n",
    "MKTF = MKT - rf\n",
    "MKTF.columns = ['MKTF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MKT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1bb1b751cbe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrf_temp_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:/Stock_Data/t_bill_one_year.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'日期'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'收盘'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrf_temp_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_temp_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'日期'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(.*?)年(.*?)月(.*?)日'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(.*?)年(.*?)月(.*?)日'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mrf_temp_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMKT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_temp_0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleft_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'收盘'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mrf_temp_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_temp_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_temp_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mrf_temp_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'return'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MKT' is not defined"
     ]
    }
   ],
   "source": [
    "# rf\n",
    "import re\n",
    "rf_temp_0 = pd.read_csv('E:/Stock_Data/t_bill_one_year.csv')[['日期','收盘']]\n",
    "rf_temp_0.index = rf_temp_0['日期'].apply(lambda x: x[:4]+'-'+re.findall('(.*?)年(.*?)月(.*?)日',x)[0][1].zfill(2)+'-'+re.findall('(.*?)年(.*?)月(.*?)日',x)[0][2].zfill(2))\n",
    "rf_temp_1 = pd.merge(left = MKT,right = rf_temp_0,left_index = True,right_index=True,how='left')[['收盘']]\n",
    "rf_temp_2 = rf_temp_1.fillna(rf_temp_1.mean())\n",
    "rf_temp_2.columns = ['return']\n",
    "rf = rf_temp_2/252/100\n",
    "rf.to_csv('E:/Stock_Data/rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入日历效应哑变量 - 星期\n",
    "sample_df = pd.read_csv('E:/Stock_Data/stock_return_data/001896.XSHE.csv',index_col=0)\n",
    "trade_day_serises = list(sample_df.index)\n",
    "\n",
    "trade_day_df = pd.DataFrame(trade_day_serises)\n",
    "trade_day_df.columns = ['weekday']\n",
    "trade_day_df['weekday'] = trade_day_df['weekday'].apply(lambda x : datetime.datetime.strptime(x, \"%Y-%m-%d\").weekday()+1)\n",
    "\n",
    "dummy_df = pd.get_dummies(trade_day_df['weekday'])\n",
    "dummy_df = dummy_df[[1,2,3,4,5]]\n",
    "dummy_df.index = sample_df.index\n",
    "\n",
    "X = dummy_df.iloc[:1943,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   -0.000484\n",
      "2    0.000467\n",
      "3    0.000099\n",
      "4   -0.001767\n",
      "5    0.000647\n",
      "dtype: float64\n",
      "1    0.491212\n",
      "2    0.498646\n",
      "3    0.884824\n",
      "4    0.010359\n",
      "5    0.349133\n",
      "dtype: float64\n",
      "1   -0.000056\n",
      "2    0.000641\n",
      "3    0.000765\n",
      "4   -0.000763\n",
      "5   -0.000571\n",
      "dtype: float64\n",
      "1    0.924734\n",
      "2    0.267614\n",
      "3    0.182846\n",
      "4    0.185843\n",
      "5    0.324120\n",
      "dtype: float64\n",
      "1    0.000911\n",
      "2   -0.000229\n",
      "3   -0.000039\n",
      "4    0.001197\n",
      "5    0.001046\n",
      "dtype: float64\n",
      "1    0.123331\n",
      "2    0.692712\n",
      "3    0.946678\n",
      "4    0.038811\n",
      "5    0.072119\n",
      "dtype: float64\n",
      "1    0.000593\n",
      "2   -0.000278\n",
      "3    0.000253\n",
      "4    0.000077\n",
      "5   -0.000220\n",
      "dtype: float64\n",
      "1    0.037010\n",
      "2    0.320136\n",
      "3    0.360773\n",
      "4    0.783021\n",
      "5    0.431464\n",
      "dtype: float64\n",
      "1   -0.000327\n",
      "2    0.000082\n",
      "3   -0.000290\n",
      "4    0.001145\n",
      "5    0.000890\n",
      "dtype: float64\n",
      "1    0.547852\n",
      "2    0.877428\n",
      "3    0.584072\n",
      "4    0.031478\n",
      "5    0.095713\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 检验各因子的周四效应\n",
    "X = dummy_df.iloc[:1943,:]\n",
    "for factor in [MKTF,SMB,HML,CMA,RMW]:\n",
    "    y = factor\n",
    "\n",
    "    est = sm.OLS(y,X)\n",
    "    result = est.fit()\n",
    "\n",
    "    print(result.params)\n",
    "    print(result.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得5因子中具有公司特征的4个因子分组的投资组合收益率数据，观察负周四效应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成分组标识\n",
    "bin_df = pd.read_csv('E:/Stock_Data/bin_data.csv',index_col=0)\n",
    "for col in ['B_M', 'OP','pe_ratio']:\n",
    "    if isinstance(bin_df[col][0],float):\n",
    "        bin_df[col] = bin_df[col].apply(lambda x : np.nan if x<0 else x)\n",
    "bin_df = bin_df.dropna(how='any',axis=0)\n",
    "\n",
    "## 分组组数\n",
    "bin_num = 8\n",
    "\n",
    "for i in range(8):\n",
    "    \n",
    "    year = str(2010+i)+'-12-31'\n",
    "    temp_df_0 = bin_df[bin_df.date==year]\n",
    "    \n",
    "    # 计算当年总行数\n",
    "    stock_num = len(temp_df_0)\n",
    "    \n",
    "    for bin_kind in ['B_M','OP','Inv','Size']:\n",
    "        \n",
    "        # 生成分组标识\n",
    "        bin_lst = []\n",
    "        for i in range(bin_num):\n",
    "            bin_lst += [bin_kind+str(i+1)]*int(stock_num/bin_num)\n",
    "        if len(bin_lst) != stock_num:\n",
    "            bin_lst += [bin_kind+str(i+1)]*(stock_num-len(bin_lst))\n",
    "        \n",
    "        temp_df_0 = temp_df_0.sort_values(bin_kind)\n",
    "        temp_df_0[bin_kind] = bin_lst\n",
    "    \n",
    "    temp_df_1 = bin_df[bin_df.date==year]\n",
    "    temp_df_1 = temp_df_1.sort_values('Size') # 和df_0对齐，最后一次是按照Size排序的\n",
    "    temp_df_0['S']=temp_df_1['Size']\n",
    "    temp_df_0.to_csv('E:/Stock_Data/factor_portfolio/5factor'+year+'.csv',index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "新加一个融资融券标的因子↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按要求生成投资组合\n",
    "\n",
    "# 保存在字典：除B_M以外的另一个组别 -> 年份 -> bin1 与 bin2 单独！ -> 组合，stock code list\n",
    "\n",
    "portfolio={}\n",
    "\n",
    "for bin2 in ['B_M','OP','Inv','margin','Size']:\n",
    "    portfolio[bin2] = {}\n",
    "    \n",
    "    for i in range(8):\n",
    "        year = str(2010+i)+'-12-31'\n",
    "        portfolio[bin2][str(2011+i)]={}\n",
    "        \n",
    "        temp_df_0 = pd.read_csv('E:/Stock_Data/factor_portfolio/5factor'+year+'.csv',index_col=0)\n",
    "        bin2_lst = list(set(temp_df_0[bin2]))\n",
    "        \n",
    "        for bin2_ in bin2_lst:  \n",
    "            temp_df_2 = temp_df_0[temp_df_0[bin2]==bin2_]\n",
    "            list_code_value = [list(temp_df_2[['code','S']].iloc[i,:]) for i in range(len(temp_df_2))]\n",
    "            portfolio[bin2][str(2011+i)][bin2_] = list_code_value\n",
    "# 保存字典\n",
    "f = open('E:/Stock_Data/factor_portfolio/5factor_portfolio.txt','w')\n",
    "f.write(str(portfolio))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取字典\n",
    "f = open('E:/Stock_Data/factor_portfolio/5factor_portfolio.txt','r')\n",
    "a = f.read()\n",
    "portfolio = eval(a)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 对于某一投资组合 bin2 计算所有收益率序列 - 市值加权平均\n",
    "address = 'E:/Stock_Data/stock_return_data/'\n",
    "\n",
    "bin2s = ['B_M','OP','Inv','margin','Size']\n",
    "stock_download_return_temp = os.listdir('E:/Stock_Data/stock_return_data/')\n",
    "stock_download_return = [x[:-4] for x in stock_download_return_temp]\n",
    "\n",
    "## 第一层，分组依据\n",
    "for bin2 in bin2s:\n",
    "    portfolio_0 = portfolio[bin2]\n",
    "    \n",
    "    ## 第二层，不同年份\n",
    "    for i in range(8):\n",
    "        year = str(2011+i)\n",
    "        portfolio_1 = portfolio_0[year]\n",
    "        cnt_bin = 0\n",
    "        \n",
    "        ## 第三层，不同小组\n",
    "        for bin1_bin2_type in portfolio_1.keys():\n",
    "            cnt = 0\n",
    "            tol_weight = 0\n",
    "            portfolio_2 = portfolio_1[bin1_bin2_type]\n",
    "            for code_weight in portfolio_2:\n",
    "                \n",
    "                code = code_weight[0]\n",
    "                weight = code_weight[1]\n",
    "                \n",
    "                # 股票由于停牌时间过长被剔除\n",
    "                if code not in stock_download_return:\n",
    "                    continue\n",
    "                \n",
    "                file_name = address+code+'.csv'\n",
    "                r = pd.read_csv(file_name,index_col=0)\n",
    "                \n",
    "                # 读取到的序列过短，剔除\n",
    "                if len(r)<1943:\n",
    "                    continue\n",
    "                \n",
    "                if cnt == 0:\n",
    "                    r_sigma = r*weight\n",
    "                else:\n",
    "                    r_sigma = r_sigma+r*weight\n",
    "                \n",
    "                tol_weight += weight       \n",
    "                cnt+=1  \n",
    "            \n",
    "            ### 求加权平均数，得到一小组的收益率序列\n",
    "            r_mean = r_sigma/tol_weight\n",
    "            r_mean.columns = [bin1_bin2_type]\n",
    "            if cnt_bin == 0:\n",
    "                r_save = r_mean\n",
    "            else:\n",
    "                r_save = pd.concat([r_save,r_mean],axis=1)\n",
    "            cnt_bin += 1\n",
    "        ### 删选当年的数据\n",
    "        r_save_0 = r_save[r_save.index< str(int(year)+1)+'-01-01']\n",
    "        r_save_1 = r_save_0[r_save_0.index> str(int(year)-1)+'-12-31']\n",
    "        ### 每一年拼接\n",
    "        if i == 0:\n",
    "            r_save_year = r_save_1\n",
    "        else:\n",
    "            r_save_year = pd.concat([r_save_year,r_save_1],axis=0)\n",
    "    \n",
    "    ### 完成一个大组的每一年计算后，保存\n",
    "    r_save_year.to_csv('E:/Stock_Data/factor_portfolio/singlebin_'+bin2+'.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin2s = ['B_M','OP','Inv','Size']\n",
    "\n",
    "for bin2 in bin2s:\n",
    "    return_df = pd.read_csv('E:/Stock_Data/factor_portfolio/singlebin_'+bin2+'.csv',index_col=0)\n",
    "    return_df = return_df.dropna(how=\"any\",axis=0)\n",
    "    bin2_list = [bin2+str(i+1) for i in range(8)]\n",
    "    bin1_bin2_save_df = pd.DataFrame(index=[''],columns=bin2_list)\n",
    "    \n",
    "    col = 0\n",
    "    for bin2_ in bin2_list:\n",
    "        bin1_bin2_ = bin2_\n",
    "        # y减去无风险收益率\n",
    "        y_temp = return_df.iloc[:1943,:]\n",
    "        y = y_temp[bin1_bin2_]\n",
    "        X = dummy_df.iloc[:1943,:]\n",
    "\n",
    "#             # 用Garch\n",
    "#             reg = arch_model(y, x=X, mean='HARX', lags=0, vol='Garch', p=1, o=0, q=1, power=1.0, dist='ged', hold_back=None)\n",
    "#             result = reg.fit()\n",
    "\n",
    "        # 用OLS\n",
    "#             X = sm.add_constant(X)\n",
    "        est = sm.OLS(y,X)\n",
    "        result = est.fit()           \n",
    "\n",
    "        calandar_effect = list(result.params)[3]\n",
    "\n",
    "        # 测试 - 结果矩阵形式保存\n",
    "        bin1_bin2_save_df.iloc[0,col] = calandar_effect\n",
    "\n",
    "        col += 1\n",
    "    # 保存\n",
    "    bin1_bin2_save_df.to_csv('E:/Stock_Data/factor_portfolio/'+ bin2 +'8bin_result.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "新加一个融资融券标的因子↓计算分组负周四效应-它不是8个组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于某一投资组合 bin2 计算所有收益率序列 - 算术&加权 平均\n",
    "address = 'E:/Stock_Data/stock_return_data/'\n",
    "\n",
    "bin2s = ['margin']\n",
    "stock_download_return_temp = os.listdir('E:/Stock_Data/stock_return_data/')\n",
    "stock_download_return = [x[:-4] for x in stock_download_return_temp]\n",
    "\n",
    "## 第一层，分组依据\n",
    "for bin2 in bin2s:\n",
    "    portfolio_0 = portfolio[bin2]\n",
    "    \n",
    "    ## 第二层，不同年份\n",
    "    for i in range(8):\n",
    "        year = str(2011+i)\n",
    "        portfolio_1 = portfolio_0[year]\n",
    "        cnt_bin = 0\n",
    "        \n",
    "        ## 第三层，不同小组\n",
    "        for bin1_bin2_type in portfolio_1.keys():\n",
    "            cnt = 0\n",
    "            tol_weight = 0\n",
    "            portfolio_2 = portfolio_1[bin1_bin2_type]\n",
    "            for code_weight in portfolio_2:\n",
    "                \n",
    "                code = code_weight[0]\n",
    "                weight = code_weight[1]\n",
    "                \n",
    "                # 股票由于停牌时间过长被剔除\n",
    "                if code not in stock_download_return:\n",
    "                    continue\n",
    "                \n",
    "                file_name = address+code+'.csv'\n",
    "                r = pd.read_csv(file_name,index_col=0)\n",
    "                \n",
    "                # 读取到的序列过短，剔除\n",
    "                if len(r)<1943:\n",
    "                    continue\n",
    "                \n",
    "                if cnt == 0:\n",
    "                    r_sigma = r\n",
    "                    r_sigma_w = r*weight\n",
    "                else:\n",
    "                    r_sigma = r_sigma+r\n",
    "                    r_sigma_w = r_sigma_w+r*weight\n",
    "                \n",
    "                tol_weight += weight       \n",
    "                cnt+=1  \n",
    "            \n",
    "            ### 求加权平均数，得到一小组的收益率序列\n",
    "            r_mean = r_sigma/cnt\n",
    "            r_mean_w = r_sigma_w/tol_weight\n",
    "            \n",
    "            r_mean.columns = [bin1_bin2_type]\n",
    "            r_mean_w.columns = [bin1_bin2_type]\n",
    "            \n",
    "            if cnt_bin == 0:\n",
    "                r_save = r_mean\n",
    "                r_save_w = r_mean_w\n",
    "            else:\n",
    "                r_save = pd.concat([r_save,r_mean],axis=1)\n",
    "                r_save_w = pd.concat([r_save_w,r_mean_w],axis=1)\n",
    "            cnt_bin += 1\n",
    "        ### 删选当年的数据\n",
    "        r_save_0 = r_save[r_save.index< str(int(year)+1)+'-01-01']\n",
    "        r_save_1 = r_save_0[r_save_0.index> str(int(year)-1)+'-12-31']\n",
    "        r_save_0_w = r_save_w[r_save_w.index< str(int(year)+1)+'-01-01']\n",
    "        r_save_1_w = r_save_0_w[r_save_0_w.index> str(int(year)-1)+'-12-31']\n",
    "        ### 每一年拼接\n",
    "        if i == 0:\n",
    "            r_save_year = r_save_1\n",
    "            r_save_year_w = r_save_1_w\n",
    "        else:\n",
    "            r_save_year = pd.concat([r_save_year,r_save_1],axis=0)\n",
    "            r_save_year_w = pd.concat([r_save_year_w,r_save_1_w],axis=0)\n",
    "    \n",
    "    ### 完成一个大组的每一年计算后，保存\n",
    "    r_save_year.to_csv('E:/Stock_Data/factor_portfolio/singlebin_'+bin2+'mean.csv',index=True)\n",
    "    r_save_year_w.to_csv('E:/Stock_Data/factor_portfolio/singlebin_'+bin2+'weight.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bin2s = ['margin']\n",
    "\n",
    "for how in ['mean','weight']:\n",
    "    for bin2 in bin2s:\n",
    "        return_df = pd.read_csv('E:/Stock_Data/factor_portfolio/singlebin_'+bin2+how+'.csv',index_col=0)\n",
    "        return_df = return_df.dropna(how=\"any\",axis=0)\n",
    "        bin2_list = ['margin','Nomargin']\n",
    "        bin1_bin2_save_df = pd.DataFrame(index=['calandar_effect','Pvalue'],columns=bin2_list)\n",
    "\n",
    "        col = 0\n",
    "        for bin2_ in bin2_list:\n",
    "            bin1_bin2_ = bin2_\n",
    "            # y减去无风险收益率\n",
    "            y_temp = return_df.iloc[:1943,:]\n",
    "            y = y_temp[bin1_bin2_]\n",
    "            X = dummy_df.iloc[:1943,:]\n",
    "\n",
    "            # 用OLS\n",
    "    #             X = sm.add_constant(X)\n",
    "            est = sm.OLS(y,X)\n",
    "            result = est.fit()           \n",
    "\n",
    "            calandar_effect = list(result.params)[3]\n",
    "            calandar_effect_sig = list(result.pvalues)[3]\n",
    "\n",
    "            # 测试 - 结果矩阵形式保存\n",
    "            bin1_bin2_save_df.iloc[0,col] = calandar_effect\n",
    "            bin1_bin2_save_df.iloc[1,col] = calandar_effect_sig\n",
    "\n",
    "            col += 1\n",
    "        # 保存\n",
    "        bin1_bin2_save_df.to_csv('E:/Stock_Data/factor_portfolio/'+ bin2 +how+'2bin_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 融资融券与非融资融券组的差别\n",
    "r_margin_temp=pd.read_csv('E:/Stock_Data/factor_portfolio/singlebin_marginweight.csv',index_col=0)\n",
    "r_margin=r_margin_temp.iloc[:1943,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时段 1 指数 margin \n",
      "系数 {1: '-0.000246', 2: '0.000574', 3: '0.000094', 4: '-0.001385', 5: '0.000900'} \n",
      "P值 {1: '0.722153', 2: '0.398582', 3: '0.889169', 4: '0.041162', 5: '0.186248'} \n",
      "F统计量P值 0.148441 \n",
      "\n",
      "时段 1 指数 Nomargin \n",
      "系数 {1: '-0.000621', 2: '0.000852', 3: '0.000557', 4: '-0.002317', 5: '0.000317'} \n",
      "P值 {1: '0.480311', 2: '0.324214', 3: '0.515601', 4: '0.007216', 5: '0.714275'} \n",
      "F统计量P值 0.064645 \n",
      "\n",
      "LeveneResult(statistic=8.69309655535009, pvalue=0.003289313680274249)\n",
      "Ttest_relResult(statistic=1.97967816091891, pvalue=0.048440559705695475)\n",
      "Ttest_indResult(statistic=0.8758219509787907, pvalue=0.38140475603593404)\n",
      "时段 2 指数 margin \n",
      "系数 {1: '0.000067', 2: '0.000789', 3: '-0.000007', 4: '-0.001308', 5: '0.000896'} \n",
      "P值 {1: '0.929173', 2: '0.290259', 3: '0.992627', 4: '0.079646', 5: '0.231599'} \n",
      "F统计量P值 0.234255 \n",
      "\n",
      "时段 2 指数 Nomargin \n",
      "系数 {1: '-0.000072', 2: '0.001288', 3: '0.000355', 4: '-0.002021', 5: '0.000277'} \n",
      "P值 {1: '0.940296', 2: '0.170311', 3: '0.703836', 4: '0.031579', 5: '0.769279'} \n",
      "F统计量P值 0.150802 \n",
      "\n",
      "LeveneResult(statistic=6.0118407285635245, pvalue=0.014459859410924123)\n",
      "Ttest_relResult(statistic=1.3925130540556803, pvalue=0.1646744097517775)\n",
      "Ttest_indResult(statistic=0.6175946131206809, pvalue=0.5370550870176457)\n",
      "时段 3 指数 margin \n",
      "系数 {1: '-0.000287', 2: '0.000555', 3: '0.000694', 4: '-0.001323', 5: '0.001031'} \n",
      "P值 {1: '0.699145', 2: '0.447383', 3: '0.338987', 4: '0.069515', 5: '0.158611'} \n",
      "F统计量P值 0.149939 \n",
      "\n",
      "时段 3 指数 Nomargin \n",
      "系数 {1: '-0.000786', 2: '0.000947', 3: '0.001163', 4: '-0.001993', 5: '0.000725'} \n",
      "P值 {1: '0.410035', 2: '0.313144', 3: '0.212365', 4: '0.033332', 5: '0.439825'} \n",
      "F统计量P值 0.078957 \n",
      "\n",
      "LeveneResult(statistic=7.70522583526961, pvalue=0.0056566388210423655)\n",
      "Ttest_relResult(statistic=1.3329808284773914, pvalue=0.18342538563648342)\n",
      "Ttest_indResult(statistic=0.590784612438807, pvalue=0.5548656228416156)\n",
      "时段 4 指数 margin \n",
      "系数 {1: '0.000582', 2: '0.000749', 3: '0.000060', 4: '-0.001505', 5: '0.000450'} \n",
      "P值 {1: '0.493344', 2: '0.368245', 3: '0.942462', 4: '0.072289', 5: '0.592126'} \n",
      "F统计量P值 0.311474 \n",
      "\n",
      "时段 4 指数 Nomargin \n",
      "系数 {1: '0.000255', 2: '0.001387', 3: '0.000495', 4: '-0.002067', 5: '-0.000196'} \n",
      "P值 {1: '0.809920', 2: '0.181636', 3: '0.632075', 4: '0.047745', 5: '0.851236'} \n",
      "F统计量P值 0.197412 \n",
      "\n",
      "LeveneResult(statistic=3.2971897001271495, pvalue=0.06991294590147056)\n",
      "Ttest_relResult(statistic=0.9858719265779292, pvalue=0.3250149520719591)\n",
      "Ttest_indResult(statistic=0.4346411385683291, pvalue=0.6639881335201241)\n",
      "时段 5 指数 margin \n",
      "系数 {1: '-0.000612', 2: '0.000401', 3: '0.000737', 4: '-0.001478', 5: '0.001187'} \n",
      "P值 {1: '0.474507', 2: '0.634073', 3: '0.379366', 4: '0.079545', 5: '0.160640'} \n",
      "F统计量P值 0.162783 \n",
      "\n",
      "时段 5 指数 Nomargin \n",
      "系数 {1: '-0.000560', 2: '0.000984', 3: '0.001358', 4: '-0.002009', 5: '0.000939'} \n",
      "P值 {1: '0.607487', 2: '0.359336', 3: '0.203484', 4: '0.061359', 5: '0.383502'} \n",
      "F统计量P值 0.142220 \n",
      "\n",
      "LeveneResult(statistic=6.627440452205484, pvalue=0.010287150154492204)\n",
      "Ttest_relResult(statistic=0.9340766300751722, pvalue=0.3510361327457161)\n",
      "Ttest_indResult(statistic=0.4059967653389264, pvalue=0.6848979315534107)\n"
     ]
    }
   ],
   "source": [
    "# 指数角度检验 - 周历效应 - 分时段\n",
    "rf = pd.read_csv('E:/Stock_Data/rf.csv',index_col=0)\n",
    "dummy_df=dummy_df.iloc[:1943,]\n",
    "for time in range(5):\n",
    "    t_test_lst=[]\n",
    "#     start = str(2011+time)+'-01-04'\n",
    "#     end = '2018-12-28'\n",
    "    \n",
    "    if time ==0:\n",
    "        start = '2011-01-04'\n",
    "        end = '2018-12-31'\n",
    "    if time ==1:\n",
    "        start = '2012-01-01'\n",
    "        end = '2018-12-31'\n",
    "    if time ==2:\n",
    "        start = '2011-01-01'\n",
    "        end = '2017-12-31'\n",
    "    if time ==3:\n",
    "        start = '2013-01-01'\n",
    "        end = '2018-12-31'\n",
    "    if time ==4:\n",
    "        start = '2011-01-01'\n",
    "        end = '2016-12-31'\n",
    "#     if time ==3:\n",
    "#         start = '2014-01-01'\n",
    "#         end = '2015-12-31'\n",
    "#     if time ==4:\n",
    "#         start = '2015-01-01'\n",
    "#         end = '2016-12-31'\n",
    "    \n",
    "    index_save_dct = {1:0,2:0,3:0,4:0,5:0}\n",
    "    index_p_save_dct = {1:0,2:0,3:0,4:0,5:0}\n",
    "    for index in ['margin','Nomargin']:\n",
    "        \n",
    "        index_df = r_margin[[index]]\n",
    "        index_df.columns=['return']\n",
    "\n",
    "        index_df = index_df[index_df.index>start]\n",
    "        index_df = index_df[index_df.index<end]\n",
    "        X = dummy_df[dummy_df.index>start]\n",
    "        X = X[X.index<end]\n",
    "        y = index_df\n",
    "        \n",
    "        tol_y_X = pd.concat([y,X],axis=1)\n",
    "        t_test_lst.append(list(tol_y_X[tol_y_X[4]==1]['return']))\n",
    "\n",
    "        # 用OLS\n",
    "        # 是否使用超额收益率\n",
    "#         temp_y = pd.merge(y,rf,left_index=True,right_index=True,how='left').fillna(rf.mean())\n",
    "#         y = temp_y[['return_x']]\n",
    "#         y.columns=['return']\n",
    "#         rf = temp_y[['return_y']]\n",
    "#         rf.columns=['return']\n",
    "#         y = y - rf\n",
    "\n",
    "        est = sm.OLS(y,X)\n",
    "        result = est.fit()\n",
    "        for i in range(5):\n",
    "            index_save_dct[i+1] = '%.6f' %list(result.params)[i]\n",
    "        for i in range(5):\n",
    "            index_p_save_dct[i+1] = '%.6f' %list(result.pvalues)[i]\n",
    "        f_p = '%.6f' %result.f_pvalue\n",
    "        \n",
    "        print('时段',time+1,'指数',index,'\\n系数',index_save_dct,'\\nP值',index_p_save_dct,'\\nF统计量P值',f_p,'\\n')\n",
    "    print(stats.levene(t_test_lst[0],t_test_lst[1]))\n",
    "    print(stats.ttest_rel(t_test_lst[0],t_test_lst[1]))\n",
    "    print(stats.ttest_ind(t_test_lst[0],t_test_lst[1],equal_var = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 对于某一投资组合 bin2 计算所有收益率序列 - 算术平均\n",
    "address = 'E:/Stock_Data/stock_return_data/'\n",
    "\n",
    "bin2s = ['B_M','OP','Inv','Size']\n",
    "stock_download_return_temp = os.listdir('E:/Stock_Data/stock_return_data/')\n",
    "stock_download_return = [x[:-4] for x in stock_download_return_temp]\n",
    "\n",
    "## 第一层，分组依据\n",
    "for bin2 in bin2s:\n",
    "    portfolio_0 = portfolio[bin2]\n",
    "    \n",
    "    ## 第二层，不同年份\n",
    "    for i in range(8):\n",
    "        year = str(2011+i)\n",
    "        portfolio_1 = portfolio_0[year]\n",
    "        cnt_bin = 0\n",
    "        \n",
    "        ## 第三层，不同小组\n",
    "        for bin1_bin2_type in portfolio_1.keys():\n",
    "            cnt = 0\n",
    "            tol_weight = 0\n",
    "            portfolio_2 = portfolio_1[bin1_bin2_type]\n",
    "            for code_weight in portfolio_2:\n",
    "                \n",
    "                code = code_weight[0]\n",
    "                weight = code_weight[1]\n",
    "                \n",
    "                # 股票由于停牌时间过长被剔除\n",
    "                if code not in stock_download_return:\n",
    "                    continue\n",
    "                \n",
    "                file_name = address+code+'.csv'\n",
    "                r = pd.read_csv(file_name,index_col=0)\n",
    "                \n",
    "                # 读取到的序列过短，剔除\n",
    "                if len(r)<1943:\n",
    "                    continue\n",
    "                \n",
    "                if cnt == 0:\n",
    "                    r_sigma = r\n",
    "                else:\n",
    "                    r_sigma = r_sigma+r\n",
    "                \n",
    "                cnt+=1  \n",
    "            \n",
    "            ### 求加权平均数，得到一小组的收益率序列\n",
    "            r_mean = r_sigma/cnt\n",
    "            r_mean.columns = [bin1_bin2_type]\n",
    "            if cnt_bin == 0:\n",
    "                r_save = r_mean\n",
    "            else:\n",
    "                r_save = pd.concat([r_save,r_mean],axis=1)\n",
    "            cnt_bin += 1\n",
    "        ### 删选当年的数据\n",
    "        r_save_0 = r_save[r_save.index< str(int(year)+1)+'-01-01']\n",
    "        r_save_1 = r_save_0[r_save_0.index> str(int(year)-1)+'-12-31']\n",
    "        ### 每一年拼接\n",
    "        if i == 0:\n",
    "            r_save_year = r_save_1\n",
    "        else:\n",
    "            r_save_year = pd.concat([r_save_year,r_save_1],axis=0)\n",
    "    \n",
    "    ### 完成一个大组的每一年计算后，保存\n",
    "    r_save_year.to_csv('E:/Stock_Data/factor_portfolio/singlebin_mean_'+bin2+'.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bin2s = ['B_M','OP','Inv','Size']\n",
    "\n",
    "for bin2 in bin2s:\n",
    "    return_df = pd.read_csv('E:/Stock_Data/factor_portfolio/singlebin_mean_'+bin2+'.csv',index_col=0)\n",
    "    return_df = return_df.dropna(how=\"any\",axis=0)\n",
    "    bin2_list = [bin2+str(i+1) for i in range(8)]\n",
    "    bin1_bin2_save_df = pd.DataFrame(index=[''],columns=bin2_list)\n",
    "    \n",
    "    col = 0\n",
    "    for bin2_ in bin2_list:\n",
    "        bin1_bin2_ = bin2_\n",
    "        # y减去无风险收益率\n",
    "        y_temp = return_df.iloc[:1943,:]\n",
    "        y = y_temp[bin1_bin2_]\n",
    "        X = dummy_df.iloc[:1943,:]\n",
    "\n",
    "#             # 用Garch\n",
    "#             reg = arch_model(y, x=X, mean='HARX', lags=0, vol='Garch', p=1, o=0, q=1, power=1.0, dist='ged', hold_back=None)\n",
    "#             result = reg.fit()\n",
    "\n",
    "        # 用OLS\n",
    "#             X = sm.add_constant(X)\n",
    "        est = sm.OLS(y,X)\n",
    "        result = est.fit()           \n",
    "\n",
    "        calandar_effect = list(result.params)[3]\n",
    "\n",
    "        # 测试 - 结果矩阵形式保存\n",
    "        bin1_bin2_save_df.iloc[0,col] = calandar_effect\n",
    "\n",
    "        col += 1\n",
    "    # 保存\n",
    "    bin1_bin2_save_df.to_csv('E:/Stock_Data/factor_portfolio/'+ bin2 +'8bin_result_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 计算得到年份平均的公司特征指标，对负周四效应回归\n",
    "bin_data_df = pd.read_csv('E:/Stock_Data/bin_data.csv')\n",
    "for col in ['B_M', 'OP','pe_ratio']:\n",
    "    if isinstance(bin_data_df[col][0],float):\n",
    "        bin_data_df[col] = bin_data_df[col].apply(lambda x : np.nan if x<0 else x)\n",
    "bin_data_df = bin_data_df.dropna(how='any',axis=0)\n",
    "\n",
    "# 剔除异常值\n",
    "bin_data_df_mean = bin_data_df.groupby('code').mean()\n",
    "bin_data_df_mean = bin_data_df_mean.sort_values('OP').iloc[int(len(bin_data_df_mean)*0.01):int(len(bin_data_df_mean)*0.99),]\n",
    "bin_data_df_mean = bin_data_df_mean.sort_values('Inv').iloc[int(len(bin_data_df_mean)*0.01):int(len(bin_data_df_mean)*0.99),]\n",
    "bin_data_df_mean = bin_data_df_mean.sort_values('Size').iloc[int(len(bin_data_df_mean)*0.01):int(len(bin_data_df_mean)*0.99),]\n",
    "\n",
    "Fama_beta_Thu = pd.read_csv('E:/Stock_Data/Fama_beta_Thu.csv',index_col=0)\n",
    "bin_data_Thu = pd.merge(Fama_beta_Thu,bin_data_df_mean,left_index=True,right_index=True,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin_data_Thu.describe().to_csv('E:/Stock_Data/describe_data/bin_data_Thu_haveOutPoint.csv')\n",
    "bin_data_Thu.describe().to_csv('E:/Stock_Data/describe_data/bin_data_Thu_noOutPoint.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "显著结果统计0.1 {1: 69, 2: 55, 3: 30, 4: 372, 5: 55} \n",
      "显著结果中正负统计 {1: 11, 2: 54, 3: 29, 4: 0, 5: 51} \n",
      "总数 709\n",
      "0.5246826516220028\n",
      "显著结果统计0.1 {1: 63, 2: 52, 3: 26, 4: 330, 5: 51} \n",
      "显著结果中正负统计 {1: 11, 2: 51, 3: 25, 4: 0, 5: 48} \n",
      "总数 639\n",
      "0.5164319248826291\n",
      "显著结果统计0.1 {1: 58, 2: 48, 3: 25, 4: 296, 5: 47} \n",
      "显著结果中正负统计 {1: 11, 2: 47, 3: 24, 4: 0, 5: 44} \n",
      "总数 567\n",
      "0.5220458553791887\n",
      "显著结果统计0.1 {1: 47, 2: 44, 3: 20, 4: 251, 5: 42} \n",
      "显著结果中正负统计 {1: 10, 2: 43, 3: 19, 4: 0, 5: 39} \n",
      "总数 493\n",
      "0.5091277890466531\n",
      "显著结果统计0.1 {1: 39, 2: 41, 3: 18, 4: 213, 5: 38} \n",
      "显著结果中正负统计 {1: 9, 2: 40, 3: 17, 4: 0, 5: 35} \n",
      "总数 422\n",
      "0.504739336492891\n",
      "显著结果统计0.1 {1: 35, 2: 36, 3: 18, 4: 173, 5: 34} \n",
      "显著结果中正负统计 {1: 8, 2: 35, 3: 17, 4: 0, 5: 31} \n",
      "总数 349\n",
      "0.49570200573065903\n",
      "显著结果统计0.1 {1: 32, 2: 29, 3: 15, 4: 136, 5: 28} \n",
      "显著结果中正负统计 {1: 6, 2: 28, 3: 14, 4: 0, 5: 25} \n",
      "总数 279\n",
      "0.4874551971326165\n",
      "显著结果统计0.1 {1: 27, 2: 22, 3: 11, 4: 100, 5: 25} \n",
      "显著结果中正负统计 {1: 6, 2: 21, 3: 11, 4: 0, 5: 24} \n",
      "总数 210\n",
      "0.47619047619047616\n",
      "显著结果统计0.1 {1: 21, 2: 15, 3: 7, 4: 57, 5: 17} \n",
      "显著结果中正负统计 {1: 5, 2: 15, 3: 7, 4: 0, 5: 16} \n",
      "总数 141\n",
      "0.40425531914893614\n",
      "显著结果统计0.1 {1: 11, 2: 11, 3: 5, 4: 24, 5: 11} \n",
      "显著结果中正负统计 {1: 2, 2: 11, 3: 5, 4: 0, 5: 10} \n",
      "总数 69\n",
      "0.34782608695652173\n"
     ]
    }
   ],
   "source": [
    "# 盈利能力分位数与负周四效应占比\n",
    "stock_download_return_temp = os.listdir('E:/Stock_Data/stock_return_data/')\n",
    "stock_download_return = [x[:-4] for x in stock_download_return_temp]\n",
    "X = dummy_df.iloc[:1943,:]\n",
    "rf = pd.read_csv('E:/Stock_Data/rf.csv',index_col=0)\n",
    "for percent in [0.5,0.45,0.4,0.35,0.3,0.25,0.2,0.15,0.1,0.05]:\n",
    "# for percent in [0.05]:\n",
    "    cnt = 0\n",
    "    tol_sig = 0\n",
    "    pvalue_01 = {1:0,2:0,3:0,4:0,5:0}\n",
    "    pvalue_pos = {1:0,2:0,3:0,4:0,5:0}\n",
    "    Thu_record = []\n",
    "    for code in bin_data_df_mean.sort_values('OP').iloc[-int(len(bin_data_df_mean)*percent):,].index:\n",
    "        if code not in stock_download_return:\n",
    "            continue\n",
    "        y_temp = pd.read_csv('E:/Stock_Data/stock_return_data/'+code+'.csv',index_col = 0)\n",
    "        if len(y_temp)<1943:\n",
    "            continue   \n",
    "\n",
    "\n",
    "        y = y_temp.iloc[:1943,:]\n",
    "\n",
    "        # 用OLS\n",
    "    #     X = sm.add_constant(X)\n",
    "        # 是否使用超额收益率\n",
    "        y = y - rf\n",
    "\n",
    "        est = sm.OLS(y,X)\n",
    "        result = est.fit()\n",
    "\n",
    "        # 统计专用\n",
    "\n",
    "#         # 显著结果统计(有显著性水平要求0.15)\n",
    "#         for i in range(5):\n",
    "#             if list(result.pvalues)[i]<0.15:\n",
    "#                 pvalue_015[i+1] += 1 \n",
    "        # 显著结果统计(有显著性水平要求0.1)\n",
    "        for i in range(5):\n",
    "            if list(result.pvalues)[i]<0.1:\n",
    "                pvalue_01[i+1] += 1\n",
    "        \n",
    "        Thu_record.append(list(result.params)[3])\n",
    "#         # 显著结果统计(有显著性水平要求0.05)\n",
    "#         for i in range(5):\n",
    "#             if list(result.pvalues)[i]<0.05:\n",
    "#                 pvalue_005[i+1] += 1\n",
    "#         # 显著结果统计(有显著性水平要求0.01)\n",
    "#         for i in range(5):\n",
    "#             if list(result.pvalues)[i]<0.01:\n",
    "#                 pvalue_001[i+1] += 1\n",
    "\n",
    "        # 显著结果中正负统计(有显著性水平要求0.1)\n",
    "        for i in range(5):\n",
    "            if list(result.pvalues)[i]<0.1 and list(result.params)[i]>0:\n",
    "                pvalue_pos[i+1] += 1\n",
    "\n",
    "        # 最显著结果统计(无显著性水平要求)\n",
    "#         result_save_dct[np.argmin(list(result.pvalues))+1]+=1    \n",
    "\n",
    "        # 正负统计-回归、其实就是样本均值\n",
    "#         for i in range(5):\n",
    "#             if list(result.params)[i]>0:\n",
    "#                 positive[i+1] += 1\n",
    "\n",
    "        # F统计量显著统计\n",
    "#         if result.f_pvalue < 0.1:\n",
    "#             f_pvalue += 1\n",
    "\n",
    "        # 收集周四收益率数据\n",
    "    #     y_Thu = y[X[4]==1]['return']\n",
    "    #     if cnt == 0:\n",
    "    #         y_Thu_save=y_Thu\n",
    "    #     else:\n",
    "    #         y_Thu_save=pd.concat([y_Thu_save,y_Thu],axis=0)\n",
    "\n",
    "        # 收集周四平均收益率数据\n",
    "    #     y_Thu = list(result.params)[3]\n",
    "    #     Thu_mean_r.append(y_Thu)\n",
    "\n",
    "    #     # 频率统计，周四为负\n",
    "    #     y_Thu = y[X[4]==1]['return']\n",
    "    #     y_Thu_std = y_Thu.std()\n",
    "    #     Thu_neg += sum(y_Thu.apply(lambda x: 1 if x<-3*y_Thu_std else 0))\n",
    "    #     Thu_pos += sum(y_Thu.apply(lambda x: 1 if x> 3*y_Thu_std else 0))\n",
    "    #     # 频率统计，周一为正\n",
    "    #     y_Mon = y[(X[2]==0) & (X[3]==0) & (X[4]==0) & (X[5]==0)]['return']\n",
    "    #     y_Mon_std = y_Mon.std()\n",
    "    #     Mon_pos += sum(y_Mon.apply(lambda x: 1 if x> 3*y_Mon_std else 0))\n",
    "    #     Mon_neg += sum(y_Mon.apply(lambda x: 1 if x<-3*y_Mon_std else 0))\n",
    "        # 频率统计，平均数正负\n",
    "\n",
    "        # 频率统计，周四小于周一\n",
    "    #     y_Mon = y[(X[2]==0) & (X[3]==0) & (X[4]==0) & (X[5]==0) ]['return']\n",
    "    #     y_Thu = y[X[4]==1]['return']\n",
    "    #     y_delta = y_Thu - y_Mon\n",
    "    #     Thu_lower_Mon += sum(y_delta.apply(lambda x: 1 if x<0 else 0))  \n",
    "\n",
    "        # 用arch\n",
    "    #     reg = arch_model(y, x=X, mean='ARX', lags=0, vol='Garch', p=1, o=0, q=1, power=1, dist='ged', hold_back=None)\n",
    "    #     result = reg.fit()\n",
    "    #     result_save_dct[np.argmin(list(result.pvalues[:5]))+1]+=1\n",
    "\n",
    "        cnt += 1\n",
    "    print('显著结果统计0.1',pvalue_01,'\\n显著结果中正负统计',pvalue_pos,'\\n总数',cnt)\n",
    "    print(pvalue_01[4]/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=array([-15.72527325]), pvalue=array([2.42425806e-24]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.ttest_1samp(Thu_record, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    -28.905116\n",
      "Size       0.002091\n",
      "B_M       -5.313841\n",
      "OP        56.067386\n",
      "Inv       -0.096094\n",
      "Size_2     0.000002\n",
      "B_M_2      6.387901\n",
      "OP_2     -88.745770\n",
      "Inv_2      0.180659\n",
      "dtype: float64\n",
      "const     2.527957e-100\n",
      "Size       5.319239e+05\n",
      "B_M        1.196578e+05\n",
      "OP         1.393853e+01\n",
      "Inv        9.530333e+05\n",
      "Size_2     3.334193e+05\n",
      "B_M_2      1.685975e+04\n",
      "OP_2       3.121320e+04\n",
      "Inv_2      7.302433e+05\n",
      "dtype: float64\n",
      "-459.82811193306577\n",
      "0.4159301400927542\n",
      "0.3158876512769173\n",
      "0.2659546553885859\n"
     ]
    }
   ],
   "source": [
    "# 用OLS\n",
    "X = bin_data_Thu.iloc[:,-5:-1]\n",
    "X = sm.add_constant(X)\n",
    "X['Size_2'] = X['Size']*X['Size']\n",
    "X['B_M_2'] = X['B_M']*X['B_M']\n",
    "X['OP_2'] = X['OP']*X['OP']\n",
    "X['Inv_2'] = X['Inv']*X['Inv']\n",
    "\n",
    "y = bin_data_Thu.iloc[:,0]\n",
    "est = sm.OLS(y,X)\n",
    "result = est.fit()\n",
    "print(result.params*10000)\n",
    "print(result.pvalues*1000000)\n",
    "print(-result.params[1]/(result.params[5]*2))\n",
    "print(-result.params[2]/(result.params[6]*2))\n",
    "print(-result.params[3]/(result.params[7]*2))\n",
    "print(-result.params[4]/(result.params[8]*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Size</th>\n",
       "      <th>B_M</th>\n",
       "      <th>OP</th>\n",
       "      <th>Inv</th>\n",
       "      <th>Size_2</th>\n",
       "      <th>B_M_2</th>\n",
       "      <th>OP_2</th>\n",
       "      <th>Inv_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1412.0</td>\n",
       "      <td>1412.000000</td>\n",
       "      <td>1412.000000</td>\n",
       "      <td>1412.000000</td>\n",
       "      <td>1412.000000</td>\n",
       "      <td>1.412000e+03</td>\n",
       "      <td>1412.000000</td>\n",
       "      <td>1412.000000</td>\n",
       "      <td>1.412000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>132.814249</td>\n",
       "      <td>0.442958</td>\n",
       "      <td>0.107828</td>\n",
       "      <td>0.251709</td>\n",
       "      <td>5.782916e+04</td>\n",
       "      <td>0.251372</td>\n",
       "      <td>0.015740</td>\n",
       "      <td>2.228650e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>200.544307</td>\n",
       "      <td>0.234945</td>\n",
       "      <td>0.064154</td>\n",
       "      <td>0.399525</td>\n",
       "      <td>2.744845e+05</td>\n",
       "      <td>0.298622</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>1.241192e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.134425</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>-0.092453</td>\n",
       "      <td>2.935885e+02</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>1.013142e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44.983325</td>\n",
       "      <td>0.277237</td>\n",
       "      <td>0.060114</td>\n",
       "      <td>0.088993</td>\n",
       "      <td>2.023500e+03</td>\n",
       "      <td>0.076860</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>8.040557e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>71.573525</td>\n",
       "      <td>0.390031</td>\n",
       "      <td>0.097873</td>\n",
       "      <td>0.162781</td>\n",
       "      <td>5.122770e+03</td>\n",
       "      <td>0.152124</td>\n",
       "      <td>0.009579</td>\n",
       "      <td>2.649766e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>132.146508</td>\n",
       "      <td>0.558306</td>\n",
       "      <td>0.141081</td>\n",
       "      <td>0.274511</td>\n",
       "      <td>1.746270e+04</td>\n",
       "      <td>0.311706</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>7.535635e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2181.927325</td>\n",
       "      <td>2.202764</td>\n",
       "      <td>0.419125</td>\n",
       "      <td>4.251257</td>\n",
       "      <td>4.760807e+06</td>\n",
       "      <td>4.852167</td>\n",
       "      <td>0.175665</td>\n",
       "      <td>1.807318e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        const         Size          B_M           OP          Inv  \\\n",
       "count  1412.0  1412.000000  1412.000000  1412.000000  1412.000000   \n",
       "mean      1.0   132.814249     0.442958     0.107828     0.251709   \n",
       "std       0.0   200.544307     0.234945     0.064154     0.399525   \n",
       "min       1.0    17.134425     0.002488     0.011783    -0.092453   \n",
       "25%       1.0    44.983325     0.277237     0.060114     0.088993   \n",
       "50%       1.0    71.573525     0.390031     0.097873     0.162781   \n",
       "75%       1.0   132.146508     0.558306     0.141081     0.274511   \n",
       "max       1.0  2181.927325     2.202764     0.419125     4.251257   \n",
       "\n",
       "             Size_2        B_M_2         OP_2         Inv_2  \n",
       "count  1.412000e+03  1412.000000  1412.000000  1.412000e+03  \n",
       "mean   5.782916e+04     0.251372     0.015740  2.228650e-01  \n",
       "std    2.744845e+05     0.298622     0.019931  1.241192e+00  \n",
       "min    2.935885e+02     0.000006     0.000139  1.013142e-11  \n",
       "25%    2.023500e+03     0.076860     0.003614  8.040557e-03  \n",
       "50%    5.122770e+03     0.152124     0.009579  2.649766e-02  \n",
       "75%    1.746270e+04     0.311706     0.019904  7.535635e-02  \n",
       "max    4.760807e+06     4.852167     0.175665  1.807318e+01  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-bff556679afd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    815\u001b[0m                  **kwargs):\n\u001b[0;32m    816\u001b[0m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[1;32m--> 817\u001b[1;33m                                   hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[0;32m    818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"weights\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weights\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[1;32m--> 663\u001b[1;33m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[0;32m    664\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \"\"\"\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pinv_wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wendog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasconst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[1;32m---> 64\u001b[1;33m                                       **kwargs)\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[1;32m--> 633\u001b[1;33m                  **kwargs)\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_endog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_exog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# this has side-effects, attaches k_constant and const_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m_convert_endog_exog\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;31m#TODO: remove this when we handle dtype systematically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[0mendog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m         \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1602\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1603\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1605\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.values_from_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4682\u001b[0m                [nan,  3.]])\n\u001b[0;32m   4683\u001b[0m         \"\"\"\n\u001b[1;32m-> 4684\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4686\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_dtype_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4626\u001b[0m         \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mRetrieving\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4627\u001b[0m         \"\"\"\n\u001b[1;32m-> 4628\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4629\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4433\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4435\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4437\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   4422\u001b[0m         \"\"\"\n\u001b[0;32m   4423\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4424\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4426\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4432\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4433\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4435\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4096\u001b[0m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4097\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4098\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4099\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4103\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4104\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   5067\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5068\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[1;32m-> 5069\u001b[1;33m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[0;32m   5070\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5071\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[0;32m   5087\u001b[0m         \u001b[1;31m# combination of those slices is a slice, too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5088\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5089\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_vstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5091\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_vstack\u001b[1;34m(to_stack, dtype)\u001b[0m\n\u001b[0;32m   5133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5134\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5135\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_stack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \"\"\"\n\u001b[0;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 5因子回归 - 得系数，用以下一步回归 + 日历效应检验回归，得负周四效应（周四平均超额收益率）\n",
    "rf = pd.read_csv('E:/Stock_Data/rf.csv',index_col=0)\n",
    "\n",
    "code_lst = os.listdir('E:/Stock_Data/stock_return_data')\n",
    "result_save_dct = {1:0,2:0,3:0,4:0,5:0}\n",
    "cnt = 0\n",
    "\n",
    "f_pvalue = 0\n",
    "Thu_mean_r = []\n",
    "for code_csv in code_lst:\n",
    "    y_temp = pd.read_csv('E:/Stock_Data/stock_return_data/'+code_csv,index_col = 0)\n",
    "    if len(y_temp)<1943:\n",
    "        continue\n",
    "    y = y_temp.iloc[:1943,:]\n",
    "    X = pd.concat([MKTF,SMB,HML,CMA,RMW],axis=1)\n",
    "    \n",
    "    # 用OLS - 1\n",
    "    X = sm.add_constant(X)\n",
    "    # 是否使用超额收益率\n",
    "    y = y - rf\n",
    "\n",
    "    est = sm.OLS(y,X)\n",
    "    result = est.fit()\n",
    "    \n",
    "    Const = list(result.params)[0]\n",
    "    MKTF_beta = list(result.params)[1]\n",
    "    SMB_beta = list(result.params)[2]\n",
    "    HML_beta = list(result.params)[3]\n",
    "    CMA_beta = list(result.params)[4]\n",
    "    RMW_beta = list(result.params)[5]\n",
    "    \n",
    "    # 用OLS - 2\n",
    "    # 是否使用超额收益率\n",
    "    X = dummy_df.iloc[:1943,]\n",
    "\n",
    "    est = sm.OLS(y,X)\n",
    "    result = est.fit()\n",
    "    \n",
    "    Thu = list(result.params)[3]\n",
    "    Thu_Pvalue = list(result.pvalues)[3]\n",
    "    \n",
    "    if cnt == 0:\n",
    "        initial_df = pd.DataFrame(columns=['Code','Thu','Thu_Pvalue','C','MKTF_beta','SMB_beta','HML_beta','CMA_beta','RMW_beta'],index=range(9999))\n",
    "        initial_df.iloc[cnt,:] = [code_csv[:-4],Thu,Thu_Pvalue,Const,MKTF_beta,SMB_beta,HML_beta,CMA_beta,RMW_beta]\n",
    "    else:\n",
    "        initial_df.iloc[cnt,:] = [code_csv[:-4],Thu,Thu_Pvalue,Const,MKTF_beta,SMB_beta,HML_beta,CMA_beta,RMW_beta]\n",
    "    \n",
    "    cnt += 1\n",
    "initial_df = initial_df.dropna()\n",
    "initial_df.to_csv('E:/Stock_Data/Fama_beta_Thu.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因子风险溢价描述性统计\n",
    "X = pd.concat([MKTF,SMB,HML,CMA,RMW],axis=1)\n",
    "X.describe().to_csv('E:/Stock_Data/describe_data/risk_premuim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = pd.read_csv('E:/Stock_Data/Fama_beta_Thu.csv')\n",
    "initial_df['isThu'] = initial_df['Thu_Pvalue'].apply(lambda x: 1 if x<0.1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    Thu   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                  0.003\n",
      "Method:                 Least Squares   F-statistic:                     5.939\n",
      "Date:                Fri, 12 Apr 2019   Prob (F-statistic):             0.0149\n",
      "Time:                        16:05:18   Log-Likelihood:                 10512.\n",
      "No. Observations:                1934   AIC:                        -2.102e+04\n",
      "Df Residuals:                    1932   BIC:                        -2.101e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0024   2.42e-05   -100.505      0.000      -0.002      -0.002\n",
      "CMA_beta      -0.0002   9.54e-05     -2.437      0.015      -0.000   -4.54e-05\n",
      "==============================================================================\n",
      "Omnibus:                       13.480   Durbin-Watson:                   1.919\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.596\n",
      "Skew:                           0.056   Prob(JB):                     9.16e-05\n",
      "Kurtosis:                       3.467   Cond. No.                         3.98\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y = initial_df[['Thu']]\n",
    "y.index=initial_df['Code']\n",
    "# X = initial_df[['MKTF_beta','SMB_beta','HML_beta','CMA_beta','RMW_beta']]\n",
    "\n",
    "X = initial_df[['CMA_beta']]\n",
    "\n",
    "X.index=initial_df['Code']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# est = sm.Logit(y,X)\n",
    "est = sm.OLS(y,X)\n",
    "result = est.fit()\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['MKTF_beta'], ['SMB_beta'], ['HML_beta'], ['CMA_beta'], ['RMW_beta']], [['MKTF_beta', 'SMB_beta'], ['MKTF_beta', 'HML_beta'], ['MKTF_beta', 'CMA_beta'], ['MKTF_beta', 'RMW_beta'], ['SMB_beta', 'HML_beta'], ['SMB_beta', 'CMA_beta'], ['SMB_beta', 'RMW_beta'], ['HML_beta', 'CMA_beta'], ['HML_beta', 'RMW_beta'], ['CMA_beta', 'RMW_beta']], [['MKTF_beta', 'SMB_beta', 'HML_beta'], ['MKTF_beta', 'SMB_beta', 'CMA_beta'], ['MKTF_beta', 'SMB_beta', 'RMW_beta'], ['MKTF_beta', 'HML_beta', 'CMA_beta'], ['MKTF_beta', 'HML_beta', 'RMW_beta'], ['MKTF_beta', 'CMA_beta', 'RMW_beta'], ['SMB_beta', 'HML_beta', 'CMA_beta'], ['SMB_beta', 'HML_beta', 'RMW_beta'], ['SMB_beta', 'CMA_beta', 'RMW_beta'], ['HML_beta', 'CMA_beta', 'RMW_beta']], [['MKTF_beta', 'SMB_beta', 'HML_beta', 'CMA_beta'], ['MKTF_beta', 'SMB_beta', 'HML_beta', 'RMW_beta'], ['MKTF_beta', 'SMB_beta', 'CMA_beta', 'RMW_beta'], ['MKTF_beta', 'HML_beta', 'CMA_beta', 'RMW_beta'], ['SMB_beta', 'HML_beta', 'CMA_beta', 'RMW_beta']], [['MKTF_beta', 'SMB_beta', 'HML_beta', 'CMA_beta', 'RMW_beta']]]\n"
     ]
    }
   ],
   "source": [
    "# 生成所有5因子敏感系数的组合 2^5-1=31种\n",
    "import itertools\n",
    "list1 = ['MKTF_beta','SMB_beta','HML_beta','CMA_beta','RMW_beta']\n",
    "list2 = []\n",
    "for i in range(1,len(list1)+1):\n",
    "    iter_ = itertools.combinations(list1,i)\n",
    "    if i ==1:\n",
    "        iter_ = [[i[0]] for i in iter_]\n",
    "    else:\n",
    "        iter_ = [list(i) for i in iter_]\n",
    "    list2.append(list(iter_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.685173\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684872\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684874\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684265\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681659\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684476\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684609\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683242\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681588\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683627\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683708\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681640\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680300\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681658\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678592\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683508\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682863\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681551\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679730\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681587\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678590\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679101\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681624\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678076\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677290\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678751\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681526\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678051\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677290\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677268\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677267\n",
      "         Iterations 4\n"
     ]
    }
   ],
   "source": [
    "# 自主采样测算敏感系数的回归系数稳定性\n",
    "cnt = 0\n",
    "y = initial_df[['isThu']]\n",
    "y.index=initial_df['Code']\n",
    "save_df = pd.DataFrame(columns=['MKTF_beta', 'SMB_beta', 'HML_beta', 'CMA_beta', 'RMW_beta'],index=range(31))\n",
    "def isPos(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "for x_list_tol in list2:\n",
    "    for x_list in x_list_tol:\n",
    "        \n",
    "        X = initial_df[x_list]\n",
    "\n",
    "        X.index=initial_df['Code']\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        est = sm.Logit(y,X)\n",
    "        result = est.fit()\n",
    "        \n",
    "        for col in x_list:\n",
    "            save_df.iloc[cnt,:][col]=isPos(result.params[col])\n",
    "        \n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MKTF_beta     9.0\n",
       "SMB_beta      8.0\n",
       "HML_beta     12.0\n",
       "CMA_beta     16.0\n",
       "RMW_beta      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.685173\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684872\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684874\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684265\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681659\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684476\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684609\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683242\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681588\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683627\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683708\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681640\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680300\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681658\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678592\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683508\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682863\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681551\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679730\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681587\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678590\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679101\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681624\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678076\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677290\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678751\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681526\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678051\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677290\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677268\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677267\n",
      "         Iterations 4\n"
     ]
    }
   ],
   "source": [
    "# 自主采样测算敏感系数的回归系数显著性\n",
    "cnt = 0\n",
    "y = initial_df[['isThu']]\n",
    "y.index=initial_df['Code']\n",
    "save_df = pd.DataFrame(columns=['MKTF_beta', 'SMB_beta', 'HML_beta', 'CMA_beta', 'RMW_beta'],index=range(31))\n",
    "def issig(x):\n",
    "    if x<0.01:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "for x_list_tol in list2:\n",
    "    for x_list in x_list_tol:\n",
    "        \n",
    "        X = initial_df[x_list]\n",
    "\n",
    "        X.index=initial_df['Code']\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        est = sm.Logit(y,X)\n",
    "        result = est.fit()\n",
    "        \n",
    "        for col in x_list:\n",
    "            save_df.iloc[cnt,:][col]=issig(result.pvalues[col])\n",
    "        \n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MKTF_beta     0.0\n",
       "SMB_beta      0.0\n",
       "HML_beta      4.0\n",
       "CMA_beta     13.0\n",
       "RMW_beta     15.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 五因子描述性统计\n",
    "X.describe().to_csv('E:/Stock_Data/describe_data/risk_premium_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5因子回归\n",
    "\n",
    "rf = pd.read_csv('E:/Stock_Data/rf.csv',index_col=0)\n",
    "\n",
    "bin1 = 'Size'\n",
    "bin2s = ['B_M','OP','Inv']\n",
    "# bin2s = ['B_M','OP','Inv','pe_ratio','industry']\n",
    "for bin2 in bin2s:\n",
    "    file_name = 'E:/Stock_Data/'+bin1+'_'+bin2+'.csv'\n",
    "    return_df = pd.read_csv('E:/Stock_Data/'+bin1+'_'+bin2+'.csv',index_col=0)\n",
    "    return_df = return_df.dropna(how=\"any\",axis=0)\n",
    "    bin1_list = [bin1+str(i+1) for i in range(5)]\n",
    "    \n",
    "    bin2_list = [bin2+str(i+1) for i in range(5)]\n",
    "    bin1_bin2_save_df = pd.DataFrame(index=bin1_list,columns=bin2_list)\n",
    "    \n",
    "    row = 0\n",
    "    for bin1_ in bin1_list:\n",
    "        col = 0\n",
    "        for bin2_ in bin2_list:\n",
    "            bin1_bin2_ = bin1_+bin2_\n",
    "            # y减去无风险收益率\n",
    "            y_temp = return_df.iloc[:1943,:]\n",
    "            y_temp_0 = y_temp[[bin1_bin2_]]\n",
    "            y_temp_0.columns=['return']\n",
    "            y = y_temp_0 - rf\n",
    "\n",
    "#             # 用Garch\n",
    "#             reg = arch_model(y, x=X, mean='HARX', lags=0, vol='Garch', p=1, o=0, q=1, power=1.0, dist='ged', hold_back=None)\n",
    "#             result = reg.fit()\n",
    "            \n",
    "            # 用OLS\n",
    "            X = pd.concat([MKTF,SMB,HML,CMA,RMW],axis=1)\n",
    "            X = sm.add_constant(X)\n",
    "            est = sm.OLS(y,X)\n",
    "            result = est.fit()           \n",
    "            \n",
    "            save1 = result.rsquared_adj\n",
    "            save2 = list(result.pvalues)[0]\n",
    "\n",
    "            # 测试 - 结果矩阵形式保存\n",
    "            bin1_bin2_save_df.iloc[row,col] = 'adjR2%.2f a_pvalue%.2f'%(save1*100,save2)\n",
    "            \n",
    "            col += 1\n",
    "        row += 1\n",
    "    # 保存\n",
    "    bin1_bin2_save_df.to_csv('E:/Stock_Data/calander_effect_adj/'+bin1+'_'+bin2+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5因子回归修正\n",
    "\n",
    "# 引入日历效应哑变量 - 星期\n",
    "sample_df = pd.read_csv('E:/Stock_Data/stock_return_data/001896.XSHE.csv',index_col=0)\n",
    "trade_day_serises = list(sample_df.index)\n",
    "\n",
    "trade_day_df = pd.DataFrame(trade_day_serises)\n",
    "trade_day_df.columns = ['weekday']\n",
    "trade_day_df['weekday'] = trade_day_df['weekday'].apply(lambda x : datetime.datetime.strptime(x, \"%Y-%m-%d\").weekday()+1)\n",
    "\n",
    "dummy_df = pd.get_dummies(trade_day_df['weekday'])\n",
    "dummy_df = dummy_df[[4]]\n",
    "dummy_df.index = sample_df.index\n",
    "dummy_df = dummy_df.iloc[:1943,:]\n",
    "\n",
    "rf = pd.read_csv('E:/Stock_Data/rf.csv',index_col=0)\n",
    "\n",
    "bin1 = 'Size'\n",
    "bin2s = ['B_M','OP','Inv']\n",
    "# bin2s = ['B_M','OP','Inv','pe_ratio','industry']\n",
    "for bin2 in bin2s:\n",
    "    file_name = 'E:/Stock_Data/'+bin1+'_'+bin2+'.csv'\n",
    "    return_df = pd.read_csv('E:/Stock_Data/'+bin1+'_'+bin2+'.csv',index_col=0)\n",
    "    return_df = return_df.dropna(how=\"any\",axis=0)\n",
    "    bin1_list = [bin1+str(i+1) for i in range(5)]\n",
    "    \n",
    "    bin2_list = [bin2+str(i+1) for i in range(5)]\n",
    "    bin1_bin2_save_df = pd.DataFrame(index=bin1_list,columns=bin2_list)\n",
    "    \n",
    "    row = 0\n",
    "    for bin1_ in bin1_list:\n",
    "        col = 0\n",
    "        for bin2_ in bin2_list:\n",
    "            bin1_bin2_ = bin1_+bin2_\n",
    "            # y减去无风险收益率\n",
    "            y_temp = return_df.iloc[:1943,:]\n",
    "            y_temp_0 = y_temp[[bin1_bin2_]]\n",
    "            y_temp_0.columns=['return']\n",
    "            y = y_temp_0 - rf\n",
    "\n",
    "#             # 用Garch\n",
    "#             reg = arch_model(y, x=X, mean='HARX', lags=0, vol='Garch', p=1, o=0, q=1, power=1.0, dist='ged', hold_back=None)\n",
    "#             result = reg.fit()\n",
    "            \n",
    "            # 用OLS\n",
    "            X = pd.concat([MKTF,SMB,HML,CMA,RMW,dummy_df],axis=1)\n",
    "            X = sm.add_constant(X)\n",
    "            est = sm.OLS(y,X)\n",
    "            result = est.fit()           \n",
    "            \n",
    "            save1 = result.rsquared_adj\n",
    "            save2 = list(result.pvalues)[0]\n",
    "            save3 = list(result.params)[6]\n",
    "            save4 = list(result.pvalues)[6]\n",
    "\n",
    "            # 测试 - 结果矩阵形式保存\n",
    "            bin1_bin2_save_df.iloc[row,col] = 'adjR2%.2f a_pvalue%.2f Thu%.2f Thu_pvalue%.2f' % (save1*100,save2,save3*100,save4)\n",
    "            \n",
    "            col += 1\n",
    "        row += 1\n",
    "    # 保存\n",
    "    bin1_bin2_save_df.to_csv('E:/Stock_Data/calander_effect_adj/'+bin1+'_'+bin2+'adj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 return   R-squared:                       0.752\n",
      "Model:                            OLS   Adj. R-squared:                  0.751\n",
      "Method:                 Least Squares   F-statistic:                     978.6\n",
      "Date:                Tue, 02 Apr 2019   Prob (F-statistic):               0.00\n",
      "Time:                        00:00:22   Log-Likelihood:                 6556.3\n",
      "No. Observations:                1943   AIC:                        -1.310e+04\n",
      "Df Residuals:                    1936   BIC:                        -1.306e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -4.806e-05      0.000     -0.228      0.820      -0.000       0.000\n",
      "MKTF           0.9939      0.015     66.659      0.000       0.965       1.023\n",
      "SMB            0.2954      0.018     16.386      0.000       0.260       0.331\n",
      "HML           -0.2639      0.018    -14.566      0.000      -0.299      -0.228\n",
      "CMA           -0.0315      0.018     -1.739      0.082      -0.067       0.004\n",
      "RMW           -0.0071      0.019     -0.382      0.702      -0.044       0.029\n",
      "4             -0.0008      0.000     -1.695      0.090      -0.002       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      202.645   Durbin-Watson:                   1.882\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1627.725\n",
      "Skew:                           0.027   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.484   Cond. No.                         124.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    8.198361e-01\n",
       "MKTF     0.000000e+00\n",
       "SMB      1.309001e-56\n",
       "HML      1.095246e-45\n",
       "CMA      8.225096e-02\n",
       "RMW      7.022682e-01\n",
       "4        9.014270e-02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
