{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNtrain(X, y, model, task, lossf, optimizer, epochs, train_size, device = 'CPU'):\n",
    "    \"\"\"\n",
    "    X, 特征向量矩阵nxd\n",
    "    y, 标签\n",
    "    model, 神经网络模型\n",
    "    task, 回归'R'或者分类'C'\n",
    "    lossf, 损失函数回归nn.MSELoss()或者分类nn.CrossEntropyLoss()\n",
    "    optimizer, 优化器'Adam' 'RMSprop' 'Adadelta' 'Adagrad' 'SGD'\n",
    "    epochs, 迭代次数\n",
    "    train_size, 训练集大小\n",
    "    device = 'CPU', 使用CPU还是GPU\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=1, train_size=train_size)\n",
    "    \n",
    "    if task == 'C':\n",
    "        x_train_tr = torch.from_numpy(x_train).float()\n",
    "        y_train_tr = torch.from_numpy(y_train).long()\n",
    "        x_test_tr = torch.from_numpy(x_test).float()\n",
    "        y_test_tr = torch.from_numpy(y_test).long()\n",
    "    if task == 'R':\n",
    "        x_train_tr = torch.from_numpy(x_train).float()\n",
    "        y_train_tr = torch.from_numpy(y_train).float()\n",
    "        x_test_tr = torch.from_numpy(x_test).float()\n",
    "        y_test_tr = torch.from_numpy(y_test).float()\n",
    "        \n",
    "    if device =='GPU':\n",
    "        model_used = model.cuda()\n",
    "        x_train_tr_used = x_train_tr.cuda()\n",
    "        y_train_tr_used = y_train_tr.cuda()\n",
    "        x_test_tr_used = x_test_tr.cuda()\n",
    "        y_test_tr_used = y_test_tr.cuda()\n",
    "    if device == 'CPU':\n",
    "        model_used = model\n",
    "        x_train_tr_used = x_train_tr\n",
    "        y_train_tr_used = y_train_tr\n",
    "        x_test_tr_used = x_test_tr\n",
    "        y_test_tr_used = y_test_tr\n",
    "    \n",
    "    optimizer = optimizer\n",
    "    loss_func = lossf\n",
    "    loss_val_past = 9999\n",
    "    loss_past = 9999\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        predict = model_used(x_train_tr_used)\n",
    "        loss = loss_func(predict, y_train_tr_used)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        out_val = model_used(x_test_tr_used)\n",
    "        loss_val = loss_func(out_val, y_test_tr_used)\n",
    "        print('Epoch: ', epoch+1, '| Train Accurancy: ', 1-float(loss), '| Validation Accurancy: ', 1-float(loss_val))\n",
    "\n",
    "        if (float(loss_val) > float(loss_val_past) and epoch>99) or ((float(loss_past)-float(loss))<1e-7 and epoch>99):\n",
    "            break\n",
    "        else:\n",
    "            loss_val_past = loss_val\n",
    "            loss_past = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | Train Accurancy:  -0.35689783096313477 | Validation Accurancy:  -0.27798378467559814\n",
      "Epoch:  2 | Train Accurancy:  -0.2722439765930176 | Validation Accurancy:  -0.21257615089416504\n",
      "Epoch:  3 | Train Accurancy:  -0.20994722843170166 | Validation Accurancy:  -0.1617361307144165\n",
      "Epoch:  4 | Train Accurancy:  -0.15970396995544434 | Validation Accurancy:  -0.11875653266906738\n",
      "Epoch:  5 | Train Accurancy:  -0.11512839794158936 | Validation Accurancy:  -0.0822974443435669\n",
      "Epoch:  6 | Train Accurancy:  -0.07320058345794678 | Validation Accurancy:  -0.04879426956176758\n",
      "Epoch:  7 | Train Accurancy:  -0.03544914722442627 | Validation Accurancy:  -0.017242074012756348\n",
      "Epoch:  8 | Train Accurancy:  -0.001459956169128418 | Validation Accurancy:  0.012257039546966553\n",
      "Epoch:  9 | Train Accurancy:  0.0308380126953125 | Validation Accurancy:  0.03996950387954712\n",
      "Epoch:  10 | Train Accurancy:  0.062419772148132324 | Validation Accurancy:  0.06660968065261841\n",
      "Epoch:  11 | Train Accurancy:  0.09260976314544678 | Validation Accurancy:  0.09257501363754272\n",
      "Epoch:  12 | Train Accurancy:  0.12117546796798706 | Validation Accurancy:  0.11791545152664185\n",
      "Epoch:  13 | Train Accurancy:  0.14780890941619873 | Validation Accurancy:  0.1416800618171692\n",
      "Epoch:  14 | Train Accurancy:  0.17125850915908813 | Validation Accurancy:  0.16413956880569458\n",
      "Epoch:  15 | Train Accurancy:  0.1919419765472412 | Validation Accurancy:  0.18713384866714478\n",
      "Epoch:  16 | Train Accurancy:  0.21315878629684448 | Validation Accurancy:  0.2112640142440796\n",
      "Epoch:  17 | Train Accurancy:  0.2353062629699707 | Validation Accurancy:  0.2358207106590271\n",
      "Epoch:  18 | Train Accurancy:  0.25795549154281616 | Validation Accurancy:  0.25965917110443115\n",
      "Epoch:  19 | Train Accurancy:  0.28040045499801636 | Validation Accurancy:  0.2810744643211365\n",
      "Epoch:  20 | Train Accurancy:  0.30173182487487793 | Validation Accurancy:  0.30029135942459106\n",
      "Epoch:  21 | Train Accurancy:  0.32121139764785767 | Validation Accurancy:  0.317165732383728\n",
      "Epoch:  22 | Train Accurancy:  0.33922815322875977 | Validation Accurancy:  0.33191806077957153\n",
      "Epoch:  23 | Train Accurancy:  0.35625535249710083 | Validation Accurancy:  0.3453702926635742\n",
      "Epoch:  24 | Train Accurancy:  0.372394323348999 | Validation Accurancy:  0.3582509756088257\n",
      "Epoch:  25 | Train Accurancy:  0.38779217004776 | Validation Accurancy:  0.37134772539138794\n",
      "Epoch:  26 | Train Accurancy:  0.4026951193809509 | Validation Accurancy:  0.38518232107162476\n",
      "Epoch:  27 | Train Accurancy:  0.4172602891921997 | Validation Accurancy:  0.399807333946228\n",
      "Epoch:  28 | Train Accurancy:  0.43147724866867065 | Validation Accurancy:  0.41479402780532837\n",
      "Epoch:  29 | Train Accurancy:  0.44512319564819336 | Validation Accurancy:  0.4294951558113098\n",
      "Epoch:  30 | Train Accurancy:  0.45797961950302124 | Validation Accurancy:  0.44330066442489624\n",
      "Epoch:  31 | Train Accurancy:  0.47000473737716675 | Validation Accurancy:  0.45591652393341064\n",
      "Epoch:  32 | Train Accurancy:  0.48135608434677124 | Validation Accurancy:  0.46729910373687744\n",
      "Epoch:  33 | Train Accurancy:  0.49228811264038086 | Validation Accurancy:  0.47751808166503906\n",
      "Epoch:  34 | Train Accurancy:  0.5029200911521912 | Validation Accurancy:  0.4868435859680176\n",
      "Epoch:  35 | Train Accurancy:  0.513206422328949 | Validation Accurancy:  0.4955925941467285\n",
      "Epoch:  36 | Train Accurancy:  0.5230593681335449 | Validation Accurancy:  0.5041916072368622\n",
      "Epoch:  37 | Train Accurancy:  0.5324523150920868 | Validation Accurancy:  0.5130840241909027\n",
      "Epoch:  38 | Train Accurancy:  0.5414760410785675 | Validation Accurancy:  0.5225188434123993\n",
      "Epoch:  39 | Train Accurancy:  0.5502300262451172 | Validation Accurancy:  0.5324014723300934\n",
      "Epoch:  40 | Train Accurancy:  0.5587337613105774 | Validation Accurancy:  0.5423680543899536\n",
      "Epoch:  41 | Train Accurancy:  0.566943347454071 | Validation Accurancy:  0.5519572794437408\n",
      "Epoch:  42 | Train Accurancy:  0.5748421549797058 | Validation Accurancy:  0.5608327984809875\n",
      "Epoch:  43 | Train Accurancy:  0.5825096368789673 | Validation Accurancy:  0.5689173638820648\n",
      "Epoch:  44 | Train Accurancy:  0.5900368094444275 | Validation Accurancy:  0.5762928128242493\n",
      "Epoch:  45 | Train Accurancy:  0.5974608063697815 | Validation Accurancy:  0.5831681191921234\n",
      "Epoch:  46 | Train Accurancy:  0.6047424674034119 | Validation Accurancy:  0.5898498296737671\n",
      "Epoch:  47 | Train Accurancy:  0.6118516325950623 | Validation Accurancy:  0.5966669321060181\n",
      "Epoch:  48 | Train Accurancy:  0.6188252568244934 | Validation Accurancy:  0.6038420498371124\n",
      "Epoch:  49 | Train Accurancy:  0.6257162392139435 | Validation Accurancy:  0.6113282442092896\n",
      "Epoch:  50 | Train Accurancy:  0.6325274407863617 | Validation Accurancy:  0.6188945770263672\n",
      "Epoch:  51 | Train Accurancy:  0.6392256915569305 | Validation Accurancy:  0.6262614130973816\n",
      "Epoch:  52 | Train Accurancy:  0.6457989513874054 | Validation Accurancy:  0.6332827806472778\n",
      "Epoch:  53 | Train Accurancy:  0.6522885262966156 | Validation Accurancy:  0.639901340007782\n",
      "Epoch:  54 | Train Accurancy:  0.658724308013916 | Validation Accurancy:  0.6462565660476685\n",
      "Epoch:  55 | Train Accurancy:  0.6650913655757904 | Validation Accurancy:  0.6525368392467499\n",
      "Epoch:  56 | Train Accurancy:  0.6713733077049255 | Validation Accurancy:  0.6589500308036804\n",
      "Epoch:  57 | Train Accurancy:  0.6775732040405273 | Validation Accurancy:  0.6656144559383392\n",
      "Epoch:  58 | Train Accurancy:  0.6837196350097656 | Validation Accurancy:  0.6724744439125061\n",
      "Epoch:  59 | Train Accurancy:  0.6898011565208435 | Validation Accurancy:  0.6793408691883087\n",
      "Epoch:  60 | Train Accurancy:  0.6957935988903046 | Validation Accurancy:  0.6859837472438812\n",
      "Epoch:  61 | Train Accurancy:  0.701683759689331 | Validation Accurancy:  0.6923342347145081\n",
      "Epoch:  62 | Train Accurancy:  0.7074752449989319 | Validation Accurancy:  0.6984215974807739\n",
      "Epoch:  63 | Train Accurancy:  0.713172435760498 | Validation Accurancy:  0.7043304741382599\n",
      "Epoch:  64 | Train Accurancy:  0.7187615931034088 | Validation Accurancy:  0.7101009786128998\n",
      "Epoch:  65 | Train Accurancy:  0.7242210805416107 | Validation Accurancy:  0.7158776521682739\n",
      "Epoch:  66 | Train Accurancy:  0.7295626401901245 | Validation Accurancy:  0.7216565907001495\n",
      "Epoch:  67 | Train Accurancy:  0.7347880005836487 | Validation Accurancy:  0.7273464500904083\n",
      "Epoch:  68 | Train Accurancy:  0.7398819029331207 | Validation Accurancy:  0.7328567206859589\n",
      "Epoch:  69 | Train Accurancy:  0.7448302805423737 | Validation Accurancy:  0.7381646037101746\n",
      "Epoch:  70 | Train Accurancy:  0.7496417462825775 | Validation Accurancy:  0.7432921826839447\n",
      "Epoch:  71 | Train Accurancy:  0.7543414086103439 | Validation Accurancy:  0.7482894361019135\n",
      "Epoch:  72 | Train Accurancy:  0.7589214444160461 | Validation Accurancy:  0.7532138228416443\n",
      "Epoch:  73 | Train Accurancy:  0.7633786499500275 | Validation Accurancy:  0.7580958008766174\n",
      "Epoch:  74 | Train Accurancy:  0.7677192986011505 | Validation Accurancy:  0.7629085630178452\n",
      "Epoch:  75 | Train Accurancy:  0.7719545215368271 | Validation Accurancy:  0.7676043808460236\n",
      "Epoch:  76 | Train Accurancy:  0.7760814428329468 | Validation Accurancy:  0.7721593528985977\n",
      "Epoch:  77 | Train Accurancy:  0.7801051437854767 | Validation Accurancy:  0.7765799909830093\n",
      "Epoch:  78 | Train Accurancy:  0.7840315699577332 | Validation Accurancy:  0.7808890789747238\n",
      "Epoch:  79 | Train Accurancy:  0.7878557443618774 | Validation Accurancy:  0.7851082235574722\n",
      "Epoch:  80 | Train Accurancy:  0.7915815114974976 | Validation Accurancy:  0.7892531901597977\n",
      "Epoch:  81 | Train Accurancy:  0.7952134907245636 | Validation Accurancy:  0.793321281671524\n",
      "Epoch:  82 | Train Accurancy:  0.7987553030252457 | Validation Accurancy:  0.7972974628210068\n",
      "Epoch:  83 | Train Accurancy:  0.8022061884403229 | Validation Accurancy:  0.801176056265831\n",
      "Epoch:  84 | Train Accurancy:  0.8055675774812698 | Validation Accurancy:  0.8049637377262115\n",
      "Epoch:  85 | Train Accurancy:  0.8088431507349014 | Validation Accurancy:  0.808667317032814\n",
      "Epoch:  86 | Train Accurancy:  0.8120334595441818 | Validation Accurancy:  0.8122880309820175\n",
      "Epoch:  87 | Train Accurancy:  0.8151378184556961 | Validation Accurancy:  0.8158264458179474\n",
      "Epoch:  88 | Train Accurancy:  0.8181591480970383 | Validation Accurancy:  0.8192786872386932\n",
      "Epoch:  89 | Train Accurancy:  0.821099653840065 | Validation Accurancy:  0.8226422220468521\n",
      "Epoch:  90 | Train Accurancy:  0.823959469795227 | Validation Accurancy:  0.825922429561615\n",
      "Epoch:  91 | Train Accurancy:  0.8267393857240677 | Validation Accurancy:  0.8291284292936325\n",
      "Epoch:  92 | Train Accurancy:  0.8294421136379242 | Validation Accurancy:  0.8322630822658539\n",
      "Epoch:  93 | Train Accurancy:  0.83206906914711 | Validation Accurancy:  0.8353202193975449\n",
      "Epoch:  94 | Train Accurancy:  0.8346206992864609 | Validation Accurancy:  0.8382927924394608\n",
      "Epoch:  95 | Train Accurancy:  0.8370994329452515 | Validation Accurancy:  0.8411772698163986\n",
      "Epoch:  96 | Train Accurancy:  0.8395074158906937 | Validation Accurancy:  0.843978688120842\n",
      "Epoch:  97 | Train Accurancy:  0.8418457061052322 | Validation Accurancy:  0.8467090725898743\n",
      "Epoch:  98 | Train Accurancy:  0.8441159576177597 | Validation Accurancy:  0.849379375576973\n",
      "Epoch:  99 | Train Accurancy:  0.846320629119873 | Validation Accurancy:  0.8519908338785172\n",
      "Epoch:  100 | Train Accurancy:  0.848461240530014 | Validation Accurancy:  0.854535311460495\n",
      "Epoch:  101 | Train Accurancy:  0.8505393415689468 | Validation Accurancy:  0.8570030480623245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  102 | Train Accurancy:  0.8525571078062057 | Validation Accurancy:  0.8593935072422028\n",
      "Epoch:  103 | Train Accurancy:  0.8545165956020355 | Validation Accurancy:  0.8617157936096191\n",
      "Epoch:  104 | Train Accurancy:  0.8564192354679108 | Validation Accurancy:  0.8639838248491287\n",
      "Epoch:  105 | Train Accurancy:  0.8582667261362076 | Validation Accurancy:  0.8662068247795105\n",
      "Epoch:  106 | Train Accurancy:  0.8600612580776215 | Validation Accurancy:  0.8683827221393585\n",
      "Epoch:  107 | Train Accurancy:  0.8618043065071106 | Validation Accurancy:  0.8705040663480759\n",
      "Epoch:  108 | Train Accurancy:  0.8634971976280212 | Validation Accurancy:  0.8725622445344925\n",
      "Epoch:  109 | Train Accurancy:  0.865141972899437 | Validation Accurancy:  0.8745572119951248\n",
      "Epoch:  110 | Train Accurancy:  0.8667402565479279 | Validation Accurancy:  0.8764985576272011\n",
      "Epoch:  111 | Train Accurancy:  0.8682932555675507 | Validation Accurancy:  0.8783988505601883\n",
      "Epoch:  112 | Train Accurancy:  0.8698026090860367 | Validation Accurancy:  0.8802641183137894\n",
      "Epoch:  113 | Train Accurancy:  0.8712699115276337 | Validation Accurancy:  0.882090650498867\n",
      "Epoch:  114 | Train Accurancy:  0.87269626557827 | Validation Accurancy:  0.8838689625263214\n",
      "Epoch:  115 | Train Accurancy:  0.8740831762552261 | Validation Accurancy:  0.8855925053358078\n",
      "Epoch:  116 | Train Accurancy:  0.8754319921135902 | Validation Accurancy:  0.8872640356421471\n",
      "Epoch:  117 | Train Accurancy:  0.8767439350485802 | Validation Accurancy:  0.8888929039239883\n",
      "Epoch:  118 | Train Accurancy:  0.8780202120542526 | Validation Accurancy:  0.8904896005988121\n",
      "Epoch:  119 | Train Accurancy:  0.8792619630694389 | Validation Accurancy:  0.8920571804046631\n",
      "Epoch:  120 | Train Accurancy:  0.880470372736454 | Validation Accurancy:  0.8935912549495697\n",
      "Epoch:  121 | Train Accurancy:  0.8816464990377426 | Validation Accurancy:  0.8950835317373276\n",
      "Epoch:  122 | Train Accurancy:  0.8827913925051689 | Validation Accurancy:  0.8965305164456367\n",
      "Epoch:  123 | Train Accurancy:  0.883906215429306 | Validation Accurancy:  0.8979361206293106\n",
      "Epoch:  124 | Train Accurancy:  0.8849917724728584 | Validation Accurancy:  0.8993100449442863\n",
      "Epoch:  125 | Train Accurancy:  0.8860491439700127 | Validation Accurancy:  0.900659941136837\n",
      "Epoch:  126 | Train Accurancy:  0.8870792165398598 | Validation Accurancy:  0.9019864946603775\n",
      "Epoch:  127 | Train Accurancy:  0.8880828469991684 | Validation Accurancy:  0.9032843187451363\n",
      "Epoch:  128 | Train Accurancy:  0.8890609666705132 | Validation Accurancy:  0.9045469462871552\n",
      "Epoch:  129 | Train Accurancy:  0.8900143876671791 | Validation Accurancy:  0.9057737439870834\n",
      "Epoch:  130 | Train Accurancy:  0.8909438028931618 | Validation Accurancy:  0.9069699048995972\n",
      "Epoch:  131 | Train Accurancy:  0.8918502107262611 | Validation Accurancy:  0.9081429690122604\n",
      "Epoch:  132 | Train Accurancy:  0.8927341774106026 | Validation Accurancy:  0.9092974960803986\n",
      "Epoch:  133 | Train Accurancy:  0.8935963436961174 | Validation Accurancy:  0.9104317426681519\n",
      "Epoch:  134 | Train Accurancy:  0.8944376558065414 | Validation Accurancy:  0.9115407392382622\n",
      "Epoch:  135 | Train Accurancy:  0.8952586278319359 | Validation Accurancy:  0.9126206189393997\n",
      "Epoch:  136 | Train Accurancy:  0.8960599303245544 | Validation Accurancy:  0.9136732816696167\n",
      "Epoch:  137 | Train Accurancy:  0.8968420922756195 | Validation Accurancy:  0.914703331887722\n",
      "Epoch:  138 | Train Accurancy:  0.897605761885643 | Validation Accurancy:  0.9157155081629753\n",
      "Epoch:  139 | Train Accurancy:  0.898351676762104 | Validation Accurancy:  0.916711337864399\n",
      "Epoch:  140 | Train Accurancy:  0.8990801498293877 | Validation Accurancy:  0.9176887348294258\n",
      "Epoch:  141 | Train Accurancy:  0.8997918739914894 | Validation Accurancy:  0.9186440706253052\n",
      "Epoch:  142 | Train Accurancy:  0.9004873409867287 | Validation Accurancy:  0.9195756912231445\n",
      "Epoch:  143 | Train Accurancy:  0.9011670798063278 | Validation Accurancy:  0.9204859063029289\n",
      "Epoch:  144 | Train Accurancy:  0.9018315225839615 | Validation Accurancy:  0.9213784635066986\n",
      "Epoch:  145 | Train Accurancy:  0.9024811536073685 | Validation Accurancy:  0.9222564548254013\n",
      "Epoch:  146 | Train Accurancy:  0.9031164646148682 | Validation Accurancy:  0.923120029270649\n",
      "Epoch:  147 | Train Accurancy:  0.9037377461791039 | Validation Accurancy:  0.923966646194458\n",
      "Epoch:  148 | Train Accurancy:  0.9043454453349113 | Validation Accurancy:  0.9247959703207016\n",
      "Epoch:  149 | Train Accurancy:  0.904940091073513 | Validation Accurancy:  0.9256066232919693\n",
      "Epoch:  150 | Train Accurancy:  0.9055218324065208 | Validation Accurancy:  0.9264016598463058\n",
      "Epoch:  151 | Train Accurancy:  0.9060913398861885 | Validation Accurancy:  0.9271825700998306\n",
      "Epoch:  152 | Train Accurancy:  0.9066488146781921 | Validation Accurancy:  0.9279507696628571\n",
      "Epoch:  153 | Train Accurancy:  0.9071946069598198 | Validation Accurancy:  0.9287058636546135\n",
      "Epoch:  154 | Train Accurancy:  0.9077291190624237 | Validation Accurancy:  0.9294469505548477\n",
      "Epoch:  155 | Train Accurancy:  0.9082526564598083 | Validation Accurancy:  0.9301732927560806\n",
      "Epoch:  156 | Train Accurancy:  0.90876554697752 | Validation Accurancy:  0.9308854341506958\n",
      "Epoch:  157 | Train Accurancy:  0.9092680439352989 | Validation Accurancy:  0.9315843656659126\n",
      "Epoch:  158 | Train Accurancy:  0.9097604602575302 | Validation Accurancy:  0.9322715103626251\n",
      "Epoch:  159 | Train Accurancy:  0.910243034362793 | Validation Accurancy:  0.9329474419355392\n",
      "Epoch:  160 | Train Accurancy:  0.9107161462306976 | Validation Accurancy:  0.9336116388440132\n",
      "Epoch:  161 | Train Accurancy:  0.911179929971695 | Validation Accurancy:  0.9342634305357933\n",
      "Epoch:  162 | Train Accurancy:  0.9116347283124924 | Validation Accurancy:  0.9349026829004288\n",
      "Epoch:  163 | Train Accurancy:  0.9120806902647018 | Validation Accurancy:  0.9355304390192032\n",
      "Epoch:  164 | Train Accurancy:  0.9125181958079338 | Validation Accurancy:  0.9361475706100464\n",
      "Epoch:  165 | Train Accurancy:  0.9129473567008972 | Validation Accurancy:  0.9367551356554031\n",
      "Epoch:  166 | Train Accurancy:  0.9133684039115906 | Validation Accurancy:  0.9373528212308884\n",
      "Epoch:  167 | Train Accurancy:  0.9137816429138184 | Validation Accurancy:  0.9379406198859215\n",
      "Epoch:  168 | Train Accurancy:  0.9141871631145477 | Validation Accurancy:  0.9385180622339249\n",
      "Epoch:  169 | Train Accurancy:  0.9145852103829384 | Validation Accurancy:  0.9390854053199291\n",
      "Epoch:  170 | Train Accurancy:  0.9149759411811829 | Validation Accurancy:  0.9396436922252178\n",
      "Epoch:  171 | Train Accurancy:  0.9153596833348274 | Validation Accurancy:  0.9401936382055283\n",
      "Epoch:  172 | Train Accurancy:  0.9157363995909691 | Validation Accurancy:  0.9407354816794395\n",
      "Epoch:  173 | Train Accurancy:  0.9161064848303795 | Validation Accurancy:  0.9412690959870815\n",
      "Epoch:  174 | Train Accurancy:  0.9164699614048004 | Validation Accurancy:  0.9417940154671669\n",
      "Epoch:  175 | Train Accurancy:  0.9168270528316498 | Validation Accurancy:  0.9423105716705322\n",
      "Epoch:  176 | Train Accurancy:  0.9171778857707977 | Validation Accurancy:  0.9428177215158939\n",
      "Epoch:  177 | Train Accurancy:  0.9175226092338562 | Validation Accurancy:  0.9433170966804028\n",
      "Epoch:  178 | Train Accurancy:  0.9178614839911461 | Validation Accurancy:  0.9438098892569542\n",
      "Epoch:  179 | Train Accurancy:  0.9181944206357002 | Validation Accurancy:  0.9442965760827065\n",
      "Epoch:  180 | Train Accurancy:  0.9185217693448067 | Validation Accurancy:  0.9447760656476021\n",
      "Epoch:  181 | Train Accurancy:  0.9188436642289162 | Validation Accurancy:  0.9452475719153881\n",
      "Epoch:  182 | Train Accurancy:  0.9191600829362869 | Validation Accurancy:  0.9457109607756138\n",
      "Epoch:  183 | Train Accurancy:  0.9194712787866592 | Validation Accurancy:  0.9461673274636269\n",
      "Epoch:  184 | Train Accurancy:  0.9197774305939674 | Validation Accurancy:  0.9466178491711617\n",
      "Epoch:  185 | Train Accurancy:  0.9200784787535667 | Validation Accurancy:  0.9470630809664726\n",
      "Epoch:  186 | Train Accurancy:  0.9203747287392616 | Validation Accurancy:  0.9475026205182076\n",
      "Epoch:  187 | Train Accurancy:  0.9206660613417625 | Validation Accurancy:  0.947936836630106\n",
      "Epoch:  188 | Train Accurancy:  0.9209527969360352 | Validation Accurancy:  0.9483644552528858\n",
      "Epoch:  189 | Train Accurancy:  0.9212350025773048 | Validation Accurancy:  0.9487849809229374\n",
      "Epoch:  190 | Train Accurancy:  0.921512670814991 | Validation Accurancy:  0.949199452996254\n",
      "Epoch:  191 | Train Accurancy:  0.9217860102653503 | Validation Accurancy:  0.9496086612343788\n",
      "Epoch:  192 | Train Accurancy:  0.9220551252365112 | Validation Accurancy:  0.9500137232244015\n",
      "Epoch:  193 | Train Accurancy:  0.9223199561238289 | Validation Accurancy:  0.9504141882061958\n",
      "Epoch:  194 | Train Accurancy:  0.9225808754563332 | Validation Accurancy:  0.9508089795708656\n",
      "Epoch:  195 | Train Accurancy:  0.9228377416729927 | Validation Accurancy:  0.9511975385248661\n",
      "Epoch:  196 | Train Accurancy:  0.9230906888842583 | Validation Accurancy:  0.9515800327062607\n",
      "Epoch:  197 | Train Accurancy:  0.9233398139476776 | Validation Accurancy:  0.9519574157893658\n",
      "Epoch:  198 | Train Accurancy:  0.9235852286219597 | Validation Accurancy:  0.9523305743932724\n",
      "Epoch:  199 | Train Accurancy:  0.9238270595669746 | Validation Accurancy:  0.952699575573206\n",
      "Epoch:  200 | Train Accurancy:  0.9240652173757553 | Validation Accurancy:  0.9530636481940746\n",
      "Epoch:  201 | Train Accurancy:  0.9242999479174614 | Validation Accurancy:  0.9534224756062031\n",
      "Epoch:  202 | Train Accurancy:  0.9245312288403511 | Validation Accurancy:  0.953775692731142\n",
      "Epoch:  203 | Train Accurancy:  0.924759179353714 | Validation Accurancy:  0.9541241489350796\n",
      "Epoch:  204 | Train Accurancy:  0.9249838143587112 | Validation Accurancy:  0.954468559473753\n",
      "Epoch:  205 | Train Accurancy:  0.9252052381634712 | Validation Accurancy:  0.9548092111945152\n",
      "Epoch:  206 | Train Accurancy:  0.9254235401749611 | Validation Accurancy:  0.9551458284258842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  207 | Train Accurancy:  0.9256387203931808 | Validation Accurancy:  0.9554774984717369\n",
      "Epoch:  208 | Train Accurancy:  0.9258509576320648 | Validation Accurancy:  0.9558053240180016\n",
      "Epoch:  209 | Train Accurancy:  0.9260601699352264 | Validation Accurancy:  0.956129115074873\n",
      "Epoch:  210 | Train Accurancy:  0.9262664020061493 | Validation Accurancy:  0.9564486667513847\n",
      "Epoch:  211 | Train Accurancy:  0.9264698699116707 | Validation Accurancy:  0.9567640163004398\n",
      "Epoch:  212 | Train Accurancy:  0.9266705587506294 | Validation Accurancy:  0.9570759534835815\n",
      "Epoch:  213 | Train Accurancy:  0.9268685728311539 | Validation Accurancy:  0.9573843330144882\n",
      "Epoch:  214 | Train Accurancy:  0.927063837647438 | Validation Accurancy:  0.9576894901692867\n",
      "Epoch:  215 | Train Accurancy:  0.9272564798593521 | Validation Accurancy:  0.9579911455512047\n",
      "Epoch:  216 | Train Accurancy:  0.927446648478508 | Validation Accurancy:  0.958288948982954\n",
      "Epoch:  217 | Train Accurancy:  0.9276341274380684 | Validation Accurancy:  0.9585833325982094\n",
      "Epoch:  218 | Train Accurancy:  0.9278192520141602 | Validation Accurancy:  0.9588743224740028\n",
      "Epoch:  219 | Train Accurancy:  0.9280019029974937 | Validation Accurancy:  0.9591622352600098\n",
      "Epoch:  220 | Train Accurancy:  0.9281822443008423 | Validation Accurancy:  0.9594472087919712\n",
      "Epoch:  221 | Train Accurancy:  0.9283601492643356 | Validation Accurancy:  0.9597289711236954\n",
      "Epoch:  222 | Train Accurancy:  0.9285358414053917 | Validation Accurancy:  0.9600075073540211\n",
      "Epoch:  223 | Train Accurancy:  0.9287092834711075 | Validation Accurancy:  0.9602828659117222\n",
      "Epoch:  224 | Train Accurancy:  0.9288805052638054 | Validation Accurancy:  0.9605549350380898\n",
      "Epoch:  225 | Train Accurancy:  0.9290495365858078 | Validation Accurancy:  0.9608242027461529\n",
      "Epoch:  226 | Train Accurancy:  0.9292164817452431 | Validation Accurancy:  0.9610904529690742\n",
      "Epoch:  227 | Train Accurancy:  0.9293813481926918 | Validation Accurancy:  0.9613536037504673\n",
      "Epoch:  228 | Train Accurancy:  0.9295441657304764 | Validation Accurancy:  0.9616142436861992\n",
      "Epoch:  229 | Train Accurancy:  0.9297048971056938 | Validation Accurancy:  0.9618720225989819\n",
      "Epoch:  230 | Train Accurancy:  0.929863840341568 | Validation Accurancy:  0.9621271304786205\n",
      "Epoch:  231 | Train Accurancy:  0.9300206527113914 | Validation Accurancy:  0.9623792171478271\n",
      "Epoch:  232 | Train Accurancy:  0.9301756247878075 | Validation Accurancy:  0.9626284912228584\n",
      "Epoch:  233 | Train Accurancy:  0.9303287714719772 | Validation Accurancy:  0.9628751128911972\n",
      "Epoch:  234 | Train Accurancy:  0.9304800555109978 | Validation Accurancy:  0.9631198085844517\n",
      "Epoch:  235 | Train Accurancy:  0.9306295663118362 | Validation Accurancy:  0.9633620418608189\n",
      "Epoch:  236 | Train Accurancy:  0.9307772591710091 | Validation Accurancy:  0.963601604104042\n",
      "Epoch:  237 | Train Accurancy:  0.930923230946064 | Validation Accurancy:  0.963838417083025\n",
      "Epoch:  238 | Train Accurancy:  0.9310675412416458 | Validation Accurancy:  0.9640726409852505\n",
      "Epoch:  239 | Train Accurancy:  0.9312100410461426 | Validation Accurancy:  0.9643048122525215\n",
      "Epoch:  240 | Train Accurancy:  0.931351013481617 | Validation Accurancy:  0.9645349644124508\n",
      "Epoch:  241 | Train Accurancy:  0.9314903095364571 | Validation Accurancy:  0.9647630043327808\n",
      "Epoch:  242 | Train Accurancy:  0.9316280111670494 | Validation Accurancy:  0.9649887718260288\n",
      "Epoch:  243 | Train Accurancy:  0.9317641779780388 | Validation Accurancy:  0.9652117565274239\n",
      "Epoch:  244 | Train Accurancy:  0.931898757815361 | Validation Accurancy:  0.9654325656592846\n",
      "Epoch:  245 | Train Accurancy:  0.9320318400859833 | Validation Accurancy:  0.9656514637172222\n",
      "Epoch:  246 | Train Accurancy:  0.9321634396910667 | Validation Accurancy:  0.9658682979643345\n",
      "Epoch:  247 | Train Accurancy:  0.9322935864329338 | Validation Accurancy:  0.9660832099616528\n",
      "Epoch:  248 | Train Accurancy:  0.9324222728610039 | Validation Accurancy:  0.966296847909689\n",
      "Epoch:  249 | Train Accurancy:  0.9325494766235352 | Validation Accurancy:  0.9665081836283207\n",
      "Epoch:  250 | Train Accurancy:  0.9326753541827202 | Validation Accurancy:  0.9667166247963905\n",
      "Epoch:  251 | Train Accurancy:  0.9327998161315918 | Validation Accurancy:  0.9669221416115761\n",
      "Epoch:  252 | Train Accurancy:  0.932922974228859 | Validation Accurancy:  0.967126227915287\n",
      "Epoch:  253 | Train Accurancy:  0.9330447539687157 | Validation Accurancy:  0.9673289284110069\n",
      "Epoch:  254 | Train Accurancy:  0.9331651926040649 | Validation Accurancy:  0.9675304256379604\n",
      "Epoch:  255 | Train Accurancy:  0.9332844242453575 | Validation Accurancy:  0.9677298851311207\n",
      "Epoch:  256 | Train Accurancy:  0.9334023743867874 | Validation Accurancy:  0.9679267890751362\n",
      "Epoch:  257 | Train Accurancy:  0.9335190877318382 | Validation Accurancy:  0.9681211486458778\n",
      "Epoch:  258 | Train Accurancy:  0.9336345195770264 | Validation Accurancy:  0.968314029276371\n",
      "Epoch:  259 | Train Accurancy:  0.933748833835125 | Validation Accurancy:  0.9685056358575821\n",
      "Epoch:  260 | Train Accurancy:  0.9338619038462639 | Validation Accurancy:  0.968695942312479\n",
      "Epoch:  261 | Train Accurancy:  0.9339737817645073 | Validation Accurancy:  0.9688844047486782\n",
      "Epoch:  262 | Train Accurancy:  0.9340845271945 | Validation Accurancy:  0.9690707679837942\n",
      "Epoch:  263 | Train Accurancy:  0.9341941997408867 | Validation Accurancy:  0.9692548904567957\n",
      "Epoch:  264 | Train Accurancy:  0.9343027099967003 | Validation Accurancy:  0.9694375675171614\n",
      "Epoch:  265 | Train Accurancy:  0.9344101324677467 | Validation Accurancy:  0.9696190189570189\n",
      "Epoch:  266 | Train Accurancy:  0.934516467154026 | Validation Accurancy:  0.9697992634028196\n",
      "Epoch:  267 | Train Accurancy:  0.9346217140555382 | Validation Accurancy:  0.9699777606874704\n",
      "Epoch:  268 | Train Accurancy:  0.9347259923815727 | Validation Accurancy:  0.9701544120907784\n",
      "Epoch:  269 | Train Accurancy:  0.9348291531205177 | Validation Accurancy:  0.9703291580080986\n",
      "Epoch:  270 | Train Accurancy:  0.9349313750863075 | Validation Accurancy:  0.9705024566501379\n",
      "Epoch:  271 | Train Accurancy:  0.935032568871975 | Validation Accurancy:  0.9706746265292168\n",
      "Epoch:  272 | Train Accurancy:  0.935132771730423 | Validation Accurancy:  0.97084547765553\n",
      "Epoch:  273 | Train Accurancy:  0.9352319687604904 | Validation Accurancy:  0.9710148815065622\n",
      "Epoch:  274 | Train Accurancy:  0.9353302791714668 | Validation Accurancy:  0.9711827747523785\n",
      "Epoch:  275 | Train Accurancy:  0.9354276061058044 | Validation Accurancy:  0.9713486358523369\n",
      "Epoch:  276 | Train Accurancy:  0.9355239942669868 | Validation Accurancy:  0.9715136047452688\n",
      "Epoch:  277 | Train Accurancy:  0.9356194734573364 | Validation Accurancy:  0.9716773200780153\n",
      "Epoch:  278 | Train Accurancy:  0.9357140511274338 | Validation Accurancy:  0.9718396179378033\n",
      "Epoch:  279 | Train Accurancy:  0.9358077496290207 | Validation Accurancy:  0.9720007255673409\n",
      "Epoch:  280 | Train Accurancy:  0.9359005391597748 | Validation Accurancy:  0.9721601642668247\n",
      "Epoch:  281 | Train Accurancy:  0.9359925016760826 | Validation Accurancy:  0.9723182842135429\n",
      "Epoch:  282 | Train Accurancy:  0.9360836371779442 | Validation Accurancy:  0.9724751636385918\n",
      "Epoch:  283 | Train Accurancy:  0.9361738786101341 | Validation Accurancy:  0.9726308658719063\n",
      "Epoch:  284 | Train Accurancy:  0.9362633302807808 | Validation Accurancy:  0.9727855529636145\n",
      "Epoch:  285 | Train Accurancy:  0.93635194003582 | Validation Accurancy:  0.9729388244450092\n",
      "Epoch:  286 | Train Accurancy:  0.9364397972822189 | Validation Accurancy:  0.9730908554047346\n",
      "Epoch:  287 | Train Accurancy:  0.9365268126130104 | Validation Accurancy:  0.9732415191829205\n",
      "Epoch:  288 | Train Accurancy:  0.9366130530834198 | Validation Accurancy:  0.9733908660709858\n",
      "Epoch:  289 | Train Accurancy:  0.9366985410451889 | Validation Accurancy:  0.9735391940921545\n",
      "Epoch:  290 | Train Accurancy:  0.9367832466959953 | Validation Accurancy:  0.9736866150051355\n",
      "Epoch:  291 | Train Accurancy:  0.9368672370910645 | Validation Accurancy:  0.9738326873630285\n",
      "Epoch:  292 | Train Accurancy:  0.9369504824280739 | Validation Accurancy:  0.9739775825291872\n",
      "Epoch:  293 | Train Accurancy:  0.9370330050587654 | Validation Accurancy:  0.9741211570799351\n",
      "Epoch:  294 | Train Accurancy:  0.9371147900819778 | Validation Accurancy:  0.9742637947201729\n",
      "Epoch:  295 | Train Accurancy:  0.9371958449482918 | Validation Accurancy:  0.9744054321199656\n",
      "Epoch:  296 | Train Accurancy:  0.9372762218117714 | Validation Accurancy:  0.9745458923280239\n",
      "Epoch:  297 | Train Accurancy:  0.9373559504747391 | Validation Accurancy:  0.974685175344348\n",
      "Epoch:  298 | Train Accurancy:  0.9374349266290665 | Validation Accurancy:  0.9748234115540981\n",
      "Epoch:  299 | Train Accurancy:  0.9375133030116558 | Validation Accurancy:  0.9749606288969517\n",
      "Epoch:  300 | Train Accurancy:  0.9375909604132175 | Validation Accurancy:  0.9750967975705862\n",
      "Epoch:  301 | Train Accurancy:  0.93766800314188 | Validation Accurancy:  0.9752319343388081\n",
      "Epoch:  302 | Train Accurancy:  0.9377443753182888 | Validation Accurancy:  0.9753660522401333\n",
      "Epoch:  303 | Train Accurancy:  0.937820129096508 | Validation Accurancy:  0.9754993282258511\n",
      "Epoch:  304 | Train Accurancy:  0.9378952160477638 | Validation Accurancy:  0.9756314437836409\n",
      "Epoch:  305 | Train Accurancy:  0.9379697442054749 | Validation Accurancy:  0.9757623039186001\n",
      "Epoch:  306 | Train Accurancy:  0.938043624162674 | Validation Accurancy:  0.9758924953639507\n",
      "Epoch:  307 | Train Accurancy:  0.9381169006228447 | Validation Accurancy:  0.9760217666625977\n",
      "Epoch:  308 | Train Accurancy:  0.938189584761858 | Validation Accurancy:  0.9761499408632517\n",
      "Epoch:  309 | Train Accurancy:  0.9382616803050041 | Validation Accurancy:  0.976277319714427\n",
      "Epoch:  310 | Train Accurancy:  0.9383331649005413 | Validation Accurancy:  0.976403696462512\n",
      "Epoch:  311 | Train Accurancy:  0.938404131680727 | Validation Accurancy:  0.9765291046351194\n",
      "Epoch:  312 | Train Accurancy:  0.9384745992720127 | Validation Accurancy:  0.9766536876559258\n",
      "Epoch:  313 | Train Accurancy:  0.9385443516075611 | Validation Accurancy:  0.9767773151397705\n",
      "Epoch:  314 | Train Accurancy:  0.9386136084794998 | Validation Accurancy:  0.9769000839442015\n",
      "Epoch:  315 | Train Accurancy:  0.9386823438107967 | Validation Accurancy:  0.9770218692719936\n",
      "Epoch:  316 | Train Accurancy:  0.9387505762279034 | Validation Accurancy:  0.9771428909152746\n",
      "Epoch:  317 | Train Accurancy:  0.9388182125985622 | Validation Accurancy:  0.9772627986967564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  318 | Train Accurancy:  0.9388853423297405 | Validation Accurancy:  0.9773823581635952\n",
      "Epoch:  319 | Train Accurancy:  0.9389519579708576 | Validation Accurancy:  0.9775006286799908\n",
      "Epoch:  320 | Train Accurancy:  0.939018078148365 | Validation Accurancy:  0.9776182491332293\n",
      "Epoch:  321 | Train Accurancy:  0.9390836842358112 | Validation Accurancy:  0.9777349624782801\n",
      "Epoch:  322 | Train Accurancy:  0.939148798584938 | Validation Accurancy:  0.9778508823364973\n",
      "Epoch:  323 | Train Accurancy:  0.9392134472727776 | Validation Accurancy:  0.977965958416462\n",
      "Epoch:  324 | Train Accurancy:  0.9392775222659111 | Validation Accurancy:  0.9780804309993982\n",
      "Epoch:  325 | Train Accurancy:  0.9393412135541439 | Validation Accurancy:  0.9781939666718245\n",
      "Epoch:  326 | Train Accurancy:  0.9394043534994125 | Validation Accurancy:  0.9783066119998693\n",
      "Epoch:  327 | Train Accurancy:  0.9394670687615871 | Validation Accurancy:  0.9784187320619822\n",
      "Epoch:  328 | Train Accurancy:  0.9395292922854424 | Validation Accurancy:  0.9785298351198435\n",
      "Epoch:  329 | Train Accurancy:  0.9395911023020744 | Validation Accurancy:  0.9786401744931936\n",
      "Epoch:  330 | Train Accurancy:  0.9396524019539356 | Validation Accurancy:  0.9787498470395803\n",
      "Epoch:  331 | Train Accurancy:  0.9397133029997349 | Validation Accurancy:  0.9788589794188738\n",
      "Epoch:  332 | Train Accurancy:  0.9397737234830856 | Validation Accurancy:  0.9789671096950769\n",
      "Epoch:  333 | Train Accurancy:  0.9398337751626968 | Validation Accurancy:  0.9790746364742517\n",
      "Epoch:  334 | Train Accurancy:  0.9398933686316013 | Validation Accurancy:  0.9791812729090452\n",
      "Epoch:  335 | Train Accurancy:  0.9399525448679924 | Validation Accurancy:  0.9792872592806816\n",
      "Epoch:  336 | Train Accurancy:  0.940011277794838 | Validation Accurancy:  0.9793927185237408\n",
      "Epoch:  337 | Train Accurancy:  0.9400696009397507 | Validation Accurancy:  0.9794972743839025\n",
      "Epoch:  338 | Train Accurancy:  0.9401275217533112 | Validation Accurancy:  0.9796011932194233\n",
      "Epoch:  339 | Train Accurancy:  0.9401850327849388 | Validation Accurancy:  0.9797044917941093\n",
      "Epoch:  340 | Train Accurancy:  0.9402421191334724 | Validation Accurancy:  0.9798069801181555\n",
      "Epoch:  341 | Train Accurancy:  0.9402988366782665 | Validation Accurancy:  0.9799088314175606\n",
      "Epoch:  342 | Train Accurancy:  0.9403551742434502 | Validation Accurancy:  0.9800100009888411\n",
      "Epoch:  343 | Train Accurancy:  0.940411102026701 | Validation Accurancy:  0.980110565200448\n",
      "Epoch:  344 | Train Accurancy:  0.9404666684567928 | Validation Accurancy:  0.9802102874964476\n",
      "Epoch:  345 | Train Accurancy:  0.9405218474566936 | Validation Accurancy:  0.9803095497190952\n",
      "Epoch:  346 | Train Accurancy:  0.9405765943229198 | Validation Accurancy:  0.9804081916809082\n",
      "Epoch:  347 | Train Accurancy:  0.9406310245394707 | Validation Accurancy:  0.9805061016231775\n",
      "Epoch:  348 | Train Accurancy:  0.9406850673258305 | Validation Accurancy:  0.9806034564971924\n",
      "Epoch:  349 | Train Accurancy:  0.9407388269901276 | Validation Accurancy:  0.980700047686696\n",
      "Epoch:  350 | Train Accurancy:  0.9407921992242336 | Validation Accurancy:  0.9807961788028479\n",
      "Epoch:  351 | Train Accurancy:  0.9408451542258263 | Validation Accurancy:  0.9808916412293911\n",
      "Epoch:  352 | Train Accurancy:  0.9408977814018726 | Validation Accurancy:  0.9809863567352295\n",
      "Epoch:  353 | Train Accurancy:  0.9409501254558563 | Validation Accurancy:  0.9810803569853306\n",
      "Epoch:  354 | Train Accurancy:  0.9410020411014557 | Validation Accurancy:  0.9811741672456264\n",
      "Epoch:  355 | Train Accurancy:  0.9410536512732506 | Validation Accurancy:  0.9812671653926373\n",
      "Epoch:  356 | Train Accurancy:  0.9411049708724022 | Validation Accurancy:  0.9813594501465559\n",
      "Epoch:  357 | Train Accurancy:  0.9411559104919434 | Validation Accurancy:  0.9814513679593801\n",
      "Epoch:  358 | Train Accurancy:  0.9412064999341965 | Validation Accurancy:  0.981542618945241\n",
      "Epoch:  359 | Train Accurancy:  0.9412569031119347 | Validation Accurancy:  0.9816332031041384\n",
      "Epoch:  360 | Train Accurancy:  0.94130689650774 | Validation Accurancy:  0.9817234985530376\n",
      "Epoch:  361 | Train Accurancy:  0.9413565322756767 | Validation Accurancy:  0.9818130023777485\n",
      "Epoch:  362 | Train Accurancy:  0.941405888646841 | Validation Accurancy:  0.9819020107388496\n",
      "Epoch:  363 | Train Accurancy:  0.9414549395442009 | Validation Accurancy:  0.9819905124604702\n",
      "Epoch:  364 | Train Accurancy:  0.9415036626160145 | Validation Accurancy:  0.982078218832612\n",
      "Epoch:  365 | Train Accurancy:  0.9415521249175072 | Validation Accurancy:  0.9821656383574009\n",
      "Epoch:  366 | Train Accurancy:  0.9416003450751305 | Validation Accurancy:  0.9822524860501289\n",
      "Epoch:  367 | Train Accurancy:  0.94164814427495 | Validation Accurancy:  0.9823387786746025\n",
      "Epoch:  368 | Train Accurancy:  0.9416956938803196 | Validation Accurancy:  0.9824246410280466\n",
      "Epoch:  369 | Train Accurancy:  0.9417429864406586 | Validation Accurancy:  0.9825097564607859\n",
      "Epoch:  370 | Train Accurancy:  0.9417899549007416 | Validation Accurancy:  0.9825943782925606\n",
      "Epoch:  371 | Train Accurancy:  0.941836666315794 | Validation Accurancy:  0.9826785083860159\n",
      "Epoch:  372 | Train Accurancy:  0.9418830797076225 | Validation Accurancy:  0.9827622417360544\n",
      "Epoch:  373 | Train Accurancy:  0.941929217427969 | Validation Accurancy:  0.9828454181551933\n",
      "Epoch:  374 | Train Accurancy:  0.9419750720262527 | Validation Accurancy:  0.9829280693084002\n",
      "Epoch:  375 | Train Accurancy:  0.9420206695795059 | Validation Accurancy:  0.9830101653933525\n",
      "Epoch:  376 | Train Accurancy:  0.9420660361647606 | Validation Accurancy:  0.9830918479710817\n",
      "Epoch:  377 | Train Accurancy:  0.9421110861003399 | Validation Accurancy:  0.9831730201840401\n",
      "Epoch:  378 | Train Accurancy:  0.9421558789908886 | Validation Accurancy:  0.9832537807524204\n",
      "Epoch:  379 | Train Accurancy:  0.9422003775835037 | Validation Accurancy:  0.9833337627351284\n",
      "Epoch:  380 | Train Accurancy:  0.9422446675598621 | Validation Accurancy:  0.9834135379642248\n",
      "Epoch:  381 | Train Accurancy:  0.9422886930406094 | Validation Accurancy:  0.9834926761686802\n",
      "Epoch:  382 | Train Accurancy:  0.9423325024545193 | Validation Accurancy:  0.9835716094821692\n",
      "Epoch:  383 | Train Accurancy:  0.9423760324716568 | Validation Accurancy:  0.9836498741060495\n",
      "Epoch:  384 | Train Accurancy:  0.9424193389713764 | Validation Accurancy:  0.9837277568876743\n",
      "Epoch:  385 | Train Accurancy:  0.9424622729420662 | Validation Accurancy:  0.9838051311671734\n",
      "Epoch:  386 | Train Accurancy:  0.9425051026046276 | Validation Accurancy:  0.983882013708353\n",
      "Epoch:  387 | Train Accurancy:  0.9425476714968681 | Validation Accurancy:  0.9839583560824394\n",
      "Epoch:  388 | Train Accurancy:  0.942590020596981 | Validation Accurancy:  0.9840345215052366\n",
      "Epoch:  389 | Train Accurancy:  0.9426320493221283 | Validation Accurancy:  0.9841101001948118\n",
      "Epoch:  390 | Train Accurancy:  0.9426739104092121 | Validation Accurancy:  0.9841852504760027\n",
      "Epoch:  391 | Train Accurancy:  0.9427155032753944 | Validation Accurancy:  0.984259907156229\n",
      "Epoch:  392 | Train Accurancy:  0.9427568838000298 | Validation Accurancy:  0.9843340869992971\n",
      "Epoch:  393 | Train Accurancy:  0.9427980706095695 | Validation Accurancy:  0.9844079334288836\n",
      "Epoch:  394 | Train Accurancy:  0.9428389929234982 | Validation Accurancy:  0.9844813188537955\n",
      "Epoch:  395 | Train Accurancy:  0.9428797252476215 | Validation Accurancy:  0.9845541957765818\n",
      "Epoch:  396 | Train Accurancy:  0.942920234054327 | Validation Accurancy:  0.984626785852015\n",
      "Epoch:  397 | Train Accurancy:  0.9429605044424534 | Validation Accurancy:  0.9846987091004848\n",
      "Epoch:  398 | Train Accurancy:  0.9430005475878716 | Validation Accurancy:  0.9847704572603106\n",
      "Epoch:  399 | Train Accurancy:  0.9430404715240002 | Validation Accurancy:  0.9848420778289437\n",
      "Epoch:  400 | Train Accurancy:  0.9430800713598728 | Validation Accurancy:  0.9849127931520343\n",
      "Epoch:  401 | Train Accurancy:  0.9431194923818111 | Validation Accurancy:  0.9849831899628043\n",
      "Epoch:  402 | Train Accurancy:  0.9431587010622025 | Validation Accurancy:  0.9850532058626413\n",
      "Epoch:  403 | Train Accurancy:  0.9431978017091751 | Validation Accurancy:  0.9851230140775442\n",
      "Epoch:  404 | Train Accurancy:  0.9432365894317627 | Validation Accurancy:  0.9851921880617738\n",
      "Epoch:  405 | Train Accurancy:  0.9432752393186092 | Validation Accurancy:  0.985261058434844\n",
      "Epoch:  406 | Train Accurancy:  0.9433136284351349 | Validation Accurancy:  0.9853295003995299\n",
      "Epoch:  407 | Train Accurancy:  0.9433519020676613 | Validation Accurancy:  0.9853975297883153\n",
      "Epoch:  408 | Train Accurancy:  0.9433899372816086 | Validation Accurancy:  0.9854653989896178\n",
      "Epoch:  409 | Train Accurancy:  0.9434277713298798 | Validation Accurancy:  0.9855326497927308\n",
      "Epoch:  410 | Train Accurancy:  0.9434654153883457 | Validation Accurancy:  0.9855996612459421\n",
      "Epoch:  411 | Train Accurancy:  0.9435028359293938 | Validation Accurancy:  0.9856661800295115\n",
      "Epoch:  412 | Train Accurancy:  0.9435401633381844 | Validation Accurancy:  0.9857324277982116\n",
      "Epoch:  413 | Train Accurancy:  0.9435772374272346 | Validation Accurancy:  0.9857982797548175\n",
      "Epoch:  414 | Train Accurancy:  0.94361412525177 | Validation Accurancy:  0.9858636064454913\n",
      "Epoch:  415 | Train Accurancy:  0.9436508752405643 | Validation Accurancy:  0.9859288213774562\n",
      "Epoch:  416 | Train Accurancy:  0.9436873458325863 | Validation Accurancy:  0.985993480309844\n",
      "Epoch:  417 | Train Accurancy:  0.9437237493693829 | Validation Accurancy:  0.9860579492524266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  418 | Train Accurancy:  0.9437599405646324 | Validation Accurancy:  0.9861217821016908\n",
      "Epoch:  419 | Train Accurancy:  0.9437959603965282 | Validation Accurancy:  0.9861854715272784\n",
      "Epoch:  420 | Train Accurancy:  0.9438317976891994 | Validation Accurancy:  0.9862488266080618\n",
      "Epoch:  421 | Train Accurancy:  0.9438674710690975 | Validation Accurancy:  0.9863117691129446\n",
      "Epoch:  422 | Train Accurancy:  0.9439030028879642 | Validation Accurancy:  0.9863741397857666\n",
      "Epoch:  423 | Train Accurancy:  0.9439382739365101 | Validation Accurancy:  0.9864363670349121\n",
      "Epoch:  424 | Train Accurancy:  0.9439734555780888 | Validation Accurancy:  0.9864984191954136\n",
      "Epoch:  425 | Train Accurancy:  0.9440084062516689 | Validation Accurancy:  0.9865599470213056\n",
      "Epoch:  426 | Train Accurancy:  0.9440432600677013 | Validation Accurancy:  0.9866211572661996\n",
      "Epoch:  427 | Train Accurancy:  0.9440779574215412 | Validation Accurancy:  0.9866817947477102\n",
      "Epoch:  428 | Train Accurancy:  0.944112416356802 | Validation Accurancy:  0.9867426073178649\n",
      "Epoch:  429 | Train Accurancy:  0.9441467747092247 | Validation Accurancy:  0.9868027055636048\n",
      "Epoch:  430 | Train Accurancy:  0.9441809840500355 | Validation Accurancy:  0.9868626752868295\n",
      "Epoch:  431 | Train Accurancy:  0.9442149586975574 | Validation Accurancy:  0.986922200769186\n",
      "Epoch:  432 | Train Accurancy:  0.9442488700151443 | Validation Accurancy:  0.9869815027341247\n",
      "Epoch:  433 | Train Accurancy:  0.9442825615406036 | Validation Accurancy:  0.9870402021333575\n",
      "Epoch:  434 | Train Accurancy:  0.9443162083625793 | Validation Accurancy:  0.9870989006012678\n",
      "Epoch:  435 | Train Accurancy:  0.9443495832383633 | Validation Accurancy:  0.9871570589020848\n",
      "Epoch:  436 | Train Accurancy:  0.9443828277289867 | Validation Accurancy:  0.9872151054441929\n",
      "Epoch:  437 | Train Accurancy:  0.944415919482708 | Validation Accurancy:  0.9872727552428842\n",
      "Epoch:  438 | Train Accurancy:  0.9444489292800426 | Validation Accurancy:  0.9873300390318036\n",
      "Epoch:  439 | Train Accurancy:  0.9444817528128624 | Validation Accurancy:  0.98738694190979\n",
      "Epoch:  440 | Train Accurancy:  0.9445143938064575 | Validation Accurancy:  0.9874436380341649\n",
      "Epoch:  441 | Train Accurancy:  0.9445469826459885 | Validation Accurancy:  0.9875001907348633\n",
      "Epoch:  442 | Train Accurancy:  0.94457932934165 | Validation Accurancy:  0.9875562191009521\n",
      "Epoch:  443 | Train Accurancy:  0.9446115791797638 | Validation Accurancy:  0.9876120407134295\n",
      "Epoch:  444 | Train Accurancy:  0.9446436986327171 | Validation Accurancy:  0.9876674972474575\n",
      "Epoch:  445 | Train Accurancy:  0.944675650447607 | Validation Accurancy:  0.987722635269165\n",
      "Epoch:  446 | Train Accurancy:  0.9447075016796589 | Validation Accurancy:  0.987777741625905\n",
      "Epoch:  447 | Train Accurancy:  0.9447391703724861 | Validation Accurancy:  0.987832291983068\n",
      "Epoch:  448 | Train Accurancy:  0.9447707869112492 | Validation Accurancy:  0.9878865564242005\n",
      "Epoch:  449 | Train Accurancy:  0.9448021985590458 | Validation Accurancy:  0.9879404222592711\n",
      "Epoch:  450 | Train Accurancy:  0.9448334723711014 | Validation Accurancy:  0.9879942098632455\n",
      "Epoch:  451 | Train Accurancy:  0.9448646418750286 | Validation Accurancy:  0.9880478857085109\n",
      "Epoch:  452 | Train Accurancy:  0.9448956735432148 | Validation Accurancy:  0.988100846298039\n",
      "Epoch:  453 | Train Accurancy:  0.9449265487492085 | Validation Accurancy:  0.9881536643952131\n",
      "Epoch:  454 | Train Accurancy:  0.9449573084712029 | Validation Accurancy:  0.9882063074037433\n",
      "Epoch:  455 | Train Accurancy:  0.944987989962101 | Validation Accurancy:  0.9882587110623717\n",
      "Epoch:  456 | Train Accurancy:  0.9450184814631939 | Validation Accurancy:  0.9883105754852295\n",
      "Epoch:  457 | Train Accurancy:  0.9450488835573196 | Validation Accurancy:  0.9883623756468296\n",
      "Epoch:  458 | Train Accurancy:  0.9450792074203491 | Validation Accurancy:  0.9884139057248831\n",
      "Epoch:  459 | Train Accurancy:  0.945109348744154 | Validation Accurancy:  0.9884651815518737\n",
      "Epoch:  460 | Train Accurancy:  0.9451393857598305 | Validation Accurancy:  0.9885161556303501\n",
      "Epoch:  461 | Train Accurancy:  0.9451691806316376 | Validation Accurancy:  0.9885667320340872\n",
      "Epoch:  462 | Train Accurancy:  0.94519904255867 | Validation Accurancy:  0.9886174835264683\n",
      "Epoch:  463 | Train Accurancy:  0.9452286809682846 | Validation Accurancy:  0.9886676790192723\n",
      "Epoch:  464 | Train Accurancy:  0.9452581889927387 | Validation Accurancy:  0.9887175243347883\n",
      "Epoch:  465 | Train Accurancy:  0.9452876597642899 | Validation Accurancy:  0.9887673696503043\n",
      "Epoch:  466 | Train Accurancy:  0.9453169927001 | Validation Accurancy:  0.988816817291081\n",
      "Epoch:  467 | Train Accurancy:  0.9453461617231369 | Validation Accurancy:  0.9888660432770848\n",
      "Epoch:  468 | Train Accurancy:  0.945375245064497 | Validation Accurancy:  0.9889154275879264\n",
      "Epoch:  469 | Train Accurancy:  0.9454042091965675 | Validation Accurancy:  0.9889639858156443\n",
      "Epoch:  470 | Train Accurancy:  0.9454330950975418 | Validation Accurancy:  0.9890125747770071\n",
      "Epoch:  471 | Train Accurancy:  0.9454617761075497 | Validation Accurancy:  0.9890609737485647\n",
      "Epoch:  472 | Train Accurancy:  0.9454903788864613 | Validation Accurancy:  0.9891088958829641\n",
      "Epoch:  473 | Train Accurancy:  0.9455189630389214 | Validation Accurancy:  0.9891568180173635\n",
      "Epoch:  474 | Train Accurancy:  0.9455473385751247 | Validation Accurancy:  0.9892044542357326\n",
      "Epoch:  475 | Train Accurancy:  0.9455757029354572 | Validation Accurancy:  0.9892516611143947\n",
      "Epoch:  476 | Train Accurancy:  0.9456038326025009 | Validation Accurancy:  0.9892985662445426\n",
      "Epoch:  477 | Train Accurancy:  0.9456319510936737 | Validation Accurancy:  0.9893452962860465\n",
      "Epoch:  478 | Train Accurancy:  0.9456599280238152 | Validation Accurancy:  0.9893919629976153\n",
      "Epoch:  479 | Train Accurancy:  0.9456878304481506 | Validation Accurancy:  0.9894382636994123\n",
      "Epoch:  480 | Train Accurancy:  0.9457155428826809 | Validation Accurancy:  0.9894840875640512\n",
      "Epoch:  481 | Train Accurancy:  0.9457432292401791 | Validation Accurancy:  0.9895298480987549\n",
      "Epoch:  482 | Train Accurancy:  0.9457708261907101 | Validation Accurancy:  0.9895754968747497\n",
      "Epoch:  483 | Train Accurancy:  0.9457982555031776 | Validation Accurancy:  0.9896205421537161\n",
      "Epoch:  484 | Train Accurancy:  0.9458256177604198 | Validation Accurancy:  0.9896658416837454\n",
      "Epoch:  485 | Train Accurancy:  0.9458528943359852 | Validation Accurancy:  0.989710315130651\n",
      "Epoch:  486 | Train Accurancy:  0.9458800591528416 | Validation Accurancy:  0.989754899404943\n",
      "Epoch:  487 | Train Accurancy:  0.9459071047604084 | Validation Accurancy:  0.989799308590591\n",
      "Epoch:  488 | Train Accurancy:  0.9459340982139111 | Validation Accurancy:  0.9898433210328221\n",
      "Epoch:  489 | Train Accurancy:  0.9459609650075436 | Validation Accurancy:  0.9898870307952166\n",
      "Epoch:  490 | Train Accurancy:  0.945987805724144 | Validation Accurancy:  0.989930422976613\n",
      "Epoch:  491 | Train Accurancy:  0.9460144303739071 | Validation Accurancy:  0.9899740694090724\n",
      "Epoch:  492 | Train Accurancy:  0.9460410140454769 | Validation Accurancy:  0.9900169214233756\n",
      "Epoch:  493 | Train Accurancy:  0.9460675083100796 | Validation Accurancy:  0.9900598842650652\n",
      "Epoch:  494 | Train Accurancy:  0.9460939280688763 | Validation Accurancy:  0.9901024820283055\n",
      "Epoch:  495 | Train Accurancy:  0.9461202248930931 | Validation Accurancy:  0.9901448572054505\n",
      "Epoch:  496 | Train Accurancy:  0.9461464285850525 | Validation Accurancy:  0.9901871364563704\n",
      "Epoch:  497 | Train Accurancy:  0.9461725428700447 | Validation Accurancy:  0.9902288755401969\n",
      "Epoch:  498 | Train Accurancy:  0.9461986161768436 | Validation Accurancy:  0.9902709638699889\n",
      "Epoch:  499 | Train Accurancy:  0.9462244659662247 | Validation Accurancy:  0.9903123220428824\n",
      "Epoch:  500 | Train Accurancy:  0.9462503865361214 | Validation Accurancy:  0.9903536001220345\n",
      "Epoch:  501 | Train Accurancy:  0.9462760910391808 | Validation Accurancy:  0.9903946714475751\n",
      "Epoch:  502 | Train Accurancy:  0.9463018551468849 | Validation Accurancy:  0.9904356952756643\n",
      "Epoch:  503 | Train Accurancy:  0.9463273659348488 | Validation Accurancy:  0.9904763698577881\n",
      "Epoch:  504 | Train Accurancy:  0.9463529363274574 | Validation Accurancy:  0.9905169010162354\n",
      "Epoch:  505 | Train Accurancy:  0.9463783465325832 | Validation Accurancy:  0.9905572570860386\n",
      "Epoch:  506 | Train Accurancy:  0.9464036747813225 | Validation Accurancy:  0.9905972480773926\n",
      "Epoch:  507 | Train Accurancy:  0.9464288912713528 | Validation Accurancy:  0.9906370956450701\n",
      "Epoch:  508 | Train Accurancy:  0.9464540965855122 | Validation Accurancy:  0.990676736459136\n",
      "Epoch:  509 | Train Accurancy:  0.9464791007339954 | Validation Accurancy:  0.9907162822782993\n",
      "Epoch:  510 | Train Accurancy:  0.9465041421353817 | Validation Accurancy:  0.9907554471865296\n",
      "Epoch:  511 | Train Accurancy:  0.9465290419757366 | Validation Accurancy:  0.9907945794984698\n",
      "Epoch:  512 | Train Accurancy:  0.9465538635849953 | Validation Accurancy:  0.9908334892243147\n",
      "Epoch:  513 | Train Accurancy:  0.94657863676548 | Validation Accurancy:  0.990872192196548\n",
      "Epoch:  514 | Train Accurancy:  0.9466033168137074 | Validation Accurancy:  0.9909107368439436\n",
      "Epoch:  515 | Train Accurancy:  0.9466279074549675 | Validation Accurancy:  0.9909489946439862\n",
      "Epoch:  516 | Train Accurancy:  0.9466524012386799 | Validation Accurancy:  0.9909872217103839\n",
      "Epoch:  517 | Train Accurancy:  0.9466767944395542 | Validation Accurancy:  0.9910251619294286\n",
      "Epoch:  518 | Train Accurancy:  0.9467011727392673 | Validation Accurancy:  0.9910628320649266\n",
      "Epoch:  519 | Train Accurancy:  0.94672542065382 | Validation Accurancy:  0.9911004388704896\n",
      "Epoch:  520 | Train Accurancy:  0.9467496685683727 | Validation Accurancy:  0.9911377904936671\n",
      "Epoch:  521 | Train Accurancy:  0.9467737190425396 | Validation Accurancy:  0.9911747295409441\n",
      "Epoch:  522 | Train Accurancy:  0.9467978104948997 | Validation Accurancy:  0.9912120820954442\n",
      "Epoch:  523 | Train Accurancy:  0.9468217082321644 | Validation Accurancy:  0.9912486867979169\n",
      "Epoch:  524 | Train Accurancy:  0.9468456394970417 | Validation Accurancy:  0.9912853557616472\n",
      "Epoch:  525 | Train Accurancy:  0.9468694552779198 | Validation Accurancy:  0.9913215953856707\n",
      "Epoch:  526 | Train Accurancy:  0.9468931518495083 | Validation Accurancy:  0.9913579309359193\n",
      "Epoch:  527 | Train Accurancy:  0.9469168707728386 | Validation Accurancy:  0.9913940588012338\n",
      "Epoch:  528 | Train Accurancy:  0.9469405002892017 | Validation Accurancy:  0.9914300125092268\n",
      "Epoch:  529 | Train Accurancy:  0.9469639025628567 | Validation Accurancy:  0.9914657436311245\n",
      "Epoch:  530 | Train Accurancy:  0.9469874426722527 | Validation Accurancy:  0.9915012996643782\n",
      "Epoch:  531 | Train Accurancy:  0.9470108523964882 | Validation Accurancy:  0.9915367448702455\n",
      "Epoch:  532 | Train Accurancy:  0.9470341019332409 | Validation Accurancy:  0.9915717598050833\n",
      "Epoch:  533 | Train Accurancy:  0.9470572955906391 | Validation Accurancy:  0.9916068715974689\n",
      "Epoch:  534 | Train Accurancy:  0.9470805078744888 | Validation Accurancy:  0.9916416322812438\n",
      "Epoch:  535 | Train Accurancy:  0.9471035748720169 | Validation Accurancy:  0.991676171310246\n",
      "Epoch:  536 | Train Accurancy:  0.9471266679465771 | Validation Accurancy:  0.9917108379304409\n",
      "Epoch:  537 | Train Accurancy:  0.9471495039761066 | Validation Accurancy:  0.9917449317872524\n",
      "Epoch:  538 | Train Accurancy:  0.9471724592149258 | Validation Accurancy:  0.9917791523039341\n",
      "Epoch:  539 | Train Accurancy:  0.9471952803432941 | Validation Accurancy:  0.9918130720034242\n",
      "Epoch:  540 | Train Accurancy:  0.9472180418670177 | Validation Accurancy:  0.9918468948453665\n",
      "Epoch:  541 | Train Accurancy:  0.9472407512366772 | Validation Accurancy:  0.9918804643675685\n",
      "Epoch:  542 | Train Accurancy:  0.9472633041441441 | Validation Accurancy:  0.9919139863923192\n",
      "Epoch:  543 | Train Accurancy:  0.9472857974469662 | Validation Accurancy:  0.9919471899047494\n",
      "Epoch:  544 | Train Accurancy:  0.9473083056509495 | Validation Accurancy:  0.991980361752212\n",
      "Epoch:  545 | Train Accurancy:  0.9473307877779007 | Validation Accurancy:  0.9920132476836443\n",
      "Epoch:  546 | Train Accurancy:  0.9473530873656273 | Validation Accurancy:  0.9920461811125278\n",
      "Epoch:  547 | Train Accurancy:  0.94737533852458 | Validation Accurancy:  0.9920786060392857\n",
      "Epoch:  548 | Train Accurancy:  0.9473976008594036 | Validation Accurancy:  0.99211117438972\n",
      "Epoch:  549 | Train Accurancy:  0.9474198222160339 | Validation Accurancy:  0.9921434558928013\n",
      "Epoch:  550 | Train Accurancy:  0.9474418647587299 | Validation Accurancy:  0.9921755632385612\n",
      "Epoch:  551 | Train Accurancy:  0.947463870048523 | Validation Accurancy:  0.992207495495677\n",
      "Epoch:  552 | Train Accurancy:  0.9474858902394772 | Validation Accurancy:  0.9922393797896802\n",
      "Epoch:  553 | Train Accurancy:  0.9475077241659164 | Validation Accurancy:  0.9922711532562971\n",
      "Epoch:  554 | Train Accurancy:  0.9475295841693878 | Validation Accurancy:  0.9923026403412223\n",
      "Epoch:  555 | Train Accurancy:  0.9475513957440853 | Validation Accurancy:  0.9923339048400521\n",
      "Epoch:  556 | Train Accurancy:  0.9475731290876865 | Validation Accurancy:  0.9923651376739144\n",
      "Epoch:  557 | Train Accurancy:  0.9475947842001915 | Validation Accurancy:  0.9923960366286337\n",
      "Epoch:  558 | Train Accurancy:  0.9476163797080517 | Validation Accurancy:  0.9924271744675934\n",
      "Epoch:  559 | Train Accurancy:  0.947637852281332 | Validation Accurancy:  0.9924578983336687\n",
      "Epoch:  560 | Train Accurancy:  0.9476593919098377 | Validation Accurancy:  0.9924884638749063\n",
      "Epoch:  561 | Train Accurancy:  0.9476807974278927 | Validation Accurancy:  0.9925189972855151\n",
      "Epoch:  562 | Train Accurancy:  0.9477021172642708 | Validation Accurancy:  0.9925491334870458\n",
      "Epoch:  563 | Train Accurancy:  0.9477234445512295 | Validation Accurancy:  0.9925792217254639\n",
      "Epoch:  564 | Train Accurancy:  0.9477447643876076 | Validation Accurancy:  0.9926093895919621\n",
      "Epoch:  565 | Train Accurancy:  0.9477658309042454 | Validation Accurancy:  0.9926390647888184\n",
      "Epoch:  566 | Train Accurancy:  0.9477869793772697 | Validation Accurancy:  0.992668628692627\n",
      "Epoch:  567 | Train Accurancy:  0.9478080160915852 | Validation Accurancy:  0.9926982400938869\n",
      "Epoch:  568 | Train Accurancy:  0.947829119861126 | Validation Accurancy:  0.9927277248352766\n",
      "Epoch:  569 | Train Accurancy:  0.9478500001132488 | Validation Accurancy:  0.9927568435668945\n",
      "Epoch:  570 | Train Accurancy:  0.9478709027171135 | Validation Accurancy:  0.9927860894240439\n",
      "Epoch:  571 | Train Accurancy:  0.9478917233645916 | Validation Accurancy:  0.9928150973282754\n",
      "Epoch:  572 | Train Accurancy:  0.94791254773736 | Validation Accurancy:  0.9928436917252839\n",
      "Epoch:  573 | Train Accurancy:  0.9479332193732262 | Validation Accurancy:  0.9928724924102426\n",
      "Epoch:  574 | Train Accurancy:  0.9479539804160595 | Validation Accurancy:  0.9929008483886719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  575 | Train Accurancy:  0.9479745142161846 | Validation Accurancy:  0.9929293156601489\n",
      "Epoch:  576 | Train Accurancy:  0.9479951076209545 | Validation Accurancy:  0.9929577829316258\n",
      "Epoch:  577 | Train Accurancy:  0.9480156525969505 | Validation Accurancy:  0.9929856937378645\n",
      "Epoch:  578 | Train Accurancy:  0.9480360299348831 | Validation Accurancy:  0.9930136362090707\n",
      "Epoch:  579 | Train Accurancy:  0.9480564258992672 | Validation Accurancy:  0.9930414040572941\n",
      "Epoch:  580 | Train Accurancy:  0.9480768218636513 | Validation Accurancy:  0.9930691877380013\n",
      "Epoch:  581 | Train Accurancy:  0.9480970725417137 | Validation Accurancy:  0.993096764665097\n",
      "Epoch:  582 | Train Accurancy:  0.9481172822415829 | Validation Accurancy:  0.9931241669692099\n",
      "Epoch:  583 | Train Accurancy:  0.9481375031173229 | Validation Accurancy:  0.993151553440839\n",
      "Epoch:  584 | Train Accurancy:  0.9481576345860958 | Validation Accurancy:  0.9931785743683577\n",
      "Epoch:  585 | Train Accurancy:  0.9481776915490627 | Validation Accurancy:  0.9932055631652474\n",
      "Epoch:  586 | Train Accurancy:  0.948197741061449 | Validation Accurancy:  0.9932325682602823\n",
      "Epoch:  587 | Train Accurancy:  0.9482177160680294 | Validation Accurancy:  0.9932592869736254\n",
      "Epoch:  588 | Train Accurancy:  0.9482376538217068 | Validation Accurancy:  0.9932858468964696\n",
      "Epoch:  589 | Train Accurancy:  0.9482575170695782 | Validation Accurancy:  0.9933122475631535\n",
      "Epoch:  590 | Train Accurancy:  0.9482773616909981 | Validation Accurancy:  0.9933387758210301\n",
      "Epoch:  591 | Train Accurancy:  0.9482971206307411 | Validation Accurancy:  0.993364938069135\n",
      "Epoch:  592 | Train Accurancy:  0.948316864669323 | Validation Accurancy:  0.9933912279084325\n",
      "Epoch:  593 | Train Accurancy:  0.9483365416526794 | Validation Accurancy:  0.9934171200729907\n",
      "Epoch:  594 | Train Accurancy:  0.9483561180531979 | Validation Accurancy:  0.9934427100233734\n",
      "Epoch:  595 | Train Accurancy:  0.9483757950365543 | Validation Accurancy:  0.9934686501510441\n",
      "Epoch:  596 | Train Accurancy:  0.9483952857553959 | Validation Accurancy:  0.9934940976090729\n",
      "Epoch:  597 | Train Accurancy:  0.9484147094190121 | Validation Accurancy:  0.9935197671875358\n",
      "Epoch:  598 | Train Accurancy:  0.948434129357338 | Validation Accurancy:  0.9935449440963566\n",
      "Epoch:  599 | Train Accurancy:  0.9484535492956638 | Validation Accurancy:  0.9935702639631927\n",
      "Epoch:  600 | Train Accurancy:  0.9484727904200554 | Validation Accurancy:  0.993595409207046\n",
      "Epoch:  601 | Train Accurancy:  0.9484920911490917 | Validation Accurancy:  0.993620268534869\n",
      "Epoch:  602 | Train Accurancy:  0.9485113210976124 | Validation Accurancy:  0.9936450798995793\n",
      "Epoch:  603 | Train Accurancy:  0.9485305324196815 | Validation Accurancy:  0.9936698754318058\n",
      "Epoch:  604 | Train Accurancy:  0.9485497213900089 | Validation Accurancy:  0.9936945596709847\n",
      "Epoch:  605 | Train Accurancy:  0.9485688172280788 | Validation Accurancy:  0.993718973826617\n",
      "Epoch:  606 | Train Accurancy:  0.9485878273844719 | Validation Accurancy:  0.9937434671446681\n",
      "Epoch:  607 | Train Accurancy:  0.9486068673431873 | Validation Accurancy:  0.9937676112167537\n",
      "Epoch:  608 | Train Accurancy:  0.9486257694661617 | Validation Accurancy:  0.9937919932417572\n",
      "Epoch:  609 | Train Accurancy:  0.9486446380615234 | Validation Accurancy:  0.9938160260207951\n",
      "Epoch:  610 | Train Accurancy:  0.9486634396016598 | Validation Accurancy:  0.9938398678787053\n",
      "Epoch:  611 | Train Accurancy:  0.9486823417246342 | Validation Accurancy:  0.9938636622391641\n",
      "Epoch:  612 | Train Accurancy:  0.9487010911107063 | Validation Accurancy:  0.9938873131759465\n",
      "Epoch:  613 | Train Accurancy:  0.9487198069691658 | Validation Accurancy:  0.9939109962433577\n",
      "Epoch:  614 | Train Accurancy:  0.9487384147942066 | Validation Accurancy:  0.9939345200546086\n",
      "Epoch:  615 | Train Accurancy:  0.9487570933997631 | Validation Accurancy:  0.9939577896147966\n",
      "Epoch:  616 | Train Accurancy:  0.9487756304442883 | Validation Accurancy:  0.9939811867661774\n",
      "Epoch:  617 | Train Accurancy:  0.9487941525876522 | Validation Accurancy:  0.9940042495727539\n",
      "Epoch:  618 | Train Accurancy:  0.9488127194344997 | Validation Accurancy:  0.9940271694213152\n",
      "Epoch:  619 | Train Accurancy:  0.9488311633467674 | Validation Accurancy:  0.9940500897355378\n",
      "Epoch:  620 | Train Accurancy:  0.9488495886325836 | Validation Accurancy:  0.9940729937516153\n",
      "Epoch:  621 | Train Accurancy:  0.9488679468631744 | Validation Accurancy:  0.9940955638885498\n",
      "Epoch:  622 | Train Accurancy:  0.9488862417638302 | Validation Accurancy:  0.9941181023605168\n",
      "Epoch:  623 | Train Accurancy:  0.9489045031368732 | Validation Accurancy:  0.9941408159211278\n",
      "Epoch:  624 | Train Accurancy:  0.9489227794110775 | Validation Accurancy:  0.9941631951369345\n",
      "Epoch:  625 | Train Accurancy:  0.9489409253001213 | Validation Accurancy:  0.9941854160279036\n",
      "Epoch:  626 | Train Accurancy:  0.9489590972661972 | Validation Accurancy:  0.9942074618302286\n",
      "Epoch:  627 | Train Accurancy:  0.9489772394299507 | Validation Accurancy:  0.9942293325439095\n",
      "Epoch:  628 | Train Accurancy:  0.9489952027797699 | Validation Accurancy:  0.9942513150162995\n",
      "Epoch:  629 | Train Accurancy:  0.9490132182836533 | Validation Accurancy:  0.9942731219343841\n",
      "Epoch:  630 | Train Accurancy:  0.9490312002599239 | Validation Accurancy:  0.9942947388626635\n",
      "Epoch:  631 | Train Accurancy:  0.9490491710603237 | Validation Accurancy:  0.9943163236603141\n",
      "Epoch:  632 | Train Accurancy:  0.9490670636296272 | Validation Accurancy:  0.9943379242904484\n",
      "Epoch:  633 | Train Accurancy:  0.9490848891437054 | Validation Accurancy:  0.9943594615906477\n",
      "Epoch:  634 | Train Accurancy:  0.9491027146577835 | Validation Accurancy:  0.9943806808441877\n",
      "Epoch:  635 | Train Accurancy:  0.9491204880177975 | Validation Accurancy:  0.9944017250090837\n",
      "Epoch:  636 | Train Accurancy:  0.9491382166743279 | Validation Accurancy:  0.9944226425141096\n",
      "Epoch:  637 | Train Accurancy:  0.9491558410227299 | Validation Accurancy:  0.9944435278885067\n",
      "Epoch:  638 | Train Accurancy:  0.9491735398769379 | Validation Accurancy:  0.9944645087234676\n",
      "Epoch:  639 | Train Accurancy:  0.9491912052035332 | Validation Accurancy:  0.9944852669723332\n",
      "Epoch:  640 | Train Accurancy:  0.9492086842656136 | Validation Accurancy:  0.9945058664306998\n",
      "Epoch:  641 | Train Accurancy:  0.9492261819541454 | Validation Accurancy:  0.9945264337584376\n",
      "Epoch:  642 | Train Accurancy:  0.9492436610162258 | Validation Accurancy:  0.9945468427613378\n",
      "Epoch:  643 | Train Accurancy:  0.9492611214518547 | Validation Accurancy:  0.9945673304609954\n",
      "Epoch:  644 | Train Accurancy:  0.9492785558104515 | Validation Accurancy:  0.9945875643752515\n",
      "Epoch:  645 | Train Accurancy:  0.9492958672344685 | Validation Accurancy:  0.9946075440384448\n",
      "Epoch:  646 | Train Accurancy:  0.9493131339550018 | Validation Accurancy:  0.9946275711990893\n",
      "Epoch:  647 | Train Accurancy:  0.9493305012583733 | Validation Accurancy:  0.9946474391035736\n",
      "Epoch:  648 | Train Accurancy:  0.9493477456271648 | Validation Accurancy:  0.9946673554368317\n",
      "Epoch:  649 | Train Accurancy:  0.9493649564683437 | Validation Accurancy:  0.9946869690902531\n",
      "Epoch:  650 | Train Accurancy:  0.9493821337819099 | Validation Accurancy:  0.9947067419998348\n",
      "Epoch:  651 | Train Accurancy:  0.9493992291390896 | Validation Accurancy:  0.9947263719514012\n",
      "Epoch:  652 | Train Accurancy:  0.9494163170456886 | Validation Accurancy:  0.9947456358931959\n",
      "Epoch:  653 | Train Accurancy:  0.9494333490729332 | Validation Accurancy:  0.9947651545517147\n",
      "Epoch:  654 | Train Accurancy:  0.9494503997266293 | Validation Accurancy:  0.9947844506241381\n",
      "Epoch:  655 | Train Accurancy:  0.9494673758745193 | Validation Accurancy:  0.994803698733449\n",
      "Epoch:  656 | Train Accurancy:  0.9494842700660229 | Validation Accurancy:  0.9948226292617619\n",
      "Epoch:  657 | Train Accurancy:  0.9495011381804943 | Validation Accurancy:  0.9948418936692178\n",
      "Epoch:  658 | Train Accurancy:  0.9495179764926434 | Validation Accurancy:  0.9948607445694506\n",
      "Epoch:  659 | Train Accurancy:  0.9495348297059536 | Validation Accurancy:  0.9948793570511043\n",
      "Epoch:  660 | Train Accurancy:  0.9495515860617161 | Validation Accurancy:  0.9948982237838209\n",
      "Epoch:  661 | Train Accurancy:  0.9495684169232845 | Validation Accurancy:  0.9949167571030557\n",
      "Epoch:  662 | Train Accurancy:  0.9495850838720798 | Validation Accurancy:  0.9949354329146445\n",
      "Epoch:  663 | Train Accurancy:  0.9496017433702946 | Validation Accurancy:  0.9949537119828165\n",
      "Epoch:  664 | Train Accurancy:  0.9496182948350906 | Validation Accurancy:  0.9949722606688738\n",
      "Epoch:  665 | Train Accurancy:  0.9496349692344666 | Validation Accurancy:  0.9949903963133693\n",
      "Epoch:  666 | Train Accurancy:  0.9496514834463596 | Validation Accurancy:  0.9950086274184287\n",
      "Epoch:  667 | Train Accurancy:  0.949668001383543 | Validation Accurancy:  0.9950266522355378\n",
      "Epoch:  668 | Train Accurancy:  0.9496845379471779 | Validation Accurancy:  0.9950448353774846\n",
      "Epoch:  669 | Train Accurancy:  0.9497009217739105 | Validation Accurancy:  0.9950626534409821\n",
      "Epoch:  670 | Train Accurancy:  0.9497173577547073 | Validation Accurancy:  0.995080423541367\n",
      "Epoch:  671 | Train Accurancy:  0.9497337453067303 | Validation Accurancy:  0.9950981615111232\n",
      "Epoch:  672 | Train Accurancy:  0.949750080704689 | Validation Accurancy:  0.9951159316115081\n",
      "Epoch:  673 | Train Accurancy:  0.9497663639485836 | Validation Accurancy:  0.9951333524659276\n",
      "Epoch:  674 | Train Accurancy:  0.9497826546430588 | Validation Accurancy:  0.9951510746032\n",
      "Epoch:  675 | Train Accurancy:  0.9497988522052765 | Validation Accurancy:  0.9951683362014592\n",
      "Epoch:  676 | Train Accurancy:  0.9498150423169136 | Validation Accurancy:  0.99518580455333\n",
      "Epoch:  677 | Train Accurancy:  0.9498312063515186 | Validation Accurancy:  0.995202986523509\n",
      "Epoch:  678 | Train Accurancy:  0.9498473331332207 | Validation Accurancy:  0.9952202956192195\n",
      "Epoch:  679 | Train Accurancy:  0.9498634859919548 | Validation Accurancy:  0.9952372550033033\n",
      "Epoch:  680 | Train Accurancy:  0.9498795196413994 | Validation Accurancy:  0.9952544053085148\n",
      "Epoch:  681 | Train Accurancy:  0.9498954899609089 | Validation Accurancy:  0.9952710471116006\n",
      "Epoch:  682 | Train Accurancy:  0.9499114789068699 | Validation Accurancy:  0.9952880064956844\n",
      "Epoch:  683 | Train Accurancy:  0.9499274753034115 | Validation Accurancy:  0.9953046482987702\n",
      "Epoch:  684 | Train Accurancy:  0.9499433524906635 | Validation Accurancy:  0.9953213850967586\n",
      "Epoch:  685 | Train Accurancy:  0.9499592743813992 | Validation Accurancy:  0.9953379789367318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  686 | Train Accurancy:  0.9499750547111034 | Validation Accurancy:  0.9953545569442213\n",
      "Epoch:  687 | Train Accurancy:  0.9499908909201622 | Validation Accurancy:  0.9953709444962442\n",
      "Epoch:  688 | Train Accurancy:  0.9500066414475441 | Validation Accurancy:  0.9953873474150896\n",
      "Epoch:  689 | Train Accurancy:  0.9500224366784096 | Validation Accurancy:  0.9954034807160497\n",
      "Epoch:  690 | Train Accurancy:  0.9500381350517273 | Validation Accurancy:  0.9954198994673789\n",
      "Epoch:  691 | Train Accurancy:  0.9500537887215614 | Validation Accurancy:  0.9954360006377101\n",
      "Epoch:  692 | Train Accurancy:  0.9500693753361702 | Validation Accurancy:  0.9954522610642016\n",
      "Epoch:  693 | Train Accurancy:  0.9500849768519402 | Validation Accurancy:  0.9954679650254548\n",
      "Epoch:  694 | Train Accurancy:  0.9501006416976452 | Validation Accurancy:  0.9954838277772069\n",
      "Epoch:  695 | Train Accurancy:  0.9501161873340607 | Validation Accurancy:  0.9954996746964753\n",
      "Epoch:  696 | Train Accurancy:  0.9501315727829933 | Validation Accurancy:  0.9955153148621321\n",
      "Epoch:  697 | Train Accurancy:  0.9501471184194088 | Validation Accurancy:  0.9955310025252402\n",
      "Epoch:  698 | Train Accurancy:  0.95016248524189 | Validation Accurancy:  0.9955465951934457\n",
      "Epoch:  699 | Train Accurancy:  0.9501779079437256 | Validation Accurancy:  0.995562203694135\n",
      "Epoch:  700 | Train Accurancy:  0.9501932747662067 | Validation Accurancy:  0.9955776054412127\n",
      "Epoch:  701 | Train Accurancy:  0.9502085782587528 | Validation Accurancy:  0.995592896360904\n",
      "Epoch:  702 | Train Accurancy:  0.950223945081234 | Validation Accurancy:  0.9956082501448691\n",
      "Epoch:  703 | Train Accurancy:  0.9502392262220383 | Validation Accurancy:  0.9956233659759164\n",
      "Epoch:  704 | Train Accurancy:  0.9502544216811657 | Validation Accurancy:  0.9956384343095124\n",
      "Epoch:  705 | Train Accurancy:  0.9502696432173252 | Validation Accurancy:  0.9956537722609937\n",
      "Epoch:  706 | Train Accurancy:  0.9502847753465176 | Validation Accurancy:  0.9956686655059457\n",
      "Epoch:  707 | Train Accurancy:  0.9502999559044838 | Validation Accurancy:  0.9956834791228175\n",
      "Epoch:  708 | Train Accurancy:  0.9503150582313538 | Validation Accurancy:  0.9956984678283334\n",
      "Epoch:  709 | Train Accurancy:  0.950330089777708 | Validation Accurancy:  0.9957131701521575\n",
      "Epoch:  710 | Train Accurancy:  0.9503452107310295 | Validation Accurancy:  0.9957278412766755\n",
      "Epoch:  711 | Train Accurancy:  0.9503601267933846 | Validation Accurancy:  0.995742432307452\n",
      "Epoch:  712 | Train Accurancy:  0.9503751620650291 | Validation Accurancy:  0.9957570871338248\n",
      "Epoch:  713 | Train Accurancy:  0.950390100479126 | Validation Accurancy:  0.9957715827040374\n",
      "Epoch:  714 | Train Accurancy:  0.9504049755632877 | Validation Accurancy:  0.9957859516143799\n",
      "Epoch:  715 | Train Accurancy:  0.950419869273901 | Validation Accurancy:  0.9958003996871412\n",
      "Epoch:  716 | Train Accurancy:  0.9504347331821918 | Validation Accurancy:  0.9958145143464208\n",
      "Epoch:  717 | Train Accurancy:  0.9504495300352573 | Validation Accurancy:  0.9958289465866983\n",
      "Epoch:  718 | Train Accurancy:  0.9504642896354198 | Validation Accurancy:  0.9958429811522365\n",
      "Epoch:  719 | Train Accurancy:  0.9504790231585503 | Validation Accurancy:  0.9958570641465485\n",
      "Epoch:  720 | Train Accurancy:  0.9504937492311001 | Validation Accurancy:  0.995871321298182\n",
      "Epoch:  721 | Train Accurancy:  0.950508464127779 | Validation Accurancy:  0.9958854038268328\n",
      "Epoch:  722 | Train Accurancy:  0.9505230709910393 | Validation Accurancy:  0.9958993433974683\n",
      "Epoch:  723 | Train Accurancy:  0.9505377523601055 | Validation Accurancy:  0.9959131083451211\n",
      "Epoch:  724 | Train Accurancy:  0.9505522921681404 | Validation Accurancy:  0.9959269044920802\n",
      "Epoch:  725 | Train Accurancy:  0.9505669064819813 | Validation Accurancy:  0.9959407011047006\n",
      "Epoch:  726 | Train Accurancy:  0.9505814723670483 | Validation Accurancy:  0.995954243466258\n",
      "Epoch:  727 | Train Accurancy:  0.9505959749221802 | Validation Accurancy:  0.9959680396132171\n",
      "Epoch:  728 | Train Accurancy:  0.9506103955209255 | Validation Accurancy:  0.9959817887283862\n",
      "Epoch:  729 | Train Accurancy:  0.9506248123943806 | Validation Accurancy:  0.9959951243363321\n",
      "Epoch:  730 | Train Accurancy:  0.9506392814218998 | Validation Accurancy:  0.9960086345672607\n",
      "Epoch:  731 | Train Accurancy:  0.9506535977125168 | Validation Accurancy:  0.9960219385102391\n",
      "Epoch:  732 | Train Accurancy:  0.9506679028272629 | Validation Accurancy:  0.9960350831970572\n",
      "Epoch:  733 | Train Accurancy:  0.9506822675466537 | Validation Accurancy:  0.9960486250929534\n",
      "Epoch:  734 | Train Accurancy:  0.9506965130567551 | Validation Accurancy:  0.9960618335753679\n",
      "Epoch:  735 | Train Accurancy:  0.9507107622921467 | Validation Accurancy:  0.9960748832672834\n",
      "Epoch:  736 | Train Accurancy:  0.9507250115275383 | Validation Accurancy:  0.9960879641585052\n",
      "Epoch:  737 | Train Accurancy:  0.950739175081253 | Validation Accurancy:  0.9961009183898568\n",
      "Epoch:  738 | Train Accurancy:  0.9507533460855484 | Validation Accurancy:  0.9961137771606445\n",
      "Epoch:  739 | Train Accurancy:  0.9507674872875214 | Validation Accurancy:  0.9961267630569637\n",
      "Epoch:  740 | Train Accurancy:  0.9507815502583981 | Validation Accurancy:  0.9961395263671875\n",
      "Epoch:  741 | Train Accurancy:  0.9507956840097904 | Validation Accurancy:  0.9961523374076933\n",
      "Epoch:  742 | Train Accurancy:  0.9508097469806671 | Validation Accurancy:  0.9961649100296199\n",
      "Epoch:  743 | Train Accurancy:  0.9508236721158028 | Validation Accurancy:  0.9961775303818285\n",
      "Epoch:  744 | Train Accurancy:  0.950837716460228 | Validation Accurancy:  0.9961902459617704\n",
      "Epoch:  745 | Train Accurancy:  0.9508516602218151 | Validation Accurancy:  0.9962025959976017\n",
      "Epoch:  746 | Train Accurancy:  0.9508655406534672 | Validation Accurancy:  0.9962149779312313\n",
      "Epoch:  747 | Train Accurancy:  0.9508794918656349 | Validation Accurancy:  0.9962272644042969\n",
      "Epoch:  748 | Train Accurancy:  0.9508933462202549 | Validation Accurancy:  0.9962395350448787\n",
      "Epoch:  749 | Train Accurancy:  0.9509071558713913 | Validation Accurancy:  0.9962517421226948\n",
      "Epoch:  750 | Train Accurancy:  0.9509209170937538 | Validation Accurancy:  0.9962641238234937\n",
      "Epoch:  751 | Train Accurancy:  0.9509346932172775 | Validation Accurancy:  0.9962762515060604\n",
      "Epoch:  752 | Train Accurancy:  0.9509484097361565 | Validation Accurancy:  0.996288204099983\n",
      "Epoch:  753 | Train Accurancy:  0.9509621895849705 | Validation Accurancy:  0.9963001885917038\n",
      "Epoch:  754 | Train Accurancy:  0.9509757645428181 | Validation Accurancy:  0.9963120142929256\n",
      "Epoch:  755 | Train Accurancy:  0.9509894624352455 | Validation Accurancy:  0.9963238397613168\n",
      "Epoch:  756 | Train Accurancy:  0.9510030746459961 | Validation Accurancy:  0.9963358561508358\n",
      "Epoch:  757 | Train Accurancy:  0.9510167129337788 | Validation Accurancy:  0.9963475703261793\n",
      "Epoch:  758 | Train Accurancy:  0.9510302282869816 | Validation Accurancy:  0.9963592211715877\n",
      "Epoch:  759 | Train Accurancy:  0.9510438367724419 | Validation Accurancy:  0.9963709353469312\n",
      "Epoch:  760 | Train Accurancy:  0.9510572850704193 | Validation Accurancy:  0.9963825384620577\n",
      "Epoch:  761 | Train Accurancy:  0.9510707557201385 | Validation Accurancy:  0.996394109679386\n",
      "Epoch:  762 | Train Accurancy:  0.9510842375457287 | Validation Accurancy:  0.9964056492317468\n",
      "Epoch:  763 | Train Accurancy:  0.9510976932942867 | Validation Accurancy:  0.9964169501326978\n",
      "Epoch:  764 | Train Accurancy:  0.9511110857129097 | Validation Accurancy:  0.9964283467270434\n",
      "Epoch:  765 | Train Accurancy:  0.951124407351017 | Validation Accurancy:  0.9964396159630269\n",
      "Epoch:  766 | Train Accurancy:  0.9511377811431885 | Validation Accurancy:  0.9964507261756808\n",
      "Epoch:  767 | Train Accurancy:  0.9511510320007801 | Validation Accurancy:  0.9964619160164148\n",
      "Epoch:  768 | Train Accurancy:  0.9511643387377262 | Validation Accurancy:  0.996473201084882\n",
      "Epoch:  769 | Train Accurancy:  0.951177604496479 | Validation Accurancy:  0.9964841683395207\n",
      "Epoch:  770 | Train Accurancy:  0.9511906877160072 | Validation Accurancy:  0.996495294617489\n",
      "Epoch:  771 | Train Accurancy:  0.9512040019035339 | Validation Accurancy:  0.9965063570998609\n",
      "Epoch:  772 | Train Accurancy:  0.9512171559035778 | Validation Accurancy:  0.9965172768570483\n",
      "Epoch:  773 | Train Accurancy:  0.9512302502989769 | Validation Accurancy:  0.9965281009208411\n",
      "Epoch:  774 | Train Accurancy:  0.9512433744966984 | Validation Accurancy:  0.9965389568824321\n",
      "Epoch:  775 | Train Accurancy:  0.9512564949691296 | Validation Accurancy:  0.9965495904907584\n",
      "Epoch:  776 | Train Accurancy:  0.9512695260345936 | Validation Accurancy:  0.9965603509917855\n",
      "Epoch:  777 | Train Accurancy:  0.951282549649477 | Validation Accurancy:  0.9965711911208928\n",
      "Epoch:  778 | Train Accurancy:  0.9512955099344254 | Validation Accurancy:  0.9965819357894361\n",
      "Epoch:  779 | Train Accurancy:  0.9513084702193737 | Validation Accurancy:  0.9965923309791833\n",
      "Epoch:  780 | Train Accurancy:  0.9513213634490967 | Validation Accurancy:  0.9966030120849609\n",
      "Epoch:  781 | Train Accurancy:  0.951334360986948 | Validation Accurancy:  0.9966134231071919\n",
      "Epoch:  782 | Train Accurancy:  0.9513472318649292 | Validation Accurancy:  0.9966238022316247\n",
      "Epoch:  783 | Train Accurancy:  0.9513600468635559 | Validation Accurancy:  0.9966342768166214\n",
      "Epoch:  784 | Train Accurancy:  0.9513728469610214 | Validation Accurancy:  0.9966445127502084\n",
      "Epoch:  785 | Train Accurancy:  0.951385710388422 | Validation Accurancy:  0.9966547966469079\n",
      "Epoch:  786 | Train Accurancy:  0.9513983987271786 | Validation Accurancy:  0.9966653028968722\n",
      "Epoch:  787 | Train Accurancy:  0.9514111690223217 | Validation Accurancy:  0.9966753642074764\n",
      "Epoch:  788 | Train Accurancy:  0.9514238722622395 | Validation Accurancy:  0.996685552643612\n",
      "Epoch:  789 | Train Accurancy:  0.9514365494251251 | Validation Accurancy:  0.9966956297867\n",
      "Epoch:  790 | Train Accurancy:  0.9514492452144623 | Validation Accurancy:  0.996705659199506\n",
      "Epoch:  791 | Train Accurancy:  0.9514618255198002 | Validation Accurancy:  0.9967157205101103\n",
      "Epoch:  792 | Train Accurancy:  0.9514743611216545 | Validation Accurancy:  0.996725654695183\n",
      "Epoch:  793 | Train Accurancy:  0.9514869973063469 | Validation Accurancy:  0.9967356841079891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  794 | Train Accurancy:  0.9514995999634266 | Validation Accurancy:  0.9967456341255456\n",
      "Epoch:  795 | Train Accurancy:  0.9515120647847652 | Validation Accurancy:  0.9967554728500545\n",
      "Epoch:  796 | Train Accurancy:  0.9515246264636517 | Validation Accurancy:  0.9967652796767652\n",
      "Epoch:  797 | Train Accurancy:  0.951537013053894 | Validation Accurancy:  0.9967751184012741\n",
      "Epoch:  798 | Train Accurancy:  0.9515494108200073 | Validation Accurancy:  0.9967848618980497\n",
      "Epoch:  799 | Train Accurancy:  0.9515618719160557 | Validation Accurancy:  0.9967945734970272\n",
      "Epoch:  800 | Train Accurancy:  0.9515743106603622 | Validation Accurancy:  0.9968043963890523\n",
      "Epoch:  801 | Train Accurancy:  0.9515866376459599 | Validation Accurancy:  0.9968140283599496\n",
      "Epoch:  802 | Train Accurancy:  0.9515989758074284 | Validation Accurancy:  0.9968235492706299\n",
      "Epoch:  803 | Train Accurancy:  0.9516112431883812 | Validation Accurancy:  0.996833038283512\n",
      "Epoch:  804 | Train Accurancy:  0.9516234584152699 | Validation Accurancy:  0.9968425433617085\n",
      "Epoch:  805 | Train Accurancy:  0.9516357965767384 | Validation Accurancy:  0.9968519688118249\n",
      "Epoch:  806 | Train Accurancy:  0.9516479559242725 | Validation Accurancy:  0.9968611400108784\n",
      "Epoch:  807 | Train Accurancy:  0.9516602493822575 | Validation Accurancy:  0.9968704858329147\n",
      "Epoch:  808 | Train Accurancy:  0.9516723267734051 | Validation Accurancy:  0.9968798637855798\n",
      "Epoch:  809 | Train Accurancy:  0.951684407889843 | Validation Accurancy:  0.996889098547399\n",
      "Epoch:  810 | Train Accurancy:  0.9516965970396996 | Validation Accurancy:  0.9968982697464526\n",
      "Epoch:  811 | Train Accurancy:  0.9517086185514927 | Validation Accurancy:  0.9969075680710375\n",
      "Epoch:  812 | Train Accurancy:  0.9517207108438015 | Validation Accurancy:  0.9969166915398091\n",
      "Epoch:  813 | Train Accurancy:  0.9517327174544334 | Validation Accurancy:  0.9969255924224854\n",
      "Epoch:  814 | Train Accurancy:  0.9517447799444199 | Validation Accurancy:  0.9969346045982093\n",
      "Epoch:  815 | Train Accurancy:  0.9517568163573742 | Validation Accurancy:  0.9969436803366989\n",
      "Epoch:  816 | Train Accurancy:  0.9517687074840069 | Validation Accurancy:  0.9969525814522058\n",
      "Epoch:  817 | Train Accurancy:  0.9517806358635426 | Validation Accurancy:  0.9969613393768668\n",
      "Epoch:  818 | Train Accurancy:  0.9517925009131432 | Validation Accurancy:  0.9969702244270593\n",
      "Epoch:  819 | Train Accurancy:  0.9518043585121632 | Validation Accurancy:  0.9969789187889546\n",
      "Epoch:  820 | Train Accurancy:  0.9518161900341511 | Validation Accurancy:  0.9969876606483012\n",
      "Epoch:  821 | Train Accurancy:  0.9518280178308487 | Validation Accurancy:  0.9969965140335262\n",
      "Epoch:  822 | Train Accurancy:  0.9518398120999336 | Validation Accurancy:  0.9970052719581872\n",
      "Epoch:  823 | Train Accurancy:  0.95185162499547 | Validation Accurancy:  0.9970139821525663\n",
      "Epoch:  824 | Train Accurancy:  0.9518633596599102 | Validation Accurancy:  0.9970224380958825\n",
      "Epoch:  825 | Train Accurancy:  0.9518750533461571 | Validation Accurancy:  0.9970309098716825\n",
      "Epoch:  826 | Train Accurancy:  0.9518866911530495 | Validation Accurancy:  0.9970396677963436\n",
      "Epoch:  827 | Train Accurancy:  0.9518984034657478 | Validation Accurancy:  0.9970480124466121\n",
      "Epoch:  828 | Train Accurancy:  0.9519100040197372 | Validation Accurancy:  0.9970564683899283\n",
      "Epoch:  829 | Train Accurancy:  0.9519216045737267 | Validation Accurancy:  0.9970648766029626\n",
      "Epoch:  830 | Train Accurancy:  0.9519331976771355 | Validation Accurancy:  0.9970732212532312\n",
      "Epoch:  831 | Train Accurancy:  0.9519447460770607 | Validation Accurancy:  0.9970814704429358\n",
      "Epoch:  832 | Train Accurancy:  0.9519562982022762 | Validation Accurancy:  0.9970898469910026\n",
      "Epoch:  833 | Train Accurancy:  0.9519678056240082 | Validation Accurancy:  0.9970980484504253\n",
      "Epoch:  834 | Train Accurancy:  0.9519792757928371 | Validation Accurancy:  0.9971062182448804\n",
      "Epoch:  835 | Train Accurancy:  0.9519907087087631 | Validation Accurancy:  0.9971143722068518\n",
      "Epoch:  836 | Train Accurancy:  0.9520020969212055 | Validation Accurancy:  0.9971225261688232\n",
      "Epoch:  837 | Train Accurancy:  0.9520135074853897 | Validation Accurancy:  0.9971306165680289\n",
      "Epoch:  838 | Train Accurancy:  0.9520249702036381 | Validation Accurancy:  0.9971388021949679\n",
      "Epoch:  839 | Train Accurancy:  0.9520363062620163 | Validation Accurancy:  0.9971467019058764\n",
      "Epoch:  840 | Train Accurancy:  0.9520476572215557 | Validation Accurancy:  0.9971546013839543\n",
      "Epoch:  841 | Train Accurancy:  0.9520589113235474 | Validation Accurancy:  0.9971624691970646\n",
      "Epoch:  842 | Train Accurancy:  0.9520701840519905 | Validation Accurancy:  0.9971705437637866\n",
      "Epoch:  843 | Train Accurancy:  0.9520814456045628 | Validation Accurancy:  0.9971782525535673\n",
      "Epoch:  844 | Train Accurancy:  0.9520927220582962 | Validation Accurancy:  0.9971861045341939\n",
      "Epoch:  845 | Train Accurancy:  0.9521038495004177 | Validation Accurancy:  0.9971938768867403\n",
      "Epoch:  846 | Train Accurancy:  0.9521149881184101 | Validation Accurancy:  0.9972017924301326\n",
      "Epoch:  847 | Train Accurancy:  0.9521261267364025 | Validation Accurancy:  0.9972094534896314\n",
      "Epoch:  848 | Train Accurancy:  0.9521372318267822 | Validation Accurancy:  0.9972171464469284\n",
      "Epoch:  849 | Train Accurancy:  0.952148362994194 | Validation Accurancy:  0.9972248077392578\n",
      "Epoch:  850 | Train Accurancy:  0.952159445732832 | Validation Accurancy:  0.9972324529662728\n",
      "Epoch:  851 | Train Accurancy:  0.9521705135703087 | Validation Accurancy:  0.9972400984261185\n",
      "Epoch:  852 | Train Accurancy:  0.9521814770996571 | Validation Accurancy:  0.9972475529648364\n",
      "Epoch:  853 | Train Accurancy:  0.9521924331784248 | Validation Accurancy:  0.9972550550010055\n",
      "Epoch:  854 | Train Accurancy:  0.9522033892571926 | Validation Accurancy:  0.9972625256050378\n",
      "Epoch:  855 | Train Accurancy:  0.9522143788635731 | Validation Accurancy:  0.9972700437065214\n",
      "Epoch:  856 | Train Accurancy:  0.9522253535687923 | Validation Accurancy:  0.9972774824127555\n",
      "Epoch:  857 | Train Accurancy:  0.9522361531853676 | Validation Accurancy:  0.9972848256584257\n",
      "Epoch:  858 | Train Accurancy:  0.9522470533847809 | Validation Accurancy:  0.9972920895088464\n",
      "Epoch:  859 | Train Accurancy:  0.9522578902542591 | Validation Accurancy:  0.997299559880048\n",
      "Epoch:  860 | Train Accurancy:  0.9522687010467052 | Validation Accurancy:  0.9973070621490479\n",
      "Epoch:  861 | Train Accurancy:  0.9522794857621193 | Validation Accurancy:  0.9973142624367028\n",
      "Epoch:  862 | Train Accurancy:  0.9522902593016624 | Validation Accurancy:  0.99732127180323\n",
      "Epoch:  863 | Train Accurancy:  0.9523009844124317 | Validation Accurancy:  0.997328472090885\n",
      "Epoch:  864 | Train Accurancy:  0.9523116536438465 | Validation Accurancy:  0.9973358472343534\n",
      "Epoch:  865 | Train Accurancy:  0.9523223824799061 | Validation Accurancy:  0.9973427930381149\n",
      "Epoch:  866 | Train Accurancy:  0.9523330964148045 | Validation Accurancy:  0.9973498980980366\n",
      "Epoch:  867 | Train Accurancy:  0.9523437209427357 | Validation Accurancy:  0.9973569074645638\n",
      "Epoch:  868 | Train Accurancy:  0.9523543305695057 | Validation Accurancy:  0.9973639806266874\n",
      "Epoch:  869 | Train Accurancy:  0.9523649290204048 | Validation Accurancy:  0.9973709264304489\n",
      "Epoch:  870 | Train Accurancy:  0.9523754753172398 | Validation Accurancy:  0.9973779837600887\n",
      "Epoch:  871 | Train Accurancy:  0.9523860067129135 | Validation Accurancy:  0.9973848343361169\n",
      "Epoch:  872 | Train Accurancy:  0.9523965120315552 | Validation Accurancy:  0.9973916371818632\n",
      "Epoch:  873 | Train Accurancy:  0.9524069912731647 | Validation Accurancy:  0.9973986307159066\n",
      "Epoch:  874 | Train Accurancy:  0.9524175003170967 | Validation Accurancy:  0.9974055925849825\n",
      "Epoch:  875 | Train Accurancy:  0.952427975833416 | Validation Accurancy:  0.9974122683051974\n",
      "Epoch:  876 | Train Accurancy:  0.9524383805692196 | Validation Accurancy:  0.9974191030487418\n",
      "Epoch:  877 | Train Accurancy:  0.9524487741291523 | Validation Accurancy:  0.9974260330200195\n",
      "Epoch:  878 | Train Accurancy:  0.9524590894579887 | Validation Accurancy:  0.9974326451774687\n",
      "Epoch:  879 | Train Accurancy:  0.9524694532155991 | Validation Accurancy:  0.9974392254371196\n",
      "Epoch:  880 | Train Accurancy:  0.9524797275662422 | Validation Accurancy:  0.9974459966178983\n",
      "Epoch:  881 | Train Accurancy:  0.9524900652468204 | Validation Accurancy:  0.9974525452125818\n",
      "Epoch:  882 | Train Accurancy:  0.9525003395974636 | Validation Accurancy:  0.9974593161605299\n",
      "Epoch:  883 | Train Accurancy:  0.9525105506181717 | Validation Accurancy:  0.9974656105041504\n",
      "Epoch:  884 | Train Accurancy:  0.9525208435952663 | Validation Accurancy:  0.997472254326567\n",
      "Epoch:  885 | Train Accurancy:  0.9525309763848782 | Validation Accurancy:  0.9974788348190486\n",
      "Epoch:  886 | Train Accurancy:  0.952541146427393 | Validation Accurancy:  0.9974851608276367\n",
      "Epoch:  887 | Train Accurancy:  0.9525512829422951 | Validation Accurancy:  0.9974917094223201\n",
      "Epoch:  888 | Train Accurancy:  0.9525614902377129 | Validation Accurancy:  0.9974981944542378\n",
      "Epoch:  889 | Train Accurancy:  0.9525715671479702 | Validation Accurancy:  0.9975046475883573\n",
      "Epoch:  890 | Train Accurancy:  0.9525816403329372 | Validation Accurancy:  0.9975109100341797\n",
      "Epoch:  891 | Train Accurancy:  0.9525916762650013 | Validation Accurancy:  0.9975175221916288\n",
      "Epoch:  892 | Train Accurancy:  0.952601745724678 | Validation Accurancy:  0.9975239436607808\n",
      "Epoch:  893 | Train Accurancy:  0.9526117518544197 | Validation Accurancy:  0.9975303013343364\n",
      "Epoch:  894 | Train Accurancy:  0.9526216983795166 | Validation Accurancy:  0.9975365321151912\n",
      "Epoch:  895 | Train Accurancy:  0.9526316449046135 | Validation Accurancy:  0.9975428581237793\n",
      "Epoch:  896 | Train Accurancy:  0.9526416286826134 | Validation Accurancy:  0.9975489934440702\n",
      "Epoch:  897 | Train Accurancy:  0.952651496976614 | Validation Accurancy:  0.997555383015424\n",
      "Epoch:  898 | Train Accurancy:  0.9526614099740982 | Validation Accurancy:  0.9975616137962788\n",
      "Epoch:  899 | Train Accurancy:  0.9526712372899055 | Validation Accurancy:  0.9975675900932401\n",
      "Epoch:  900 | Train Accurancy:  0.9526810571551323 | Validation Accurancy:  0.9975737889762968\n",
      "Epoch:  901 | Train Accurancy:  0.9526908956468105 | Validation Accurancy:  0.997580019524321\n",
      "Epoch:  902 | Train Accurancy:  0.9527006782591343 | Validation Accurancy:  0.9975860277190804\n",
      "Epoch:  903 | Train Accurancy:  0.952710397541523 | Validation Accurancy:  0.9975921313744038\n",
      "Epoch:  904 | Train Accurancy:  0.9527202621102333 | Validation Accurancy:  0.9975980441085994\n",
      "Epoch:  905 | Train Accurancy:  0.9527298808097839 | Validation Accurancy:  0.9976042110938579\n",
      "Epoch:  906 | Train Accurancy:  0.9527395665645599 | Validation Accurancy:  0.9976100921630859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  907 | Train Accurancy:  0.9527492858469486 | Validation Accurancy:  0.9976161003578454\n",
      "Epoch:  908 | Train Accurancy:  0.9527588859200478 | Validation Accurancy:  0.9976223628036678\n",
      "Epoch:  909 | Train Accurancy:  0.952768474817276 | Validation Accurancy:  0.9976281800772995\n",
      "Epoch:  910 | Train Accurancy:  0.9527781121432781 | Validation Accurancy:  0.9976342201698571\n",
      "Epoch:  911 | Train Accurancy:  0.9527876749634743 | Validation Accurancy:  0.997640069341287\n",
      "Epoch:  912 | Train Accurancy:  0.9527972005307674 | Validation Accurancy:  0.9976459504105151\n",
      "Epoch:  913 | Train Accurancy:  0.9528067335486412 | Validation Accurancy:  0.997651704121381\n",
      "Epoch:  914 | Train Accurancy:  0.9528163149952888 | Validation Accurancy:  0.9976576804183424\n",
      "Epoch:  915 | Train Accurancy:  0.9528257623314857 | Validation Accurancy:  0.997663434362039\n",
      "Epoch:  916 | Train Accurancy:  0.9528352469205856 | Validation Accurancy:  0.997669315431267\n",
      "Epoch:  917 | Train Accurancy:  0.9528447203338146 | Validation Accurancy:  0.9976749101188034\n",
      "Epoch:  918 | Train Accurancy:  0.9528540521860123 | Validation Accurancy:  0.9976807276252657\n",
      "Epoch:  919 | Train Accurancy:  0.9528634697198868 | Validation Accurancy:  0.997686258982867\n",
      "Epoch:  920 | Train Accurancy:  0.9528728164732456 | Validation Accurancy:  0.9976921400520951\n",
      "Epoch:  921 | Train Accurancy:  0.9528821371495724 | Validation Accurancy:  0.9976977347396314\n",
      "Epoch:  922 | Train Accurancy:  0.9528914801776409 | Validation Accurancy:  0.9977032660972327\n",
      "Epoch:  923 | Train Accurancy:  0.9529007598757744 | Validation Accurancy:  0.9977089881431311\n",
      "Epoch:  924 | Train Accurancy:  0.9529100358486176 | Validation Accurancy:  0.9977144240401685\n",
      "Epoch:  925 | Train Accurancy:  0.9529193006455898 | Validation Accurancy:  0.997720146086067\n",
      "Epoch:  926 | Train Accurancy:  0.9529285579919815 | Validation Accurancy:  0.9977256774436682\n",
      "Epoch:  927 | Train Accurancy:  0.9529378190636635 | Validation Accurancy:  0.9977311133407056\n",
      "Epoch:  928 | Train Accurancy:  0.9529469385743141 | Validation Accurancy:  0.9977365811355412\n",
      "Epoch:  929 | Train Accurancy:  0.9529561176896095 | Validation Accurancy:  0.9977419534698129\n",
      "Epoch:  930 | Train Accurancy:  0.952965185046196 | Validation Accurancy:  0.997747294139117\n",
      "Epoch:  931 | Train Accurancy:  0.9529743865132332 | Validation Accurancy:  0.9977529207244515\n",
      "Epoch:  932 | Train Accurancy:  0.9529834687709808 | Validation Accurancy:  0.9977581659331918\n",
      "Epoch:  933 | Train Accurancy:  0.9529925510287285 | Validation Accurancy:  0.9977636337280273\n",
      "Epoch:  934 | Train Accurancy:  0.9530015252530575 | Validation Accurancy:  0.997768719913438\n",
      "Epoch:  935 | Train Accurancy:  0.9530106075108051 | Validation Accurancy:  0.9977741241455078\n",
      "Epoch:  936 | Train Accurancy:  0.95301952958107 | Validation Accurancy:  0.9977794012520462\n",
      "Epoch:  937 | Train Accurancy:  0.9530285149812698 | Validation Accurancy:  0.9977845510002226\n",
      "Epoch:  938 | Train Accurancy:  0.9530374817550182 | Validation Accurancy:  0.9977899552322924\n",
      "Epoch:  939 | Train Accurancy:  0.9530464671552181 | Validation Accurancy:  0.9977948507294059\n",
      "Epoch:  940 | Train Accurancy:  0.9530553668737411 | Validation Accurancy:  0.9978001595009118\n",
      "Epoch:  941 | Train Accurancy:  0.9530642591416836 | Validation Accurancy:  0.9978051821235567\n",
      "Epoch:  942 | Train Accurancy:  0.9530730582773685 | Validation Accurancy:  0.9978101730812341\n",
      "Epoch:  943 | Train Accurancy:  0.9530819207429886 | Validation Accurancy:  0.9978154499549419\n",
      "Epoch:  944 | Train Accurancy:  0.9530908092856407 | Validation Accurancy:  0.9978205363731831\n",
      "Epoch:  945 | Train Accurancy:  0.9530995450913906 | Validation Accurancy:  0.9978254954330623\n",
      "Epoch:  946 | Train Accurancy:  0.9531083442270756 | Validation Accurancy:  0.9978306135162711\n",
      "Epoch:  947 | Train Accurancy:  0.9531170092523098 | Validation Accurancy:  0.9978353818878531\n",
      "Epoch:  948 | Train Accurancy:  0.9531257823109627 | Validation Accurancy:  0.997840499971062\n",
      "Epoch:  949 | Train Accurancy:  0.9531344994902611 | Validation Accurancy:  0.9978455542586744\n",
      "Epoch:  950 | Train Accurancy:  0.9531431719660759 | Validation Accurancy:  0.9978504499886185\n",
      "Epoch:  951 | Train Accurancy:  0.9531518444418907 | Validation Accurancy:  0.9978554407134652\n",
      "Epoch:  952 | Train Accurancy:  0.9531604126095772 | Validation Accurancy:  0.9978601774200797\n",
      "Epoch:  953 | Train Accurancy:  0.9531691111624241 | Validation Accurancy:  0.9978650729171932\n",
      "Epoch:  954 | Train Accurancy:  0.9531776830554008 | Validation Accurancy:  0.9978698412887752\n",
      "Epoch:  955 | Train Accurancy:  0.9531863108277321 | Validation Accurancy:  0.9978748639114201\n",
      "Epoch:  956 | Train Accurancy:  0.9531949013471603 | Validation Accurancy:  0.9978796006180346\n",
      "Epoch:  957 | Train Accurancy:  0.9532033354043961 | Validation Accurancy:  0.9978843689896166\n",
      "Epoch:  958 | Train Accurancy:  0.9532118625938892 | Validation Accurancy:  0.997889073798433\n",
      "Epoch:  959 | Train Accurancy:  0.9532203450798988 | Validation Accurancy:  0.9978938102722168\n",
      "Epoch:  960 | Train Accurancy:  0.9532288238406181 | Validation Accurancy:  0.9978984831832349\n",
      "Epoch:  961 | Train Accurancy:  0.9532372653484344 | Validation Accurancy:  0.9979034741409123\n",
      "Epoch:  962 | Train Accurancy:  0.9532456919550896 | Validation Accurancy:  0.9979079246986657\n",
      "Epoch:  963 | Train Accurancy:  0.9532540962100029 | Validation Accurancy:  0.9979128201957792\n",
      "Epoch:  964 | Train Accurancy:  0.9532624632120132 | Validation Accurancy:  0.9979173343162984\n",
      "Epoch:  965 | Train Accurancy:  0.9532708562910557 | Validation Accurancy:  0.9979220072273165\n",
      "Epoch:  966 | Train Accurancy:  0.9532791636884212 | Validation Accurancy:  0.9979265213478357\n",
      "Epoch:  967 | Train Accurancy:  0.953287448734045 | Validation Accurancy:  0.9979313213843852\n",
      "Epoch:  968 | Train Accurancy:  0.9532957747578621 | Validation Accurancy:  0.9979358674027026\n",
      "Epoch:  969 | Train Accurancy:  0.9533040374517441 | Validation Accurancy:  0.9979403496254236\n",
      "Epoch:  970 | Train Accurancy:  0.9533122964203358 | Validation Accurancy:  0.9979449273087084\n",
      "Epoch:  971 | Train Accurancy:  0.9533204920589924 | Validation Accurancy:  0.9979493459686637\n",
      "Epoch:  972 | Train Accurancy:  0.9533286765217781 | Validation Accurancy:  0.9979539236519486\n",
      "Epoch:  973 | Train Accurancy:  0.9533368460834026 | Validation Accurancy:  0.9979585011024028\n",
      "Epoch:  974 | Train Accurancy:  0.9533450119197369 | Validation Accurancy:  0.9979629516601562\n",
      "Epoch:  975 | Train Accurancy:  0.9533531926572323 | Validation Accurancy:  0.9979674657806754\n",
      "Epoch:  976 | Train Accurancy:  0.9533612355589867 | Validation Accurancy:  0.9979717889800668\n",
      "Epoch:  977 | Train Accurancy:  0.953369352966547 | Validation Accurancy:  0.9979764621239156\n",
      "Epoch:  978 | Train Accurancy:  0.9533774629235268 | Validation Accurancy:  0.9979807217605412\n",
      "Epoch:  979 | Train Accurancy:  0.953385453671217 | Validation Accurancy:  0.9979852994438261\n",
      "Epoch:  980 | Train Accurancy:  0.9533935561776161 | Validation Accurancy:  0.9979895274154842\n",
      "Epoch:  981 | Train Accurancy:  0.9534015245735645 | Validation Accurancy:  0.9979939460754395\n",
      "Epoch:  982 | Train Accurancy:  0.9534095264971256 | Validation Accurancy:  0.9979981421492994\n",
      "Epoch:  983 | Train Accurancy:  0.953417468816042 | Validation Accurancy:  0.9980025610420853\n",
      "Epoch:  984 | Train Accurancy:  0.9534254483878613 | Validation Accurancy:  0.9980070113670081\n",
      "Epoch:  985 | Train Accurancy:  0.9534333273768425 | Validation Accurancy:  0.998011048650369\n",
      "Epoch:  986 | Train Accurancy:  0.9534412771463394 | Validation Accurancy:  0.9980155944358557\n",
      "Epoch:  987 | Train Accurancy:  0.9534491933882236 | Validation Accurancy:  0.9980196952819824\n",
      "Epoch:  988 | Train Accurancy:  0.9534570761024952 | Validation Accurancy:  0.998024050379172\n",
      "Epoch:  989 | Train Accurancy:  0.9534648805856705 | Validation Accurancy:  0.9980280876625329\n",
      "Epoch:  990 | Train Accurancy:  0.9534726589918137 | Validation Accurancy:  0.9980324108619243\n",
      "Epoch:  991 | Train Accurancy:  0.9534805119037628 | Validation Accurancy:  0.998036511708051\n",
      "Epoch:  992 | Train Accurancy:  0.9534883052110672 | Validation Accurancy:  0.9980407715775073\n",
      "Epoch:  993 | Train Accurancy:  0.9534960128366947 | Validation Accurancy:  0.9980448086280376\n",
      "Epoch:  994 | Train Accurancy:  0.9535036757588387 | Validation Accurancy:  0.9980491320602596\n",
      "Epoch:  995 | Train Accurancy:  0.9535114504396915 | Validation Accurancy:  0.9980530421016738\n",
      "Epoch:  996 | Train Accurancy:  0.9535192102193832 | Validation Accurancy:  0.998057238291949\n",
      "Epoch:  997 | Train Accurancy:  0.953526895493269 | Validation Accurancy:  0.9980613390216604\n",
      "Epoch:  998 | Train Accurancy:  0.9535345993936062 | Validation Accurancy:  0.9980653127422556\n",
      "Epoch:  999 | Train Accurancy:  0.95354213565588 | Validation Accurancy:  0.9980695724952966\n",
      "Epoch:  1000 | Train Accurancy:  0.9535497352480888 | Validation Accurancy:  0.9980734189739451\n",
      "Epoch:  1001 | Train Accurancy:  0.9535573534667492 | Validation Accurancy:  0.9980775832664222\n",
      "Epoch:  1002 | Train Accurancy:  0.9535648934543133 | Validation Accurancy:  0.9980815252056345\n",
      "Epoch:  1003 | Train Accurancy:  0.9535724483430386 | Validation Accurancy:  0.9980855305911973\n",
      "Epoch:  1004 | Train Accurancy:  0.9535800069570541 | Validation Accurancy:  0.9980893770698458\n",
      "Epoch:  1005 | Train Accurancy:  0.9535875581204891 | Validation Accurancy:  0.9980936368228868\n",
      "Epoch:  1006 | Train Accurancy:  0.9535950422286987 | Validation Accurancy:  0.9980975150829181\n",
      "Epoch:  1007 | Train Accurancy:  0.9536025002598763 | Validation Accurancy:  0.9981014888035133\n",
      "Epoch:  1008 | Train Accurancy:  0.9536099284887314 | Validation Accurancy:  0.9981053352821618\n",
      "Epoch:  1009 | Train Accurancy:  0.9536173790693283 | Validation Accurancy:  0.9981092771049589\n",
      "Epoch:  1010 | Train Accurancy:  0.953624777495861 | Validation Accurancy:  0.9981131235836074\n",
      "Epoch:  1011 | Train Accurancy:  0.9536321982741356 | Validation Accurancy:  0.9981169064994901\n",
      "Epoch:  1012 | Train Accurancy:  0.9536395892500877 | Validation Accurancy:  0.9981208165409043\n",
      "Epoch:  1013 | Train Accurancy:  0.9536468982696533 | Validation Accurancy:  0.9981248538242653\n",
      "Epoch:  1014 | Train Accurancy:  0.953654233366251 | Validation Accurancy:  0.9981286685215309\n",
      "Epoch:  1015 | Train Accurancy:  0.9536615498363972 | Validation Accurancy:  0.9981323877582327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1016 | Train Accurancy:  0.9536688402295113 | Validation Accurancy:  0.998136043548584\n",
      "Epoch:  1017 | Train Accurancy:  0.9536761306226254 | Validation Accurancy:  0.998139985371381\n",
      "Epoch:  1018 | Train Accurancy:  0.9536834359169006 | Validation Accurancy:  0.9981435775989667\n",
      "Epoch:  1019 | Train Accurancy:  0.9536906033754349 | Validation Accurancy:  0.9981474876403809\n",
      "Epoch:  1020 | Train Accurancy:  0.9536978676915169 | Validation Accurancy:  0.9981512069934979\n",
      "Epoch:  1021 | Train Accurancy:  0.9537049829959869 | Validation Accurancy:  0.9981551170349121\n",
      "Epoch:  1022 | Train Accurancy:  0.9537121914327145 | Validation Accurancy:  0.9981586455833167\n",
      "Epoch:  1023 | Train Accurancy:  0.9537193216383457 | Validation Accurancy:  0.9981623649364337\n",
      "Epoch:  1024 | Train Accurancy:  0.9537264369428158 | Validation Accurancy:  0.9981661160709336\n",
      "Epoch:  1025 | Train Accurancy:  0.9537335149943829 | Validation Accurancy:  0.9981696765171364\n",
      "Epoch:  1026 | Train Accurancy:  0.9537406452000141 | Validation Accurancy:  0.998173427535221\n",
      "Epoch:  1027 | Train Accurancy:  0.9537476897239685 | Validation Accurancy:  0.9981768926372752\n",
      "Epoch:  1028 | Train Accurancy:  0.9537548124790192 | Validation Accurancy:  0.9981807708973065\n",
      "Epoch:  1029 | Train Accurancy:  0.9537618272006512 | Validation Accurancy:  0.9981844265712425\n",
      "Epoch:  1030 | Train Accurancy:  0.9537688568234444 | Validation Accurancy:  0.9981881141429767\n",
      "Epoch:  1031 | Train Accurancy:  0.9537758231163025 | Validation Accurancy:  0.9981917063705623\n",
      "Epoch:  1032 | Train Accurancy:  0.9537828117609024 | Validation Accurancy:  0.9981952984817326\n",
      "Epoch:  1033 | Train Accurancy:  0.9537897408008575 | Validation Accurancy:  0.9981988271465525\n",
      "Epoch:  1034 | Train Accurancy:  0.9537966661155224 | Validation Accurancy:  0.9982024510391057\n",
      "Epoch:  1035 | Train Accurancy:  0.9538035690784454 | Validation Accurancy:  0.9982059797039255\n",
      "Epoch:  1036 | Train Accurancy:  0.953810453414917 | Validation Accurancy:  0.9982094764709473\n",
      "Epoch:  1037 | Train Accurancy:  0.9538173824548721 | Validation Accurancy:  0.9982130050193518\n",
      "Epoch:  1038 | Train Accurancy:  0.9538242667913437 | Validation Accurancy:  0.9982165654655546\n",
      "Epoch:  1039 | Train Accurancy:  0.9538310654461384 | Validation Accurancy:  0.9982200304511935\n",
      "Epoch:  1040 | Train Accurancy:  0.9538379088044167 | Validation Accurancy:  0.9982234636554495\n",
      "Epoch:  1041 | Train Accurancy:  0.953844714909792 | Validation Accurancy:  0.9982268650783226\n",
      "Epoch:  1042 | Train Accurancy:  0.9538515210151672 | Validation Accurancy:  0.9982302983989939\n",
      "Epoch:  1043 | Train Accurancy:  0.9538583233952522 | Validation Accurancy:  0.9982338905101642\n",
      "Epoch:  1044 | Train Accurancy:  0.9538649506866932 | Validation Accurancy:  0.9982372283702716\n",
      "Epoch:  1045 | Train Accurancy:  0.9538717977702618 | Validation Accurancy:  0.9982407252537087\n",
      "Epoch:  1046 | Train Accurancy:  0.9538784362375736 | Validation Accurancy:  0.9982440631138161\n",
      "Epoch:  1047 | Train Accurancy:  0.95388513058424 | Validation Accurancy:  0.9982474645366892\n",
      "Epoch:  1048 | Train Accurancy:  0.9538917802274227 | Validation Accurancy:  0.9982508341781795\n",
      "Epoch:  1049 | Train Accurancy:  0.9538984447717667 | Validation Accurancy:  0.9982542038196698\n",
      "Epoch:  1050 | Train Accurancy:  0.9539050906896591 | Validation Accurancy:  0.9982576688053086\n",
      "Epoch:  1051 | Train Accurancy:  0.9539117179811001 | Validation Accurancy:  0.9982609431026503\n",
      "Epoch:  1052 | Train Accurancy:  0.9539183564484119 | Validation Accurancy:  0.998264217399992\n",
      "Epoch:  1053 | Train Accurancy:  0.9539248831570148 | Validation Accurancy:  0.9982676188228652\n",
      "Epoch:  1054 | Train Accurancy:  0.9539315551519394 | Validation Accurancy:  0.9982708295574412\n",
      "Epoch:  1055 | Train Accurancy:  0.9539379477500916 | Validation Accurancy:  0.9982744216686115\n",
      "Epoch:  1056 | Train Accurancy:  0.9539445154368877 | Validation Accurancy:  0.9982775370590389\n",
      "Epoch:  1057 | Train Accurancy:  0.9539509639143944 | Validation Accurancy:  0.9982808113563806\n",
      "Epoch:  1058 | Train Accurancy:  0.9539574719965458 | Validation Accurancy:  0.9982842763420194\n",
      "Epoch:  1059 | Train Accurancy:  0.9539639502763748 | Validation Accurancy:  0.9982874870765954\n",
      "Epoch:  1060 | Train Accurancy:  0.95397038012743 | Validation Accurancy:  0.9982906976947561\n",
      "Epoch:  1061 | Train Accurancy:  0.9539767988026142 | Validation Accurancy:  0.9982939084293321\n",
      "Epoch:  1062 | Train Accurancy:  0.9539832063019276 | Validation Accurancy:  0.9982970238197595\n",
      "Epoch:  1063 | Train Accurancy:  0.9539896510541439 | Validation Accurancy:  0.9983002980006859\n",
      "Epoch:  1064 | Train Accurancy:  0.9539959765970707 | Validation Accurancy:  0.9983034133911133\n",
      "Epoch:  1065 | Train Accurancy:  0.9540023393929005 | Validation Accurancy:  0.9983065287815407\n",
      "Epoch:  1066 | Train Accurancy:  0.954008661210537 | Validation Accurancy:  0.9983099937671795\n",
      "Epoch:  1067 | Train Accurancy:  0.9540149718523026 | Validation Accurancy:  0.9983129819156602\n",
      "Epoch:  1068 | Train Accurancy:  0.954021267592907 | Validation Accurancy:  0.9983163515571505\n",
      "Epoch:  1069 | Train Accurancy:  0.9540275447070599 | Validation Accurancy:  0.9983193397056311\n",
      "Epoch:  1070 | Train Accurancy:  0.9540337771177292 | Validation Accurancy:  0.9983223915332928\n",
      "Epoch:  1071 | Train Accurancy:  0.9540400691330433 | Validation Accurancy:  0.9983255068073049\n",
      "Epoch:  1072 | Train Accurancy:  0.9540463015437126 | Validation Accurancy:  0.9983286221977323\n",
      "Epoch:  1073 | Train Accurancy:  0.9540525190532207 | Validation Accurancy:  0.9983318011509255\n",
      "Epoch:  1074 | Train Accurancy:  0.9540586806833744 | Validation Accurancy:  0.9983350117690861\n",
      "Epoch:  1075 | Train Accurancy:  0.9540648832917213 | Validation Accurancy:  0.9983378727920353\n",
      "Epoch:  1076 | Train Accurancy:  0.9540710113942623 | Validation Accurancy:  0.9983411153079942\n",
      "Epoch:  1077 | Train Accurancy:  0.9540771991014481 | Validation Accurancy:  0.998344071675092\n",
      "Epoch:  1078 | Train Accurancy:  0.9540833011269569 | Validation Accurancy:  0.998347059939988\n",
      "Epoch:  1079 | Train Accurancy:  0.9540893994271755 | Validation Accurancy:  0.9983502069953829\n",
      "Epoch:  1080 | Train Accurancy:  0.9540954567492008 | Validation Accurancy:  0.9983530362369493\n",
      "Epoch:  1081 | Train Accurancy:  0.9541015699505806 | Validation Accurancy:  0.9983561834087595\n",
      "Epoch:  1082 | Train Accurancy:  0.9541075527667999 | Validation Accurancy:  0.9983593304641545\n",
      "Epoch:  1083 | Train Accurancy:  0.9541136138141155 | Validation Accurancy:  0.9983623187290505\n",
      "Epoch:  1084 | Train Accurancy:  0.9541196003556252 | Validation Accurancy:  0.9983653704402968\n",
      "Epoch:  1085 | Train Accurancy:  0.9541256241500378 | Validation Accurancy:  0.9983683268073946\n",
      "Epoch:  1086 | Train Accurancy:  0.9541315883398056 | Validation Accurancy:  0.998371156048961\n",
      "Epoch:  1087 | Train Accurancy:  0.9541375674307346 | Validation Accurancy:  0.9983742714393884\n",
      "Epoch:  1088 | Train Accurancy:  0.9541435316205025 | Validation Accurancy:  0.9983771324623376\n",
      "Epoch:  1089 | Train Accurancy:  0.9541494436562061 | Validation Accurancy:  0.9983800570480525\n",
      "Epoch:  1090 | Train Accurancy:  0.9541553445160389 | Validation Accurancy:  0.9983831405406818\n",
      "Epoch:  1091 | Train Accurancy:  0.9541612938046455 | Validation Accurancy:  0.9983859380008653\n",
      "Epoch:  1092 | Train Accurancy:  0.9541671052575111 | Validation Accurancy:  0.9983888943679631\n",
      "Epoch:  1093 | Train Accurancy:  0.9541729167103767 | Validation Accurancy:  0.9983917236095294\n",
      "Epoch:  1094 | Train Accurancy:  0.9541787467896938 | Validation Accurancy:  0.9983946164138615\n",
      "Epoch:  1095 | Train Accurancy:  0.9541846737265587 | Validation Accurancy:  0.9983976364601403\n",
      "Epoch:  1096 | Train Accurancy:  0.9541904181241989 | Validation Accurancy:  0.9984005292644724\n",
      "Epoch:  1097 | Train Accurancy:  0.9541962370276451 | Validation Accurancy:  0.9984032948268577\n",
      "Epoch:  1098 | Train Accurancy:  0.9542019590735435 | Validation Accurancy:  0.9984063466545194\n",
      "Epoch:  1099 | Train Accurancy:  0.9542077444493771 | Validation Accurancy:  0.9984091123333201\n",
      "Epoch:  1100 | Train Accurancy:  0.9542135186493397 | Validation Accurancy:  0.9984119733562693\n",
      "Epoch:  1101 | Train Accurancy:  0.954219214618206 | Validation Accurancy:  0.9984148661606014\n",
      "Epoch:  1102 | Train Accurancy:  0.9542249403893948 | Validation Accurancy:  0.9984175363788381\n",
      "Epoch:  1103 | Train Accurancy:  0.9542306773364544 | Validation Accurancy:  0.9984204291831702\n",
      "Epoch:  1104 | Train Accurancy:  0.9542362987995148 | Validation Accurancy:  0.9984230677364394\n",
      "Epoch:  1105 | Train Accurancy:  0.9542419612407684 | Validation Accurancy:  0.9984258651966229\n",
      "Epoch:  1106 | Train Accurancy:  0.9542475417256355 | Validation Accurancy:  0.9984286944381893\n",
      "Epoch:  1107 | Train Accurancy:  0.9542532041668892 | Validation Accurancy:  0.9984316190239042\n",
      "Epoch:  1108 | Train Accurancy:  0.954258818179369 | Validation Accurancy:  0.9984343211399391\n",
      "Epoch:  1109 | Train Accurancy:  0.9542644210159779 | Validation Accurancy:  0.9984370549209416\n",
      "Epoch:  1110 | Train Accurancy:  0.9542699865996838 | Validation Accurancy:  0.9984397888183594\n",
      "Epoch:  1111 | Train Accurancy:  0.9542755074799061 | Validation Accurancy:  0.9984425862785429\n",
      "Epoch:  1112 | Train Accurancy:  0.9542810544371605 | Validation Accurancy:  0.9984454473014921\n",
      "Epoch:  1113 | Train Accurancy:  0.9542865753173828 | Validation Accurancy:  0.9984480221755803\n",
      "Epoch:  1114 | Train Accurancy:  0.9542920999228954 | Validation Accurancy:  0.9984509467612952\n",
      "Epoch:  1115 | Train Accurancy:  0.9542975872755051 | Validation Accurancy:  0.9984535853145644\n",
      "Epoch:  1116 | Train Accurancy:  0.9543030858039856 | Validation Accurancy:  0.9984561284072697\n",
      "Epoch:  1117 | Train Accurancy:  0.9543085061013699 | Validation Accurancy:  0.9984589576488361\n",
      "Epoch:  1118 | Train Accurancy:  0.954313937574625 | Validation Accurancy:  0.9984615008579567\n",
      "Epoch:  1119 | Train Accurancy:  0.9543193392455578 | Validation Accurancy:  0.9984642028575763\n",
      "Epoch:  1120 | Train Accurancy:  0.9543248079717159 | Validation Accurancy:  0.9984668731922284\n",
      "Epoch:  1121 | Train Accurancy:  0.9543301612138748 | Validation Accurancy:  0.998469638871029\n",
      "Epoch:  1122 | Train Accurancy:  0.9543355777859688 | Validation Accurancy:  0.9984721184009686\n",
      "Epoch:  1123 | Train Accurancy:  0.9543409533798695 | Validation Accurancy:  0.9984747568378225\n",
      "Epoch:  1124 | Train Accurancy:  0.9543462246656418 | Validation Accurancy:  0.9984775860793889\n",
      "Epoch:  1125 | Train Accurancy:  0.9543515890836716 | Validation Accurancy:  0.9984800975071266\n",
      "Epoch:  1126 | Train Accurancy:  0.9543568715453148 | Validation Accurancy:  0.9984828312881291\n",
      "Epoch:  1127 | Train Accurancy:  0.9543622322380543 | Validation Accurancy:  0.9984853108180687\n",
      "Epoch:  1128 | Train Accurancy:  0.9543674811720848 | Validation Accurancy:  0.9984879493713379\n",
      "Epoch:  1129 | Train Accurancy:  0.9543726891279221 | Validation Accurancy:  0.9984905560268089\n",
      "Epoch:  1130 | Train Accurancy:  0.9543779082596302 | Validation Accurancy:  0.9984929721103981\n",
      "Epoch:  1131 | Train Accurancy:  0.9543831944465637 | Validation Accurancy:  0.9984955787658691\n",
      "Epoch:  1132 | Train Accurancy:  0.9543884173035622 | Validation Accurancy:  0.9984981218585745\n",
      "Epoch:  1133 | Train Accurancy:  0.9543935619294643 | Validation Accurancy:  0.9985008557559922\n",
      "Epoch:  1134 | Train Accurancy:  0.9543987773358822 | Validation Accurancy:  0.9985031763790175\n",
      "Epoch:  1135 | Train Accurancy:  0.954403955489397 | Validation Accurancy:  0.9985060056205839\n",
      "Epoch:  1136 | Train Accurancy:  0.9544090889394283 | Validation Accurancy:  0.9985084533691406\n",
      "Epoch:  1137 | Train Accurancy:  0.9544142819941044 | Validation Accurancy:  0.9985109328990802\n",
      "Epoch:  1138 | Train Accurancy:  0.9544193707406521 | Validation Accurancy:  0.9985134442104027\n",
      "Epoch:  1139 | Train Accurancy:  0.9544244036078453 | Validation Accurancy:  0.9985159238567576\n",
      "Epoch:  1140 | Train Accurancy:  0.9544295221567154 | Validation Accurancy:  0.9985185622936115\n",
      "Epoch:  1141 | Train Accurancy:  0.9544346630573273 | Validation Accurancy:  0.9985209464794025\n",
      "Epoch:  1142 | Train Accurancy:  0.9544396735727787 | Validation Accurancy:  0.998523743939586\n",
      "Epoch:  1143 | Train Accurancy:  0.9544447213411331 | Validation Accurancy:  0.9985263188136742\n",
      "Epoch:  1144 | Train Accurancy:  0.9544497355818748 | Validation Accurancy:  0.9985287029994652\n",
      "Epoch:  1145 | Train Accurancy:  0.9544547833502293 | Validation Accurancy:  0.9985311190830544\n",
      "Epoch:  1146 | Train Accurancy:  0.9544597342610359 | Validation Accurancy:  0.9985335350502282\n",
      "Epoch:  1147 | Train Accurancy:  0.9544647336006165 | Validation Accurancy:  0.9985361734870821\n",
      "Epoch:  1148 | Train Accurancy:  0.9544697143137455 | Validation Accurancy:  0.9985385258914903\n",
      "Epoch:  1149 | Train Accurancy:  0.9544747024774551 | Validation Accurancy:  0.9985409418586642\n",
      "Epoch:  1150 | Train Accurancy:  0.9544796049594879 | Validation Accurancy:  0.9985436121933162\n",
      "Epoch:  1151 | Train Accurancy:  0.9544845223426819 | Validation Accurancy:  0.9985460917232558\n",
      "Epoch:  1152 | Train Accurancy:  0.9544893614947796 | Validation Accurancy:  0.9985486030345783\n",
      "Epoch:  1153 | Train Accurancy:  0.9544943198561668 | Validation Accurancy:  0.998551050783135\n",
      "Epoch:  1154 | Train Accurancy:  0.9544992037117481 | Validation Accurancy:  0.9985533714061603\n",
      "Epoch:  1155 | Train Accurancy:  0.9545041434466839 | Validation Accurancy:  0.9985559146152809\n",
      "Epoch:  1156 | Train Accurancy:  0.9545090086758137 | Validation Accurancy:  0.9985583941452205\n",
      "Epoch:  1157 | Train Accurancy:  0.9545137770473957 | Validation Accurancy:  0.9985608736751601\n",
      "Epoch:  1158 | Train Accurancy:  0.954518586397171 | Validation Accurancy:  0.9985631625168025\n",
      "Epoch:  1159 | Train Accurancy:  0.9545233696699142 | Validation Accurancy:  0.9985655784839764\n",
      "Epoch:  1160 | Train Accurancy:  0.954528134316206 | Validation Accurancy:  0.9985680262325332\n",
      "Epoch:  1161 | Train Accurancy:  0.9545328840613365 | Validation Accurancy:  0.9985704104183242\n",
      "Epoch:  1162 | Train Accurancy:  0.9545376747846603 | Validation Accurancy:  0.9985727628227323\n",
      "Epoch:  1163 | Train Accurancy:  0.9545424431562424 | Validation Accurancy:  0.9985752741340548\n",
      "Epoch:  1164 | Train Accurancy:  0.9545472115278244 | Validation Accurancy:  0.9985774994129315\n",
      "Epoch:  1165 | Train Accurancy:  0.9545518942177296 | Validation Accurancy:  0.9985799153801054\n",
      "Epoch:  1166 | Train Accurancy:  0.9545565694570541 | Validation Accurancy:  0.9985822995658964\n",
      "Epoch:  1167 | Train Accurancy:  0.954561248421669 | Validation Accurancy:  0.998584556626156\n",
      "Epoch:  1168 | Train Accurancy:  0.9545659348368645 | Validation Accurancy:  0.998586940811947\n",
      "Epoch:  1169 | Train Accurancy:  0.9545705989003181 | Validation Accurancy:  0.9985893567791209\n",
      "Epoch:  1170 | Train Accurancy:  0.9545752331614494 | Validation Accurancy:  0.998591709183529\n",
      "Epoch:  1171 | Train Accurancy:  0.9545798934996128 | Validation Accurancy:  0.998594029690139\n",
      "Epoch:  1172 | Train Accurancy:  0.9545845054090023 | Validation Accurancy:  0.99859641387593\n",
      "Epoch:  1173 | Train Accurancy:  0.95458909496665 | Validation Accurancy:  0.9985986709361896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1174 | Train Accurancy:  0.9545936733484268 | Validation Accurancy:  0.9986010233405977\n",
      "Epoch:  1175 | Train Accurancy:  0.9545982182025909 | Validation Accurancy:  0.9986035346519202\n",
      "Epoch:  1176 | Train Accurancy:  0.954602800309658 | Validation Accurancy:  0.9986056328052655\n",
      "Epoch:  1177 | Train Accurancy:  0.9546073526144028 | Validation Accurancy:  0.998607826186344\n",
      "Epoch:  1178 | Train Accurancy:  0.9546118192374706 | Validation Accurancy:  0.998610210372135\n",
      "Epoch:  1179 | Train Accurancy:  0.9546163901686668 | Validation Accurancy:  0.9986123403068632\n",
      "Epoch:  1180 | Train Accurancy:  0.954620786011219 | Validation Accurancy:  0.9986147244926542\n",
      "Epoch:  1181 | Train Accurancy:  0.9546253494918346 | Validation Accurancy:  0.9986170451156795\n",
      "Epoch:  1182 | Train Accurancy:  0.9546298198401928 | Validation Accurancy:  0.9986191431526095\n",
      "Epoch:  1183 | Train Accurancy:  0.9546343050897121 | Validation Accurancy:  0.9986213366501033\n",
      "Epoch:  1184 | Train Accurancy:  0.9546387195587158 | Validation Accurancy:  0.9986235300311819\n",
      "Epoch:  1185 | Train Accurancy:  0.9546431005001068 | Validation Accurancy:  0.9986259142169729\n",
      "Epoch:  1186 | Train Accurancy:  0.9546475224196911 | Validation Accurancy:  0.9986279805889353\n",
      "Epoch:  1187 | Train Accurancy:  0.9546520449221134 | Validation Accurancy:  0.9986299832817167\n",
      "Epoch:  1188 | Train Accurancy:  0.954656396061182 | Validation Accurancy:  0.9986323356861249\n",
      "Epoch:  1189 | Train Accurancy:  0.9546607695519924 | Validation Accurancy:  0.9986344337230548\n",
      "Epoch:  1190 | Train Accurancy:  0.9546650908887386 | Validation Accurancy:  0.998636786127463\n",
      "Epoch:  1191 | Train Accurancy:  0.9546694569289684 | Validation Accurancy:  0.9986390114063397\n",
      "Epoch:  1192 | Train Accurancy:  0.954673707485199 | Validation Accurancy:  0.9986410776618868\n",
      "Epoch:  1193 | Train Accurancy:  0.9546780772507191 | Validation Accurancy:  0.9986432393779978\n",
      "Epoch:  1194 | Train Accurancy:  0.9546824134886265 | Validation Accurancy:  0.9986454645404592\n",
      "Epoch:  1195 | Train Accurancy:  0.95468670129776 | Validation Accurancy:  0.9986476580379531\n",
      "Epoch:  1196 | Train Accurancy:  0.9546909406781197 | Validation Accurancy:  0.9986496925121173\n",
      "Epoch:  1197 | Train Accurancy:  0.9546952359378338 | Validation Accurancy:  0.9986519495723769\n",
      "Epoch:  1198 | Train Accurancy:  0.9546995311975479 | Validation Accurancy:  0.9986539840465412\n",
      "Epoch:  1199 | Train Accurancy:  0.9547037705779076 | Validation Accurancy:  0.9986560821998864\n",
      "Epoch:  1200 | Train Accurancy:  0.9547079801559448 | Validation Accurancy:  0.9986584027064964\n",
      "Epoch:  1201 | Train Accurancy:  0.9547121971845627 | Validation Accurancy:  0.998660437297076\n",
      "Epoch:  1202 | Train Accurancy:  0.9547163508832455 | Validation Accurancy:  0.9986624717712402\n",
      "Epoch:  1203 | Train Accurancy:  0.9547205120325089 | Validation Accurancy:  0.9986644744640216\n",
      "Epoch:  1204 | Train Accurancy:  0.9547247141599655 | Validation Accurancy:  0.9986666679615155\n",
      "Epoch:  1205 | Train Accurancy:  0.954728938639164 | Validation Accurancy:  0.9986687659984455\n",
      "Epoch:  1206 | Train Accurancy:  0.9547330029308796 | Validation Accurancy:  0.9986708004726097\n",
      "Epoch:  1207 | Train Accurancy:  0.9547372199594975 | Validation Accurancy:  0.9986731528770179\n",
      "Epoch:  1208 | Train Accurancy:  0.9547412805259228 | Validation Accurancy:  0.9986751239048317\n",
      "Epoch:  1209 | Train Accurancy:  0.9547453969717026 | Validation Accurancy:  0.998677158378996\n",
      "Epoch:  1210 | Train Accurancy:  0.9547495022416115 | Validation Accurancy:  0.9986793517600745\n",
      "Epoch:  1211 | Train Accurancy:  0.954753577709198 | Validation Accurancy:  0.9986813545692712\n",
      "Epoch:  1212 | Train Accurancy:  0.9547576457262039 | Validation Accurancy:  0.9986834208248183\n",
      "Epoch:  1213 | Train Accurancy:  0.9547617398202419 | Validation Accurancy:  0.9986855188617483\n",
      "Epoch:  1214 | Train Accurancy:  0.9547657482326031 | Validation Accurancy:  0.9986874262103811\n",
      "Epoch:  1215 | Train Accurancy:  0.9547697529196739 | Validation Accurancy:  0.9986895561451092\n",
      "Epoch:  1216 | Train Accurancy:  0.9547737911343575 | Validation Accurancy:  0.9986915906192735\n",
      "Epoch:  1217 | Train Accurancy:  0.9547777995467186 | Validation Accurancy:  0.9986936250934377\n",
      "Epoch:  1218 | Train Accurancy:  0.9547818191349506 | Validation Accurancy:  0.9986955960048363\n",
      "Epoch:  1219 | Train Accurancy:  0.9547857642173767 | Validation Accurancy:  0.9986975670326501\n",
      "Epoch:  1220 | Train Accurancy:  0.9547897316515446 | Validation Accurancy:  0.9986998557578772\n",
      "Epoch:  1221 | Train Accurancy:  0.9547936767339706 | Validation Accurancy:  0.9987017313251272\n",
      "Epoch:  1222 | Train Accurancy:  0.9547976031899452 | Validation Accurancy:  0.9987036704551429\n",
      "Epoch:  1223 | Train Accurancy:  0.9548015296459198 | Validation Accurancy:  0.9987057368271053\n",
      "Epoch:  1224 | Train Accurancy:  0.9548054374754429 | Validation Accurancy:  0.9987076123943552\n",
      "Epoch:  1225 | Train Accurancy:  0.9548093527555466 | Validation Accurancy:  0.9987096150871366\n",
      "Epoch:  1226 | Train Accurancy:  0.9548131935298443 | Validation Accurancy:  0.9987117131240666\n",
      "Epoch:  1227 | Train Accurancy:  0.954817108809948 | Validation Accurancy:  0.9987136840354651\n",
      "Epoch:  1228 | Train Accurancy:  0.954820990562439 | Validation Accurancy:  0.9987155913840979\n",
      "Epoch:  1229 | Train Accurancy:  0.9548248499631882 | Validation Accurancy:  0.9987175305141136\n",
      "Epoch:  1230 | Train Accurancy:  0.9548287056386471 | Validation Accurancy:  0.9987197240116075\n",
      "Epoch:  1231 | Train Accurancy:  0.9548325538635254 | Validation Accurancy:  0.9987215360160917\n",
      "Epoch:  1232 | Train Accurancy:  0.954836368560791 | Validation Accurancy:  0.9987234433647245\n",
      "Epoch:  1233 | Train Accurancy:  0.9548401348292828 | Validation Accurancy:  0.9987255096202716\n",
      "Epoch:  1234 | Train Accurancy:  0.954843919724226 | Validation Accurancy:  0.9987272580619901\n",
      "Epoch:  1235 | Train Accurancy:  0.9548477306962013 | Validation Accurancy:  0.9987294514430687\n",
      "Epoch:  1236 | Train Accurancy:  0.9548514820635319 | Validation Accurancy:  0.9987313587917015\n",
      "Epoch:  1237 | Train Accurancy:  0.9548552557826042 | Validation Accurancy:  0.99873310723342\n",
      "Epoch:  1238 | Train Accurancy:  0.9548589959740639 | Validation Accurancy:  0.9987350463634357\n",
      "Epoch:  1239 | Train Accurancy:  0.9548627510666847 | Validation Accurancy:  0.9987370808375999\n",
      "Epoch:  1240 | Train Accurancy:  0.9548664428293705 | Validation Accurancy:  0.9987393696792424\n",
      "Epoch:  1241 | Train Accurancy:  0.9548701457679272 | Validation Accurancy:  0.9987411181209609\n",
      "Epoch:  1242 | Train Accurancy:  0.954873863607645 | Validation Accurancy:  0.9987429301254451\n",
      "Epoch:  1243 | Train Accurancy:  0.9548775479197502 | Validation Accurancy:  0.9987449963809922\n",
      "Epoch:  1244 | Train Accurancy:  0.9548812098801136 | Validation Accurancy:  0.9987467766040936\n",
      "Epoch:  1245 | Train Accurancy:  0.9548848159611225 | Validation Accurancy:  0.9987486521713436\n",
      "Epoch:  1246 | Train Accurancy:  0.9548884928226471 | Validation Accurancy:  0.9987505913013592\n",
      "Epoch:  1247 | Train Accurancy:  0.9548921100795269 | Validation Accurancy:  0.9987523715244606\n",
      "Epoch:  1248 | Train Accurancy:  0.954895731061697 | Validation Accurancy:  0.9987543106544763\n",
      "Epoch:  1249 | Train Accurancy:  0.9548993781208992 | Validation Accurancy:  0.9987561543239281\n",
      "Epoch:  1250 | Train Accurancy:  0.9549029804766178 | Validation Accurancy:  0.9987582206958905\n",
      "Epoch:  1251 | Train Accurancy:  0.9549065642058849 | Validation Accurancy:  0.998760191607289\n",
      "Epoch:  1252 | Train Accurancy:  0.954910185188055 | Validation Accurancy:  0.9987619718303904\n",
      "Epoch:  1253 | Train Accurancy:  0.9549137130379677 | Validation Accurancy:  0.9987639745231718\n",
      "Epoch:  1254 | Train Accurancy:  0.9549173302948475 | Validation Accurancy:  0.9987657229648903\n",
      "Epoch:  1255 | Train Accurancy:  0.954920832067728 | Validation Accurancy:  0.9987674395088106\n",
      "Epoch:  1256 | Train Accurancy:  0.9549243152141571 | Validation Accurancy:  0.998769442201592\n",
      "Epoch:  1257 | Train Accurancy:  0.9549278318881989 | Validation Accurancy:  0.9987711906433105\n",
      "Epoch:  1258 | Train Accurancy:  0.9549313746392727 | Validation Accurancy:  0.9987730344291776\n",
      "Epoch:  1259 | Train Accurancy:  0.9549348540604115 | Validation Accurancy:  0.9987747828708962\n",
      "Epoch:  1260 | Train Accurancy:  0.9549383074045181 | Validation Accurancy:  0.998776690219529\n",
      "Epoch:  1261 | Train Accurancy:  0.9549417719244957 | Validation Accurancy:  0.9987785656703636\n",
      "Epoch:  1262 | Train Accurancy:  0.954945296049118 | Validation Accurancy:  0.9987803776748478\n",
      "Epoch:  1263 | Train Accurancy:  0.9549487046897411 | Validation Accurancy:  0.9987822850234807\n",
      "Epoch:  1264 | Train Accurancy:  0.9549521990120411 | Validation Accurancy:  0.9987841605907306\n",
      "Epoch:  1265 | Train Accurancy:  0.9549555592238903 | Validation Accurancy:  0.9987857819069177\n",
      "Epoch:  1266 | Train Accurancy:  0.9549590237438679 | Validation Accurancy:  0.9987876574741676\n",
      "Epoch:  1267 | Train Accurancy:  0.9549624733626842 | Validation Accurancy:  0.9987894693622366\n",
      "Epoch:  1268 | Train Accurancy:  0.9549658298492432 | Validation Accurancy:  0.9987911860225722\n",
      "Epoch:  1269 | Train Accurancy:  0.954969260841608 | Validation Accurancy:  0.9987929980270565\n",
      "Epoch:  1270 | Train Accurancy:  0.954972580075264 | Validation Accurancy:  0.9987948418129236\n",
      "Epoch:  1271 | Train Accurancy:  0.954975962638855 | Validation Accurancy:  0.9987967491615564\n",
      "Epoch:  1272 | Train Accurancy:  0.9549792744219303 | Validation Accurancy:  0.998798402142711\n",
      "Epoch:  1273 | Train Accurancy:  0.9549826607108116 | Validation Accurancy:  0.9988000870216638\n",
      "Epoch:  1274 | Train Accurancy:  0.954985972493887 | Validation Accurancy:  0.9988019943702966\n",
      "Epoch:  1275 | Train Accurancy:  0.9549892544746399 | Validation Accurancy:  0.9988038380397484\n",
      "Epoch:  1276 | Train Accurancy:  0.9549925774335861 | Validation Accurancy:  0.9988054275745526\n",
      "Epoch:  1277 | Train Accurancy:  0.954995896667242 | Validation Accurancy:  0.9988073031418025\n",
      "Epoch:  1278 | Train Accurancy:  0.9549991972744465 | Validation Accurancy:  0.9988091469276696\n",
      "Epoch:  1279 | Train Accurancy:  0.9550025351345539 | Validation Accurancy:  0.99881086347159\n",
      "Epoch:  1280 | Train Accurancy:  0.9550057649612427 | Validation Accurancy:  0.9988125801319256\n",
      "Epoch:  1281 | Train Accurancy:  0.9550090283155441 | Validation Accurancy:  0.9988144239177927\n",
      "Epoch:  1282 | Train Accurancy:  0.9550122506916523 | Validation Accurancy:  0.9988161404617131\n",
      "Epoch:  1283 | Train Accurancy:  0.9550154991447926 | Validation Accurancy:  0.998817793559283\n",
      "Epoch:  1284 | Train Accurancy:  0.9550186917185783 | Validation Accurancy:  0.9988197009079158\n",
      "Epoch:  1285 | Train Accurancy:  0.9550219140946865 | Validation Accurancy:  0.9988212903263047\n",
      "Epoch:  1286 | Train Accurancy:  0.9550250768661499 | Validation Accurancy:  0.9988229434238747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1287 | Train Accurancy:  0.9550282582640648 | Validation Accurancy:  0.9988246917491779\n",
      "Epoch:  1288 | Train Accurancy:  0.9550314135849476 | Validation Accurancy:  0.9988264719722793\n",
      "Epoch:  1289 | Train Accurancy:  0.9550345875322819 | Validation Accurancy:  0.9988280613906682\n",
      "Epoch:  1290 | Train Accurancy:  0.9550378322601318 | Validation Accurancy:  0.9988297780510038\n",
      "Epoch:  1291 | Train Accurancy:  0.9550410024821758 | Validation Accurancy:  0.9988315582741052\n",
      "Epoch:  1292 | Train Accurancy:  0.9550440832972527 | Validation Accurancy:  0.9988333065994084\n",
      "Epoch:  1293 | Train Accurancy:  0.9550472423434258 | Validation Accurancy:  0.9988349279155955\n",
      "Epoch:  1294 | Train Accurancy:  0.9550503678619862 | Validation Accurancy:  0.9988367717014626\n",
      "Epoch:  1295 | Train Accurancy:  0.9550535306334496 | Validation Accurancy:  0.9988385835895315\n",
      "Epoch:  1296 | Train Accurancy:  0.9550565779209137 | Validation Accurancy:  0.9988401413429528\n",
      "Epoch:  1297 | Train Accurancy:  0.9550596177577972 | Validation Accurancy:  0.9988416989799589\n",
      "Epoch:  1298 | Train Accurancy:  0.9550627768039703 | Validation Accurancy:  0.9988434792030603\n",
      "Epoch:  1299 | Train Accurancy:  0.9550657980144024 | Validation Accurancy:  0.9988451321842149\n",
      "Epoch:  1300 | Train Accurancy:  0.955068826675415 | Validation Accurancy:  0.9988467852817848\n",
      "Epoch:  1301 | Train Accurancy:  0.9550718665122986 | Validation Accurancy:  0.9988484064815566\n",
      "Epoch:  1302 | Train Accurancy:  0.9550749398767948 | Validation Accurancy:  0.9988500912440941\n",
      "Epoch:  1303 | Train Accurancy:  0.9550779424607754 | Validation Accurancy:  0.9988519032485783\n",
      "Epoch:  1304 | Train Accurancy:  0.9550809934735298 | Validation Accurancy:  0.9988533973228186\n",
      "Epoch:  1305 | Train Accurancy:  0.9550839774310589 | Validation Accurancy:  0.9988552093273029\n",
      "Epoch:  1306 | Train Accurancy:  0.9550869725644588 | Validation Accurancy:  0.99885683064349\n",
      "Epoch:  1307 | Train Accurancy:  0.9550899937748909 | Validation Accurancy:  0.998858388280496\n",
      "Epoch:  1308 | Train Accurancy:  0.9550929516553879 | Validation Accurancy:  0.9988601048244163\n",
      "Epoch:  1309 | Train Accurancy:  0.9550958573818207 | Validation Accurancy:  0.9988617261406034\n",
      "Epoch:  1310 | Train Accurancy:  0.9550988599658012 | Validation Accurancy:  0.9988633155589923\n",
      "Epoch:  1311 | Train Accurancy:  0.9551017843186855 | Validation Accurancy:  0.9988650004379451\n",
      "Epoch:  1312 | Train Accurancy:  0.9551047645509243 | Validation Accurancy:  0.9988666852004826\n",
      "Epoch:  1313 | Train Accurancy:  0.9551076591014862 | Validation Accurancy:  0.9988682747352868\n",
      "Epoch:  1314 | Train Accurancy:  0.9551106244325638 | Validation Accurancy:  0.9988700866233557\n",
      "Epoch:  1315 | Train Accurancy:  0.9551135078072548 | Validation Accurancy:  0.9988715808140114\n",
      "Epoch:  1316 | Train Accurancy:  0.9551164470613003 | Validation Accurancy:  0.9988734244834632\n",
      "Epoch:  1317 | Train Accurancy:  0.9551193118095398 | Validation Accurancy:  0.9988748867763206\n",
      "Epoch:  1318 | Train Accurancy:  0.9551221616566181 | Validation Accurancy:  0.9988764127483591\n",
      "Epoch:  1319 | Train Accurancy:  0.9551250301301479 | Validation Accurancy:  0.9988780339481309\n",
      "Epoch:  1320 | Train Accurancy:  0.9551278874278069 | Validation Accurancy:  0.9988796551479027\n",
      "Epoch:  1321 | Train Accurancy:  0.9551306888461113 | Validation Accurancy:  0.9988811175571755\n",
      "Epoch:  1322 | Train Accurancy:  0.9551336281001568 | Validation Accurancy:  0.9988828341010958\n",
      "Epoch:  1323 | Train Accurancy:  0.9551364295184612 | Validation Accurancy:  0.9988843917381018\n",
      "Epoch:  1324 | Train Accurancy:  0.9551392607390881 | Validation Accurancy:  0.9988859812729061\n",
      "Epoch:  1325 | Train Accurancy:  0.9551420509815216 | Validation Accurancy:  0.9988875389099121\n",
      "Epoch:  1326 | Train Accurancy:  0.955144852399826 | Validation Accurancy:  0.9988891918910667\n",
      "Epoch:  1327 | Train Accurancy:  0.9551476761698723 | Validation Accurancy:  0.9988908767700195\n",
      "Epoch:  1328 | Train Accurancy:  0.9551504515111446 | Validation Accurancy:  0.9988923708442599\n",
      "Epoch:  1329 | Train Accurancy:  0.955153226852417 | Validation Accurancy:  0.9988939284812659\n",
      "Epoch:  1330 | Train Accurancy:  0.9551560282707214 | Validation Accurancy:  0.9988954862346873\n",
      "Epoch:  1331 | Train Accurancy:  0.9551587998867035 | Validation Accurancy:  0.9988971392158419\n",
      "Epoch:  1332 | Train Accurancy:  0.955161526799202 | Validation Accurancy:  0.9988986332900822\n",
      "Epoch:  1333 | Train Accurancy:  0.9551642090082169 | Validation Accurancy:  0.9989002228248864\n",
      "Epoch:  1334 | Train Accurancy:  0.9551669247448444 | Validation Accurancy:  0.9989018122432753\n",
      "Epoch:  1335 | Train Accurancy:  0.9551697000861168 | Validation Accurancy:  0.99890346522443\n",
      "Epoch:  1336 | Train Accurancy:  0.9551723822951317 | Validation Accurancy:  0.9989048321731389\n",
      "Epoch:  1337 | Train Accurancy:  0.9551750794053078 | Validation Accurancy:  0.9989064534893259\n",
      "Epoch:  1338 | Train Accurancy:  0.9551778323948383 | Validation Accurancy:  0.9989081700332463\n",
      "Epoch:  1339 | Train Accurancy:  0.955180499702692 | Validation Accurancy:  0.998909568763338\n",
      "Epoch:  1340 | Train Accurancy:  0.9551831483840942 | Validation Accurancy:  0.9989110628375784\n",
      "Epoch:  1341 | Train Accurancy:  0.95518584176898 | Validation Accurancy:  0.9989126841537654\n",
      "Epoch:  1342 | Train Accurancy:  0.9551884531974792 | Validation Accurancy:  0.9989142417907715\n",
      "Epoch:  1343 | Train Accurancy:  0.9551912061870098 | Validation Accurancy:  0.998915704083629\n",
      "Epoch:  1344 | Train Accurancy:  0.9551937952637672 | Validation Accurancy:  0.9989172935020179\n",
      "Epoch:  1345 | Train Accurancy:  0.9551963806152344 | Validation Accurancy:  0.9989188194740564\n",
      "Epoch:  1346 | Train Accurancy:  0.9551990181207657 | Validation Accurancy:  0.9989203135482967\n",
      "Epoch:  1347 | Train Accurancy:  0.9552017115056515 | Validation Accurancy:  0.9989218394039199\n",
      "Epoch:  1348 | Train Accurancy:  0.9552042484283447 | Validation Accurancy:  0.9989232063526288\n",
      "Epoch:  1349 | Train Accurancy:  0.9552068039774895 | Validation Accurancy:  0.998924954677932\n",
      "Epoch:  1350 | Train Accurancy:  0.9552093669772148 | Validation Accurancy:  0.9989264806499705\n",
      "Epoch:  1351 | Train Accurancy:  0.9552119933068752 | Validation Accurancy:  0.9989279429428279\n",
      "Epoch:  1352 | Train Accurancy:  0.9552145712077618 | Validation Accurancy:  0.9989295323612168\n",
      "Epoch:  1353 | Train Accurancy:  0.9552171230316162 | Validation Accurancy:  0.99893105821684\n",
      "Epoch:  1354 | Train Accurancy:  0.9552196487784386 | Validation Accurancy:  0.9989324887283146\n",
      "Epoch:  1355 | Train Accurancy:  0.9552222117781639 | Validation Accurancy:  0.9989340145839378\n",
      "Epoch:  1356 | Train Accurancy:  0.9552247598767281 | Validation Accurancy:  0.9989353497512639\n",
      "Epoch:  1357 | Train Accurancy:  0.9552273564040661 | Validation Accurancy:  0.9989370664115995\n",
      "Epoch:  1358 | Train Accurancy:  0.9552298858761787 | Validation Accurancy:  0.9989384333603084\n",
      "Epoch:  1359 | Train Accurancy:  0.9552323743700981 | Validation Accurancy:  0.9989398320904002\n",
      "Epoch:  1360 | Train Accurancy:  0.9552348591387272 | Validation Accurancy:  0.9989415486343205\n",
      "Epoch:  1361 | Train Accurancy:  0.9552372954785824 | Validation Accurancy:  0.9989428520202637\n",
      "Epoch:  1362 | Train Accurancy:  0.9552398063242435 | Validation Accurancy:  0.9989442507503554\n",
      "Epoch:  1363 | Train Accurancy:  0.9552422426640987 | Validation Accurancy:  0.9989457766059786\n",
      "Epoch:  1364 | Train Accurancy:  0.9552446901798248 | Validation Accurancy:  0.9989473024616018\n",
      "Epoch:  1365 | Train Accurancy:  0.9552472159266472 | Validation Accurancy:  0.9989486694103107\n",
      "Epoch:  1366 | Train Accurancy:  0.9552496634423733 | Validation Accurancy:  0.9989501952659339\n",
      "Epoch:  1367 | Train Accurancy:  0.9552520290017128 | Validation Accurancy:  0.998951498651877\n",
      "Epoch:  1368 | Train Accurancy:  0.9552545584738255 | Validation Accurancy:  0.9989531199680641\n",
      "Epoch:  1369 | Train Accurancy:  0.9552569165825844 | Validation Accurancy:  0.9989544868003577\n",
      "Epoch:  1370 | Train Accurancy:  0.9552593305706978 | Validation Accurancy:  0.9989558219676837\n",
      "Epoch:  1371 | Train Accurancy:  0.9552616737782955 | Validation Accurancy:  0.9989573478233069\n",
      "Epoch:  1372 | Train Accurancy:  0.9552641250193119 | Validation Accurancy:  0.9989589373581111\n",
      "Epoch:  1373 | Train Accurancy:  0.9552665688097477 | Validation Accurancy:  0.9989603678695858\n",
      "Epoch:  1374 | Train Accurancy:  0.9552689641714096 | Validation Accurancy:  0.9989617983810604\n",
      "Epoch:  1375 | Train Accurancy:  0.9552713446319103 | Validation Accurancy:  0.9989632606739178\n",
      "Epoch:  1376 | Train Accurancy:  0.9552737101912498 | Validation Accurancy:  0.9989645958412439\n",
      "Epoch:  1377 | Train Accurancy:  0.9552760683000088 | Validation Accurancy:  0.998966121696867\n",
      "Epoch:  1378 | Train Accurancy:  0.9552784524857998 | Validation Accurancy:  0.9989674250828102\n",
      "Epoch:  1379 | Train Accurancy:  0.9552807696163654 | Validation Accurancy:  0.9989688873756677\n",
      "Epoch:  1380 | Train Accurancy:  0.9552830830216408 | Validation Accurancy:  0.9989703496685252\n",
      "Epoch:  1381 | Train Accurancy:  0.9552854411303997 | Validation Accurancy:  0.9989716847194359\n",
      "Epoch:  1382 | Train Accurancy:  0.9552877359092236 | Validation Accurancy:  0.9989730834495276\n",
      "Epoch:  1383 | Train Accurancy:  0.9552901275455952 | Validation Accurancy:  0.9989745776401833\n",
      "Epoch:  1384 | Train Accurancy:  0.9552923738956451 | Validation Accurancy:  0.9989760081516579\n",
      "Epoch:  1385 | Train Accurancy:  0.9552946500480175 | Validation Accurancy:  0.9989774386631325\n",
      "Epoch:  1386 | Train Accurancy:  0.9552969858050346 | Validation Accurancy:  0.9989787737140432\n",
      "Epoch:  1387 | Train Accurancy:  0.9552992433309555 | Validation Accurancy:  0.998980172444135\n",
      "Epoch:  1388 | Train Accurancy:  0.9553014598786831 | Validation Accurancy:  0.9989816029556096\n",
      "Epoch:  1389 | Train Accurancy:  0.9553037844598293 | Validation Accurancy:  0.9989828745601699\n",
      "Epoch:  1390 | Train Accurancy:  0.955306027084589 | Validation Accurancy:  0.9989842097274959\n",
      "Epoch:  1391 | Train Accurancy:  0.9553082697093487 | Validation Accurancy:  0.9989857991458848\n",
      "Epoch:  1392 | Train Accurancy:  0.955310545861721 | Validation Accurancy:  0.9989870071876794\n",
      "Epoch:  1393 | Train Accurancy:  0.955312792211771 | Validation Accurancy:  0.9989883422385901\n",
      "Epoch:  1394 | Train Accurancy:  0.9553150124847889 | Validation Accurancy:  0.9989899317733943\n",
      "Epoch:  1395 | Train Accurancy:  0.9553171694278717 | Validation Accurancy:  0.9989913305034861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1396 | Train Accurancy:  0.9553194455802441 | Validation Accurancy:  0.9989927610149607\n",
      "Epoch:  1397 | Train Accurancy:  0.9553216099739075 | Validation Accurancy:  0.9989941279636696\n",
      "Epoch:  1398 | Train Accurancy:  0.9553238116204739 | Validation Accurancy:  0.9989954630145803\n",
      "Epoch:  1399 | Train Accurancy:  0.9553260281682014 | Validation Accurancy:  0.9989969253074378\n",
      "Epoch:  1400 | Train Accurancy:  0.9553281851112843 | Validation Accurancy:  0.9989982922561467\n",
      "Epoch:  1401 | Train Accurancy:  0.955330353230238 | Validation Accurancy:  0.9989995320793241\n",
      "Epoch:  1402 | Train Accurancy:  0.9553325287997723 | Validation Accurancy:  0.999000899028033\n",
      "Epoch:  1403 | Train Accurancy:  0.9553346857428551 | Validation Accurancy:  0.9990023295395076\n",
      "Epoch:  1404 | Train Accurancy:  0.9553368464112282 | Validation Accurancy:  0.9990035692462698\n",
      "Epoch:  1405 | Train Accurancy:  0.9553389921784401 | Validation Accurancy:  0.9990049997577444\n",
      "Epoch:  1406 | Train Accurancy:  0.9553412273526192 | Validation Accurancy:  0.999006207799539\n",
      "Epoch:  1407 | Train Accurancy:  0.9553432613611221 | Validation Accurancy:  0.9990076383110136\n",
      "Epoch:  1408 | Train Accurancy:  0.9553454145789146 | Validation Accurancy:  0.9990090052597225\n",
      "Epoch:  1409 | Train Accurancy:  0.9553475417196751 | Validation Accurancy:  0.9990104039898142\n",
      "Epoch:  1410 | Train Accurancy:  0.955349650233984 | Validation Accurancy:  0.9990117390407249\n",
      "Epoch:  1411 | Train Accurancy:  0.9553516879677773 | Validation Accurancy:  0.9990131377708167\n",
      "Epoch:  1412 | Train Accurancy:  0.9553537853062153 | Validation Accurancy:  0.9990143775939941\n",
      "Epoch:  1413 | Train Accurancy:  0.9553558863699436 | Validation Accurancy:  0.9990155856357887\n",
      "Epoch:  1414 | Train Accurancy:  0.9553579762578011 | Validation Accurancy:  0.9990171114914119\n",
      "Epoch:  1415 | Train Accurancy:  0.9553600586950779 | Validation Accurancy:  0.9990183511981741\n",
      "Epoch:  1416 | Train Accurancy:  0.9553621225059032 | Validation Accurancy:  0.9990195910213515\n",
      "Epoch:  1417 | Train Accurancy:  0.9553641639649868 | Validation Accurancy:  0.9990209579700604\n",
      "Epoch:  1418 | Train Accurancy:  0.955366212874651 | Validation Accurancy:  0.9990223249187693\n",
      "Epoch:  1419 | Train Accurancy:  0.9553681798279285 | Validation Accurancy:  0.9990235646837391\n",
      "Epoch:  1420 | Train Accurancy:  0.9553702510893345 | Validation Accurancy:  0.9990248997928575\n",
      "Epoch:  1421 | Train Accurancy:  0.9553723484277725 | Validation Accurancy:  0.9990262031788006\n",
      "Epoch:  1422 | Train Accurancy:  0.9553743898868561 | Validation Accurancy:  0.9990277290344238\n",
      "Epoch:  1423 | Train Accurancy:  0.955376360565424 | Validation Accurancy:  0.9990289687993936\n",
      "Epoch:  1424 | Train Accurancy:  0.955378457903862 | Validation Accurancy:  0.9990301132202148\n",
      "Epoch:  1425 | Train Accurancy:  0.9553803615272045 | Validation Accurancy:  0.9990314165479504\n",
      "Epoch:  1426 | Train Accurancy:  0.9553824104368687 | Validation Accurancy:  0.9990327834966592\n",
      "Epoch:  1427 | Train Accurancy:  0.955384373664856 | Validation Accurancy:  0.9990341186639853\n",
      "Epoch:  1428 | Train Accurancy:  0.9553863517940044 | Validation Accurancy:  0.9990353902103379\n",
      "Epoch:  1429 | Train Accurancy:  0.955388318747282 | Validation Accurancy:  0.999036566412542\n",
      "Epoch:  1430 | Train Accurancy:  0.9553902670741081 | Validation Accurancy:  0.999037901579868\n",
      "Epoch:  1431 | Train Accurancy:  0.9553922675549984 | Validation Accurancy:  0.9990392366889864\n",
      "Epoch:  1432 | Train Accurancy:  0.9553941413760185 | Validation Accurancy:  0.9990404764539562\n",
      "Epoch:  1433 | Train Accurancy:  0.9553960785269737 | Validation Accurancy:  0.9990415890933946\n",
      "Epoch:  1434 | Train Accurancy:  0.9553980752825737 | Validation Accurancy:  0.9990431785699911\n",
      "Epoch:  1435 | Train Accurancy:  0.9554000236093998 | Validation Accurancy:  0.9990443865535781\n",
      "Epoch:  1436 | Train Accurancy:  0.9554019644856453 | Validation Accurancy:  0.999045594537165\n",
      "Epoch:  1437 | Train Accurancy:  0.9554038867354393 | Validation Accurancy:  0.9990469614858739\n",
      "Epoch:  1438 | Train Accurancy:  0.9554057903587818 | Validation Accurancy:  0.9990482330322266\n",
      "Epoch:  1439 | Train Accurancy:  0.9554076679050922 | Validation Accurancy:  0.9990492820506915\n",
      "Epoch:  1440 | Train Accurancy:  0.9554096087813377 | Validation Accurancy:  0.9990507444017567\n",
      "Epoch:  1441 | Train Accurancy:  0.9554114677011967 | Validation Accurancy:  0.9990519205457531\n",
      "Epoch:  1442 | Train Accurancy:  0.9554133489727974 | Validation Accurancy:  0.9990532239316963\n",
      "Epoch:  1443 | Train Accurancy:  0.9554152227938175 | Validation Accurancy:  0.9990544636966661\n",
      "Epoch:  1444 | Train Accurancy:  0.9554171375930309 | Validation Accurancy:  0.9990556398988701\n",
      "Epoch:  1445 | Train Accurancy:  0.9554190598428249 | Validation Accurancy:  0.9990568478824571\n",
      "Epoch:  1446 | Train Accurancy:  0.9554208964109421 | Validation Accurancy:  0.9990583737962879\n",
      "Epoch:  1447 | Train Accurancy:  0.9554228261113167 | Validation Accurancy:  0.9990594863775186\n",
      "Epoch:  1448 | Train Accurancy:  0.955424640327692 | Validation Accurancy:  0.9990607261424884\n",
      "Epoch:  1449 | Train Accurancy:  0.9554264768958092 | Validation Accurancy:  0.9990618705633096\n",
      "Epoch:  1450 | Train Accurancy:  0.9554283060133457 | Validation Accurancy:  0.9990631103282794\n",
      "Epoch:  1451 | Train Accurancy:  0.955430094152689 | Validation Accurancy:  0.9990643501514569\n",
      "Epoch:  1452 | Train Accurancy:  0.9554319158196449 | Validation Accurancy:  0.9990654627326876\n",
      "Epoch:  1453 | Train Accurancy:  0.95543372631073 | Validation Accurancy:  0.999066575372126\n",
      "Epoch:  1454 | Train Accurancy:  0.9554355815052986 | Validation Accurancy:  0.999067910539452\n",
      "Epoch:  1455 | Train Accurancy:  0.9554373621940613 | Validation Accurancy:  0.9990690866834484\n",
      "Epoch:  1456 | Train Accurancy:  0.955439206212759 | Validation Accurancy:  0.9990701675415039\n",
      "Epoch:  1457 | Train Accurancy:  0.9554409347474575 | Validation Accurancy:  0.9990714708692394\n",
      "Epoch:  1458 | Train Accurancy:  0.9554426856338978 | Validation Accurancy:  0.9990727106924169\n",
      "Epoch:  1459 | Train Accurancy:  0.955444473773241 | Validation Accurancy:  0.9990739186760038\n",
      "Epoch:  1460 | Train Accurancy:  0.9554461762309074 | Validation Accurancy:  0.9990751266595908\n",
      "Epoch:  1461 | Train Accurancy:  0.9554480090737343 | Validation Accurancy:  0.999076271080412\n",
      "Epoch:  1462 | Train Accurancy:  0.9554497338831425 | Validation Accurancy:  0.9990777333732694\n",
      "Epoch:  1463 | Train Accurancy:  0.9554515480995178 | Validation Accurancy:  0.9990787823917344\n",
      "Epoch:  1464 | Train Accurancy:  0.955453235656023 | Validation Accurancy:  0.9990798314684071\n",
      "Epoch:  1465 | Train Accurancy:  0.9554550759494305 | Validation Accurancy:  0.9990810712333769\n",
      "Epoch:  1466 | Train Accurancy:  0.9554567895829678 | Validation Accurancy:  0.9990822792169638\n",
      "Epoch:  1467 | Train Accurancy:  0.9554585367441177 | Validation Accurancy:  0.9990833917981945\n",
      "Epoch:  1468 | Train Accurancy:  0.9554602764546871 | Validation Accurancy:  0.9990847269655205\n",
      "Epoch:  1469 | Train Accurancy:  0.9554619565606117 | Validation Accurancy:  0.9990856806398369\n",
      "Epoch:  1470 | Train Accurancy:  0.9554636143147945 | Validation Accurancy:  0.9990869204048067\n",
      "Epoch:  1471 | Train Accurancy:  0.9554653503000736 | Validation Accurancy:  0.9990881601697765\n",
      "Epoch:  1472 | Train Accurancy:  0.955467164516449 | Validation Accurancy:  0.999089399992954\n",
      "Epoch:  1473 | Train Accurancy:  0.9554687552154064 | Validation Accurancy:  0.999090449011419\n",
      "Epoch:  1474 | Train Accurancy:  0.9554704017937183 | Validation Accurancy:  0.999091625213623\n",
      "Epoch:  1475 | Train Accurancy:  0.9554721526801586 | Validation Accurancy:  0.9990929285413586\n",
      "Epoch:  1476 | Train Accurancy:  0.9554738067090511 | Validation Accurancy:  0.9990940093994141\n",
      "Epoch:  1477 | Train Accurancy:  0.9554754830896854 | Validation Accurancy:  0.9990951856016181\n",
      "Epoch:  1478 | Train Accurancy:  0.955477137118578 | Validation Accurancy:  0.9990962028387003\n",
      "Epoch:  1479 | Train Accurancy:  0.9554787762463093 | Validation Accurancy:  0.9990975380060263\n",
      "Epoch:  1480 | Train Accurancy:  0.955480445176363 | Validation Accurancy:  0.9990987777709961\n",
      "Epoch:  1481 | Train Accurancy:  0.9554821364581585 | Validation Accurancy:  0.9990997314453125\n",
      "Epoch:  1482 | Train Accurancy:  0.9554837942123413 | Validation Accurancy:  0.9991008440847509\n",
      "Epoch:  1483 | Train Accurancy:  0.9554853737354279 | Validation Accurancy:  0.9991022109752521\n",
      "Epoch:  1484 | Train Accurancy:  0.955486997961998 | Validation Accurancy:  0.9991032918333076\n",
      "Epoch:  1485 | Train Accurancy:  0.9554886035621166 | Validation Accurancy:  0.9991043408517726\n",
      "Epoch:  1486 | Train Accurancy:  0.9554902017116547 | Validation Accurancy:  0.9991057713632472\n",
      "Epoch:  1487 | Train Accurancy:  0.9554918371140957 | Validation Accurancy:  0.9991068522213027\n",
      "Epoch:  1488 | Train Accurancy:  0.9554934352636337 | Validation Accurancy:  0.999107964860741\n",
      "Epoch:  1489 | Train Accurancy:  0.9554950557649136 | Validation Accurancy:  0.9991092999698594\n",
      "Epoch:  1490 | Train Accurancy:  0.9554966166615486 | Validation Accurancy:  0.9991103808279149\n",
      "Epoch:  1491 | Train Accurancy:  0.9554982110857964 | Validation Accurancy:  0.9991114934091456\n",
      "Epoch:  1492 | Train Accurancy:  0.9554998725652695 | Validation Accurancy:  0.9991127013927326\n",
      "Epoch:  1493 | Train Accurancy:  0.9555013999342918 | Validation Accurancy:  0.9991137504694052\n",
      "Epoch:  1494 | Train Accurancy:  0.9555029720067978 | Validation Accurancy:  0.9991148948902264\n",
      "Epoch:  1495 | Train Accurancy:  0.9555045552551746 | Validation Accurancy:  0.99911603925284\n",
      "Epoch:  1496 | Train Accurancy:  0.9555061049759388 | Validation Accurancy:  0.9991171836736612\n",
      "Epoch:  1497 | Train Accurancy:  0.9555076397955418 | Validation Accurancy:  0.9991183280944824\n",
      "Epoch:  1498 | Train Accurancy:  0.9555091708898544 | Validation Accurancy:  0.9991194725153036\n",
      "Epoch:  1499 | Train Accurancy:  0.9555107392370701 | Validation Accurancy:  0.9991206169361249\n",
      "Epoch:  1500 | Train Accurancy:  0.9555123299360275 | Validation Accurancy:  0.9991218567010947\n",
      "Epoch:  1501 | Train Accurancy:  0.9555138498544693 | Validation Accurancy:  0.9991230646846816\n",
      "Epoch:  1502 | Train Accurancy:  0.955515418201685 | Validation Accurancy:  0.9991240819217637\n",
      "Epoch:  1503 | Train Accurancy:  0.9555169269442558 | Validation Accurancy:  0.9991251627798192\n",
      "Epoch:  1504 | Train Accurancy:  0.955518439412117 | Validation Accurancy:  0.9991262435796671\n",
      "Epoch:  1505 | Train Accurancy:  0.9555199630558491 | Validation Accurancy:  0.9991274833446369\n",
      "Epoch:  1506 | Train Accurancy:  0.9555214792490005 | Validation Accurancy:  0.9991285959840752\n",
      "Epoch:  1507 | Train Accurancy:  0.9555229842662811 | Validation Accurancy:  0.9991295814397745\n",
      "Epoch:  1508 | Train Accurancy:  0.955524493008852 | Validation Accurancy:  0.9991306940792128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1509 | Train Accurancy:  0.9555259272456169 | Validation Accurancy:  0.9991319338441826\n",
      "Epoch:  1510 | Train Accurancy:  0.9555274173617363 | Validation Accurancy:  0.9991329192998819\n",
      "Epoch:  1511 | Train Accurancy:  0.9555289261043072 | Validation Accurancy:  0.999134095502086\n",
      "Epoch:  1512 | Train Accurancy:  0.9555304199457169 | Validation Accurancy:  0.9991350809577852\n",
      "Epoch:  1513 | Train Accurancy:  0.9555318839848042 | Validation Accurancy:  0.9991361935972236\n",
      "Epoch:  1514 | Train Accurancy:  0.9555333107709885 | Validation Accurancy:  0.9991374651435763\n",
      "Epoch:  1515 | Train Accurancy:  0.9555347971618176 | Validation Accurancy:  0.9991386095643975\n",
      "Epoch:  1516 | Train Accurancy:  0.9555362053215504 | Validation Accurancy:  0.9991396268014796\n",
      "Epoch:  1517 | Train Accurancy:  0.9555376544594765 | Validation Accurancy:  0.9991407712223008\n",
      "Epoch:  1518 | Train Accurancy:  0.9555390700697899 | Validation Accurancy:  0.9991418838617392\n",
      "Epoch:  1519 | Train Accurancy:  0.9555405452847481 | Validation Accurancy:  0.9991429328802042\n",
      "Epoch:  1520 | Train Accurancy:  0.95554194226861 | Validation Accurancy:  0.9991440455196425\n",
      "Epoch:  1521 | Train Accurancy:  0.9555434621870518 | Validation Accurancy:  0.9991449991939589\n",
      "Epoch:  1522 | Train Accurancy:  0.9555449150502682 | Validation Accurancy:  0.9991462707403116\n",
      "Epoch:  1523 | Train Accurancy:  0.9555462822318077 | Validation Accurancy:  0.9991473198169842\n",
      "Epoch:  1524 | Train Accurancy:  0.955547709017992 | Validation Accurancy:  0.9991483688354492\n",
      "Epoch:  1525 | Train Accurancy:  0.9555491171777248 | Validation Accurancy:  0.9991492907283828\n",
      "Epoch:  1526 | Train Accurancy:  0.9555504992604256 | Validation Accurancy:  0.9991503079654649\n",
      "Epoch:  1527 | Train Accurancy:  0.9555519707500935 | Validation Accurancy:  0.9991515795118175\n",
      "Epoch:  1528 | Train Accurancy:  0.9555533118546009 | Validation Accurancy:  0.9991526921512559\n",
      "Epoch:  1529 | Train Accurancy:  0.9555547051131725 | Validation Accurancy:  0.9991536776069552\n",
      "Epoch:  1530 | Train Accurancy:  0.9555560573935509 | Validation Accurancy:  0.9991547902463935\n",
      "Epoch:  1531 | Train Accurancy:  0.9555574357509613 | Validation Accurancy:  0.9991559346672148\n",
      "Epoch:  1532 | Train Accurancy:  0.9555587694048882 | Validation Accurancy:  0.9991570154670626\n",
      "Epoch:  1533 | Train Accurancy:  0.9555601887404919 | Validation Accurancy:  0.9991580645437352\n",
      "Epoch:  1534 | Train Accurancy:  0.9555615186691284 | Validation Accurancy:  0.9991590499994345\n",
      "Epoch:  1535 | Train Accurancy:  0.9555628560483456 | Validation Accurancy:  0.9991600990178995\n",
      "Epoch:  1536 | Train Accurancy:  0.955564197152853 | Validation Accurancy:  0.9991612752201036\n",
      "Epoch:  1537 | Train Accurancy:  0.9555655531585217 | Validation Accurancy:  0.9991623242967762\n",
      "Epoch:  1538 | Train Accurancy:  0.9555669538676739 | Validation Accurancy:  0.9991632143501192\n",
      "Epoch:  1539 | Train Accurancy:  0.9555683024227619 | Validation Accurancy:  0.9991643905523233\n",
      "Epoch:  1540 | Train Accurancy:  0.9555696323513985 | Validation Accurancy:  0.999165280663874\n",
      "Epoch:  1541 | Train Accurancy:  0.9555709883570671 | Validation Accurancy:  0.9991664568660781\n",
      "Epoch:  1542 | Train Accurancy:  0.9555723145604134 | Validation Accurancy:  0.9991674105403945\n",
      "Epoch:  1543 | Train Accurancy:  0.9555736482143402 | Validation Accurancy:  0.9991686503053643\n",
      "Epoch:  1544 | Train Accurancy:  0.9555749893188477 | Validation Accurancy:  0.9991696039796807\n",
      "Epoch:  1545 | Train Accurancy:  0.9555763155221939 | Validation Accurancy:  0.9991707801818848\n",
      "Epoch:  1546 | Train Accurancy:  0.9555776119232178 | Validation Accurancy:  0.9991718610399403\n",
      "Epoch:  1547 | Train Accurancy:  0.9555788710713387 | Validation Accurancy:  0.9991729418397881\n",
      "Epoch:  1548 | Train Accurancy:  0.9555802196264267 | Validation Accurancy:  0.9991737365489826\n",
      "Epoch:  1549 | Train Accurancy:  0.955581534653902 | Validation Accurancy:  0.9991750399349257\n",
      "Epoch:  1550 | Train Accurancy:  0.9555828236043453 | Validation Accurancy:  0.9991759618278593\n",
      "Epoch:  1551 | Train Accurancy:  0.9555840231478214 | Validation Accurancy:  0.9991770426277071\n",
      "Epoch:  1552 | Train Accurancy:  0.9555853307247162 | Validation Accurancy:  0.9991779327392578\n",
      "Epoch:  1553 | Train Accurancy:  0.9555866084992886 | Validation Accurancy:  0.9991792042856105\n",
      "Epoch:  1554 | Train Accurancy:  0.955587912350893 | Validation Accurancy:  0.9991799990530126\n",
      "Epoch:  1555 | Train Accurancy:  0.9555891193449497 | Validation Accurancy:  0.9991814295644872\n",
      "Epoch:  1556 | Train Accurancy:  0.9555903822183609 | Validation Accurancy:  0.999181842780672\n",
      "Epoch:  1557 | Train Accurancy:  0.9555916637182236 | Validation Accurancy:  0.9991834640386514\n",
      "Epoch:  1558 | Train Accurancy:  0.955592930316925 | Validation Accurancy:  0.999183718347922\n",
      "Epoch:  1559 | Train Accurancy:  0.9555941484868526 | Validation Accurancy:  0.9991859436267987\n",
      "Epoch:  1560 | Train Accurancy:  0.9555954113602638 | Validation Accurancy:  0.9991856256965548\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):  # 继承 torch 的 Module\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()     # 继承 __init__ 功能\n",
    "        # 定义每层用什么样的形式\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # 隐藏层线性输出\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # 输出层线性输出\n",
    "\n",
    "    def forward(self, x):   # 这同时也是 Module 中的 forward 功能\n",
    "        # 正向传播输入值, 神经网络分析出输出值\n",
    "        x = F.relu(self.hidden(x))      # 激励函数(隐藏层的线性值)\n",
    "        x = self.predict(x)             # 输出值\n",
    "        return x\n",
    "\n",
    "net = Net(n_feature=4, n_hidden=9, n_output=4)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "NNtrain(\n",
    "    X=iris.data, \n",
    "    y=iris.target, \n",
    "    model=net, \n",
    "    task='C', \n",
    "    lossf=nn.CrossEntropyLoss(), \n",
    "    optimizer=torch.optim.Adam(net.parameters(), lr=0.01), \n",
    "    epochs=30000, \n",
    "    train_size=0.9, \n",
    "    device = 'CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
