{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 适用于不同类别的图片放在不同文件夹 文件夹名即为标签 对类别较少很方便！\n",
    "import torch  \n",
    "import torchvision  \n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn  \n",
    "from torch.autograd import Variable  \n",
    "import torch.utils.data as Data  \n",
    "import time  \n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2945\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "train_img_data = torchvision.datasets.ImageFolder('C:/Users/jxjsj/Desktop/JupyterHome/Data/flowers/train',\n",
    "                                            transform=transforms.Compose([\n",
    "                                                transforms.Resize(256),\n",
    "                                                transforms.CenterCrop(224),\n",
    "                                                transforms.ToTensor()])\n",
    "                                            )\n",
    "\n",
    "print(len(train_img_data))\n",
    "train_data_loader = torch.utils.data.DataLoader(train_img_data, batch_size=50,shuffle=True)\n",
    "print(len(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "test_img_data = torchvision.datasets.ImageFolder('C:/Users/jxjsj/Desktop/JupyterHome/Data/flowers/test',\n",
    "                                            transform=transforms.Compose([\n",
    "                                                transforms.Resize(256),\n",
    "                                                transforms.CenterCrop(224), # 变成224 x 224像素\n",
    "                                                transforms.ToTensor()])\n",
    "                                            )\n",
    "\n",
    "print(len(test_img_data))\n",
    "test_data_loader = torch.utils.data.DataLoader(test_img_data, batch_size=50,shuffle=True)\n",
    "print(len(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reluCNNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(reluCNNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential( # 224\n",
    "            torch.nn.Conv2d(3, 32, 5, 1, 2), # 224\n",
    "            torch.nn.BatchNorm2d(num_features=32, eps=1e-05, momentum=0.1, affine=True), # BN 处理\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2) # 110\n",
    "        ) \n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, 5, 1, 2), # 112\n",
    "            torch.nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1, affine=True), # BN 处理\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2) # 56\n",
    "        )\n",
    "        self.conv3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 32, 5, 2, 0), # 26\n",
    "            torch.nn.BatchNorm2d(num_features=32, eps=1e-05, momentum=0.1, affine=True), # BN 处理\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2) # 12\n",
    "        )\n",
    "        self.dense = torch.nn.Sequential(\n",
    "            torch.nn.Linear(32*13*13, 128),\n",
    "#             torch.nn.Dropout(0.5),  # 防止过拟合尝试\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv2_out = self.conv2(conv1_out)\n",
    "        conv3_out = self.conv3(conv2_out)\n",
    "        res = conv3_out.view(conv3_out.size(0), -1)\n",
    "        out = self.dense(res)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型参数并赋予模型\n",
    "model = reluCNNet()\n",
    "# model.load_state_dict(torch.load('C:/Users/jxjsj/Desktop/JupyterHome/DLmodel/reluCNN_flower.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Train Acc: 0.967402\n",
      "Test Acc: 0.648276\n",
      "epoch 2\n",
      "Train Acc: 0.987097\n",
      "Test Acc: 0.663448\n",
      "epoch 3\n",
      "Train Acc: 0.989474\n",
      "Test Acc: 0.652414\n",
      "epoch 4\n",
      "Train Acc: 0.998302\n",
      "Test Acc: 0.678621\n",
      "epoch 5\n",
      "Train Acc: 0.993888\n",
      "Test Acc: 0.638621\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "else:\n",
    "    model = model.cpu()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    # training-----------------------------\n",
    "    model.train()\n",
    "    train_acc = 0.\n",
    "#     L_train_pred = []\n",
    "#     L_train_real = []\n",
    "    for step, (batch_x, batch_y) in enumerate(train_data_loader):\n",
    "        batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "        \n",
    "        if use_gpu:\n",
    "            batch_x = batch_x.cuda()\n",
    "            batch_y = batch_y.cuda()\n",
    "            \n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = torch.max(out, 1)[1]\n",
    "        num_correct = (pred == batch_y).sum()\n",
    "        train_acc += num_correct.data\n",
    "        \n",
    "#         L_train_pred += pred.cpu().numpy().tolist()\n",
    "#         L_train_real += batch_y.cpu().numpy().tolist()\n",
    "        \n",
    "#         print('Step:',step+1,'Finished!')\n",
    "    print('Train Acc: {:.6f}'.format(train_acc.cpu().numpy() / (len(train_img_data))))\n",
    "#     print(classification_report(L_train_real,L_train_pred))\n",
    "\n",
    "    # evaluation--------------------------------\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        eval_acc = 0.\n",
    "#         L_val_pred = []\n",
    "#         L_val_real = []\n",
    "        for batch_x, batch_y in test_data_loader:\n",
    "            batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "\n",
    "            if use_gpu:\n",
    "                batch_x = batch_x.cuda()\n",
    "                batch_y = batch_y.cuda()\n",
    "\n",
    "            out = model(batch_x)\n",
    "            loss = loss_func(out, batch_y)\n",
    "            \n",
    "            pred = torch.max(out, 1)[1]\n",
    "            num_correct = (pred == batch_y).sum()\n",
    "            eval_acc += num_correct\n",
    "            \n",
    "#             L_val_pred += pred.cpu().numpy().tolist()\n",
    "#             L_val_real += batch_y.cpu().numpy().tolist()\n",
    "            \n",
    "        print('Test Acc: {:.6f}'.format(eval_acc.cpu().numpy() / (len(test_img_data))))\n",
    "#         print(classification_report(L_val_real,L_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'C:/Users/jxjsj/Desktop/JupyterHome/DLmodel/reluCNN_flower.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tulips'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用外来图片检测test\n",
    "from PIL import Image\n",
    "test_use_rose = Image.open('C:/Users/jxjsj/Desktop/test_use_flowers/pgy_.jpg').convert('RGB')\n",
    "transform=transforms.Compose([transforms.Resize(256),\n",
    "                              transforms.CenterCrop(224),\n",
    "                              transforms.ToTensor()])\n",
    "test_rose = transform(test_use_rose)\n",
    "model.cpu()\n",
    "model.eval()\n",
    "test_rose = test_rose.unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    test_rose = Variable(test_rose)\n",
    "    test_out = model(test_rose)\n",
    "    pred = torch.max(test_out, 1)[1]\n",
    "\n",
    "# print(train_img_data.class_to_idx)\n",
    "# print(test_img_data.class_to_idx)\n",
    "\n",
    "index_label_dct = {train_img_data.class_to_idx[label] : label for label in train_img_data.class_to_idx}\n",
    "index_label_dct[int(pred.cpu().numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n"
     ]
    }
   ],
   "source": [
    "print(train_img_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
