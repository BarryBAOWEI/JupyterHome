{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## RNN 简单练习：一维输入数据，前一天的高频收益率序列 ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array(pd.read_csv('C:/Users/jxjsj/Desktop/JupyterHome/Data/SZZSlnrlnR.csv',header = None)[list(range(47))]) # 其实是Xt-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(pd.read_csv('C:/Users/jxjsj/Desktop/JupyterHome/Data/SZZSlnrlnR.csv',header = None)[[47]]) # 其实是yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2108.0, 527.0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)*0.8, len(X)*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:2108]\n",
    "y_train = y[:2108]\n",
    "X_test = X[2108:]\n",
    "y_test = y[2108:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据装入加载器\n",
    "x_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "x_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "train_dataset = Data.TensorDataset(x_train, y_train)\n",
    "test_dataset = Data.TensorDataset(x_test, y_test)\n",
    "\n",
    "train_data_loader = Data.DataLoader(train_dataset, batch_size=len(train_dataset),shuffle=True)\n",
    "test_data_loader = Data.DataLoader(test_dataset, batch_size=len(test_dataset),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2108, 47])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_data_loader:\n",
    "    print(x.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### 先用一维CNN尝试 ###################################################\n",
    "class reluCNNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(reluCNNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential( # 47\n",
    "            torch.nn.Conv1d(1, 32, 5, 1, 0), # 43\n",
    "            torch.nn.BatchNorm1d(num_features=32, eps=1e-05, momentum=0.1, affine=True), # BN 处理\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2) # 21\n",
    "        )\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(32, 64, 5, 1, 0), # 17\n",
    "            torch.nn.BatchNorm1d(num_features=64, eps=1e-05, momentum=0.1, affine=True), # BN 处理\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2) # 8\n",
    "        )\n",
    "        self.dense = torch.nn.Sequential(\n",
    "            torch.nn.Linear(64*8, 32),\n",
    "#             torch.nn.Dropout(0.3),  # 防止过拟合尝试\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv2_out = self.conv2(conv1_out)\n",
    "        res = conv2_out.view(conv2_out.size(0), -1) # 64*8* -> 64*8 1d无意义\n",
    "        out = self.dense(res)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Train MSE: 0.0000010490\n",
      "Test MSE: 0.0000523151\n",
      "epoch 2\n",
      "Train MSE: 0.0000086631\n",
      "Test MSE: 0.0000482639\n",
      "epoch 3\n",
      "Train MSE: 0.0000381450\n",
      "Test MSE: 0.0000735950\n",
      "epoch 4\n",
      "Train MSE: 0.0000111902\n",
      "Test MSE: 0.0000795517\n",
      "epoch 5\n",
      "Train MSE: 0.0000186973\n",
      "Test MSE: 0.0000512167\n",
      "epoch 6\n",
      "Train MSE: 0.0000141163\n",
      "Test MSE: 0.0000438776\n",
      "epoch 7\n",
      "Train MSE: 0.0000095139\n",
      "Test MSE: 0.0000595365\n",
      "epoch 8\n",
      "Train MSE: 0.0000148218\n",
      "Test MSE: 0.0000582733\n",
      "epoch 9\n",
      "Train MSE: 0.0000106440\n",
      "Test MSE: 0.0000453783\n",
      "epoch 10\n",
      "Train MSE: 0.0000031582\n",
      "Test MSE: 0.0000456674\n",
      "epoch 11\n",
      "Train MSE: 0.0000054098\n",
      "Test MSE: 0.0000504665\n",
      "epoch 12\n",
      "Train MSE: 0.0000111630\n",
      "Test MSE: 0.0000461946\n",
      "epoch 13\n",
      "Train MSE: 0.0000096326\n",
      "Test MSE: 0.0000458940\n",
      "epoch 14\n",
      "Train MSE: 0.0000037164\n",
      "Test MSE: 0.0000537804\n",
      "epoch 15\n",
      "Train MSE: 0.0000019012\n",
      "Test MSE: 0.0000618768\n",
      "epoch 16\n",
      "Train MSE: 0.0000048145\n",
      "Test MSE: 0.0000590654\n",
      "epoch 17\n",
      "Train MSE: 0.0000060991\n",
      "Test MSE: 0.0000488835\n",
      "epoch 18\n",
      "Train MSE: 0.0000044803\n",
      "Test MSE: 0.0000429955\n",
      "epoch 19\n",
      "Train MSE: 0.0000036821\n",
      "Test MSE: 0.0000432221\n",
      "epoch 20\n",
      "Train MSE: 0.0000036054\n",
      "Test MSE: 0.0000440653\n",
      "epoch 21\n",
      "Train MSE: 0.0000027247\n",
      "Test MSE: 0.0000441021\n",
      "epoch 22\n",
      "Train MSE: 0.0000023903\n",
      "Test MSE: 0.0000447695\n",
      "epoch 23\n",
      "Train MSE: 0.0000035158\n",
      "Test MSE: 0.0000456446\n",
      "epoch 24\n",
      "Train MSE: 0.0000038372\n",
      "Test MSE: 0.0000451511\n",
      "epoch 25\n",
      "Train MSE: 0.0000023407\n",
      "Test MSE: 0.0000438554\n",
      "epoch 26\n",
      "Train MSE: 0.0000012837\n",
      "Test MSE: 0.0000430921\n",
      "epoch 27\n",
      "Train MSE: 0.0000020497\n",
      "Test MSE: 0.0000429932\n",
      "epoch 28\n",
      "Train MSE: 0.0000029404\n",
      "Test MSE: 0.0000438446\n",
      "epoch 29\n",
      "Train MSE: 0.0000025621\n",
      "Test MSE: 0.0000450885\n",
      "epoch 30\n",
      "Train MSE: 0.0000018421\n",
      "Test MSE: 0.0000460032\n",
      "epoch 31\n",
      "Train MSE: 0.0000017331\n",
      "Test MSE: 0.0000462544\n",
      "epoch 32\n",
      "Train MSE: 0.0000017985\n",
      "Test MSE: 0.0000461674\n",
      "epoch 33\n",
      "Train MSE: 0.0000017053\n",
      "Test MSE: 0.0000470157\n",
      "epoch 34\n",
      "Train MSE: 0.0000018260\n",
      "Test MSE: 0.0000476917\n",
      "epoch 35\n",
      "Train MSE: 0.0000019237\n",
      "Test MSE: 0.0000469062\n",
      "epoch 36\n",
      "Train MSE: 0.0000015332\n",
      "Test MSE: 0.0000464018\n",
      "epoch 37\n",
      "Train MSE: 0.0000011811\n",
      "Test MSE: 0.0000467271\n",
      "epoch 38\n",
      "Train MSE: 0.0000014508\n",
      "Test MSE: 0.0000467261\n",
      "epoch 39\n",
      "Train MSE: 0.0000017551\n",
      "Test MSE: 0.0000463511\n",
      "epoch 40\n",
      "Train MSE: 0.0000015239\n",
      "Test MSE: 0.0000462947\n",
      "epoch 41\n",
      "Train MSE: 0.0000012426\n",
      "Test MSE: 0.0000470291\n",
      "epoch 42\n",
      "Train MSE: 0.0000012949\n",
      "Test MSE: 0.0000475059\n",
      "epoch 43\n",
      "Train MSE: 0.0000013738\n",
      "Test MSE: 0.0000473274\n",
      "epoch 44\n",
      "Train MSE: 0.0000013329\n",
      "Test MSE: 0.0000467961\n",
      "epoch 45\n",
      "Train MSE: 0.0000013245\n",
      "Test MSE: 0.0000466077\n",
      "epoch 46\n",
      "Train MSE: 0.0000012639\n",
      "Test MSE: 0.0000464055\n",
      "epoch 47\n",
      "Train MSE: 0.0000011450\n",
      "Test MSE: 0.0000461093\n",
      "epoch 48\n",
      "Train MSE: 0.0000011933\n",
      "Test MSE: 0.0000459984\n",
      "epoch 49\n",
      "Train MSE: 0.0000013184\n",
      "Test MSE: 0.0000461079\n",
      "epoch 50\n",
      "Train MSE: 0.0000012510\n",
      "Test MSE: 0.0000463776\n",
      "epoch 51\n",
      "Train MSE: 0.0000011166\n",
      "Test MSE: 0.0000467044\n",
      "epoch 52\n",
      "Train MSE: 0.0000011409\n",
      "Test MSE: 0.0000469868\n",
      "epoch 53\n",
      "Train MSE: 0.0000011970\n",
      "Test MSE: 0.0000471261\n",
      "epoch 54\n",
      "Train MSE: 0.0000011670\n",
      "Test MSE: 0.0000470807\n",
      "epoch 55\n",
      "Train MSE: 0.0000011363\n",
      "Test MSE: 0.0000467860\n",
      "epoch 56\n",
      "Train MSE: 0.0000011239\n",
      "Test MSE: 0.0000464472\n",
      "epoch 57\n",
      "Train MSE: 0.0000011002\n",
      "Test MSE: 0.0000462039\n",
      "epoch 58\n",
      "Train MSE: 0.0000011275\n",
      "Test MSE: 0.0000460522\n",
      "epoch 59\n",
      "Train MSE: 0.0000011523\n",
      "Test MSE: 0.0000459685\n",
      "epoch 60\n",
      "Train MSE: 0.0000010998\n",
      "Test MSE: 0.0000460875\n",
      "epoch 61\n",
      "Train MSE: 0.0000010707\n",
      "Test MSE: 0.0000463269\n",
      "epoch 62\n",
      "Train MSE: 0.0000011052\n",
      "Test MSE: 0.0000463190\n",
      "epoch 63\n",
      "Train MSE: 0.0000011093\n",
      "Test MSE: 0.0000459932\n",
      "epoch 64\n",
      "Train MSE: 0.0000010814\n",
      "Test MSE: 0.0000456535\n",
      "epoch 65\n",
      "Train MSE: 0.0000010763\n",
      "Test MSE: 0.0000454880\n",
      "epoch 66\n",
      "Train MSE: 0.0000010753\n",
      "Test MSE: 0.0000455628\n",
      "epoch 67\n",
      "Train MSE: 0.0000010762\n",
      "Test MSE: 0.0000458209\n",
      "epoch 68\n",
      "Train MSE: 0.0000010844\n",
      "Test MSE: 0.0000460133\n",
      "epoch 69\n",
      "Train MSE: 0.0000010689\n",
      "Test MSE: 0.0000461083\n",
      "epoch 70\n",
      "Train MSE: 0.0000010530\n",
      "Test MSE: 0.0000461365\n",
      "epoch 71\n",
      "Train MSE: 0.0000010675\n",
      "Test MSE: 0.0000461996\n",
      "epoch 72\n",
      "Train MSE: 0.0000010671\n",
      "Test MSE: 0.0000462619\n",
      "epoch 73\n",
      "Train MSE: 0.0000010509\n",
      "Test MSE: 0.0000462597\n",
      "epoch 74\n",
      "Train MSE: 0.0000010541\n",
      "Test MSE: 0.0000461342\n",
      "epoch 75\n",
      "Train MSE: 0.0000010582\n",
      "Test MSE: 0.0000459906\n",
      "epoch 76\n",
      "Train MSE: 0.0000010544\n",
      "Test MSE: 0.0000459861\n",
      "epoch 77\n",
      "Train MSE: 0.0000010526\n",
      "Test MSE: 0.0000461287\n",
      "epoch 78\n",
      "Train MSE: 0.0000010471\n",
      "Test MSE: 0.0000463654\n",
      "epoch 79\n",
      "Train MSE: 0.0000010453\n",
      "Test MSE: 0.0000464315\n",
      "epoch 80\n",
      "Train MSE: 0.0000010499\n",
      "Test MSE: 0.0000462802\n",
      "epoch 81\n",
      "Train MSE: 0.0000010451\n",
      "Test MSE: 0.0000459774\n",
      "epoch 82\n",
      "Train MSE: 0.0000010391\n",
      "Test MSE: 0.0000457532\n",
      "epoch 83\n",
      "Train MSE: 0.0000010418\n",
      "Test MSE: 0.0000456943\n",
      "epoch 84\n",
      "Train MSE: 0.0000010415\n",
      "Test MSE: 0.0000457216\n",
      "epoch 85\n",
      "Train MSE: 0.0000010385\n",
      "Test MSE: 0.0000457459\n",
      "epoch 86\n",
      "Train MSE: 0.0000010371\n",
      "Test MSE: 0.0000456987\n",
      "epoch 87\n",
      "Train MSE: 0.0000010369\n",
      "Test MSE: 0.0000455545\n",
      "epoch 88\n",
      "Train MSE: 0.0000010358\n",
      "Test MSE: 0.0000454273\n",
      "epoch 89\n",
      "Train MSE: 0.0000010332\n",
      "Test MSE: 0.0000453853\n",
      "epoch 90\n",
      "Train MSE: 0.0000010327\n",
      "Test MSE: 0.0000454172\n",
      "epoch 91\n",
      "Train MSE: 0.0000010330\n",
      "Test MSE: 0.0000454459\n",
      "epoch 92\n",
      "Train MSE: 0.0000010320\n",
      "Test MSE: 0.0000454700\n",
      "epoch 93\n",
      "Train MSE: 0.0000010298\n",
      "Test MSE: 0.0000454767\n",
      "epoch 94\n",
      "Train MSE: 0.0000010297\n",
      "Test MSE: 0.0000454508\n",
      "epoch 95\n",
      "Train MSE: 0.0000010292\n",
      "Test MSE: 0.0000454293\n",
      "epoch 96\n",
      "Train MSE: 0.0000010273\n",
      "Test MSE: 0.0000453832\n",
      "epoch 97\n",
      "Train MSE: 0.0000010262\n",
      "Test MSE: 0.0000453234\n",
      "epoch 98\n",
      "Train MSE: 0.0000010252\n",
      "Test MSE: 0.0000452673\n",
      "epoch 99\n",
      "Train MSE: 0.0000010244\n",
      "Test MSE: 0.0000452489\n",
      "epoch 100\n",
      "Train MSE: 0.0000010249\n",
      "Test MSE: 0.0000453121\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "\n",
    "# model = reluCNNet()\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    # training-----------------------------\n",
    "    model.train()\n",
    "    train_acc = 0.\n",
    "    pred_train_lst = []\n",
    "    for step, (batch_x, batch_y) in enumerate(train_data_loader):\n",
    "        \n",
    "        batch_x = batch_x.unsqueeze(1)\n",
    "        \n",
    "        batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "        \n",
    "        if use_gpu:\n",
    "            batch_x = batch_x.cuda()\n",
    "            batch_y = batch_y.cuda()\n",
    "            \n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_train_lst.append(out.cpu().detach().numpy().tolist())\n",
    "        \n",
    "    print('Train MSE: {:.10f}'.format(loss))\n",
    "\n",
    "    # evaluation--------------------------------\n",
    "    model.eval()\n",
    "    pred_lst = []\n",
    "    with torch.no_grad():\n",
    "        eval_acc = 0.\n",
    "\n",
    "        for batch_x, batch_y in test_data_loader:\n",
    "            \n",
    "            batch_x = batch_x.unsqueeze(1)\n",
    "            \n",
    "            batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "\n",
    "            if use_gpu:\n",
    "                batch_x = batch_x.cuda()\n",
    "                batch_y = batch_y.cuda()\n",
    "\n",
    "            out = model(batch_x)\n",
    "            loss = loss_func(out, batch_y)\n",
    "            \n",
    "            pred_lst.append(out.cpu().numpy().tolist())\n",
    "            \n",
    "        print('Test MSE: {:.10f}'.format(loss))\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### 用LSTM-rnn+CNN尝试 ###################################################\n",
    "# class LSTMrnn(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LSTMrnn, self).__init__()\n",
    "#         self.lstm1 = torch.nn.Sequential(  \n",
    "#                        nn.LSTM(input_size = 47, hidden_size = 97, num_layers = 1, batch_first=True) # batch_first=True很重要！\n",
    "#         )   \n",
    "#         self.dense = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(97, 32),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Linear(32, 1)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # 设置初始状态h_0与c_0的状态是初始的状态，一般设置为0，尺寸是,x.size(0)\n",
    "#         h0 = Variable(torch.zeros(1, x.size(0), 97).cuda())\n",
    "#         c0 = Variable(torch.zeros(1, x.size(0), 97).cuda())\n",
    "#         h_c_0 = (h0, c0)\n",
    "        \n",
    "#         # Forward propagate RNN\n",
    "#         x, h_c_n = self.lstm1(x, h_c_0)  # 送入一个初始的x值，作为输入以及(h0, c0)\n",
    "        \n",
    "#         # Decode hidden state of last time step\n",
    "#         out = self.dense(x[:, -1, :])  # output也是batch_first, 实际上h_n与c_n并不是batch_first\n",
    "#         return out\n",
    "\n",
    "class LSTMrnn(nn.Module):\n",
    "    def __init__(self,input_size,hidden_dim,target_size):\n",
    "        super(LSTMrnn,self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim=hidden_dim  \n",
    "        self.target_size=target_size\n",
    "        self.hidden=(Variable(torch.zeros(1,1,self.hidden_dim)).cuda(),\n",
    "                     Variable(torch.zeros(1,1,self.hidden_dim)).cuda())\n",
    "        \n",
    "        self.lstm=torch.nn.LSTM(self.input_size,self.hidden_dim)\n",
    "        self.conv=torch.nn.Sequential( # hidden_dim\n",
    "            torch.nn.Conv1d(1, 16, 5, 1, 0), # 32*(hidden_dim-4)\n",
    "            torch.nn.BatchNorm1d(num_features=16, eps=1e-05, momentum=0.1, affine=True), # BN 处理\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.dense = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16*(hidden_dim-4), 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        lstm,self.hidden = self.lstm(x,self.hidden)\n",
    "        conv = self.conv(lstm)\n",
    "        tags = self.dense(conv.view(conv.size(0), -1)) # conv：2108*32*46 -> 2108*（32*46）\n",
    "        return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Train MSE: 0.0305720922\n",
      "Test MSE: 0.0068498715\n",
      "epoch 2\n",
      "Train MSE: 0.0015730838\n",
      "Test MSE: 0.0055450480\n",
      "epoch 3\n",
      "Train MSE: 0.0003703936\n",
      "Test MSE: 0.0048413821\n",
      "epoch 4\n",
      "Train MSE: 0.0017482007\n",
      "Test MSE: 0.0046250988\n",
      "epoch 5\n",
      "Train MSE: 0.0030927472\n",
      "Test MSE: 0.0047268630\n",
      "epoch 6\n",
      "Train MSE: 0.0032245487\n",
      "Test MSE: 0.0050369375\n",
      "epoch 7\n",
      "Train MSE: 0.0023895910\n",
      "Test MSE: 0.0054712673\n",
      "epoch 8\n",
      "Train MSE: 0.0013023252\n",
      "Test MSE: 0.0059633763\n",
      "epoch 9\n",
      "Train MSE: 0.0005330021\n",
      "Test MSE: 0.0064712195\n",
      "epoch 10\n",
      "Train MSE: 0.0003171294\n",
      "Test MSE: 0.0069182767\n",
      "epoch 11\n",
      "Train MSE: 0.0005817998\n",
      "Test MSE: 0.0072464808\n",
      "epoch 12\n",
      "Train MSE: 0.0010295453\n",
      "Test MSE: 0.0074502775\n",
      "epoch 13\n",
      "Train MSE: 0.0013490946\n",
      "Test MSE: 0.0075488710\n",
      "epoch 14\n",
      "Train MSE: 0.0013897121\n",
      "Test MSE: 0.0075627104\n",
      "epoch 15\n",
      "Train MSE: 0.0011731026\n",
      "Test MSE: 0.0075124511\n",
      "epoch 16\n",
      "Train MSE: 0.0008276085\n",
      "Test MSE: 0.0074065016\n",
      "epoch 17\n",
      "Train MSE: 0.0005104080\n",
      "Test MSE: 0.0072928411\n",
      "epoch 18\n",
      "Train MSE: 0.0003341477\n",
      "Test MSE: 0.0071901241\n",
      "epoch 19\n",
      "Train MSE: 0.0003322799\n",
      "Test MSE: 0.0071257576\n",
      "epoch 20\n",
      "Train MSE: 0.0004587936\n",
      "Test MSE: 0.0071097161\n",
      "epoch 21\n",
      "Train MSE: 0.0006174910\n",
      "Test MSE: 0.0071282904\n",
      "epoch 22\n",
      "Train MSE: 0.0007163535\n",
      "Test MSE: 0.0071686041\n",
      "epoch 23\n",
      "Train MSE: 0.0007098204\n",
      "Test MSE: 0.0072378204\n",
      "epoch 24\n",
      "Train MSE: 0.0006119149\n",
      "Test MSE: 0.0073405281\n",
      "epoch 25\n",
      "Train MSE: 0.0004763778\n",
      "Test MSE: 0.0074689887\n",
      "epoch 26\n",
      "Train MSE: 0.0003638260\n",
      "Test MSE: 0.0076039420\n",
      "epoch 27\n",
      "Train MSE: 0.0003131061\n",
      "Test MSE: 0.0077334736\n",
      "epoch 28\n",
      "Train MSE: 0.0003286341\n",
      "Test MSE: 0.0078238426\n",
      "epoch 29\n",
      "Train MSE: 0.0003853614\n",
      "Test MSE: 0.0078714387\n",
      "epoch 30\n",
      "Train MSE: 0.0004454185\n",
      "Test MSE: 0.0078679631\n",
      "epoch 31\n",
      "Train MSE: 0.0004770006\n",
      "Test MSE: 0.0078063100\n",
      "epoch 32\n",
      "Train MSE: 0.0004669818\n",
      "Test MSE: 0.0076884506\n",
      "epoch 33\n",
      "Train MSE: 0.0004235680\n",
      "Test MSE: 0.0075268121\n",
      "epoch 34\n",
      "Train MSE: 0.0003688209\n",
      "Test MSE: 0.0073328195\n",
      "epoch 35\n",
      "Train MSE: 0.0003260139\n",
      "Test MSE: 0.0071190884\n",
      "epoch 36\n",
      "Train MSE: 0.0003099678\n",
      "Test MSE: 0.0069028540\n",
      "epoch 37\n",
      "Train MSE: 0.0003213921\n",
      "Test MSE: 0.0067000287\n",
      "epoch 38\n",
      "Train MSE: 0.0003475486\n",
      "Test MSE: 0.0065216627\n",
      "epoch 39\n",
      "Train MSE: 0.0003711262\n",
      "Test MSE: 0.0063742697\n",
      "epoch 40\n",
      "Train MSE: 0.0003791383\n",
      "Test MSE: 0.0062591657\n",
      "epoch 41\n",
      "Train MSE: 0.0003682034\n",
      "Test MSE: 0.0061732652\n",
      "epoch 42\n",
      "Train MSE: 0.0003454926\n",
      "Test MSE: 0.0061085783\n",
      "epoch 43\n",
      "Train MSE: 0.0003227922\n",
      "Test MSE: 0.0060549066\n",
      "epoch 44\n",
      "Train MSE: 0.0003099554\n",
      "Test MSE: 0.0059983386\n",
      "epoch 45\n",
      "Train MSE: 0.0003105371\n",
      "Test MSE: 0.0059262579\n",
      "epoch 46\n",
      "Train MSE: 0.0003203477\n",
      "Test MSE: 0.0058264332\n",
      "epoch 47\n",
      "Train MSE: 0.0003317975\n",
      "Test MSE: 0.0056879851\n",
      "epoch 48\n",
      "Train MSE: 0.0003380002\n",
      "Test MSE: 0.0055092210\n",
      "epoch 49\n",
      "Train MSE: 0.0003353856\n",
      "Test MSE: 0.0052927718\n",
      "epoch 50\n",
      "Train MSE: 0.0003264800\n",
      "Test MSE: 0.0050456622\n",
      "epoch 51\n",
      "Train MSE: 0.0003157146\n",
      "Test MSE: 0.0047794022\n",
      "epoch 52\n",
      "Train MSE: 0.0003085283\n",
      "Test MSE: 0.0045076334\n",
      "epoch 53\n",
      "Train MSE: 0.0003074943\n",
      "Test MSE: 0.0042437869\n",
      "epoch 54\n",
      "Train MSE: 0.0003115271\n",
      "Test MSE: 0.0039990763\n",
      "epoch 55\n",
      "Train MSE: 0.0003171424\n",
      "Test MSE: 0.0037810064\n",
      "epoch 56\n",
      "Train MSE: 0.0003199475\n",
      "Test MSE: 0.0035922548\n",
      "epoch 57\n",
      "Train MSE: 0.0003186782\n",
      "Test MSE: 0.0034308385\n",
      "epoch 58\n",
      "Train MSE: 0.0003143863\n",
      "Test MSE: 0.0032912826\n",
      "epoch 59\n",
      "Train MSE: 0.0003095235\n",
      "Test MSE: 0.0031649871\n",
      "epoch 60\n",
      "Train MSE: 0.0003059178\n",
      "Test MSE: 0.0030415847\n",
      "epoch 61\n",
      "Train MSE: 0.0003060137\n",
      "Test MSE: 0.0029113230\n",
      "epoch 62\n",
      "Train MSE: 0.0003081113\n",
      "Test MSE: 0.0027665929\n",
      "epoch 63\n",
      "Train MSE: 0.0003101702\n",
      "Test MSE: 0.0026034606\n",
      "epoch 64\n",
      "Train MSE: 0.0003111168\n",
      "Test MSE: 0.0024222848\n",
      "epoch 65\n",
      "Train MSE: 0.0003099444\n",
      "Test MSE: 0.0022274572\n",
      "epoch 66\n",
      "Train MSE: 0.0003076805\n",
      "Test MSE: 0.0020269144\n",
      "epoch 67\n",
      "Train MSE: 0.0003056236\n",
      "Test MSE: 0.0018293955\n",
      "epoch 68\n",
      "Train MSE: 0.0003045329\n",
      "Test MSE: 0.0016433243\n",
      "epoch 69\n",
      "Train MSE: 0.0003044427\n",
      "Test MSE: 0.0014757531\n",
      "epoch 70\n",
      "Train MSE: 0.0003057687\n",
      "Test MSE: 0.0013302047\n",
      "epoch 71\n",
      "Train MSE: 0.0003065960\n",
      "Test MSE: 0.0012073071\n",
      "epoch 72\n",
      "Train MSE: 0.0003061069\n",
      "Test MSE: 0.0011052572\n",
      "epoch 73\n",
      "Train MSE: 0.0003052817\n",
      "Test MSE: 0.0010197192\n",
      "epoch 74\n",
      "Train MSE: 0.0003040776\n",
      "Test MSE: 0.0009455061\n",
      "epoch 75\n",
      "Train MSE: 0.0003027547\n",
      "Test MSE: 0.0008774290\n",
      "epoch 76\n",
      "Train MSE: 0.0003028487\n",
      "Test MSE: 0.0008111462\n",
      "epoch 77\n",
      "Train MSE: 0.0003028603\n",
      "Test MSE: 0.0007437439\n",
      "epoch 78\n",
      "Train MSE: 0.0003034278\n",
      "Test MSE: 0.0006739094\n",
      "epoch 79\n",
      "Train MSE: 0.0003031466\n",
      "Test MSE: 0.0006024778\n",
      "epoch 80\n",
      "Train MSE: 0.0003029906\n",
      "Test MSE: 0.0005316771\n",
      "epoch 81\n",
      "Train MSE: 0.0003022285\n",
      "Test MSE: 0.0004643110\n",
      "epoch 82\n",
      "Train MSE: 0.0003013847\n",
      "Test MSE: 0.0004032727\n",
      "epoch 83\n",
      "Train MSE: 0.0003008433\n",
      "Test MSE: 0.0003505899\n",
      "epoch 84\n",
      "Train MSE: 0.0003011681\n",
      "Test MSE: 0.0003069218\n",
      "epoch 85\n",
      "Train MSE: 0.0003013164\n",
      "Test MSE: 0.0002722092\n",
      "epoch 86\n",
      "Train MSE: 0.0003010597\n",
      "Test MSE: 0.0002452844\n",
      "epoch 87\n",
      "Train MSE: 0.0003008110\n",
      "Test MSE: 0.0002246652\n",
      "epoch 88\n",
      "Train MSE: 0.0003001776\n",
      "Test MSE: 0.0002082878\n",
      "epoch 89\n",
      "Train MSE: 0.0002995708\n",
      "Test MSE: 0.0001943892\n",
      "epoch 90\n",
      "Train MSE: 0.0002997632\n",
      "Test MSE: 0.0001817672\n",
      "epoch 91\n",
      "Train MSE: 0.0002994604\n",
      "Test MSE: 0.0001695844\n",
      "epoch 92\n",
      "Train MSE: 0.0002992047\n",
      "Test MSE: 0.0001571727\n",
      "epoch 93\n",
      "Train MSE: 0.0002993973\n",
      "Test MSE: 0.0001450219\n",
      "epoch 94\n",
      "Train MSE: 0.0002987916\n",
      "Test MSE: 0.0001331994\n",
      "epoch 95\n",
      "Train MSE: 0.0002981653\n",
      "Test MSE: 0.0001221510\n",
      "epoch 96\n",
      "Train MSE: 0.0002979370\n",
      "Test MSE: 0.0001130977\n",
      "epoch 97\n",
      "Train MSE: 0.0002978961\n",
      "Test MSE: 0.0001057752\n",
      "epoch 98\n",
      "Train MSE: 0.0002970653\n",
      "Test MSE: 0.0001000663\n",
      "epoch 99\n",
      "Train MSE: 0.0002974586\n",
      "Test MSE: 0.0000959263\n",
      "epoch 100\n",
      "Train MSE: 0.0002974276\n",
      "Test MSE: 0.0000934412\n",
      "epoch 101\n",
      "Train MSE: 0.0002972401\n",
      "Test MSE: 0.0000914223\n",
      "epoch 102\n",
      "Train MSE: 0.0002962776\n",
      "Test MSE: 0.0000902259\n",
      "epoch 103\n",
      "Train MSE: 0.0002963341\n",
      "Test MSE: 0.0000889281\n",
      "epoch 104\n",
      "Train MSE: 0.0002957764\n",
      "Test MSE: 0.0000879763\n",
      "epoch 105\n",
      "Train MSE: 0.0002954880\n",
      "Test MSE: 0.0000868014\n",
      "epoch 106\n",
      "Train MSE: 0.0002954574\n",
      "Test MSE: 0.0000856556\n",
      "epoch 107\n",
      "Train MSE: 0.0002949067\n",
      "Test MSE: 0.0000844750\n",
      "epoch 108\n",
      "Train MSE: 0.0002950292\n",
      "Test MSE: 0.0000832543\n",
      "epoch 109\n",
      "Train MSE: 0.0002940660\n",
      "Test MSE: 0.0000819397\n",
      "epoch 110\n",
      "Train MSE: 0.0002938167\n",
      "Test MSE: 0.0000809966\n",
      "epoch 111\n",
      "Train MSE: 0.0002941374\n",
      "Test MSE: 0.0000802827\n",
      "epoch 112\n",
      "Train MSE: 0.0002933928\n",
      "Test MSE: 0.0000800505\n",
      "epoch 113\n",
      "Train MSE: 0.0002931691\n",
      "Test MSE: 0.0000798902\n",
      "epoch 114\n",
      "Train MSE: 0.0002926735\n",
      "Test MSE: 0.0000795631\n",
      "epoch 115\n",
      "Train MSE: 0.0002924796\n",
      "Test MSE: 0.0000793965\n",
      "epoch 116\n",
      "Train MSE: 0.0002924841\n",
      "Test MSE: 0.0000794899\n",
      "epoch 117\n",
      "Train MSE: 0.0002920808\n",
      "Test MSE: 0.0000794607\n",
      "epoch 118\n",
      "Train MSE: 0.0002912902\n",
      "Test MSE: 0.0000793904\n",
      "epoch 119\n",
      "Train MSE: 0.0002913248\n",
      "Test MSE: 0.0000789768\n",
      "epoch 120\n",
      "Train MSE: 0.0002915925\n",
      "Test MSE: 0.0000787009\n",
      "epoch 121\n",
      "Train MSE: 0.0002905301\n",
      "Test MSE: 0.0000785759\n",
      "epoch 122\n",
      "Train MSE: 0.0002894805\n",
      "Test MSE: 0.0000785157\n",
      "epoch 123\n",
      "Train MSE: 0.0002897368\n",
      "Test MSE: 0.0000784917\n",
      "epoch 124\n",
      "Train MSE: 0.0002895787\n",
      "Test MSE: 0.0000780206\n",
      "epoch 125\n",
      "Train MSE: 0.0002892241\n",
      "Test MSE: 0.0000780509\n",
      "epoch 126\n",
      "Train MSE: 0.0002889301\n",
      "Test MSE: 0.0000780812\n",
      "epoch 127\n",
      "Train MSE: 0.0002884848\n",
      "Test MSE: 0.0000780396\n",
      "epoch 128\n",
      "Train MSE: 0.0002880736\n",
      "Test MSE: 0.0000778100\n",
      "epoch 129\n",
      "Train MSE: 0.0002873839\n",
      "Test MSE: 0.0000775668\n",
      "epoch 130\n",
      "Train MSE: 0.0002874368\n",
      "Test MSE: 0.0000777384\n",
      "epoch 131\n",
      "Train MSE: 0.0002867882\n",
      "Test MSE: 0.0000777362\n",
      "epoch 132\n",
      "Train MSE: 0.0002855211\n",
      "Test MSE: 0.0000778369\n",
      "epoch 133\n",
      "Train MSE: 0.0002857974\n",
      "Test MSE: 0.0000775652\n",
      "epoch 134\n",
      "Train MSE: 0.0002855791\n",
      "Test MSE: 0.0000772630\n",
      "epoch 135\n",
      "Train MSE: 0.0002851272\n",
      "Test MSE: 0.0000771023\n",
      "epoch 136\n",
      "Train MSE: 0.0002848243\n",
      "Test MSE: 0.0000773479\n",
      "epoch 137\n",
      "Train MSE: 0.0002838615\n",
      "Test MSE: 0.0000771022\n",
      "epoch 138\n",
      "Train MSE: 0.0002848135\n",
      "Test MSE: 0.0000767446\n",
      "epoch 139\n",
      "Train MSE: 0.0002829977\n",
      "Test MSE: 0.0000769362\n",
      "epoch 140\n",
      "Train MSE: 0.0002823119\n",
      "Test MSE: 0.0000769050\n",
      "epoch 141\n",
      "Train MSE: 0.0002822879\n",
      "Test MSE: 0.0000766130\n",
      "epoch 142\n",
      "Train MSE: 0.0002816735\n",
      "Test MSE: 0.0000762944\n",
      "epoch 143\n",
      "Train MSE: 0.0002816773\n",
      "Test MSE: 0.0000764637\n",
      "epoch 144\n",
      "Train MSE: 0.0002808720\n",
      "Test MSE: 0.0000763553\n",
      "epoch 145\n",
      "Train MSE: 0.0002808044\n",
      "Test MSE: 0.0000758636\n",
      "epoch 146\n",
      "Train MSE: 0.0002803058\n",
      "Test MSE: 0.0000762309\n",
      "epoch 147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.0002792775\n",
      "Test MSE: 0.0000756730\n",
      "epoch 148\n",
      "Train MSE: 0.0002787824\n",
      "Test MSE: 0.0000759364\n",
      "epoch 149\n",
      "Train MSE: 0.0002780172\n",
      "Test MSE: 0.0000754568\n",
      "epoch 150\n",
      "Train MSE: 0.0002775255\n",
      "Test MSE: 0.0000755255\n",
      "epoch 151\n",
      "Train MSE: 0.0002763376\n",
      "Test MSE: 0.0000754228\n",
      "epoch 152\n",
      "Train MSE: 0.0002761609\n",
      "Test MSE: 0.0000748667\n",
      "epoch 153\n",
      "Train MSE: 0.0002754348\n",
      "Test MSE: 0.0000756361\n",
      "epoch 154\n",
      "Train MSE: 0.0002748153\n",
      "Test MSE: 0.0000748120\n",
      "epoch 155\n",
      "Train MSE: 0.0002744775\n",
      "Test MSE: 0.0000747824\n",
      "epoch 156\n",
      "Train MSE: 0.0002728334\n",
      "Test MSE: 0.0000745445\n",
      "epoch 157\n",
      "Train MSE: 0.0002730291\n",
      "Test MSE: 0.0000746292\n",
      "epoch 158\n",
      "Train MSE: 0.0002714647\n",
      "Test MSE: 0.0000746141\n",
      "epoch 159\n",
      "Train MSE: 0.0002720541\n",
      "Test MSE: 0.0000738517\n",
      "epoch 160\n",
      "Train MSE: 0.0002703242\n",
      "Test MSE: 0.0000737469\n",
      "epoch 161\n",
      "Train MSE: 0.0002677803\n",
      "Test MSE: 0.0000732991\n",
      "epoch 162\n",
      "Train MSE: 0.0002677867\n",
      "Test MSE: 0.0000728297\n",
      "epoch 163\n",
      "Train MSE: 0.0002655956\n",
      "Test MSE: 0.0000728776\n",
      "epoch 164\n",
      "Train MSE: 0.0002643014\n",
      "Test MSE: 0.0000727079\n",
      "epoch 165\n",
      "Train MSE: 0.0002615084\n",
      "Test MSE: 0.0000723308\n",
      "epoch 166\n",
      "Train MSE: 0.0002614420\n",
      "Test MSE: 0.0000719266\n",
      "epoch 167\n",
      "Train MSE: 0.0002617553\n",
      "Test MSE: 0.0000719637\n",
      "epoch 168\n",
      "Train MSE: 0.0002601938\n",
      "Test MSE: 0.0000719190\n",
      "epoch 169\n",
      "Train MSE: 0.0002580271\n",
      "Test MSE: 0.0000712831\n",
      "epoch 170\n",
      "Train MSE: 0.0002576424\n",
      "Test MSE: 0.0000711774\n",
      "epoch 171\n",
      "Train MSE: 0.0002556049\n",
      "Test MSE: 0.0000707442\n",
      "epoch 172\n",
      "Train MSE: 0.0002558728\n",
      "Test MSE: 0.0000706410\n",
      "epoch 173\n",
      "Train MSE: 0.0002527800\n",
      "Test MSE: 0.0000699355\n",
      "epoch 174\n",
      "Train MSE: 0.0002527315\n",
      "Test MSE: 0.0000699949\n",
      "epoch 175\n",
      "Train MSE: 0.0002498585\n",
      "Test MSE: 0.0000696233\n",
      "epoch 176\n",
      "Train MSE: 0.0002500817\n",
      "Test MSE: 0.0000691929\n",
      "epoch 177\n",
      "Train MSE: 0.0002492975\n",
      "Test MSE: 0.0000689384\n",
      "epoch 178\n",
      "Train MSE: 0.0002454909\n",
      "Test MSE: 0.0000682469\n",
      "epoch 179\n",
      "Train MSE: 0.0002454769\n",
      "Test MSE: 0.0000684101\n",
      "epoch 180\n",
      "Train MSE: 0.0002433430\n",
      "Test MSE: 0.0000673499\n",
      "epoch 181\n",
      "Train MSE: 0.0002441095\n",
      "Test MSE: 0.0000674799\n",
      "epoch 182\n",
      "Train MSE: 0.0002396409\n",
      "Test MSE: 0.0000670527\n",
      "epoch 183\n",
      "Train MSE: 0.0002377088\n",
      "Test MSE: 0.0000672423\n",
      "epoch 184\n",
      "Train MSE: 0.0002394559\n",
      "Test MSE: 0.0000663587\n",
      "epoch 185\n",
      "Train MSE: 0.0002364657\n",
      "Test MSE: 0.0000658580\n",
      "epoch 186\n",
      "Train MSE: 0.0002345976\n",
      "Test MSE: 0.0000660307\n",
      "epoch 187\n",
      "Train MSE: 0.0002332322\n",
      "Test MSE: 0.0000656238\n",
      "epoch 188\n",
      "Train MSE: 0.0002298128\n",
      "Test MSE: 0.0000642840\n",
      "epoch 189\n",
      "Train MSE: 0.0002303890\n",
      "Test MSE: 0.0000648400\n",
      "epoch 190\n",
      "Train MSE: 0.0002290632\n",
      "Test MSE: 0.0000642994\n",
      "epoch 191\n",
      "Train MSE: 0.0002264901\n",
      "Test MSE: 0.0000646936\n",
      "epoch 192\n",
      "Train MSE: 0.0002250059\n",
      "Test MSE: 0.0000633752\n",
      "epoch 193\n",
      "Train MSE: 0.0002218535\n",
      "Test MSE: 0.0000633873\n",
      "epoch 194\n",
      "Train MSE: 0.0002214022\n",
      "Test MSE: 0.0000631289\n",
      "epoch 195\n",
      "Train MSE: 0.0002193601\n",
      "Test MSE: 0.0000615611\n",
      "epoch 196\n",
      "Train MSE: 0.0002180631\n",
      "Test MSE: 0.0000622599\n",
      "epoch 197\n",
      "Train MSE: 0.0002161208\n",
      "Test MSE: 0.0000617977\n",
      "epoch 198\n",
      "Train MSE: 0.0002135656\n",
      "Test MSE: 0.0000611631\n",
      "epoch 199\n",
      "Train MSE: 0.0002101311\n",
      "Test MSE: 0.0000602061\n",
      "epoch 200\n",
      "Train MSE: 0.0002112712\n",
      "Test MSE: 0.0000607955\n",
      "epoch 201\n",
      "Train MSE: 0.0002077868\n",
      "Test MSE: 0.0000604304\n",
      "epoch 202\n",
      "Train MSE: 0.0002069869\n",
      "Test MSE: 0.0000595364\n",
      "epoch 203\n",
      "Train MSE: 0.0002030297\n",
      "Test MSE: 0.0000582554\n",
      "epoch 204\n",
      "Train MSE: 0.0002034544\n",
      "Test MSE: 0.0000588644\n",
      "epoch 205\n",
      "Train MSE: 0.0002026532\n",
      "Test MSE: 0.0000583944\n",
      "epoch 206\n",
      "Train MSE: 0.0001990543\n",
      "Test MSE: 0.0000574298\n",
      "epoch 207\n",
      "Train MSE: 0.0001974762\n",
      "Test MSE: 0.0000577198\n",
      "epoch 208\n",
      "Train MSE: 0.0001961193\n",
      "Test MSE: 0.0000561618\n",
      "epoch 209\n",
      "Train MSE: 0.0001908083\n",
      "Test MSE: 0.0000561136\n",
      "epoch 210\n",
      "Train MSE: 0.0001912357\n",
      "Test MSE: 0.0000552407\n",
      "epoch 211\n",
      "Train MSE: 0.0001890506\n",
      "Test MSE: 0.0000546985\n",
      "epoch 212\n",
      "Train MSE: 0.0001879541\n",
      "Test MSE: 0.0000549914\n",
      "epoch 213\n",
      "Train MSE: 0.0001857161\n",
      "Test MSE: 0.0000537132\n",
      "epoch 214\n",
      "Train MSE: 0.0001809083\n",
      "Test MSE: 0.0000537809\n",
      "epoch 215\n",
      "Train MSE: 0.0001788782\n",
      "Test MSE: 0.0000530786\n",
      "epoch 216\n",
      "Train MSE: 0.0001799296\n",
      "Test MSE: 0.0000532405\n",
      "epoch 217\n",
      "Train MSE: 0.0001776245\n",
      "Test MSE: 0.0000524058\n",
      "epoch 218\n",
      "Train MSE: 0.0001749872\n",
      "Test MSE: 0.0000524369\n",
      "epoch 219\n",
      "Train MSE: 0.0001703547\n",
      "Test MSE: 0.0000512326\n",
      "epoch 220\n",
      "Train MSE: 0.0001705030\n",
      "Test MSE: 0.0000509594\n",
      "epoch 221\n",
      "Train MSE: 0.0001683471\n",
      "Test MSE: 0.0000502946\n",
      "epoch 222\n",
      "Train MSE: 0.0001673141\n",
      "Test MSE: 0.0000499822\n",
      "epoch 223\n",
      "Train MSE: 0.0001638805\n",
      "Test MSE: 0.0000489315\n",
      "epoch 224\n",
      "Train MSE: 0.0001617337\n",
      "Test MSE: 0.0000502898\n",
      "epoch 225\n",
      "Train MSE: 0.0001617999\n",
      "Test MSE: 0.0000481859\n",
      "epoch 226\n",
      "Train MSE: 0.0001582733\n",
      "Test MSE: 0.0000476350\n",
      "epoch 227\n",
      "Train MSE: 0.0001567467\n",
      "Test MSE: 0.0000473449\n",
      "epoch 228\n",
      "Train MSE: 0.0001563936\n",
      "Test MSE: 0.0000469509\n",
      "epoch 229\n",
      "Train MSE: 0.0001524318\n",
      "Test MSE: 0.0000482462\n",
      "epoch 230\n",
      "Train MSE: 0.0001528346\n",
      "Test MSE: 0.0000466471\n",
      "epoch 231\n",
      "Train MSE: 0.0001496711\n",
      "Test MSE: 0.0000450841\n",
      "epoch 232\n",
      "Train MSE: 0.0001483498\n",
      "Test MSE: 0.0000452588\n",
      "epoch 233\n",
      "Train MSE: 0.0001447029\n",
      "Test MSE: 0.0000449124\n",
      "epoch 234\n",
      "Train MSE: 0.0001407394\n",
      "Test MSE: 0.0000438326\n",
      "epoch 235\n",
      "Train MSE: 0.0001423650\n",
      "Test MSE: 0.0000445149\n",
      "epoch 236\n",
      "Train MSE: 0.0001393024\n",
      "Test MSE: 0.0000433298\n",
      "epoch 237\n",
      "Train MSE: 0.0001368247\n",
      "Test MSE: 0.0000425247\n",
      "epoch 238\n",
      "Train MSE: 0.0001392047\n",
      "Test MSE: 0.0000417956\n",
      "epoch 239\n",
      "Train MSE: 0.0001338267\n",
      "Test MSE: 0.0000422950\n",
      "epoch 240\n",
      "Train MSE: 0.0001320337\n",
      "Test MSE: 0.0000421805\n",
      "epoch 241\n",
      "Train MSE: 0.0001336463\n",
      "Test MSE: 0.0000426110\n",
      "epoch 242\n",
      "Train MSE: 0.0001311554\n",
      "Test MSE: 0.0000416566\n",
      "epoch 243\n",
      "Train MSE: 0.0001313339\n",
      "Test MSE: 0.0000409878\n",
      "epoch 244\n",
      "Train MSE: 0.0001288594\n",
      "Test MSE: 0.0000396817\n",
      "epoch 245\n",
      "Train MSE: 0.0001252539\n",
      "Test MSE: 0.0000381575\n",
      "epoch 246\n",
      "Train MSE: 0.0001226131\n",
      "Test MSE: 0.0000392956\n",
      "epoch 247\n",
      "Train MSE: 0.0001232499\n",
      "Test MSE: 0.0000350600\n",
      "epoch 248\n",
      "Train MSE: 0.0001228835\n",
      "Test MSE: 0.0000388436\n",
      "epoch 249\n",
      "Train MSE: 0.0001175750\n",
      "Test MSE: 0.0000387193\n",
      "epoch 250\n",
      "Train MSE: 0.0001211181\n",
      "Test MSE: 0.0000392301\n",
      "epoch 251\n",
      "Train MSE: 0.0001208874\n",
      "Test MSE: 0.0000382882\n",
      "epoch 252\n",
      "Train MSE: 0.0001167494\n",
      "Test MSE: 0.0000362208\n",
      "epoch 253\n",
      "Train MSE: 0.0001161582\n",
      "Test MSE: 0.0000361705\n",
      "epoch 254\n",
      "Train MSE: 0.0001160622\n",
      "Test MSE: 0.0000376866\n",
      "epoch 255\n",
      "Train MSE: 0.0001132358\n",
      "Test MSE: 0.0000364660\n",
      "epoch 256\n",
      "Train MSE: 0.0001123608\n",
      "Test MSE: 0.0000365632\n",
      "epoch 257\n",
      "Train MSE: 0.0001089771\n",
      "Test MSE: 0.0000359697\n",
      "epoch 258\n",
      "Train MSE: 0.0001071796\n",
      "Test MSE: 0.0000385361\n",
      "epoch 259\n",
      "Train MSE: 0.0001079058\n",
      "Test MSE: 0.0000342664\n",
      "epoch 260\n",
      "Train MSE: 0.0001069754\n",
      "Test MSE: 0.0000356073\n",
      "epoch 261\n",
      "Train MSE: 0.0001055571\n",
      "Test MSE: 0.0000326940\n",
      "epoch 262\n",
      "Train MSE: 0.0001058011\n",
      "Test MSE: 0.0000351421\n",
      "epoch 263\n",
      "Train MSE: 0.0001034839\n",
      "Test MSE: 0.0000348800\n",
      "epoch 264\n",
      "Train MSE: 0.0001021537\n",
      "Test MSE: 0.0000367632\n",
      "epoch 265\n",
      "Train MSE: 0.0001038408\n",
      "Test MSE: 0.0000329593\n",
      "epoch 266\n",
      "Train MSE: 0.0001031148\n",
      "Test MSE: 0.0000372665\n",
      "epoch 267\n",
      "Train MSE: 0.0001029459\n",
      "Test MSE: 0.0000359259\n",
      "epoch 268\n",
      "Train MSE: 0.0001042115\n",
      "Test MSE: 0.0000447328\n",
      "epoch 269\n",
      "Train MSE: 0.0001099537\n",
      "Test MSE: 0.0000490420\n",
      "epoch 270\n",
      "Train MSE: 0.0001221279\n",
      "Test MSE: 0.0000655290\n",
      "epoch 271\n",
      "Train MSE: 0.0001235281\n",
      "Test MSE: 0.0000421212\n",
      "epoch 272\n",
      "Train MSE: 0.0001142368\n",
      "Test MSE: 0.0000360307\n",
      "epoch 273\n",
      "Train MSE: 0.0000989788\n",
      "Test MSE: 0.0000433575\n",
      "epoch 274\n",
      "Train MSE: 0.0001067337\n",
      "Test MSE: 0.0000404498\n",
      "epoch 275\n",
      "Train MSE: 0.0001137452\n",
      "Test MSE: 0.0000437629\n",
      "epoch 276\n",
      "Train MSE: 0.0001015667\n",
      "Test MSE: 0.0000335250\n",
      "epoch 277\n",
      "Train MSE: 0.0000973208\n",
      "Test MSE: 0.0000341335\n",
      "epoch 278\n",
      "Train MSE: 0.0001018946\n",
      "Test MSE: 0.0000488090\n",
      "epoch 279\n",
      "Train MSE: 0.0001021810\n",
      "Test MSE: 0.0000308328\n",
      "epoch 280\n",
      "Train MSE: 0.0000965235\n",
      "Test MSE: 0.0000305775\n",
      "epoch 281\n",
      "Train MSE: 0.0000986701\n",
      "Test MSE: 0.0000450300\n",
      "epoch 282\n",
      "Train MSE: 0.0001053613\n",
      "Test MSE: 0.0000306325\n",
      "epoch 283\n",
      "Train MSE: 0.0000951738\n",
      "Test MSE: 0.0000305368\n",
      "epoch 284\n",
      "Train MSE: 0.0000945019\n",
      "Test MSE: 0.0000403237\n",
      "epoch 285\n",
      "Train MSE: 0.0000983920\n",
      "Test MSE: 0.0000318681\n",
      "epoch 286\n",
      "Train MSE: 0.0000953053\n",
      "Test MSE: 0.0000307946\n",
      "epoch 287\n",
      "Train MSE: 0.0000898724\n",
      "Test MSE: 0.0000368315\n",
      "epoch 288\n",
      "Train MSE: 0.0000950754\n",
      "Test MSE: 0.0000298326\n",
      "epoch 289\n",
      "Train MSE: 0.0000937177\n",
      "Test MSE: 0.0000306422\n",
      "epoch 290\n",
      "Train MSE: 0.0000877629\n",
      "Test MSE: 0.0000312048\n",
      "epoch 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.0000923691\n",
      "Test MSE: 0.0000311547\n",
      "epoch 292\n",
      "Train MSE: 0.0000915696\n",
      "Test MSE: 0.0000308001\n",
      "epoch 293\n",
      "Train MSE: 0.0000921222\n",
      "Test MSE: 0.0000311370\n",
      "epoch 294\n",
      "Train MSE: 0.0000913134\n",
      "Test MSE: 0.0000298412\n",
      "epoch 295\n",
      "Train MSE: 0.0000921854\n",
      "Test MSE: 0.0000314796\n",
      "epoch 296\n",
      "Train MSE: 0.0000889337\n",
      "Test MSE: 0.0000308461\n",
      "epoch 297\n",
      "Train MSE: 0.0000873046\n",
      "Test MSE: 0.0000295388\n",
      "epoch 298\n",
      "Train MSE: 0.0000871950\n",
      "Test MSE: 0.0000337635\n",
      "epoch 299\n",
      "Train MSE: 0.0000891705\n",
      "Test MSE: 0.0000285528\n",
      "epoch 300\n",
      "Train MSE: 0.0000895213\n",
      "Test MSE: 0.0000294183\n",
      "epoch 301\n",
      "Train MSE: 0.0000886606\n",
      "Test MSE: 0.0000297510\n",
      "epoch 302\n",
      "Train MSE: 0.0000853489\n",
      "Test MSE: 0.0000291445\n",
      "epoch 303\n",
      "Train MSE: 0.0000855096\n",
      "Test MSE: 0.0000271124\n",
      "epoch 304\n",
      "Train MSE: 0.0000856593\n",
      "Test MSE: 0.0000306508\n",
      "epoch 305\n",
      "Train MSE: 0.0000826990\n",
      "Test MSE: 0.0000294891\n",
      "epoch 306\n",
      "Train MSE: 0.0000871559\n",
      "Test MSE: 0.0000292830\n",
      "epoch 307\n",
      "Train MSE: 0.0000835780\n",
      "Test MSE: 0.0000284385\n",
      "epoch 308\n",
      "Train MSE: 0.0000840427\n",
      "Test MSE: 0.0000283116\n",
      "epoch 309\n",
      "Train MSE: 0.0000876344\n",
      "Test MSE: 0.0000281936\n",
      "epoch 310\n",
      "Train MSE: 0.0000833548\n",
      "Test MSE: 0.0000274040\n",
      "epoch 311\n",
      "Train MSE: 0.0000857339\n",
      "Test MSE: 0.0000282874\n",
      "epoch 312\n",
      "Train MSE: 0.0000849586\n",
      "Test MSE: 0.0000302423\n",
      "epoch 313\n",
      "Train MSE: 0.0000839695\n",
      "Test MSE: 0.0000274111\n",
      "epoch 314\n",
      "Train MSE: 0.0000795332\n",
      "Test MSE: 0.0000276746\n",
      "epoch 315\n",
      "Train MSE: 0.0000808430\n",
      "Test MSE: 0.0000270001\n",
      "epoch 316\n",
      "Train MSE: 0.0000821059\n",
      "Test MSE: 0.0000266324\n",
      "epoch 317\n",
      "Train MSE: 0.0000804832\n",
      "Test MSE: 0.0000279621\n",
      "epoch 318\n",
      "Train MSE: 0.0000788589\n",
      "Test MSE: 0.0000285400\n",
      "epoch 319\n",
      "Train MSE: 0.0000811195\n",
      "Test MSE: 0.0000273036\n",
      "epoch 320\n",
      "Train MSE: 0.0000792686\n",
      "Test MSE: 0.0000274130\n",
      "epoch 321\n",
      "Train MSE: 0.0000807811\n",
      "Test MSE: 0.0000271454\n",
      "epoch 322\n",
      "Train MSE: 0.0000791479\n",
      "Test MSE: 0.0000269093\n",
      "epoch 323\n",
      "Train MSE: 0.0000788802\n",
      "Test MSE: 0.0000262644\n",
      "epoch 324\n",
      "Train MSE: 0.0000769018\n",
      "Test MSE: 0.0000274737\n",
      "epoch 325\n",
      "Train MSE: 0.0000784846\n",
      "Test MSE: 0.0000275853\n",
      "epoch 326\n",
      "Train MSE: 0.0000758044\n",
      "Test MSE: 0.0000271494\n",
      "epoch 327\n",
      "Train MSE: 0.0000763876\n",
      "Test MSE: 0.0000265277\n",
      "epoch 328\n",
      "Train MSE: 0.0000776314\n",
      "Test MSE: 0.0000259550\n",
      "epoch 329\n",
      "Train MSE: 0.0000792742\n",
      "Test MSE: 0.0000283066\n",
      "epoch 330\n",
      "Train MSE: 0.0000764570\n",
      "Test MSE: 0.0000264783\n",
      "epoch 331\n",
      "Train MSE: 0.0000774752\n",
      "Test MSE: 0.0000272454\n",
      "epoch 332\n",
      "Train MSE: 0.0000762847\n",
      "Test MSE: 0.0000275879\n",
      "epoch 333\n",
      "Train MSE: 0.0000759894\n",
      "Test MSE: 0.0000252228\n",
      "epoch 334\n",
      "Train MSE: 0.0000757698\n",
      "Test MSE: 0.0000263188\n",
      "epoch 335\n",
      "Train MSE: 0.0000746091\n",
      "Test MSE: 0.0000262254\n",
      "epoch 336\n",
      "Train MSE: 0.0000759393\n",
      "Test MSE: 0.0000259618\n",
      "epoch 337\n",
      "Train MSE: 0.0000750102\n",
      "Test MSE: 0.0000265119\n",
      "epoch 338\n",
      "Train MSE: 0.0000746157\n",
      "Test MSE: 0.0000246451\n",
      "epoch 339\n",
      "Train MSE: 0.0000738149\n",
      "Test MSE: 0.0000258868\n",
      "epoch 340\n",
      "Train MSE: 0.0000752992\n",
      "Test MSE: 0.0000248792\n",
      "epoch 341\n",
      "Train MSE: 0.0000753656\n",
      "Test MSE: 0.0000273179\n",
      "epoch 342\n",
      "Train MSE: 0.0000739802\n",
      "Test MSE: 0.0000270389\n",
      "epoch 343\n",
      "Train MSE: 0.0000732826\n",
      "Test MSE: 0.0000259412\n",
      "epoch 344\n",
      "Train MSE: 0.0000730417\n",
      "Test MSE: 0.0000248335\n",
      "epoch 345\n",
      "Train MSE: 0.0000720322\n",
      "Test MSE: 0.0000252070\n",
      "epoch 346\n",
      "Train MSE: 0.0000725988\n",
      "Test MSE: 0.0000245300\n",
      "epoch 347\n",
      "Train MSE: 0.0000736568\n",
      "Test MSE: 0.0000259825\n",
      "epoch 348\n",
      "Train MSE: 0.0000742457\n",
      "Test MSE: 0.0000249853\n",
      "epoch 349\n",
      "Train MSE: 0.0000718104\n",
      "Test MSE: 0.0000247544\n",
      "epoch 350\n",
      "Train MSE: 0.0000723664\n",
      "Test MSE: 0.0000250155\n",
      "epoch 351\n",
      "Train MSE: 0.0000707824\n",
      "Test MSE: 0.0000248535\n",
      "epoch 352\n",
      "Train MSE: 0.0000719024\n",
      "Test MSE: 0.0000255381\n",
      "epoch 353\n",
      "Train MSE: 0.0000703013\n",
      "Test MSE: 0.0000257828\n",
      "epoch 354\n",
      "Train MSE: 0.0000724230\n",
      "Test MSE: 0.0000255221\n",
      "epoch 355\n",
      "Train MSE: 0.0000717141\n",
      "Test MSE: 0.0000255870\n",
      "epoch 356\n",
      "Train MSE: 0.0000704608\n",
      "Test MSE: 0.0000249874\n",
      "epoch 357\n",
      "Train MSE: 0.0000691371\n",
      "Test MSE: 0.0000248392\n",
      "epoch 358\n",
      "Train MSE: 0.0000706955\n",
      "Test MSE: 0.0000231995\n",
      "epoch 359\n",
      "Train MSE: 0.0000705423\n",
      "Test MSE: 0.0000253687\n",
      "epoch 360\n",
      "Train MSE: 0.0000709413\n",
      "Test MSE: 0.0000250054\n",
      "epoch 361\n",
      "Train MSE: 0.0000722569\n",
      "Test MSE: 0.0000336361\n",
      "epoch 362\n",
      "Train MSE: 0.0000756810\n",
      "Test MSE: 0.0000422926\n",
      "epoch 363\n",
      "Train MSE: 0.0000920595\n",
      "Test MSE: 0.0001103476\n",
      "epoch 364\n",
      "Train MSE: 0.0001467200\n",
      "Test MSE: 0.0001687980\n",
      "epoch 365\n",
      "Train MSE: 0.0002438031\n",
      "Test MSE: 0.0002025397\n",
      "epoch 366\n",
      "Train MSE: 0.0002006819\n",
      "Test MSE: 0.0000259566\n",
      "epoch 367\n",
      "Train MSE: 0.0000747231\n",
      "Test MSE: 0.0000550556\n",
      "epoch 368\n",
      "Train MSE: 0.0001268833\n",
      "Test MSE: 0.0001530530\n",
      "epoch 369\n",
      "Train MSE: 0.0001535870\n",
      "Test MSE: 0.0000255114\n",
      "epoch 370\n",
      "Train MSE: 0.0000702043\n",
      "Test MSE: 0.0000489030\n",
      "epoch 371\n",
      "Train MSE: 0.0001190816\n",
      "Test MSE: 0.0000853390\n",
      "epoch 372\n",
      "Train MSE: 0.0001035646\n",
      "Test MSE: 0.0000447654\n",
      "epoch 373\n",
      "Train MSE: 0.0000741271\n",
      "Test MSE: 0.0000427597\n",
      "epoch 374\n",
      "Train MSE: 0.0001119942\n",
      "Test MSE: 0.0000337791\n",
      "epoch 375\n",
      "Train MSE: 0.0000703360\n",
      "Test MSE: 0.0000798867\n",
      "epoch 376\n",
      "Train MSE: 0.0000979833\n",
      "Test MSE: 0.0000253838\n",
      "epoch 377\n",
      "Train MSE: 0.0000804648\n",
      "Test MSE: 0.0000274275\n",
      "epoch 378\n",
      "Train MSE: 0.0000841113\n",
      "Test MSE: 0.0000626309\n",
      "epoch 379\n",
      "Train MSE: 0.0000858788\n",
      "Test MSE: 0.0000374183\n",
      "epoch 380\n",
      "Train MSE: 0.0000718817\n",
      "Test MSE: 0.0000296958\n",
      "epoch 381\n",
      "Train MSE: 0.0000873839\n",
      "Test MSE: 0.0000288506\n",
      "epoch 382\n",
      "Train MSE: 0.0000700887\n",
      "Test MSE: 0.0000646320\n",
      "epoch 383\n",
      "Train MSE: 0.0000845029\n",
      "Test MSE: 0.0000260370\n",
      "epoch 384\n",
      "Train MSE: 0.0000692314\n",
      "Test MSE: 0.0000249874\n",
      "epoch 385\n",
      "Train MSE: 0.0000790263\n",
      "Test MSE: 0.0000432402\n",
      "epoch 386\n",
      "Train MSE: 0.0000715300\n",
      "Test MSE: 0.0000475099\n",
      "epoch 387\n",
      "Train MSE: 0.0000745961\n",
      "Test MSE: 0.0000240285\n",
      "epoch 388\n",
      "Train MSE: 0.0000733829\n",
      "Test MSE: 0.0000252445\n",
      "epoch 389\n",
      "Train MSE: 0.0000706652\n",
      "Test MSE: 0.0000474262\n",
      "epoch 390\n",
      "Train MSE: 0.0000738872\n",
      "Test MSE: 0.0000308921\n",
      "epoch 391\n",
      "Train MSE: 0.0000681329\n",
      "Test MSE: 0.0000254114\n",
      "epoch 392\n",
      "Train MSE: 0.0000741731\n",
      "Test MSE: 0.0000270709\n",
      "epoch 393\n",
      "Train MSE: 0.0000685709\n",
      "Test MSE: 0.0000340823\n",
      "epoch 394\n",
      "Train MSE: 0.0000720705\n",
      "Test MSE: 0.0000239321\n",
      "epoch 395\n",
      "Train MSE: 0.0000680838\n",
      "Test MSE: 0.0000247723\n",
      "epoch 396\n",
      "Train MSE: 0.0000699521\n",
      "Test MSE: 0.0000290512\n",
      "epoch 397\n",
      "Train MSE: 0.0000689190\n",
      "Test MSE: 0.0000277561\n",
      "epoch 398\n",
      "Train MSE: 0.0000684891\n",
      "Test MSE: 0.0000249579\n",
      "epoch 399\n",
      "Train MSE: 0.0000698332\n",
      "Test MSE: 0.0000248017\n",
      "epoch 400\n",
      "Train MSE: 0.0000676517\n",
      "Test MSE: 0.0000290506\n",
      "epoch 401\n",
      "Train MSE: 0.0000702089\n",
      "Test MSE: 0.0000253922\n",
      "epoch 402\n",
      "Train MSE: 0.0000657406\n",
      "Test MSE: 0.0000248173\n",
      "epoch 403\n",
      "Train MSE: 0.0000685277\n",
      "Test MSE: 0.0000249436\n",
      "epoch 404\n",
      "Train MSE: 0.0000660089\n",
      "Test MSE: 0.0000248119\n",
      "epoch 405\n",
      "Train MSE: 0.0000677988\n",
      "Test MSE: 0.0000242837\n",
      "epoch 406\n",
      "Train MSE: 0.0000663877\n",
      "Test MSE: 0.0000238553\n",
      "epoch 407\n",
      "Train MSE: 0.0000665057\n",
      "Test MSE: 0.0000251212\n",
      "epoch 408\n",
      "Train MSE: 0.0000672198\n",
      "Test MSE: 0.0000237468\n",
      "epoch 409\n",
      "Train MSE: 0.0000647253\n",
      "Test MSE: 0.0000251399\n",
      "epoch 410\n",
      "Train MSE: 0.0000676509\n",
      "Test MSE: 0.0000233624\n",
      "epoch 411\n",
      "Train MSE: 0.0000655709\n",
      "Test MSE: 0.0000241828\n",
      "epoch 412\n",
      "Train MSE: 0.0000651892\n",
      "Test MSE: 0.0000237637\n",
      "epoch 413\n",
      "Train MSE: 0.0000670640\n",
      "Test MSE: 0.0000247830\n",
      "epoch 414\n",
      "Train MSE: 0.0000669212\n",
      "Test MSE: 0.0000247368\n",
      "epoch 415\n",
      "Train MSE: 0.0000662892\n",
      "Test MSE: 0.0000229770\n",
      "epoch 416\n",
      "Train MSE: 0.0000659942\n",
      "Test MSE: 0.0000249975\n",
      "epoch 417\n",
      "Train MSE: 0.0000648873\n",
      "Test MSE: 0.0000238952\n",
      "epoch 418\n",
      "Train MSE: 0.0000653835\n",
      "Test MSE: 0.0000237700\n",
      "epoch 419\n",
      "Train MSE: 0.0000661672\n",
      "Test MSE: 0.0000244536\n",
      "epoch 420\n",
      "Train MSE: 0.0000651834\n",
      "Test MSE: 0.0000244871\n",
      "epoch 421\n",
      "Train MSE: 0.0000664974\n",
      "Test MSE: 0.0000229747\n",
      "epoch 422\n",
      "Train MSE: 0.0000641748\n",
      "Test MSE: 0.0000233623\n",
      "epoch 423\n",
      "Train MSE: 0.0000642671\n",
      "Test MSE: 0.0000250133\n",
      "epoch 424\n",
      "Train MSE: 0.0000659183\n",
      "Test MSE: 0.0000236693\n",
      "epoch 425\n",
      "Train MSE: 0.0000657462\n",
      "Test MSE: 0.0000231386\n",
      "epoch 426\n",
      "Train MSE: 0.0000654908\n",
      "Test MSE: 0.0000242804\n",
      "epoch 427\n",
      "Train MSE: 0.0000644820\n",
      "Test MSE: 0.0000234723\n",
      "epoch 428\n",
      "Train MSE: 0.0000658885\n",
      "Test MSE: 0.0000237539\n",
      "epoch 429\n",
      "Train MSE: 0.0000645256\n",
      "Test MSE: 0.0000231904\n",
      "epoch 430\n",
      "Train MSE: 0.0000651643\n",
      "Test MSE: 0.0000240716\n",
      "epoch 431\n",
      "Train MSE: 0.0000656623\n",
      "Test MSE: 0.0000235920\n",
      "epoch 432\n",
      "Train MSE: 0.0000642208\n",
      "Test MSE: 0.0000239856\n",
      "epoch 433\n",
      "Train MSE: 0.0000654474\n",
      "Test MSE: 0.0000236313\n",
      "epoch 434\n",
      "Train MSE: 0.0000649243\n",
      "Test MSE: 0.0000235015\n",
      "epoch 435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.0000651598\n",
      "Test MSE: 0.0000230430\n",
      "epoch 436\n",
      "Train MSE: 0.0000643009\n",
      "Test MSE: 0.0000239840\n",
      "epoch 437\n",
      "Train MSE: 0.0000648699\n",
      "Test MSE: 0.0000230277\n",
      "epoch 438\n",
      "Train MSE: 0.0000654612\n",
      "Test MSE: 0.0000236205\n",
      "epoch 439\n",
      "Train MSE: 0.0000655241\n",
      "Test MSE: 0.0000224250\n",
      "epoch 440\n",
      "Train MSE: 0.0000643020\n",
      "Test MSE: 0.0000228626\n",
      "epoch 441\n",
      "Train MSE: 0.0000644239\n",
      "Test MSE: 0.0000232491\n",
      "epoch 442\n",
      "Train MSE: 0.0000639825\n",
      "Test MSE: 0.0000232964\n",
      "epoch 443\n",
      "Train MSE: 0.0000639837\n",
      "Test MSE: 0.0000233368\n",
      "epoch 444\n",
      "Train MSE: 0.0000635769\n",
      "Test MSE: 0.0000233279\n",
      "epoch 445\n",
      "Train MSE: 0.0000638518\n",
      "Test MSE: 0.0000237690\n",
      "epoch 446\n",
      "Train MSE: 0.0000646891\n",
      "Test MSE: 0.0000236538\n",
      "epoch 447\n",
      "Train MSE: 0.0000647575\n",
      "Test MSE: 0.0000234572\n",
      "epoch 448\n",
      "Train MSE: 0.0000643813\n",
      "Test MSE: 0.0000230726\n",
      "epoch 449\n",
      "Train MSE: 0.0000642272\n",
      "Test MSE: 0.0000239065\n",
      "epoch 450\n",
      "Train MSE: 0.0000648448\n",
      "Test MSE: 0.0000233357\n",
      "epoch 451\n",
      "Train MSE: 0.0000639050\n",
      "Test MSE: 0.0000230450\n",
      "epoch 452\n",
      "Train MSE: 0.0000641712\n",
      "Test MSE: 0.0000229654\n",
      "epoch 453\n",
      "Train MSE: 0.0000640654\n",
      "Test MSE: 0.0000229099\n",
      "epoch 454\n",
      "Train MSE: 0.0000635146\n",
      "Test MSE: 0.0000235487\n",
      "epoch 455\n",
      "Train MSE: 0.0000640939\n",
      "Test MSE: 0.0000225037\n",
      "epoch 456\n",
      "Train MSE: 0.0000634581\n",
      "Test MSE: 0.0000229236\n",
      "epoch 457\n",
      "Train MSE: 0.0000633504\n",
      "Test MSE: 0.0000234846\n",
      "epoch 458\n",
      "Train MSE: 0.0000638069\n",
      "Test MSE: 0.0000232828\n",
      "epoch 459\n",
      "Train MSE: 0.0000631277\n",
      "Test MSE: 0.0000230140\n",
      "epoch 460\n",
      "Train MSE: 0.0000628888\n",
      "Test MSE: 0.0000232238\n",
      "epoch 461\n",
      "Train MSE: 0.0000634040\n",
      "Test MSE: 0.0000230058\n",
      "epoch 462\n",
      "Train MSE: 0.0000630422\n",
      "Test MSE: 0.0000225111\n",
      "epoch 463\n",
      "Train MSE: 0.0000627084\n",
      "Test MSE: 0.0000230795\n",
      "epoch 464\n",
      "Train MSE: 0.0000642205\n",
      "Test MSE: 0.0000233431\n",
      "epoch 465\n",
      "Train MSE: 0.0000626054\n",
      "Test MSE: 0.0000232918\n",
      "epoch 466\n",
      "Train MSE: 0.0000633962\n",
      "Test MSE: 0.0000232994\n",
      "epoch 467\n",
      "Train MSE: 0.0000635756\n",
      "Test MSE: 0.0000231574\n",
      "epoch 468\n",
      "Train MSE: 0.0000632784\n",
      "Test MSE: 0.0000232340\n",
      "epoch 469\n",
      "Train MSE: 0.0000627323\n",
      "Test MSE: 0.0000230401\n",
      "epoch 470\n",
      "Train MSE: 0.0000634634\n",
      "Test MSE: 0.0000230481\n",
      "epoch 471\n",
      "Train MSE: 0.0000630823\n",
      "Test MSE: 0.0000231149\n",
      "epoch 472\n",
      "Train MSE: 0.0000640877\n",
      "Test MSE: 0.0000225762\n",
      "epoch 473\n",
      "Train MSE: 0.0000628996\n",
      "Test MSE: 0.0000227997\n",
      "epoch 474\n",
      "Train MSE: 0.0000621400\n",
      "Test MSE: 0.0000227269\n",
      "epoch 475\n",
      "Train MSE: 0.0000622216\n",
      "Test MSE: 0.0000229679\n",
      "epoch 476\n",
      "Train MSE: 0.0000626874\n",
      "Test MSE: 0.0000234815\n",
      "epoch 477\n",
      "Train MSE: 0.0000620653\n",
      "Test MSE: 0.0000233232\n",
      "epoch 478\n",
      "Train MSE: 0.0000622896\n",
      "Test MSE: 0.0000226746\n",
      "epoch 479\n",
      "Train MSE: 0.0000625983\n",
      "Test MSE: 0.0000230378\n",
      "epoch 480\n",
      "Train MSE: 0.0000619108\n",
      "Test MSE: 0.0000231521\n",
      "epoch 481\n",
      "Train MSE: 0.0000625360\n",
      "Test MSE: 0.0000229593\n",
      "epoch 482\n",
      "Train MSE: 0.0000623442\n",
      "Test MSE: 0.0000226182\n",
      "epoch 483\n",
      "Train MSE: 0.0000622381\n",
      "Test MSE: 0.0000227361\n",
      "epoch 484\n",
      "Train MSE: 0.0000617970\n",
      "Test MSE: 0.0000229214\n",
      "epoch 485\n",
      "Train MSE: 0.0000619395\n",
      "Test MSE: 0.0000234347\n",
      "epoch 486\n",
      "Train MSE: 0.0000624811\n",
      "Test MSE: 0.0000231970\n",
      "epoch 487\n",
      "Train MSE: 0.0000615173\n",
      "Test MSE: 0.0000229518\n",
      "epoch 488\n",
      "Train MSE: 0.0000625536\n",
      "Test MSE: 0.0000233969\n",
      "epoch 489\n",
      "Train MSE: 0.0000619647\n",
      "Test MSE: 0.0000226597\n",
      "epoch 490\n",
      "Train MSE: 0.0000613560\n",
      "Test MSE: 0.0000228525\n",
      "epoch 491\n",
      "Train MSE: 0.0000617200\n",
      "Test MSE: 0.0000223851\n",
      "epoch 492\n",
      "Train MSE: 0.0000616900\n",
      "Test MSE: 0.0000225867\n",
      "epoch 493\n",
      "Train MSE: 0.0000623467\n",
      "Test MSE: 0.0000231585\n",
      "epoch 494\n",
      "Train MSE: 0.0000609760\n",
      "Test MSE: 0.0000222664\n",
      "epoch 495\n",
      "Train MSE: 0.0000617490\n",
      "Test MSE: 0.0000233651\n",
      "epoch 496\n",
      "Train MSE: 0.0000612615\n",
      "Test MSE: 0.0000229390\n",
      "epoch 497\n",
      "Train MSE: 0.0000607871\n",
      "Test MSE: 0.0000225573\n",
      "epoch 498\n",
      "Train MSE: 0.0000608694\n",
      "Test MSE: 0.0000223780\n",
      "epoch 499\n",
      "Train MSE: 0.0000621222\n",
      "Test MSE: 0.0000227777\n",
      "epoch 500\n",
      "Train MSE: 0.0000613305\n",
      "Test MSE: 0.0000225394\n",
      "epoch 501\n",
      "Train MSE: 0.0000609634\n",
      "Test MSE: 0.0000226235\n",
      "epoch 502\n",
      "Train MSE: 0.0000612882\n",
      "Test MSE: 0.0000226674\n",
      "epoch 503\n",
      "Train MSE: 0.0000608271\n",
      "Test MSE: 0.0000229330\n",
      "epoch 504\n",
      "Train MSE: 0.0000614044\n",
      "Test MSE: 0.0000226749\n",
      "epoch 505\n",
      "Train MSE: 0.0000612319\n",
      "Test MSE: 0.0000223974\n",
      "epoch 506\n",
      "Train MSE: 0.0000608011\n",
      "Test MSE: 0.0000226196\n",
      "epoch 507\n",
      "Train MSE: 0.0000613043\n",
      "Test MSE: 0.0000227968\n",
      "epoch 508\n",
      "Train MSE: 0.0000619796\n",
      "Test MSE: 0.0000228159\n",
      "epoch 509\n",
      "Train MSE: 0.0000609521\n",
      "Test MSE: 0.0000227986\n",
      "epoch 510\n",
      "Train MSE: 0.0000613749\n",
      "Test MSE: 0.0000223794\n",
      "epoch 511\n",
      "Train MSE: 0.0000611268\n",
      "Test MSE: 0.0000228818\n",
      "epoch 512\n",
      "Train MSE: 0.0000611857\n",
      "Test MSE: 0.0000222563\n",
      "epoch 513\n",
      "Train MSE: 0.0000608403\n",
      "Test MSE: 0.0000228498\n",
      "epoch 514\n",
      "Train MSE: 0.0000612115\n",
      "Test MSE: 0.0000224132\n",
      "epoch 515\n",
      "Train MSE: 0.0000604517\n",
      "Test MSE: 0.0000228264\n",
      "epoch 516\n",
      "Train MSE: 0.0000610254\n",
      "Test MSE: 0.0000229979\n",
      "epoch 517\n",
      "Train MSE: 0.0000612178\n",
      "Test MSE: 0.0000227236\n",
      "epoch 518\n",
      "Train MSE: 0.0000611562\n",
      "Test MSE: 0.0000228792\n",
      "epoch 519\n",
      "Train MSE: 0.0000607074\n",
      "Test MSE: 0.0000227017\n",
      "epoch 520\n",
      "Train MSE: 0.0000608304\n",
      "Test MSE: 0.0000226436\n",
      "epoch 521\n",
      "Train MSE: 0.0000606228\n",
      "Test MSE: 0.0000226930\n",
      "epoch 522\n",
      "Train MSE: 0.0000601908\n",
      "Test MSE: 0.0000224025\n",
      "epoch 523\n",
      "Train MSE: 0.0000609684\n",
      "Test MSE: 0.0000227155\n",
      "epoch 524\n",
      "Train MSE: 0.0000604797\n",
      "Test MSE: 0.0000227269\n",
      "epoch 525\n",
      "Train MSE: 0.0000613750\n",
      "Test MSE: 0.0000227000\n",
      "epoch 526\n",
      "Train MSE: 0.0000603771\n",
      "Test MSE: 0.0000225768\n",
      "epoch 527\n",
      "Train MSE: 0.0000599262\n",
      "Test MSE: 0.0000228481\n",
      "epoch 528\n",
      "Train MSE: 0.0000606181\n",
      "Test MSE: 0.0000230442\n",
      "epoch 529\n",
      "Train MSE: 0.0000603086\n",
      "Test MSE: 0.0000227881\n",
      "epoch 530\n",
      "Train MSE: 0.0000601695\n",
      "Test MSE: 0.0000227570\n",
      "epoch 531\n",
      "Train MSE: 0.0000606295\n",
      "Test MSE: 0.0000225708\n",
      "epoch 532\n",
      "Train MSE: 0.0000608085\n",
      "Test MSE: 0.0000230496\n",
      "epoch 533\n",
      "Train MSE: 0.0000603792\n",
      "Test MSE: 0.0000226879\n",
      "epoch 534\n",
      "Train MSE: 0.0000599099\n",
      "Test MSE: 0.0000229688\n",
      "epoch 535\n",
      "Train MSE: 0.0000602739\n",
      "Test MSE: 0.0000233581\n",
      "epoch 536\n",
      "Train MSE: 0.0000599654\n",
      "Test MSE: 0.0000227986\n",
      "epoch 537\n",
      "Train MSE: 0.0000606156\n",
      "Test MSE: 0.0000229037\n",
      "epoch 538\n",
      "Train MSE: 0.0000595465\n",
      "Test MSE: 0.0000231280\n",
      "epoch 539\n",
      "Train MSE: 0.0000601126\n",
      "Test MSE: 0.0000228075\n",
      "epoch 540\n",
      "Train MSE: 0.0000594591\n",
      "Test MSE: 0.0000228484\n",
      "epoch 541\n",
      "Train MSE: 0.0000600045\n",
      "Test MSE: 0.0000230634\n",
      "epoch 542\n",
      "Train MSE: 0.0000595947\n",
      "Test MSE: 0.0000230059\n",
      "epoch 543\n",
      "Train MSE: 0.0000597193\n",
      "Test MSE: 0.0000226555\n",
      "epoch 544\n",
      "Train MSE: 0.0000591799\n",
      "Test MSE: 0.0000230086\n",
      "epoch 545\n",
      "Train MSE: 0.0000600272\n",
      "Test MSE: 0.0000225231\n",
      "epoch 546\n",
      "Train MSE: 0.0000597789\n",
      "Test MSE: 0.0000227975\n",
      "epoch 547\n",
      "Train MSE: 0.0000600472\n",
      "Test MSE: 0.0000228559\n",
      "epoch 548\n",
      "Train MSE: 0.0000595499\n",
      "Test MSE: 0.0000228526\n",
      "epoch 549\n",
      "Train MSE: 0.0000599436\n",
      "Test MSE: 0.0000227962\n",
      "epoch 550\n",
      "Train MSE: 0.0000595536\n",
      "Test MSE: 0.0000229417\n",
      "epoch 551\n",
      "Train MSE: 0.0000598826\n",
      "Test MSE: 0.0000227645\n",
      "epoch 552\n",
      "Train MSE: 0.0000599145\n",
      "Test MSE: 0.0000228907\n",
      "epoch 553\n",
      "Train MSE: 0.0000590530\n",
      "Test MSE: 0.0000229905\n",
      "epoch 554\n",
      "Train MSE: 0.0000597388\n",
      "Test MSE: 0.0000229102\n",
      "epoch 555\n",
      "Train MSE: 0.0000595229\n",
      "Test MSE: 0.0000224988\n",
      "epoch 556\n",
      "Train MSE: 0.0000593435\n",
      "Test MSE: 0.0000228670\n",
      "epoch 557\n",
      "Train MSE: 0.0000598337\n",
      "Test MSE: 0.0000226534\n",
      "epoch 558\n",
      "Train MSE: 0.0000590501\n",
      "Test MSE: 0.0000224321\n",
      "epoch 559\n",
      "Train MSE: 0.0000595260\n",
      "Test MSE: 0.0000228985\n",
      "epoch 560\n",
      "Train MSE: 0.0000592981\n",
      "Test MSE: 0.0000224397\n",
      "epoch 561\n",
      "Train MSE: 0.0000598506\n",
      "Test MSE: 0.0000225410\n",
      "epoch 562\n",
      "Train MSE: 0.0000592926\n",
      "Test MSE: 0.0000227135\n",
      "epoch 563\n",
      "Train MSE: 0.0000590786\n",
      "Test MSE: 0.0000224434\n",
      "epoch 564\n",
      "Train MSE: 0.0000595390\n",
      "Test MSE: 0.0000225336\n",
      "epoch 565\n",
      "Train MSE: 0.0000593201\n",
      "Test MSE: 0.0000227652\n",
      "epoch 566\n",
      "Train MSE: 0.0000593865\n",
      "Test MSE: 0.0000225292\n",
      "epoch 567\n",
      "Train MSE: 0.0000588286\n",
      "Test MSE: 0.0000226034\n",
      "epoch 568\n",
      "Train MSE: 0.0000587825\n",
      "Test MSE: 0.0000227352\n",
      "epoch 569\n",
      "Train MSE: 0.0000588127\n",
      "Test MSE: 0.0000225173\n",
      "epoch 570\n",
      "Train MSE: 0.0000590797\n",
      "Test MSE: 0.0000227270\n",
      "epoch 571\n",
      "Train MSE: 0.0000596518\n",
      "Test MSE: 0.0000226779\n",
      "epoch 572\n",
      "Train MSE: 0.0000586731\n",
      "Test MSE: 0.0000227188\n",
      "epoch 573\n",
      "Train MSE: 0.0000584135\n",
      "Test MSE: 0.0000226624\n",
      "epoch 574\n",
      "Train MSE: 0.0000590255\n",
      "Test MSE: 0.0000226216\n",
      "epoch 575\n",
      "Train MSE: 0.0000588032\n",
      "Test MSE: 0.0000225647\n",
      "epoch 576\n",
      "Train MSE: 0.0000591744\n",
      "Test MSE: 0.0000221966\n",
      "epoch 577\n",
      "Train MSE: 0.0000589804\n",
      "Test MSE: 0.0000226690\n",
      "epoch 578\n",
      "Train MSE: 0.0000584397\n",
      "Test MSE: 0.0000227423\n",
      "epoch 579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.0000585798\n",
      "Test MSE: 0.0000223130\n",
      "epoch 580\n",
      "Train MSE: 0.0000587434\n",
      "Test MSE: 0.0000225646\n",
      "epoch 581\n",
      "Train MSE: 0.0000586448\n",
      "Test MSE: 0.0000227435\n",
      "epoch 582\n",
      "Train MSE: 0.0000589500\n",
      "Test MSE: 0.0000225570\n",
      "epoch 583\n",
      "Train MSE: 0.0000584507\n",
      "Test MSE: 0.0000224512\n",
      "epoch 584\n",
      "Train MSE: 0.0000588571\n",
      "Test MSE: 0.0000225397\n",
      "epoch 585\n",
      "Train MSE: 0.0000584027\n",
      "Test MSE: 0.0000226632\n",
      "epoch 586\n",
      "Train MSE: 0.0000586617\n",
      "Test MSE: 0.0000223559\n",
      "epoch 587\n",
      "Train MSE: 0.0000578949\n",
      "Test MSE: 0.0000222263\n",
      "epoch 588\n",
      "Train MSE: 0.0000587532\n",
      "Test MSE: 0.0000225049\n",
      "epoch 589\n",
      "Train MSE: 0.0000580527\n",
      "Test MSE: 0.0000226049\n",
      "epoch 590\n",
      "Train MSE: 0.0000580311\n",
      "Test MSE: 0.0000224339\n",
      "epoch 591\n",
      "Train MSE: 0.0000579667\n",
      "Test MSE: 0.0000222550\n",
      "epoch 592\n",
      "Train MSE: 0.0000584867\n",
      "Test MSE: 0.0000227398\n",
      "epoch 593\n",
      "Train MSE: 0.0000586698\n",
      "Test MSE: 0.0000227312\n",
      "epoch 594\n",
      "Train MSE: 0.0000581126\n",
      "Test MSE: 0.0000226568\n",
      "epoch 595\n",
      "Train MSE: 0.0000578193\n",
      "Test MSE: 0.0000224809\n",
      "epoch 596\n",
      "Train MSE: 0.0000581261\n",
      "Test MSE: 0.0000222409\n",
      "epoch 597\n",
      "Train MSE: 0.0000577630\n",
      "Test MSE: 0.0000222742\n",
      "epoch 598\n",
      "Train MSE: 0.0000585094\n",
      "Test MSE: 0.0000227461\n",
      "epoch 599\n",
      "Train MSE: 0.0000583056\n",
      "Test MSE: 0.0000225040\n",
      "epoch 600\n",
      "Train MSE: 0.0000575941\n",
      "Test MSE: 0.0000225446\n",
      "epoch 601\n",
      "Train MSE: 0.0000576958\n",
      "Test MSE: 0.0000226674\n",
      "epoch 602\n",
      "Train MSE: 0.0000580479\n",
      "Test MSE: 0.0000226812\n",
      "epoch 603\n",
      "Train MSE: 0.0000583251\n",
      "Test MSE: 0.0000224497\n",
      "epoch 604\n",
      "Train MSE: 0.0000579562\n",
      "Test MSE: 0.0000230211\n",
      "epoch 605\n",
      "Train MSE: 0.0000579025\n",
      "Test MSE: 0.0000225310\n",
      "epoch 606\n",
      "Train MSE: 0.0000578000\n",
      "Test MSE: 0.0000227098\n",
      "epoch 607\n",
      "Train MSE: 0.0000576810\n",
      "Test MSE: 0.0000226986\n",
      "epoch 608\n",
      "Train MSE: 0.0000578462\n",
      "Test MSE: 0.0000226526\n",
      "epoch 609\n",
      "Train MSE: 0.0000580342\n",
      "Test MSE: 0.0000225459\n",
      "epoch 610\n",
      "Train MSE: 0.0000573840\n",
      "Test MSE: 0.0000227254\n",
      "epoch 611\n",
      "Train MSE: 0.0000575353\n",
      "Test MSE: 0.0000223000\n",
      "epoch 612\n",
      "Train MSE: 0.0000579471\n",
      "Test MSE: 0.0000225779\n",
      "epoch 613\n",
      "Train MSE: 0.0000576651\n",
      "Test MSE: 0.0000225937\n",
      "epoch 614\n",
      "Train MSE: 0.0000583493\n",
      "Test MSE: 0.0000224262\n",
      "epoch 615\n",
      "Train MSE: 0.0000579839\n",
      "Test MSE: 0.0000226185\n",
      "epoch 616\n",
      "Train MSE: 0.0000579995\n",
      "Test MSE: 0.0000225929\n",
      "epoch 617\n",
      "Train MSE: 0.0000572862\n",
      "Test MSE: 0.0000223852\n",
      "epoch 618\n",
      "Train MSE: 0.0000577965\n",
      "Test MSE: 0.0000228920\n",
      "epoch 619\n",
      "Train MSE: 0.0000573551\n",
      "Test MSE: 0.0000225405\n",
      "epoch 620\n",
      "Train MSE: 0.0000573985\n",
      "Test MSE: 0.0000225848\n",
      "epoch 621\n",
      "Train MSE: 0.0000574347\n",
      "Test MSE: 0.0000226756\n",
      "epoch 622\n",
      "Train MSE: 0.0000576854\n",
      "Test MSE: 0.0000226392\n",
      "epoch 623\n",
      "Train MSE: 0.0000575282\n",
      "Test MSE: 0.0000226608\n",
      "epoch 624\n",
      "Train MSE: 0.0000573259\n",
      "Test MSE: 0.0000226401\n",
      "epoch 625\n",
      "Train MSE: 0.0000577721\n",
      "Test MSE: 0.0000225420\n",
      "epoch 626\n",
      "Train MSE: 0.0000570439\n",
      "Test MSE: 0.0000226299\n",
      "epoch 627\n",
      "Train MSE: 0.0000573955\n",
      "Test MSE: 0.0000226197\n",
      "epoch 628\n",
      "Train MSE: 0.0000567894\n",
      "Test MSE: 0.0000226545\n",
      "epoch 629\n",
      "Train MSE: 0.0000574893\n",
      "Test MSE: 0.0000228342\n",
      "epoch 630\n",
      "Train MSE: 0.0000569099\n",
      "Test MSE: 0.0000226399\n",
      "epoch 631\n",
      "Train MSE: 0.0000572949\n",
      "Test MSE: 0.0000225948\n",
      "epoch 632\n",
      "Train MSE: 0.0000568178\n",
      "Test MSE: 0.0000228560\n",
      "epoch 633\n",
      "Train MSE: 0.0000570061\n",
      "Test MSE: 0.0000227886\n",
      "epoch 634\n",
      "Train MSE: 0.0000568732\n",
      "Test MSE: 0.0000225764\n",
      "epoch 635\n",
      "Train MSE: 0.0000570089\n",
      "Test MSE: 0.0000226676\n",
      "epoch 636\n",
      "Train MSE: 0.0000567325\n",
      "Test MSE: 0.0000225890\n",
      "epoch 637\n",
      "Train MSE: 0.0000571344\n",
      "Test MSE: 0.0000224826\n",
      "epoch 638\n",
      "Train MSE: 0.0000570032\n",
      "Test MSE: 0.0000224462\n",
      "epoch 639\n",
      "Train MSE: 0.0000571162\n",
      "Test MSE: 0.0000225139\n",
      "epoch 640\n",
      "Train MSE: 0.0000567875\n",
      "Test MSE: 0.0000228152\n",
      "epoch 641\n",
      "Train MSE: 0.0000568540\n",
      "Test MSE: 0.0000229440\n",
      "epoch 642\n",
      "Train MSE: 0.0000570355\n",
      "Test MSE: 0.0000229241\n",
      "epoch 643\n",
      "Train MSE: 0.0000574429\n",
      "Test MSE: 0.0000231422\n",
      "epoch 644\n",
      "Train MSE: 0.0000565604\n",
      "Test MSE: 0.0000233008\n",
      "epoch 645\n",
      "Train MSE: 0.0000572213\n",
      "Test MSE: 0.0000231962\n",
      "epoch 646\n",
      "Train MSE: 0.0000565499\n",
      "Test MSE: 0.0000234409\n",
      "epoch 647\n",
      "Train MSE: 0.0000567247\n",
      "Test MSE: 0.0000229041\n",
      "epoch 648\n",
      "Train MSE: 0.0000566899\n",
      "Test MSE: 0.0000232752\n",
      "epoch 649\n",
      "Train MSE: 0.0000566553\n",
      "Test MSE: 0.0000231260\n",
      "epoch 650\n",
      "Train MSE: 0.0000568294\n",
      "Test MSE: 0.0000228564\n",
      "epoch 651\n",
      "Train MSE: 0.0000567435\n",
      "Test MSE: 0.0000230430\n",
      "epoch 652\n",
      "Train MSE: 0.0000560918\n",
      "Test MSE: 0.0000225561\n",
      "epoch 653\n",
      "Train MSE: 0.0000571668\n",
      "Test MSE: 0.0000228044\n",
      "epoch 654\n",
      "Train MSE: 0.0000568357\n",
      "Test MSE: 0.0000225585\n",
      "epoch 655\n",
      "Train MSE: 0.0000561185\n",
      "Test MSE: 0.0000221272\n",
      "epoch 656\n",
      "Train MSE: 0.0000567805\n",
      "Test MSE: 0.0000226519\n",
      "epoch 657\n",
      "Train MSE: 0.0000561822\n",
      "Test MSE: 0.0000223746\n",
      "epoch 658\n",
      "Train MSE: 0.0000567337\n",
      "Test MSE: 0.0000224340\n",
      "epoch 659\n",
      "Train MSE: 0.0000569370\n",
      "Test MSE: 0.0000223957\n",
      "epoch 660\n",
      "Train MSE: 0.0000561843\n",
      "Test MSE: 0.0000223970\n",
      "epoch 661\n",
      "Train MSE: 0.0000565645\n",
      "Test MSE: 0.0000225422\n",
      "epoch 662\n",
      "Train MSE: 0.0000564721\n",
      "Test MSE: 0.0000222975\n",
      "epoch 663\n",
      "Train MSE: 0.0000561661\n",
      "Test MSE: 0.0000224141\n",
      "epoch 664\n",
      "Train MSE: 0.0000561427\n",
      "Test MSE: 0.0000228476\n",
      "epoch 665\n",
      "Train MSE: 0.0000560979\n",
      "Test MSE: 0.0000227765\n",
      "epoch 666\n",
      "Train MSE: 0.0000564346\n",
      "Test MSE: 0.0000224222\n",
      "epoch 667\n",
      "Train MSE: 0.0000564293\n",
      "Test MSE: 0.0000230809\n",
      "epoch 668\n",
      "Train MSE: 0.0000560216\n",
      "Test MSE: 0.0000226319\n",
      "epoch 669\n",
      "Train MSE: 0.0000560628\n",
      "Test MSE: 0.0000226808\n",
      "epoch 670\n",
      "Train MSE: 0.0000558872\n",
      "Test MSE: 0.0000232059\n",
      "epoch 671\n",
      "Train MSE: 0.0000560197\n",
      "Test MSE: 0.0000245963\n",
      "epoch 672\n",
      "Train MSE: 0.0000565382\n",
      "Test MSE: 0.0000261531\n",
      "epoch 673\n",
      "Train MSE: 0.0000564566\n",
      "Test MSE: 0.0000283678\n",
      "epoch 674\n",
      "Train MSE: 0.0000566751\n",
      "Test MSE: 0.0000290989\n",
      "epoch 675\n",
      "Train MSE: 0.0000559120\n",
      "Test MSE: 0.0000300144\n",
      "epoch 676\n",
      "Train MSE: 0.0000562504\n",
      "Test MSE: 0.0000312042\n",
      "epoch 677\n",
      "Train MSE: 0.0000558762\n",
      "Test MSE: 0.0000301993\n",
      "epoch 678\n",
      "Train MSE: 0.0000557666\n",
      "Test MSE: 0.0000312912\n",
      "epoch 679\n",
      "Train MSE: 0.0000559458\n",
      "Test MSE: 0.0000311193\n",
      "epoch 680\n",
      "Train MSE: 0.0000560055\n",
      "Test MSE: 0.0000299282\n",
      "epoch 681\n",
      "Train MSE: 0.0000558972\n",
      "Test MSE: 0.0000317901\n",
      "epoch 682\n",
      "Train MSE: 0.0000556930\n",
      "Test MSE: 0.0000302004\n",
      "epoch 683\n",
      "Train MSE: 0.0000561739\n",
      "Test MSE: 0.0000310815\n",
      "epoch 684\n",
      "Train MSE: 0.0000560656\n",
      "Test MSE: 0.0000309954\n",
      "epoch 685\n",
      "Train MSE: 0.0000558808\n",
      "Test MSE: 0.0000299003\n",
      "epoch 686\n",
      "Train MSE: 0.0000557105\n",
      "Test MSE: 0.0000294181\n",
      "epoch 687\n",
      "Train MSE: 0.0000559181\n",
      "Test MSE: 0.0000295289\n",
      "epoch 688\n",
      "Train MSE: 0.0000559478\n",
      "Test MSE: 0.0000283873\n",
      "epoch 689\n",
      "Train MSE: 0.0000557824\n",
      "Test MSE: 0.0000282848\n",
      "epoch 690\n",
      "Train MSE: 0.0000560084\n",
      "Test MSE: 0.0000272865\n",
      "epoch 691\n",
      "Train MSE: 0.0000555717\n",
      "Test MSE: 0.0000266999\n",
      "epoch 692\n",
      "Train MSE: 0.0000556627\n",
      "Test MSE: 0.0000276728\n",
      "epoch 693\n",
      "Train MSE: 0.0000551951\n",
      "Test MSE: 0.0000263596\n",
      "epoch 694\n",
      "Train MSE: 0.0000553891\n",
      "Test MSE: 0.0000264311\n",
      "epoch 695\n",
      "Train MSE: 0.0000556402\n",
      "Test MSE: 0.0000261853\n",
      "epoch 696\n",
      "Train MSE: 0.0000557017\n",
      "Test MSE: 0.0000257625\n",
      "epoch 697\n",
      "Train MSE: 0.0000550728\n",
      "Test MSE: 0.0000254133\n",
      "epoch 698\n",
      "Train MSE: 0.0000554778\n",
      "Test MSE: 0.0000257947\n",
      "epoch 699\n",
      "Train MSE: 0.0000555492\n",
      "Test MSE: 0.0000248236\n",
      "epoch 700\n",
      "Train MSE: 0.0000554818\n",
      "Test MSE: 0.0000250657\n",
      "epoch 701\n",
      "Train MSE: 0.0000552847\n",
      "Test MSE: 0.0000250689\n",
      "epoch 702\n",
      "Train MSE: 0.0000554859\n",
      "Test MSE: 0.0000243958\n",
      "epoch 703\n",
      "Train MSE: 0.0000556397\n",
      "Test MSE: 0.0000241804\n",
      "epoch 704\n",
      "Train MSE: 0.0000553918\n",
      "Test MSE: 0.0000239231\n",
      "epoch 705\n",
      "Train MSE: 0.0000549911\n",
      "Test MSE: 0.0000236986\n",
      "epoch 706\n",
      "Train MSE: 0.0000553086\n",
      "Test MSE: 0.0000230476\n",
      "epoch 707\n",
      "Train MSE: 0.0000552517\n",
      "Test MSE: 0.0000229717\n",
      "epoch 708\n",
      "Train MSE: 0.0000553617\n",
      "Test MSE: 0.0000223670\n",
      "epoch 709\n",
      "Train MSE: 0.0000547666\n",
      "Test MSE: 0.0000225162\n",
      "epoch 710\n",
      "Train MSE: 0.0000553942\n",
      "Test MSE: 0.0000224190\n",
      "epoch 711\n",
      "Train MSE: 0.0000555177\n",
      "Test MSE: 0.0000225042\n",
      "epoch 712\n",
      "Train MSE: 0.0000549359\n",
      "Test MSE: 0.0000222780\n",
      "epoch 713\n",
      "Train MSE: 0.0000550372\n",
      "Test MSE: 0.0000222722\n",
      "epoch 714\n",
      "Train MSE: 0.0000557349\n",
      "Test MSE: 0.0000222488\n",
      "epoch 715\n",
      "Train MSE: 0.0000549177\n",
      "Test MSE: 0.0000223820\n",
      "epoch 716\n",
      "Train MSE: 0.0000547548\n",
      "Test MSE: 0.0000221629\n",
      "epoch 717\n",
      "Train MSE: 0.0000552316\n",
      "Test MSE: 0.0000223081\n",
      "epoch 718\n",
      "Train MSE: 0.0000548560\n",
      "Test MSE: 0.0000226823\n",
      "epoch 719\n",
      "Train MSE: 0.0000550196\n",
      "Test MSE: 0.0000224324\n",
      "epoch 720\n",
      "Train MSE: 0.0000547182\n",
      "Test MSE: 0.0000222301\n",
      "epoch 721\n",
      "Train MSE: 0.0000543431\n",
      "Test MSE: 0.0000225181\n",
      "epoch 722\n",
      "Train MSE: 0.0000551507\n",
      "Test MSE: 0.0000226608\n",
      "epoch 723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.0000548050\n",
      "Test MSE: 0.0000227287\n",
      "epoch 724\n",
      "Train MSE: 0.0000547864\n",
      "Test MSE: 0.0000227208\n",
      "epoch 725\n",
      "Train MSE: 0.0000550085\n",
      "Test MSE: 0.0000226524\n",
      "epoch 726\n",
      "Train MSE: 0.0000547945\n",
      "Test MSE: 0.0000225031\n",
      "epoch 727\n",
      "Train MSE: 0.0000541653\n",
      "Test MSE: 0.0000224985\n",
      "epoch 728\n",
      "Train MSE: 0.0000540739\n",
      "Test MSE: 0.0000222543\n",
      "epoch 729\n",
      "Train MSE: 0.0000548488\n",
      "Test MSE: 0.0000225937\n",
      "epoch 730\n",
      "Train MSE: 0.0000550710\n",
      "Test MSE: 0.0000224116\n",
      "epoch 731\n",
      "Train MSE: 0.0000544983\n",
      "Test MSE: 0.0000225454\n",
      "epoch 732\n",
      "Train MSE: 0.0000546035\n",
      "Test MSE: 0.0000224758\n",
      "epoch 733\n",
      "Train MSE: 0.0000543474\n",
      "Test MSE: 0.0000220607\n",
      "epoch 734\n",
      "Train MSE: 0.0000542605\n",
      "Test MSE: 0.0000222382\n",
      "epoch 735\n",
      "Train MSE: 0.0000545946\n",
      "Test MSE: 0.0000222588\n",
      "epoch 736\n",
      "Train MSE: 0.0000545123\n",
      "Test MSE: 0.0000228783\n",
      "epoch 737\n",
      "Train MSE: 0.0000545144\n",
      "Test MSE: 0.0000229010\n",
      "epoch 738\n",
      "Train MSE: 0.0000546351\n",
      "Test MSE: 0.0000225900\n",
      "epoch 739\n",
      "Train MSE: 0.0000539844\n",
      "Test MSE: 0.0000232327\n",
      "epoch 740\n",
      "Train MSE: 0.0000547962\n",
      "Test MSE: 0.0000227849\n",
      "epoch 741\n",
      "Train MSE: 0.0000545347\n",
      "Test MSE: 0.0000232683\n",
      "epoch 742\n",
      "Train MSE: 0.0000543563\n",
      "Test MSE: 0.0000225045\n",
      "epoch 743\n",
      "Train MSE: 0.0000545678\n",
      "Test MSE: 0.0000231956\n",
      "epoch 744\n",
      "Train MSE: 0.0000543561\n",
      "Test MSE: 0.0000225522\n",
      "epoch 745\n",
      "Train MSE: 0.0000543581\n",
      "Test MSE: 0.0000227774\n",
      "epoch 746\n",
      "Train MSE: 0.0000540260\n",
      "Test MSE: 0.0000229589\n",
      "epoch 747\n",
      "Train MSE: 0.0000543028\n",
      "Test MSE: 0.0000222896\n",
      "epoch 748\n",
      "Train MSE: 0.0000543954\n",
      "Test MSE: 0.0000230808\n",
      "epoch 749\n",
      "Train MSE: 0.0000548306\n",
      "Test MSE: 0.0000224858\n",
      "epoch 750\n",
      "Train MSE: 0.0000543869\n",
      "Test MSE: 0.0000225699\n",
      "epoch 751\n",
      "Train MSE: 0.0000541698\n",
      "Test MSE: 0.0000228213\n",
      "epoch 752\n",
      "Train MSE: 0.0000541423\n",
      "Test MSE: 0.0000224689\n",
      "epoch 753\n",
      "Train MSE: 0.0000539404\n",
      "Test MSE: 0.0000236115\n",
      "epoch 754\n",
      "Train MSE: 0.0000544782\n",
      "Test MSE: 0.0000225474\n",
      "epoch 755\n",
      "Train MSE: 0.0000542817\n",
      "Test MSE: 0.0000239220\n",
      "epoch 756\n",
      "Train MSE: 0.0000539637\n",
      "Test MSE: 0.0000226435\n",
      "epoch 757\n",
      "Train MSE: 0.0000540964\n",
      "Test MSE: 0.0000233628\n",
      "epoch 758\n",
      "Train MSE: 0.0000539368\n",
      "Test MSE: 0.0000224206\n",
      "epoch 759\n",
      "Train MSE: 0.0000537598\n",
      "Test MSE: 0.0000225912\n",
      "epoch 760\n",
      "Train MSE: 0.0000536299\n",
      "Test MSE: 0.0000225227\n",
      "epoch 761\n",
      "Train MSE: 0.0000534948\n",
      "Test MSE: 0.0000223334\n",
      "epoch 762\n",
      "Train MSE: 0.0000539812\n",
      "Test MSE: 0.0000230866\n",
      "epoch 763\n",
      "Train MSE: 0.0000540575\n",
      "Test MSE: 0.0000224978\n",
      "epoch 764\n",
      "Train MSE: 0.0000537819\n",
      "Test MSE: 0.0000230447\n",
      "epoch 765\n",
      "Train MSE: 0.0000538710\n",
      "Test MSE: 0.0000223190\n",
      "epoch 766\n",
      "Train MSE: 0.0000542818\n",
      "Test MSE: 0.0000225069\n",
      "epoch 767\n",
      "Train MSE: 0.0000537458\n",
      "Test MSE: 0.0000223918\n",
      "epoch 768\n",
      "Train MSE: 0.0000533823\n",
      "Test MSE: 0.0000225689\n",
      "epoch 769\n",
      "Train MSE: 0.0000540833\n",
      "Test MSE: 0.0000229485\n",
      "epoch 770\n",
      "Train MSE: 0.0000536533\n",
      "Test MSE: 0.0000229895\n",
      "epoch 771\n",
      "Train MSE: 0.0000539865\n",
      "Test MSE: 0.0000225180\n",
      "epoch 772\n",
      "Train MSE: 0.0000537996\n",
      "Test MSE: 0.0000229486\n",
      "epoch 773\n",
      "Train MSE: 0.0000534566\n",
      "Test MSE: 0.0000227628\n",
      "epoch 774\n",
      "Train MSE: 0.0000538918\n",
      "Test MSE: 0.0000225444\n",
      "epoch 775\n",
      "Train MSE: 0.0000535729\n",
      "Test MSE: 0.0000228005\n",
      "epoch 776\n",
      "Train MSE: 0.0000531576\n",
      "Test MSE: 0.0000224790\n",
      "epoch 777\n",
      "Train MSE: 0.0000531629\n",
      "Test MSE: 0.0000234021\n",
      "epoch 778\n",
      "Train MSE: 0.0000533760\n",
      "Test MSE: 0.0000223003\n",
      "epoch 779\n",
      "Train MSE: 0.0000536543\n",
      "Test MSE: 0.0000230859\n",
      "epoch 780\n",
      "Train MSE: 0.0000531350\n",
      "Test MSE: 0.0000226378\n",
      "epoch 781\n",
      "Train MSE: 0.0000533794\n",
      "Test MSE: 0.0000226483\n",
      "epoch 782\n",
      "Train MSE: 0.0000531708\n",
      "Test MSE: 0.0000234617\n",
      "epoch 783\n",
      "Train MSE: 0.0000531678\n",
      "Test MSE: 0.0000223206\n",
      "epoch 784\n",
      "Train MSE: 0.0000533166\n",
      "Test MSE: 0.0000226744\n",
      "epoch 785\n",
      "Train MSE: 0.0000532860\n",
      "Test MSE: 0.0000223836\n",
      "epoch 786\n",
      "Train MSE: 0.0000530799\n",
      "Test MSE: 0.0000229066\n",
      "epoch 787\n",
      "Train MSE: 0.0000538275\n",
      "Test MSE: 0.0000226327\n",
      "epoch 788\n",
      "Train MSE: 0.0000536185\n",
      "Test MSE: 0.0000226155\n",
      "epoch 789\n",
      "Train MSE: 0.0000530592\n",
      "Test MSE: 0.0000228695\n",
      "epoch 790\n",
      "Train MSE: 0.0000532723\n",
      "Test MSE: 0.0000223809\n",
      "epoch 791\n",
      "Train MSE: 0.0000535631\n",
      "Test MSE: 0.0000228060\n",
      "epoch 792\n",
      "Train MSE: 0.0000531637\n",
      "Test MSE: 0.0000223973\n",
      "epoch 793\n",
      "Train MSE: 0.0000524780\n",
      "Test MSE: 0.0000221349\n",
      "epoch 794\n",
      "Train MSE: 0.0000529681\n",
      "Test MSE: 0.0000223495\n",
      "epoch 795\n",
      "Train MSE: 0.0000527988\n",
      "Test MSE: 0.0000221642\n",
      "epoch 796\n",
      "Train MSE: 0.0000528765\n",
      "Test MSE: 0.0000226721\n",
      "epoch 797\n",
      "Train MSE: 0.0000533729\n",
      "Test MSE: 0.0000222677\n",
      "epoch 798\n",
      "Train MSE: 0.0000533193\n",
      "Test MSE: 0.0000225713\n",
      "epoch 799\n",
      "Train MSE: 0.0000530728\n",
      "Test MSE: 0.0000221675\n",
      "epoch 800\n",
      "Train MSE: 0.0000530686\n",
      "Test MSE: 0.0000228505\n",
      "epoch 801\n",
      "Train MSE: 0.0000535183\n",
      "Test MSE: 0.0000226022\n",
      "epoch 802\n",
      "Train MSE: 0.0000538816\n",
      "Test MSE: 0.0000230799\n",
      "epoch 803\n",
      "Train MSE: 0.0000536811\n",
      "Test MSE: 0.0000220896\n",
      "epoch 804\n",
      "Train MSE: 0.0000528283\n",
      "Test MSE: 0.0000232392\n",
      "epoch 805\n",
      "Train MSE: 0.0000528079\n",
      "Test MSE: 0.0000218941\n",
      "epoch 806\n",
      "Train MSE: 0.0000528441\n",
      "Test MSE: 0.0000228696\n",
      "epoch 807\n",
      "Train MSE: 0.0000528378\n",
      "Test MSE: 0.0000217879\n",
      "epoch 808\n",
      "Train MSE: 0.0000526423\n",
      "Test MSE: 0.0000220853\n",
      "epoch 809\n",
      "Train MSE: 0.0000523123\n",
      "Test MSE: 0.0000223918\n",
      "epoch 810\n",
      "Train MSE: 0.0000533240\n",
      "Test MSE: 0.0000222041\n",
      "epoch 811\n",
      "Train MSE: 0.0000526399\n",
      "Test MSE: 0.0000231868\n",
      "epoch 812\n",
      "Train MSE: 0.0000534049\n",
      "Test MSE: 0.0000230768\n",
      "epoch 813\n",
      "Train MSE: 0.0000539137\n",
      "Test MSE: 0.0000241711\n",
      "epoch 814\n",
      "Train MSE: 0.0000541836\n",
      "Test MSE: 0.0000235665\n",
      "epoch 815\n",
      "Train MSE: 0.0000549346\n",
      "Test MSE: 0.0000259453\n",
      "epoch 816\n",
      "Train MSE: 0.0000550217\n",
      "Test MSE: 0.0000240048\n",
      "epoch 817\n",
      "Train MSE: 0.0000552491\n",
      "Test MSE: 0.0000251491\n",
      "epoch 818\n",
      "Train MSE: 0.0000552680\n",
      "Test MSE: 0.0000224866\n",
      "epoch 819\n",
      "Train MSE: 0.0000535850\n",
      "Test MSE: 0.0000241582\n",
      "epoch 820\n",
      "Train MSE: 0.0000529277\n",
      "Test MSE: 0.0000223107\n",
      "epoch 821\n",
      "Train MSE: 0.0000528876\n",
      "Test MSE: 0.0000230639\n",
      "epoch 822\n",
      "Train MSE: 0.0000520657\n",
      "Test MSE: 0.0000229949\n",
      "epoch 823\n",
      "Train MSE: 0.0000530511\n",
      "Test MSE: 0.0000231956\n",
      "epoch 824\n",
      "Train MSE: 0.0000528517\n",
      "Test MSE: 0.0000235011\n",
      "epoch 825\n",
      "Train MSE: 0.0000519763\n",
      "Test MSE: 0.0000227393\n",
      "epoch 826\n",
      "Train MSE: 0.0000521879\n",
      "Test MSE: 0.0000238819\n",
      "epoch 827\n",
      "Train MSE: 0.0000519846\n",
      "Test MSE: 0.0000228615\n",
      "epoch 828\n",
      "Train MSE: 0.0000522922\n",
      "Test MSE: 0.0000248682\n",
      "epoch 829\n",
      "Train MSE: 0.0000523705\n",
      "Test MSE: 0.0000223700\n",
      "epoch 830\n",
      "Train MSE: 0.0000525394\n",
      "Test MSE: 0.0000249546\n",
      "epoch 831\n",
      "Train MSE: 0.0000529327\n",
      "Test MSE: 0.0000227754\n",
      "epoch 832\n",
      "Train MSE: 0.0000526510\n",
      "Test MSE: 0.0000247743\n",
      "epoch 833\n",
      "Train MSE: 0.0000518957\n",
      "Test MSE: 0.0000230939\n",
      "epoch 834\n",
      "Train MSE: 0.0000519525\n",
      "Test MSE: 0.0000242111\n",
      "epoch 835\n",
      "Train MSE: 0.0000523538\n",
      "Test MSE: 0.0000239578\n",
      "epoch 836\n",
      "Train MSE: 0.0000520712\n",
      "Test MSE: 0.0000240609\n",
      "epoch 837\n",
      "Train MSE: 0.0000519157\n",
      "Test MSE: 0.0000243067\n",
      "epoch 838\n",
      "Train MSE: 0.0000519911\n",
      "Test MSE: 0.0000233641\n",
      "epoch 839\n",
      "Train MSE: 0.0000514288\n",
      "Test MSE: 0.0000241495\n",
      "epoch 840\n",
      "Train MSE: 0.0000520523\n",
      "Test MSE: 0.0000230602\n",
      "epoch 841\n",
      "Train MSE: 0.0000516544\n",
      "Test MSE: 0.0000242448\n",
      "epoch 842\n",
      "Train MSE: 0.0000520843\n",
      "Test MSE: 0.0000225232\n",
      "epoch 843\n",
      "Train MSE: 0.0000523573\n",
      "Test MSE: 0.0000256857\n",
      "epoch 844\n",
      "Train MSE: 0.0000527770\n",
      "Test MSE: 0.0000223185\n",
      "epoch 845\n",
      "Train MSE: 0.0000526428\n",
      "Test MSE: 0.0000262194\n",
      "epoch 846\n",
      "Train MSE: 0.0000530967\n",
      "Test MSE: 0.0000227405\n",
      "epoch 847\n",
      "Train MSE: 0.0000534892\n",
      "Test MSE: 0.0000285022\n",
      "epoch 848\n",
      "Train MSE: 0.0000547219\n",
      "Test MSE: 0.0000242037\n",
      "epoch 849\n",
      "Train MSE: 0.0000561451\n",
      "Test MSE: 0.0000312701\n",
      "epoch 850\n",
      "Train MSE: 0.0000590860\n",
      "Test MSE: 0.0000326145\n",
      "epoch 851\n",
      "Train MSE: 0.0000616995\n",
      "Test MSE: 0.0000294780\n",
      "epoch 852\n",
      "Train MSE: 0.0000631324\n",
      "Test MSE: 0.0000448924\n",
      "epoch 853\n",
      "Train MSE: 0.0000616555\n",
      "Test MSE: 0.0000238708\n",
      "epoch 854\n",
      "Train MSE: 0.0000581913\n",
      "Test MSE: 0.0000390682\n",
      "epoch 855\n",
      "Train MSE: 0.0000548992\n",
      "Test MSE: 0.0000266288\n",
      "epoch 856\n",
      "Train MSE: 0.0000517992\n",
      "Test MSE: 0.0000269121\n",
      "epoch 857\n",
      "Train MSE: 0.0000519344\n",
      "Test MSE: 0.0000337816\n",
      "epoch 858\n",
      "Train MSE: 0.0000540476\n",
      "Test MSE: 0.0000252399\n",
      "epoch 859\n",
      "Train MSE: 0.0000555911\n",
      "Test MSE: 0.0000442557\n",
      "epoch 860\n",
      "Train MSE: 0.0000577391\n",
      "Test MSE: 0.0000248424\n",
      "epoch 861\n",
      "Train MSE: 0.0000579584\n",
      "Test MSE: 0.0000480589\n",
      "epoch 862\n",
      "Train MSE: 0.0000563642\n",
      "Test MSE: 0.0000254362\n",
      "epoch 863\n",
      "Train MSE: 0.0000534401\n",
      "Test MSE: 0.0000352191\n",
      "epoch 864\n",
      "Train MSE: 0.0000516189\n",
      "Test MSE: 0.0000345139\n",
      "epoch 865\n",
      "Train MSE: 0.0000522762\n",
      "Test MSE: 0.0000258045\n",
      "epoch 866\n",
      "Train MSE: 0.0000531546\n",
      "Test MSE: 0.0000449487\n",
      "epoch 867\n",
      "Train MSE: 0.0000540691\n",
      "Test MSE: 0.0000245968\n",
      "epoch 868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.0000548469\n",
      "Test MSE: 0.0000475540\n",
      "epoch 869\n",
      "Train MSE: 0.0000565909\n",
      "Test MSE: 0.0000247980\n",
      "epoch 870\n",
      "Train MSE: 0.0000564001\n",
      "Test MSE: 0.0000437889\n",
      "epoch 871\n",
      "Train MSE: 0.0000558612\n",
      "Test MSE: 0.0000230625\n",
      "epoch 872\n",
      "Train MSE: 0.0000548445\n",
      "Test MSE: 0.0000348216\n",
      "epoch 873\n",
      "Train MSE: 0.0000528406\n",
      "Test MSE: 0.0000249832\n",
      "epoch 874\n",
      "Train MSE: 0.0000512111\n",
      "Test MSE: 0.0000240334\n",
      "epoch 875\n",
      "Train MSE: 0.0000510368\n",
      "Test MSE: 0.0000291015\n",
      "epoch 876\n",
      "Train MSE: 0.0000529050\n",
      "Test MSE: 0.0000233945\n",
      "epoch 877\n",
      "Train MSE: 0.0000538380\n",
      "Test MSE: 0.0000307346\n",
      "epoch 878\n",
      "Train MSE: 0.0000543279\n",
      "Test MSE: 0.0000245172\n",
      "epoch 879\n",
      "Train MSE: 0.0000541477\n",
      "Test MSE: 0.0000261352\n",
      "epoch 880\n",
      "Train MSE: 0.0000526073\n",
      "Test MSE: 0.0000231057\n",
      "epoch 881\n",
      "Train MSE: 0.0000516428\n",
      "Test MSE: 0.0000225967\n",
      "epoch 882\n",
      "Train MSE: 0.0000515316\n",
      "Test MSE: 0.0000225443\n",
      "epoch 883\n",
      "Train MSE: 0.0000513843\n",
      "Test MSE: 0.0000225803\n",
      "epoch 884\n",
      "Train MSE: 0.0000511942\n",
      "Test MSE: 0.0000231708\n",
      "epoch 885\n",
      "Train MSE: 0.0000507520\n",
      "Test MSE: 0.0000232520\n",
      "epoch 886\n",
      "Train MSE: 0.0000516956\n",
      "Test MSE: 0.0000222847\n",
      "epoch 887\n",
      "Train MSE: 0.0000509683\n",
      "Test MSE: 0.0000229188\n",
      "epoch 888\n",
      "Train MSE: 0.0000520912\n",
      "Test MSE: 0.0000225517\n",
      "epoch 889\n",
      "Train MSE: 0.0000512541\n",
      "Test MSE: 0.0000231113\n",
      "epoch 890\n",
      "Train MSE: 0.0000511622\n",
      "Test MSE: 0.0000227108\n",
      "epoch 891\n",
      "Train MSE: 0.0000510210\n",
      "Test MSE: 0.0000230626\n",
      "epoch 892\n",
      "Train MSE: 0.0000518991\n",
      "Test MSE: 0.0000231682\n",
      "epoch 893\n",
      "Train MSE: 0.0000505688\n",
      "Test MSE: 0.0000228294\n",
      "epoch 894\n",
      "Train MSE: 0.0000507005\n",
      "Test MSE: 0.0000243991\n",
      "epoch 895\n",
      "Train MSE: 0.0000516990\n",
      "Test MSE: 0.0000226955\n",
      "epoch 896\n",
      "Train MSE: 0.0000513930\n",
      "Test MSE: 0.0000249006\n",
      "epoch 897\n",
      "Train MSE: 0.0000513489\n",
      "Test MSE: 0.0000228665\n",
      "epoch 898\n",
      "Train MSE: 0.0000520115\n",
      "Test MSE: 0.0000251541\n",
      "epoch 899\n",
      "Train MSE: 0.0000511538\n",
      "Test MSE: 0.0000223985\n",
      "epoch 900\n",
      "Train MSE: 0.0000504228\n",
      "Test MSE: 0.0000251027\n",
      "epoch 901\n",
      "Train MSE: 0.0000511108\n",
      "Test MSE: 0.0000221511\n",
      "epoch 902\n",
      "Train MSE: 0.0000505209\n",
      "Test MSE: 0.0000240081\n",
      "epoch 903\n",
      "Train MSE: 0.0000502141\n",
      "Test MSE: 0.0000230590\n",
      "epoch 904\n",
      "Train MSE: 0.0000500388\n",
      "Test MSE: 0.0000232409\n",
      "epoch 905\n",
      "Train MSE: 0.0000505024\n",
      "Test MSE: 0.0000248774\n",
      "epoch 906\n",
      "Train MSE: 0.0000508536\n",
      "Test MSE: 0.0000227108\n",
      "epoch 907\n",
      "Train MSE: 0.0000509908\n",
      "Test MSE: 0.0000265763\n",
      "epoch 908\n",
      "Train MSE: 0.0000511655\n",
      "Test MSE: 0.0000225893\n",
      "epoch 909\n",
      "Train MSE: 0.0000524068\n",
      "Test MSE: 0.0000293336\n",
      "epoch 910\n",
      "Train MSE: 0.0000533479\n",
      "Test MSE: 0.0000241170\n",
      "epoch 911\n",
      "Train MSE: 0.0000539726\n",
      "Test MSE: 0.0000296852\n",
      "epoch 912\n",
      "Train MSE: 0.0000541883\n",
      "Test MSE: 0.0000238126\n",
      "epoch 913\n",
      "Train MSE: 0.0000543654\n",
      "Test MSE: 0.0000283570\n",
      "epoch 914\n",
      "Train MSE: 0.0000524461\n",
      "Test MSE: 0.0000228018\n",
      "epoch 915\n",
      "Train MSE: 0.0000510812\n",
      "Test MSE: 0.0000248123\n",
      "epoch 916\n",
      "Train MSE: 0.0000501499\n",
      "Test MSE: 0.0000268270\n",
      "epoch 917\n",
      "Train MSE: 0.0000507741\n",
      "Test MSE: 0.0000228289\n",
      "epoch 918\n",
      "Train MSE: 0.0000516063\n",
      "Test MSE: 0.0000322725\n",
      "epoch 919\n",
      "Train MSE: 0.0000529721\n",
      "Test MSE: 0.0000228927\n",
      "epoch 920\n",
      "Train MSE: 0.0000527959\n",
      "Test MSE: 0.0000352585\n",
      "epoch 921\n",
      "Train MSE: 0.0000532836\n",
      "Test MSE: 0.0000228586\n",
      "epoch 922\n",
      "Train MSE: 0.0000532898\n",
      "Test MSE: 0.0000360612\n",
      "epoch 923\n",
      "Train MSE: 0.0000519425\n",
      "Test MSE: 0.0000262497\n",
      "epoch 924\n",
      "Train MSE: 0.0000506102\n",
      "Test MSE: 0.0000331619\n",
      "epoch 925\n",
      "Train MSE: 0.0000496616\n",
      "Test MSE: 0.0000361557\n",
      "epoch 926\n",
      "Train MSE: 0.0000507070\n",
      "Test MSE: 0.0000295642\n",
      "epoch 927\n",
      "Train MSE: 0.0000511799\n",
      "Test MSE: 0.0000433723\n",
      "epoch 928\n",
      "Train MSE: 0.0000516529\n",
      "Test MSE: 0.0000272641\n",
      "epoch 929\n",
      "Train MSE: 0.0000512112\n",
      "Test MSE: 0.0000478226\n",
      "epoch 930\n",
      "Train MSE: 0.0000516639\n",
      "Test MSE: 0.0000278385\n",
      "epoch 931\n",
      "Train MSE: 0.0000522156\n",
      "Test MSE: 0.0000483564\n",
      "epoch 932\n",
      "Train MSE: 0.0000523685\n",
      "Test MSE: 0.0000264809\n",
      "epoch 933\n",
      "Train MSE: 0.0000523575\n",
      "Test MSE: 0.0000437347\n",
      "epoch 934\n",
      "Train MSE: 0.0000518368\n",
      "Test MSE: 0.0000266694\n",
      "epoch 935\n",
      "Train MSE: 0.0000514573\n",
      "Test MSE: 0.0000346888\n",
      "epoch 936\n",
      "Train MSE: 0.0000502577\n",
      "Test MSE: 0.0000272310\n",
      "epoch 937\n",
      "Train MSE: 0.0000499462\n",
      "Test MSE: 0.0000271773\n",
      "epoch 938\n",
      "Train MSE: 0.0000499971\n",
      "Test MSE: 0.0000283296\n",
      "epoch 939\n",
      "Train MSE: 0.0000505317\n",
      "Test MSE: 0.0000260976\n",
      "epoch 940\n",
      "Train MSE: 0.0000503858\n",
      "Test MSE: 0.0000288196\n",
      "epoch 941\n",
      "Train MSE: 0.0000494873\n",
      "Test MSE: 0.0000253450\n",
      "epoch 942\n",
      "Train MSE: 0.0000494003\n",
      "Test MSE: 0.0000270465\n",
      "epoch 943\n",
      "Train MSE: 0.0000495163\n",
      "Test MSE: 0.0000261930\n",
      "epoch 944\n",
      "Train MSE: 0.0000495125\n",
      "Test MSE: 0.0000251676\n",
      "epoch 945\n",
      "Train MSE: 0.0000498455\n",
      "Test MSE: 0.0000273202\n",
      "epoch 946\n",
      "Train MSE: 0.0000499752\n",
      "Test MSE: 0.0000234182\n",
      "epoch 947\n",
      "Train MSE: 0.0000501800\n",
      "Test MSE: 0.0000293245\n",
      "epoch 948\n",
      "Train MSE: 0.0000504244\n",
      "Test MSE: 0.0000221514\n",
      "epoch 949\n",
      "Train MSE: 0.0000517116\n",
      "Test MSE: 0.0000324444\n",
      "epoch 950\n",
      "Train MSE: 0.0000516752\n",
      "Test MSE: 0.0000221800\n",
      "epoch 951\n",
      "Train MSE: 0.0000529751\n",
      "Test MSE: 0.0000364628\n",
      "epoch 952\n",
      "Train MSE: 0.0000545535\n",
      "Test MSE: 0.0000229455\n",
      "epoch 953\n",
      "Train MSE: 0.0000552311\n",
      "Test MSE: 0.0000375905\n",
      "epoch 954\n",
      "Train MSE: 0.0000571828\n",
      "Test MSE: 0.0000243250\n",
      "epoch 955\n",
      "Train MSE: 0.0000561688\n",
      "Test MSE: 0.0000327917\n",
      "epoch 956\n",
      "Train MSE: 0.0000553425\n",
      "Test MSE: 0.0000248120\n",
      "epoch 957\n",
      "Train MSE: 0.0000525982\n",
      "Test MSE: 0.0000236888\n",
      "epoch 958\n",
      "Train MSE: 0.0000499232\n",
      "Test MSE: 0.0000225015\n",
      "epoch 959\n",
      "Train MSE: 0.0000488850\n",
      "Test MSE: 0.0000232404\n",
      "epoch 960\n",
      "Train MSE: 0.0000497819\n",
      "Test MSE: 0.0000232187\n",
      "epoch 961\n",
      "Train MSE: 0.0000513082\n",
      "Test MSE: 0.0000294305\n",
      "epoch 962\n",
      "Train MSE: 0.0000541726\n",
      "Test MSE: 0.0000251250\n",
      "epoch 963\n",
      "Train MSE: 0.0000564879\n",
      "Test MSE: 0.0000338868\n",
      "epoch 964\n",
      "Train MSE: 0.0000563723\n",
      "Test MSE: 0.0000263409\n",
      "epoch 965\n",
      "Train MSE: 0.0000548715\n",
      "Test MSE: 0.0000246780\n",
      "epoch 966\n",
      "Train MSE: 0.0000527230\n",
      "Test MSE: 0.0000229825\n",
      "epoch 967\n",
      "Train MSE: 0.0000496926\n",
      "Test MSE: 0.0000229151\n",
      "epoch 968\n",
      "Train MSE: 0.0000504716\n",
      "Test MSE: 0.0000235681\n",
      "epoch 969\n",
      "Train MSE: 0.0000509827\n",
      "Test MSE: 0.0000256836\n",
      "epoch 970\n",
      "Train MSE: 0.0000526740\n",
      "Test MSE: 0.0000269831\n",
      "epoch 971\n",
      "Train MSE: 0.0000532703\n",
      "Test MSE: 0.0000257169\n",
      "epoch 972\n",
      "Train MSE: 0.0000532849\n",
      "Test MSE: 0.0000241386\n",
      "epoch 973\n",
      "Train MSE: 0.0000517138\n",
      "Test MSE: 0.0000244633\n",
      "epoch 974\n",
      "Train MSE: 0.0000502747\n",
      "Test MSE: 0.0000224410\n",
      "epoch 975\n",
      "Train MSE: 0.0000490982\n",
      "Test MSE: 0.0000217401\n",
      "epoch 976\n",
      "Train MSE: 0.0000488833\n",
      "Test MSE: 0.0000249156\n",
      "epoch 977\n",
      "Train MSE: 0.0000503163\n",
      "Test MSE: 0.0000234901\n",
      "epoch 978\n",
      "Train MSE: 0.0000511987\n",
      "Test MSE: 0.0000289293\n",
      "epoch 979\n",
      "Train MSE: 0.0000518318\n",
      "Test MSE: 0.0000226575\n",
      "epoch 980\n",
      "Train MSE: 0.0000514645\n",
      "Test MSE: 0.0000294858\n",
      "epoch 981\n",
      "Train MSE: 0.0000504589\n",
      "Test MSE: 0.0000226066\n",
      "epoch 982\n",
      "Train MSE: 0.0000501936\n",
      "Test MSE: 0.0000252969\n",
      "epoch 983\n",
      "Train MSE: 0.0000490838\n",
      "Test MSE: 0.0000233201\n",
      "epoch 984\n",
      "Train MSE: 0.0000491083\n",
      "Test MSE: 0.0000232818\n",
      "epoch 985\n",
      "Train MSE: 0.0000484027\n",
      "Test MSE: 0.0000249824\n",
      "epoch 986\n",
      "Train MSE: 0.0000497127\n",
      "Test MSE: 0.0000227500\n",
      "epoch 987\n",
      "Train MSE: 0.0000491856\n",
      "Test MSE: 0.0000255772\n",
      "epoch 988\n",
      "Train MSE: 0.0000494095\n",
      "Test MSE: 0.0000224508\n",
      "epoch 989\n",
      "Train MSE: 0.0000489781\n",
      "Test MSE: 0.0000254027\n",
      "epoch 990\n",
      "Train MSE: 0.0000498944\n",
      "Test MSE: 0.0000225798\n",
      "epoch 991\n",
      "Train MSE: 0.0000492446\n",
      "Test MSE: 0.0000258606\n",
      "epoch 992\n",
      "Train MSE: 0.0000496944\n",
      "Test MSE: 0.0000224787\n",
      "epoch 993\n",
      "Train MSE: 0.0000490725\n",
      "Test MSE: 0.0000236457\n",
      "epoch 994\n",
      "Train MSE: 0.0000483806\n",
      "Test MSE: 0.0000228361\n",
      "epoch 995\n",
      "Train MSE: 0.0000479774\n",
      "Test MSE: 0.0000227782\n",
      "epoch 996\n",
      "Train MSE: 0.0000485903\n",
      "Test MSE: 0.0000233404\n",
      "epoch 997\n",
      "Train MSE: 0.0000482021\n",
      "Test MSE: 0.0000227367\n",
      "epoch 998\n",
      "Train MSE: 0.0000487222\n",
      "Test MSE: 0.0000231945\n",
      "epoch 999\n",
      "Train MSE: 0.0000485741\n",
      "Test MSE: 0.0000228070\n",
      "epoch 1000\n",
      "Train MSE: 0.0000492403\n",
      "Test MSE: 0.0000234443\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "\n",
    "model = LSTMrnn(47,95,1)\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(1000):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    # training-----------------------------\n",
    "    model.train()\n",
    "    train_acc = 0.\n",
    "    pred_train_lst = []\n",
    "    for step, (batch_x, batch_y) in enumerate(train_data_loader):\n",
    "        \n",
    "        batch_x = batch_x.unsqueeze(1)\n",
    "        \n",
    "        batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "        \n",
    "        if use_gpu:\n",
    "            batch_x = batch_x.cuda()\n",
    "            batch_y = batch_y.cuda()\n",
    "            \n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_train_lst.append(out.cpu().detach().numpy().tolist())\n",
    "        \n",
    "    print('Train MSE: {:.10f}'.format(loss))\n",
    "\n",
    "    # evaluation--------------------------------\n",
    "    model.eval()\n",
    "    pred_lst = []\n",
    "    with torch.no_grad():\n",
    "        eval_acc = 0.\n",
    "\n",
    "        for batch_x, batch_y in test_data_loader:\n",
    "            \n",
    "            batch_x = batch_x.unsqueeze(1)\n",
    "            \n",
    "            batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "\n",
    "            if use_gpu:\n",
    "                batch_x = batch_x.cuda()\n",
    "                batch_y = batch_y.cuda()\n",
    "\n",
    "            out = model(batch_x)\n",
    "            loss = loss_func(out, batch_y)\n",
    "            \n",
    "            pred_lst.append(out.cpu().numpy().tolist())\n",
    "            \n",
    "        print('Test MSE: {:.10f}'.format(loss))\n",
    "############################################################################################################################\n",
    "#### 训练集效果远不如CNN，可能由于过拟合并不严重，测试集效果好于CNN ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### 用LSTM尝试手写数据分类 ###################################################\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./Ministdata/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./Ministdata/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=1000, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=1000, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM处理图片不同于CNN，会将图片28*28视作28个28维的向量输入(剪成一条条)，图片的结构关系识别的不如CNN巧妙\n",
    "class LSTMrnn(nn.Module):\n",
    "    def __init__(self,input_size,hidden_dim,target_size,use_gpu):\n",
    "        super(LSTMrnn,self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim=hidden_dim  \n",
    "        self.target_size=target_size\n",
    "        self.use_gpu=use_gpu\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            self.hidden=(Variable(torch.zeros(1,input_size,self.hidden_dim)).cuda(),\n",
    "                         Variable(torch.zeros(1,input_size,self.hidden_dim)).cuda())\n",
    "        else:\n",
    "            self.hidden=(Variable(torch.zeros(1,input_size,self.hidden_dim)),\n",
    "                         Variable(torch.zeros(1,input_size,self.hidden_dim)))\n",
    "        \n",
    "        self.lstm=torch.nn.LSTM(self.input_size,self.hidden_dim)\n",
    "\n",
    "        self.dense = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.input_size*self.hidden_dim, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        lstm,self.hidden = self.lstm(x,self.hidden)\n",
    "        tags = self.dense(lstm.view(lstm.size(0),-1))\n",
    "        return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Train Acc: 0.9375666667\n",
      "Train Acc 56254 Train Tol 60000\n",
      "Test Acc: 0.9449000000\n",
      "Test Acc 9449 Test Tol 10000\n",
      "epoch 2\n",
      "Train Acc: 0.9433833333\n",
      "Train Acc 56603 Train Tol 60000\n",
      "Test Acc: 0.9488000000\n",
      "Test Acc 9488 Test Tol 10000\n",
      "epoch 3\n",
      "Train Acc: 0.9448666667\n",
      "Train Acc 56692 Train Tol 60000\n",
      "Test Acc: 0.9496000000\n",
      "Test Acc 9496 Test Tol 10000\n",
      "epoch 4\n",
      "Train Acc: 0.9490333333\n",
      "Train Acc 56942 Train Tol 60000\n",
      "Test Acc: 0.9523000000\n",
      "Test Acc 9523 Test Tol 10000\n",
      "epoch 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f4ff74937ed6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 因为梯度还要用到后续计算中\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "\n",
    "# model = LSTMrnn(28,57,10,use_gpu)\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "else:\n",
    "    model = model.cpu()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    # training-----------------------------\n",
    "    model.train()\n",
    "    train_acc = 0.\n",
    "\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        \n",
    "        batch_x = batch_x.squeeze(1)\n",
    "        \n",
    "        batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "        \n",
    "        if use_gpu:\n",
    "            batch_x = batch_x.cuda()\n",
    "            batch_y = batch_y.cuda()\n",
    "            \n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)  # 因为梯度还要用到后续计算中\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = torch.max(out, 1)[1]\n",
    "        num_correct = (pred == batch_y).sum()\n",
    "        train_acc += num_correct.data\n",
    "        \n",
    "    print('Train Acc: {:.10f}'.format(train_acc.cpu().numpy()/len(train_dataset)))\n",
    "    print('Train Acc',train_acc.cpu().numpy(),'Train Tol',len(train_dataset))\n",
    "    \n",
    "    # evaluation--------------------------------\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        eval_acc = 0.\n",
    "\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            \n",
    "            batch_x = batch_x.squeeze(1)\n",
    "            \n",
    "            batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "\n",
    "            if use_gpu:\n",
    "                batch_x = batch_x.cuda()\n",
    "                batch_y = batch_y.cuda()\n",
    "\n",
    "            out = model(batch_x)\n",
    "            loss = loss_func(out, batch_y)\n",
    "            \n",
    "            pred = torch.max(out, 1)[1]\n",
    "            num_correct = (pred == batch_y).sum()\n",
    "            eval_acc += num_correct.data\n",
    "            \n",
    "        print('Test Acc: {:.10f}'.format(eval_acc.cpu().numpy()/len(test_dataset)))\n",
    "        print('Test Acc',eval_acc.cpu().numpy(),'Test Tol',len(test_dataset))\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMrnn(28,57,10,use_gpu)\n",
    "model.load_state_dict(torch.load('C:/Users/jxjsj/Desktop/JupyterHome/DLmodel/LSTMrnnMinist.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"C:/Users/jxjsj/Desktop/JupyterHome/DLmodel/LSTMrnnMinist.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
