{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F     # 激励函数都在这\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=1, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 转为 tensor：.numpy()\n",
    "# tensor 转为 numpy: torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | Train Accurancy:  -0.35592877864837646 | Validation Accurancy:  -0.1592344045639038\n",
      "Epoch:  2 | Train Accurancy:  -0.18066442012786865 | Validation Accurancy:  -0.08678698539733887\n",
      "Epoch:  3 | Train Accurancy:  -0.07929337024688721 | Validation Accurancy:  -0.07295680046081543\n",
      "Epoch:  4 | Train Accurancy:  -0.040003180503845215 | Validation Accurancy:  -0.06346619129180908\n",
      "Epoch:  5 | Train Accurancy:  -0.016294121742248535 | Validation Accurancy:  -0.032282352447509766\n",
      "Epoch:  6 | Train Accurancy:  0.016680359840393066 | Validation Accurancy:  0.019817709922790527\n",
      "Epoch:  7 | Train Accurancy:  0.06097286939620972 | Validation Accurancy:  0.07798850536346436\n",
      "Epoch:  8 | Train Accurancy:  0.10667002201080322 | Validation Accurancy:  0.13029605150222778\n",
      "Epoch:  9 | Train Accurancy:  0.14407795667648315 | Validation Accurancy:  0.1671949028968811\n",
      "Epoch:  10 | Train Accurancy:  0.16878312826156616 | Validation Accurancy:  0.194041907787323\n",
      "Epoch:  11 | Train Accurancy:  0.18936854600906372 | Validation Accurancy:  0.22094595432281494\n",
      "Epoch:  12 | Train Accurancy:  0.21584945917129517 | Validation Accurancy:  0.2504081726074219\n",
      "Epoch:  13 | Train Accurancy:  0.25015491247177124 | Validation Accurancy:  0.2782391309738159\n",
      "Epoch:  14 | Train Accurancy:  0.2864745259284973 | Validation Accurancy:  0.29978305101394653\n",
      "Epoch:  15 | Train Accurancy:  0.317976176738739 | Validation Accurancy:  0.31582844257354736\n",
      "Epoch:  16 | Train Accurancy:  0.3427337408065796 | Validation Accurancy:  0.3336235284805298\n",
      "Epoch:  17 | Train Accurancy:  0.3652390241622925 | Validation Accurancy:  0.3594765067100525\n",
      "Epoch:  18 | Train Accurancy:  0.39063483476638794 | Validation Accurancy:  0.3925599455833435\n",
      "Epoch:  19 | Train Accurancy:  0.41879206895828247 | Validation Accurancy:  0.4266500473022461\n",
      "Epoch:  20 | Train Accurancy:  0.4453399181365967 | Validation Accurancy:  0.45552438497543335\n",
      "Epoch:  21 | Train Accurancy:  0.46673476696014404 | Validation Accurancy:  0.4776034355163574\n",
      "Epoch:  22 | Train Accurancy:  0.4837263822555542 | Validation Accurancy:  0.4955558180809021\n",
      "Epoch:  23 | Train Accurancy:  0.5001610517501831 | Validation Accurancy:  0.5113253891468048\n",
      "Epoch:  24 | Train Accurancy:  0.518344521522522 | Validation Accurancy:  0.5243843793869019\n",
      "Epoch:  25 | Train Accurancy:  0.5363430082798004 | Validation Accurancy:  0.533755749464035\n",
      "Epoch:  26 | Train Accurancy:  0.5512409508228302 | Validation Accurancy:  0.5415593385696411\n",
      "Epoch:  27 | Train Accurancy:  0.5630362927913666 | Validation Accurancy:  0.5522916615009308\n",
      "Epoch:  28 | Train Accurancy:  0.5745979249477386 | Validation Accurancy:  0.5683172047138214\n",
      "Epoch:  29 | Train Accurancy:  0.5877606868743896 | Validation Accurancy:  0.5872009098529816\n",
      "Epoch:  30 | Train Accurancy:  0.6012676358222961 | Validation Accurancy:  0.6045560836791992\n",
      "Epoch:  31 | Train Accurancy:  0.612935483455658 | Validation Accurancy:  0.6185164153575897\n",
      "Epoch:  32 | Train Accurancy:  0.6229373216629028 | Validation Accurancy:  0.6302520334720612\n",
      "Epoch:  33 | Train Accurancy:  0.6336373090744019 | Validation Accurancy:  0.6406989693641663\n",
      "Epoch:  34 | Train Accurancy:  0.6456943452358246 | Validation Accurancy:  0.649365097284317\n",
      "Epoch:  35 | Train Accurancy:  0.6571932137012482 | Validation Accurancy:  0.6572490632534027\n",
      "Epoch:  36 | Train Accurancy:  0.6672289669513702 | Validation Accurancy:  0.6674421429634094\n",
      "Epoch:  37 | Train Accurancy:  0.6774993538856506 | Validation Accurancy:  0.6810384392738342\n",
      "Epoch:  38 | Train Accurancy:  0.6890409886837006 | Validation Accurancy:  0.6952126324176788\n",
      "Epoch:  39 | Train Accurancy:  0.7003266513347626 | Validation Accurancy:  0.7073951661586761\n",
      "Epoch:  40 | Train Accurancy:  0.7103281617164612 | Validation Accurancy:  0.7184046506881714\n",
      "Epoch:  41 | Train Accurancy:  0.720596045255661 | Validation Accurancy:  0.7292830049991608\n",
      "Epoch:  42 | Train Accurancy:  0.7317640781402588 | Validation Accurancy:  0.739255964756012\n",
      "Epoch:  43 | Train Accurancy:  0.7421103417873383 | Validation Accurancy:  0.7491194009780884\n",
      "Epoch:  44 | Train Accurancy:  0.751622661948204 | Validation Accurancy:  0.7605445981025696\n",
      "Epoch:  45 | Train Accurancy:  0.7618275433778763 | Validation Accurancy:  0.771949365735054\n",
      "Epoch:  46 | Train Accurancy:  0.771913930773735 | Validation Accurancy:  0.7816672176122665\n",
      "Epoch:  47 | Train Accurancy:  0.7808543741703033 | Validation Accurancy:  0.7914400100708008\n",
      "Epoch:  48 | Train Accurancy:  0.7899870574474335 | Validation Accurancy:  0.8016318678855896\n",
      "Epoch:  49 | Train Accurancy:  0.7991627007722855 | Validation Accurancy:  0.8109608143568039\n",
      "Epoch:  50 | Train Accurancy:  0.807235598564148 | Validation Accurancy:  0.8199737519025803\n",
      "Epoch:  51 | Train Accurancy:  0.8153049647808075 | Validation Accurancy:  0.8281208425760269\n",
      "Epoch:  52 | Train Accurancy:  0.8233194947242737 | Validation Accurancy:  0.834912121295929\n",
      "Epoch:  53 | Train Accurancy:  0.8303364515304565 | Validation Accurancy:  0.8427145630121231\n",
      "Epoch:  54 | Train Accurancy:  0.8373655527830124 | Validation Accurancy:  0.8513672798871994\n",
      "Epoch:  55 | Train Accurancy:  0.8440861254930496 | Validation Accurancy:  0.8589134067296982\n",
      "Epoch:  56 | Train Accurancy:  0.8500127196311951 | Validation Accurancy:  0.8649878352880478\n",
      "Epoch:  57 | Train Accurancy:  0.8560138046741486 | Validation Accurancy:  0.8693615347146988\n",
      "Epoch:  58 | Train Accurancy:  0.8614511787891388 | Validation Accurancy:  0.8742320090532303\n",
      "Epoch:  59 | Train Accurancy:  0.8664243370294571 | Validation Accurancy:  0.8810857459902763\n",
      "Epoch:  60 | Train Accurancy:  0.8713717758655548 | Validation Accurancy:  0.8875038474798203\n",
      "Epoch:  61 | Train Accurancy:  0.8756657913327217 | Validation Accurancy:  0.8919273093342781\n",
      "Epoch:  62 | Train Accurancy:  0.8798388764262199 | Validation Accurancy:  0.8944276794791222\n",
      "Epoch:  63 | Train Accurancy:  0.8837302252650261 | Validation Accurancy:  0.897319383919239\n",
      "Epoch:  64 | Train Accurancy:  0.8871859163045883 | Validation Accurancy:  0.9024937003850937\n",
      "Epoch:  65 | Train Accurancy:  0.8906117081642151 | Validation Accurancy:  0.9076832756400108\n",
      "Epoch:  66 | Train Accurancy:  0.8936054334044456 | Validation Accurancy:  0.9107539802789688\n",
      "Epoch:  67 | Train Accurancy:  0.8964777961373329 | Validation Accurancy:  0.9119280502200127\n",
      "Epoch:  68 | Train Accurancy:  0.8991580754518509 | Validation Accurancy:  0.9138154312968254\n",
      "Epoch:  69 | Train Accurancy:  0.9015523418784142 | Validation Accurancy:  0.9179493933916092\n",
      "Epoch:  70 | Train Accurancy:  0.9039060398936272 | Validation Accurancy:  0.9219501465559006\n",
      "Epoch:  71 | Train Accurancy:  0.9059679955244064 | Validation Accurancy:  0.9237791076302528\n",
      "Epoch:  72 | Train Accurancy:  0.9079700037837029 | Validation Accurancy:  0.9241433814167976\n",
      "Epoch:  73 | Train Accurancy:  0.9098003655672073 | Validation Accurancy:  0.9257839545607567\n",
      "Epoch:  74 | Train Accurancy:  0.9114851802587509 | Validation Accurancy:  0.9292962402105331\n",
      "Epoch:  75 | Train Accurancy:  0.9131072834134102 | Validation Accurancy:  0.9320969581604004\n",
      "Epoch:  76 | Train Accurancy:  0.9145474135875702 | Validation Accurancy:  0.9327987655997276\n",
      "Epoch:  77 | Train Accurancy:  0.9159626215696335 | Validation Accurancy:  0.9329002052545547\n",
      "Epoch:  78 | Train Accurancy:  0.9172255620360374 | Validation Accurancy:  0.9347875937819481\n",
      "Epoch:  79 | Train Accurancy:  0.9184418991208076 | Validation Accurancy:  0.9376951232552528\n",
      "Epoch:  80 | Train Accurancy:  0.9195640459656715 | Validation Accurancy:  0.9392090477049351\n",
      "Epoch:  81 | Train Accurancy:  0.9206089973449707 | Validation Accurancy:  0.9391215965151787\n",
      "Epoch:  82 | Train Accurancy:  0.9216095209121704 | Validation Accurancy:  0.939624659717083\n",
      "Epoch:  83 | Train Accurancy:  0.922517217695713 | Validation Accurancy:  0.9418095275759697\n",
      "Epoch:  84 | Train Accurancy:  0.9234034195542336 | Validation Accurancy:  0.9437944740056992\n",
      "Epoch:  85 | Train Accurancy:  0.9242030307650566 | Validation Accurancy:  0.9441330283880234\n",
      "Epoch:  86 | Train Accurancy:  0.9249848499894142 | Validation Accurancy:  0.9440010711550713\n",
      "Epoch:  87 | Train Accurancy:  0.9256982579827309 | Validation Accurancy:  0.9452696181833744\n",
      "Epoch:  88 | Train Accurancy:  0.9263870045542717 | Validation Accurancy:  0.9472331665456295\n",
      "Epoch:  89 | Train Accurancy:  0.927027516067028 | Validation Accurancy:  0.9480252899229527\n",
      "Epoch:  90 | Train Accurancy:  0.9276365712285042 | Validation Accurancy:  0.9478061683475971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  91 | Train Accurancy:  0.9282141923904419 | Validation Accurancy:  0.9483961723744869\n",
      "Epoch:  92 | Train Accurancy:  0.9287562221288681 | Validation Accurancy:  0.950060810893774\n",
      "Epoch:  93 | Train Accurancy:  0.9292779043316841 | Validation Accurancy:  0.9511137343943119\n",
      "Epoch:  94 | Train Accurancy:  0.9297638684511185 | Validation Accurancy:  0.9510387405753136\n",
      "Epoch:  95 | Train Accurancy:  0.9302360266447067 | Validation Accurancy:  0.9512654952704906\n",
      "Epoch:  96 | Train Accurancy:  0.9306750223040581 | Validation Accurancy:  0.9525754302740097\n",
      "Epoch:  97 | Train Accurancy:  0.9311030805110931 | Validation Accurancy:  0.9536950439214706\n",
      "Epoch:  98 | Train Accurancy:  0.9315019473433495 | Validation Accurancy:  0.9537836387753487\n",
      "Epoch:  99 | Train Accurancy:  0.9318914860486984 | Validation Accurancy:  0.9538706131279469\n",
      "Epoch:  100 | Train Accurancy:  0.9322556853294373 | Validation Accurancy:  0.9549034424126148\n",
      "Epoch:  101 | Train Accurancy:  0.9326115548610687 | Validation Accurancy:  0.9559720978140831\n",
      "Epoch:  102 | Train Accurancy:  0.9329458475112915 | Validation Accurancy:  0.9561681114137173\n",
      "Epoch:  103 | Train Accurancy:  0.9332720786333084 | Validation Accurancy:  0.956234771758318\n",
      "Epoch:  104 | Train Accurancy:  0.9335801601409912 | Validation Accurancy:  0.9570891074836254\n",
      "Epoch:  105 | Train Accurancy:  0.9338805451989174 | Validation Accurancy:  0.9580542556941509\n",
      "Epoch:  106 | Train Accurancy:  0.9341654181480408 | Validation Accurancy:  0.9582903534173965\n",
      "Epoch:  107 | Train Accurancy:  0.9344431757926941 | Validation Accurancy:  0.9583893157541752\n",
      "Epoch:  108 | Train Accurancy:  0.934707522392273 | Validation Accurancy:  0.9591471664607525\n",
      "Epoch:  109 | Train Accurancy:  0.9349652901291847 | Validation Accurancy:  0.959993489086628\n",
      "Epoch:  110 | Train Accurancy:  0.9352112710475922 | Validation Accurancy:  0.9602213241159916\n",
      "Epoch:  111 | Train Accurancy:  0.9354514479637146 | Validation Accurancy:  0.9603755325078964\n",
      "Epoch:  112 | Train Accurancy:  0.9356811866164207 | Validation Accurancy:  0.9610890075564384\n",
      "Epoch:  113 | Train Accurancy:  0.935905747115612 | Validation Accurancy:  0.9618114791810513\n",
      "Epoch:  114 | Train Accurancy:  0.9361210241913795 | Validation Accurancy:  0.9620092697441578\n",
      "Epoch:  115 | Train Accurancy:  0.9363315254449844 | Validation Accurancy:  0.9622343704104424\n",
      "Epoch:  116 | Train Accurancy:  0.9365338310599327 | Validation Accurancy:  0.9629254005849361\n",
      "Epoch:  117 | Train Accurancy:  0.9367318153381348 | Validation Accurancy:  0.9635198898613453\n",
      "Epoch:  118 | Train Accurancy:  0.9369225949048996 | Validation Accurancy:  0.9636935852468014\n",
      "Epoch:  119 | Train Accurancy:  0.9371091350913048 | Validation Accurancy:  0.9640022292733192\n",
      "Epoch:  120 | Train Accurancy:  0.9372895732522011 | Validation Accurancy:  0.964663602411747\n",
      "Epoch:  121 | Train Accurancy:  0.9374658837914467 | Validation Accurancy:  0.9651270881295204\n",
      "Epoch:  122 | Train Accurancy:  0.9376369118690491 | Validation Accurancy:  0.9652979858219624\n",
      "Epoch:  123 | Train Accurancy:  0.937803890556097 | Validation Accurancy:  0.9656944908201694\n",
      "Epoch:  124 | Train Accurancy:  0.937966488301754 | Validation Accurancy:  0.9663004241883755\n",
      "Epoch:  125 | Train Accurancy:  0.9381250999867916 | Validation Accurancy:  0.9666442237794399\n",
      "Epoch:  126 | Train Accurancy:  0.9382800050079823 | Validation Accurancy:  0.966850820928812\n",
      "Epoch:  127 | Train Accurancy:  0.9384310245513916 | Validation Accurancy:  0.9673202522099018\n",
      "Epoch:  128 | Train Accurancy:  0.938578873872757 | Validation Accurancy:  0.9678363800048828\n",
      "Epoch:  129 | Train Accurancy:  0.9387230686843395 | Validation Accurancy:  0.9680941253900528\n",
      "Epoch:  130 | Train Accurancy:  0.9388644397258759 | Validation Accurancy:  0.9683722481131554\n",
      "Epoch:  131 | Train Accurancy:  0.9390023611485958 | Validation Accurancy:  0.9688699077814817\n",
      "Epoch:  132 | Train Accurancy:  0.9391377978026867 | Validation Accurancy:  0.969273503869772\n",
      "Epoch:  133 | Train Accurancy:  0.9392701610922813 | Validation Accurancy:  0.9695015586912632\n",
      "Epoch:  134 | Train Accurancy:  0.9394000582396984 | Validation Accurancy:  0.9698632247745991\n",
      "Epoch:  135 | Train Accurancy:  0.9395273365080357 | Validation Accurancy:  0.9703303016722202\n",
      "Epoch:  136 | Train Accurancy:  0.9396520256996155 | Validation Accurancy:  0.9706322029232979\n",
      "Epoch:  137 | Train Accurancy:  0.9397746622562408 | Validation Accurancy:  0.9708906803280115\n",
      "Epoch:  138 | Train Accurancy:  0.9398946687579155 | Validation Accurancy:  0.9713063556700945\n",
      "Epoch:  139 | Train Accurancy:  0.9400128535926342 | Validation Accurancy:  0.9716940242797136\n",
      "Epoch:  140 | Train Accurancy:  0.9401286095380783 | Validation Accurancy:  0.9719418212771416\n",
      "Epoch:  141 | Train Accurancy:  0.9402426891028881 | Validation Accurancy:  0.9722660072147846\n",
      "Epoch:  142 | Train Accurancy:  0.9403546638786793 | Validation Accurancy:  0.9726767539978027\n",
      "Epoch:  143 | Train Accurancy:  0.9404648318886757 | Validation Accurancy:  0.972974268719554\n",
      "Epoch:  144 | Train Accurancy:  0.9405732676386833 | Validation Accurancy:  0.9732360206544399\n",
      "Epoch:  145 | Train Accurancy:  0.9406799115240574 | Validation Accurancy:  0.9736085254698992\n",
      "Epoch:  146 | Train Accurancy:  0.9407851062715054 | Validation Accurancy:  0.9739547409117222\n",
      "Epoch:  147 | Train Accurancy:  0.9408885203301907 | Validation Accurancy:  0.9742066692560911\n",
      "Epoch:  148 | Train Accurancy:  0.9409904070198536 | Validation Accurancy:  0.9745200481265783\n",
      "Epoch:  149 | Train Accurancy:  0.9410908855497837 | Validation Accurancy:  0.9748809169977903\n",
      "Epoch:  150 | Train Accurancy:  0.9411899521946907 | Validation Accurancy:  0.9751554802060127\n",
      "Epoch:  151 | Train Accurancy:  0.9412875771522522 | Validation Accurancy:  0.9754249565303326\n",
      "Epoch:  152 | Train Accurancy:  0.9413839131593704 | Validation Accurancy:  0.9757675491273403\n",
      "Epoch:  153 | Train Accurancy:  0.9414789900183678 | Validation Accurancy:  0.9760678298771381\n",
      "Epoch:  154 | Train Accurancy:  0.9415728189051151 | Validation Accurancy:  0.9763189312070608\n",
      "Epoch:  155 | Train Accurancy:  0.9416655115783215 | Validation Accurancy:  0.9766282085329294\n",
      "Epoch:  156 | Train Accurancy:  0.9417568929493427 | Validation Accurancy:  0.9769406002014875\n",
      "Epoch:  157 | Train Accurancy:  0.9418472535908222 | Validation Accurancy:  0.9771924968808889\n",
      "Epoch:  158 | Train Accurancy:  0.941936518996954 | Validation Accurancy:  0.9774702712893486\n",
      "Epoch:  159 | Train Accurancy:  0.9420247562229633 | Validation Accurancy:  0.9777796100825071\n",
      "Epoch:  160 | Train Accurancy:  0.942111898213625 | Validation Accurancy:  0.978036530315876\n",
      "Epoch:  161 | Train Accurancy:  0.9421981237828732 | Validation Accurancy:  0.97829351387918\n",
      "Epoch:  162 | Train Accurancy:  0.9422834143042564 | Validation Accurancy:  0.9785904251039028\n",
      "Epoch:  163 | Train Accurancy:  0.9423677772283554 | Validation Accurancy:  0.9788540843874216\n",
      "Epoch:  164 | Train Accurancy:  0.9424511715769768 | Validation Accurancy:  0.9790966678410769\n",
      "Epoch:  165 | Train Accurancy:  0.9425338506698608 | Validation Accurancy:  0.9793765712529421\n",
      "Epoch:  166 | Train Accurancy:  0.9426155239343643 | Validation Accurancy:  0.979642104357481\n",
      "Epoch:  167 | Train Accurancy:  0.9426963999867439 | Validation Accurancy:  0.979877408593893\n",
      "Epoch:  168 | Train Accurancy:  0.942776545882225 | Validation Accurancy:  0.9801396373659372\n",
      "Epoch:  169 | Train Accurancy:  0.9428559504449368 | Validation Accurancy:  0.9804021827876568\n",
      "Epoch:  170 | Train Accurancy:  0.942934513092041 | Validation Accurancy:  0.980633893981576\n",
      "Epoch:  171 | Train Accurancy:  0.9430124126374722 | Validation Accurancy:  0.980880992487073\n",
      "Epoch:  172 | Train Accurancy:  0.9430895484983921 | Validation Accurancy:  0.9811362903565168\n",
      "Epoch:  173 | Train Accurancy:  0.9431659765541553 | Validation Accurancy:  0.9813650455325842\n",
      "Epoch:  174 | Train Accurancy:  0.9432417638599873 | Validation Accurancy:  0.9816003795713186\n",
      "Epoch:  175 | Train Accurancy:  0.9433169737458229 | Validation Accurancy:  0.9818471278995275\n",
      "Epoch:  176 | Train Accurancy:  0.9433914050459862 | Validation Accurancy:  0.9820721633732319\n",
      "Epoch:  177 | Train Accurancy:  0.9434653073549271 | Validation Accurancy:  0.9822972305119038\n",
      "Epoch:  178 | Train Accurancy:  0.9435385465621948 | Validation Accurancy:  0.9825345035642385\n",
      "Epoch:  179 | Train Accurancy:  0.9436111524701118 | Validation Accurancy:  0.9827569965273142\n",
      "Epoch:  180 | Train Accurancy:  0.9436832554638386 | Validation Accurancy:  0.982971541583538\n",
      "Epoch:  181 | Train Accurancy:  0.9437547624111176 | Validation Accurancy:  0.9831996280699968\n",
      "Epoch:  182 | Train Accurancy:  0.9438257105648518 | Validation Accurancy:  0.9834159538149834\n",
      "Epoch:  183 | Train Accurancy:  0.9438962191343307 | Validation Accurancy:  0.9836235996335745\n",
      "Epoch:  184 | Train Accurancy:  0.9439660906791687 | Validation Accurancy:  0.9838416092097759\n",
      "Epoch:  185 | Train Accurancy:  0.9440355226397514 | Validation Accurancy:  0.984052212908864\n",
      "Epoch:  186 | Train Accurancy:  0.9441043771803379 | Validation Accurancy:  0.9842533431947231\n",
      "Epoch:  187 | Train Accurancy:  0.9441727437078953 | Validation Accurancy:  0.9844629289582372\n",
      "Epoch:  188 | Train Accurancy:  0.9442406632006168 | Validation Accurancy:  0.9846665067598224\n",
      "Epoch:  189 | Train Accurancy:  0.9443081170320511 | Validation Accurancy:  0.9848611196503043\n",
      "Epoch:  190 | Train Accurancy:  0.9443750865757465 | Validation Accurancy:  0.9850629810243845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  191 | Train Accurancy:  0.9444415494799614 | Validation Accurancy:  0.9852588335052133\n",
      "Epoch:  192 | Train Accurancy:  0.944507610052824 | Validation Accurancy:  0.9854477243497968\n",
      "Epoch:  193 | Train Accurancy:  0.9445733092725277 | Validation Accurancy:  0.9856418929994106\n",
      "Epoch:  194 | Train Accurancy:  0.9446385391056538 | Validation Accurancy:  0.9858304345980287\n",
      "Epoch:  195 | Train Accurancy:  0.9447033815085888 | Validation Accurancy:  0.9860129673033953\n",
      "Epoch:  196 | Train Accurancy:  0.944767739623785 | Validation Accurancy:  0.9862003326416016\n",
      "Epoch:  197 | Train Accurancy:  0.9448317475616932 | Validation Accurancy:  0.9863810855895281\n",
      "Epoch:  198 | Train Accurancy:  0.9448953680694103 | Validation Accurancy:  0.9865583097562194\n",
      "Epoch:  199 | Train Accurancy:  0.9449585415422916 | Validation Accurancy:  0.9867380456998944\n",
      "Epoch:  200 | Train Accurancy:  0.9450213275849819 | Validation Accurancy:  0.9869121871888638\n",
      "Epoch:  201 | Train Accurancy:  0.9450837895274162 | Validation Accurancy:  0.9870834667235613\n",
      "Epoch:  202 | Train Accurancy:  0.9451458938419819 | Validation Accurancy:  0.9872566862031817\n",
      "Epoch:  203 | Train Accurancy:  0.945207666605711 | Validation Accurancy:  0.9874238967895508\n",
      "Epoch:  204 | Train Accurancy:  0.9452690295875072 | Validation Accurancy:  0.9875896451994777\n",
      "Epoch:  205 | Train Accurancy:  0.945330124348402 | Validation Accurancy:  0.9877551076933742\n",
      "Epoch:  206 | Train Accurancy:  0.9453907646238804 | Validation Accurancy:  0.9879166604951024\n",
      "Epoch:  207 | Train Accurancy:  0.9454512149095535 | Validation Accurancy:  0.9880766235291958\n",
      "Epoch:  208 | Train Accurancy:  0.9455112926661968 | Validation Accurancy:  0.988235441967845\n",
      "Epoch:  209 | Train Accurancy:  0.9455708600580692 | Validation Accurancy:  0.9883908592164516\n",
      "Epoch:  210 | Train Accurancy:  0.9456303715705872 | Validation Accurancy:  0.9885451318696141\n",
      "Epoch:  211 | Train Accurancy:  0.9456893876194954 | Validation Accurancy:  0.9886979423463345\n",
      "Epoch:  212 | Train Accurancy:  0.9457481876015663 | Validation Accurancy:  0.9888473507016897\n",
      "Epoch:  213 | Train Accurancy:  0.9458065964281559 | Validation Accurancy:  0.9889955520629883\n",
      "Epoch:  214 | Train Accurancy:  0.9458648078143597 | Validation Accurancy:  0.9891425454989076\n",
      "Epoch:  215 | Train Accurancy:  0.9459226131439209 | Validation Accurancy:  0.9892862318083644\n",
      "Epoch:  216 | Train Accurancy:  0.9459802582859993 | Validation Accurancy:  0.9894290287047625\n",
      "Epoch:  217 | Train Accurancy:  0.9460374973714352 | Validation Accurancy:  0.9895701725035906\n",
      "Epoch:  218 | Train Accurancy:  0.9460944905877113 | Validation Accurancy:  0.9897080417722464\n",
      "Epoch:  219 | Train Accurancy:  0.9461512453854084 | Validation Accurancy:  0.989845784381032\n",
      "Epoch:  220 | Train Accurancy:  0.946207694709301 | Validation Accurancy:  0.9899806343019009\n",
      "Epoch:  221 | Train Accurancy:  0.9462637826800346 | Validation Accurancy:  0.9901138301938772\n",
      "Epoch:  222 | Train Accurancy:  0.9463196806609631 | Validation Accurancy:  0.9902460100129247\n",
      "Epoch:  223 | Train Accurancy:  0.946375384926796 | Validation Accurancy:  0.9903752962127328\n",
      "Epoch:  224 | Train Accurancy:  0.9464307874441147 | Validation Accurancy:  0.9905035654082894\n",
      "Epoch:  225 | Train Accurancy:  0.9464858435094357 | Validation Accurancy:  0.990630435757339\n",
      "Epoch:  226 | Train Accurancy:  0.9465407468378544 | Validation Accurancy:  0.9907543500885367\n",
      "Epoch:  227 | Train Accurancy:  0.9465954340994358 | Validation Accurancy:  0.9908780418336391\n",
      "Epoch:  228 | Train Accurancy:  0.9466497823596001 | Validation Accurancy:  0.9909990942105651\n",
      "Epoch:  229 | Train Accurancy:  0.9467039257287979 | Validation Accurancy:  0.9911187486723065\n",
      "Epoch:  230 | Train Accurancy:  0.946757860481739 | Validation Accurancy:  0.9912371318787336\n",
      "Epoch:  231 | Train Accurancy:  0.946811530739069 | Validation Accurancy:  0.9913534168154001\n",
      "Epoch:  232 | Train Accurancy:  0.9468649439513683 | Validation Accurancy:  0.9914681119844317\n",
      "Epoch:  233 | Train Accurancy:  0.946918174624443 | Validation Accurancy:  0.9915821077302098\n",
      "Epoch:  234 | Train Accurancy:  0.9469711259007454 | Validation Accurancy:  0.9916933057829738\n",
      "Epoch:  235 | Train Accurancy:  0.9470239020884037 | Validation Accurancy:  0.9918039320036769\n",
      "Epoch:  236 | Train Accurancy:  0.947076391428709 | Validation Accurancy:  0.9919124599546194\n",
      "Epoch:  237 | Train Accurancy:  0.947128739207983 | Validation Accurancy:  0.9920196533203125\n",
      "Epoch:  238 | Train Accurancy:  0.9471807479858398 | Validation Accurancy:  0.9921257020905614\n",
      "Epoch:  239 | Train Accurancy:  0.9472326710820198 | Validation Accurancy:  0.9922297797165811\n",
      "Epoch:  240 | Train Accurancy:  0.9472843632102013 | Validation Accurancy:  0.9923329036682844\n",
      "Epoch:  241 | Train Accurancy:  0.9473357759416103 | Validation Accurancy:  0.9924344378523529\n",
      "Epoch:  242 | Train Accurancy:  0.9473870135843754 | Validation Accurancy:  0.9925343194045126\n",
      "Epoch:  243 | Train Accurancy:  0.9474380575120449 | Validation Accurancy:  0.9926330568268895\n",
      "Epoch:  244 | Train Accurancy:  0.9474888518452644 | Validation Accurancy:  0.9927302044816315\n",
      "Epoch:  245 | Train Accurancy:  0.9475395493209362 | Validation Accurancy:  0.9928262075409293\n",
      "Epoch:  246 | Train Accurancy:  0.9475899152457714 | Validation Accurancy:  0.992920748423785\n",
      "Epoch:  247 | Train Accurancy:  0.9476401247084141 | Validation Accurancy:  0.9930143356323242\n",
      "Epoch:  248 | Train Accurancy:  0.9476901665329933 | Validation Accurancy:  0.9931062697432935\n",
      "Epoch:  249 | Train Accurancy:  0.9477399811148643 | Validation Accurancy:  0.9931969959288836\n",
      "Epoch:  250 | Train Accurancy:  0.9477896653115749 | Validation Accurancy:  0.9932862599380314\n",
      "Epoch:  251 | Train Accurancy:  0.9478391148149967 | Validation Accurancy:  0.9933745702728629\n",
      "Epoch:  252 | Train Accurancy:  0.9478884227573872 | Validation Accurancy:  0.9934612908400595\n",
      "Epoch:  253 | Train Accurancy:  0.9479374885559082 | Validation Accurancy:  0.9935472486540675\n",
      "Epoch:  254 | Train Accurancy:  0.9479864053428173 | Validation Accurancy:  0.9936315538361669\n",
      "Epoch:  255 | Train Accurancy:  0.9480350762605667 | Validation Accurancy:  0.993715095333755\n",
      "Epoch:  256 | Train Accurancy:  0.9480836316943169 | Validation Accurancy:  0.9937969208694994\n",
      "Epoch:  257 | Train Accurancy:  0.9481319785118103 | Validation Accurancy:  0.9938781736418605\n",
      "Epoch:  258 | Train Accurancy:  0.9481800571084023 | Validation Accurancy:  0.9939581551589072\n",
      "Epoch:  259 | Train Accurancy:  0.9482280872762203 | Validation Accurancy:  0.9940366744995117\n",
      "Epoch:  260 | Train Accurancy:  0.9482759274542332 | Validation Accurancy:  0.9941142401657999\n",
      "Epoch:  261 | Train Accurancy:  0.9483236223459244 | Validation Accurancy:  0.9941905974410474\n",
      "Epoch:  262 | Train Accurancy:  0.948370985686779 | Validation Accurancy:  0.994266064837575\n",
      "Epoch:  263 | Train Accurancy:  0.948418315500021 | Validation Accurancy:  0.9943404514342546\n",
      "Epoch:  264 | Train Accurancy:  0.9484653808176517 | Validation Accurancy:  0.9944136939011514\n",
      "Epoch:  265 | Train Accurancy:  0.9485123828053474 | Validation Accurancy:  0.9944857913069427\n",
      "Epoch:  266 | Train Accurancy:  0.9485591985285282 | Validation Accurancy:  0.9945568721741438\n",
      "Epoch:  267 | Train Accurancy:  0.9486057572066784 | Validation Accurancy:  0.9946269989013672\n",
      "Epoch:  268 | Train Accurancy:  0.9486522115767002 | Validation Accurancy:  0.994696426205337\n",
      "Epoch:  269 | Train Accurancy:  0.9486984871327877 | Validation Accurancy:  0.9947645189240575\n",
      "Epoch:  270 | Train Accurancy:  0.9487445950508118 | Validation Accurancy:  0.9948316575028002\n",
      "Epoch:  271 | Train Accurancy:  0.9487906135618687 | Validation Accurancy:  0.9948978424072266\n",
      "Epoch:  272 | Train Accurancy:  0.9488363862037659 | Validation Accurancy:  0.9949629465118051\n",
      "Epoch:  273 | Train Accurancy:  0.9488820247352123 | Validation Accurancy:  0.99502735119313\n",
      "Epoch:  274 | Train Accurancy:  0.9489274993538857 | Validation Accurancy:  0.9950906755402684\n",
      "Epoch:  275 | Train Accurancy:  0.9489728473126888 | Validation Accurancy:  0.9951532362028956\n",
      "Epoch:  276 | Train Accurancy:  0.949017945677042 | Validation Accurancy:  0.9952144622802734\n",
      "Epoch:  277 | Train Accurancy:  0.9490629360079765 | Validation Accurancy:  0.9952754974365234\n",
      "Epoch:  278 | Train Accurancy:  0.9491077773272991 | Validation Accurancy:  0.9953347523696721\n",
      "Epoch:  279 | Train Accurancy:  0.949152547866106 | Validation Accurancy:  0.9953940073028207\n",
      "Epoch:  280 | Train Accurancy:  0.9491970501840115 | Validation Accurancy:  0.995451990980655\n",
      "Epoch:  281 | Train Accurancy:  0.9492413997650146 | Validation Accurancy:  0.9955095928162336\n",
      "Epoch:  282 | Train Accurancy:  0.949285663664341 | Validation Accurancy:  0.9955650963820517\n",
      "Epoch:  283 | Train Accurancy:  0.9493297822773457 | Validation Accurancy:  0.9956218083389103\n",
      "Epoch:  284 | Train Accurancy:  0.9493737146258354 | Validation Accurancy:  0.9956750869750977\n",
      "Epoch:  285 | Train Accurancy:  0.949417483061552 | Validation Accurancy:  0.9957306543365121\n",
      "Epoch:  286 | Train Accurancy:  0.949461042881012 | Validation Accurancy:  0.9957816442474723\n",
      "Epoch:  287 | Train Accurancy:  0.9495044872164726 | Validation Accurancy:  0.995836703106761\n",
      "Epoch:  288 | Train Accurancy:  0.9495478309690952 | Validation Accurancy:  0.9958848315291107\n",
      "Epoch:  289 | Train Accurancy:  0.9495909996330738 | Validation Accurancy:  0.9959404626861215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  290 | Train Accurancy:  0.949634063988924 | Validation Accurancy:  0.9959833147004247\n",
      "Epoch:  291 | Train Accurancy:  0.9496768228709698 | Validation Accurancy:  0.9960426329635084\n",
      "Epoch:  292 | Train Accurancy:  0.9497195668518543 | Validation Accurancy:  0.9960771561600268\n",
      "Epoch:  293 | Train Accurancy:  0.9497620426118374 | Validation Accurancy:  0.9961455026641488\n",
      "Epoch:  294 | Train Accurancy:  0.9498044140636921 | Validation Accurancy:  0.9961620967369527\n",
      "Epoch:  295 | Train Accurancy:  0.9498464018106461 | Validation Accurancy:  0.9962540944106877\n",
      "Epoch:  296 | Train Accurancy:  0.9498879313468933 | Validation Accurancy:  0.9962302525527775\n"
     ]
    }
   ],
   "source": [
    "# 回归问题\n",
    "class Net(torch.nn.Module):  # 继承 torch 的 Module\n",
    "    def __init__(self, n_feature, n_hidden, n_hidden1, n_output):\n",
    "        super(Net, self).__init__()     # 继承 __init__ 功能\n",
    "        # 定义每层用什么样的形式\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # 隐藏层线性输出\n",
    "        self.hidden1 = torch.nn.Linear(n_hidden, n_hidden1)\n",
    "        self.predict = torch.nn.Linear(n_hidden1, n_output)   # 输出层线性输出\n",
    "\n",
    "    def forward(self, x):   # 这同时也是 Module 中的 forward 功能\n",
    "        # 正向传播输入值, 神经网络分析出输出值\n",
    "        x = F.relu(self.hidden(x))      # 激励函数(隐藏层的线性值)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.predict(x)             # 输出值\n",
    "        return x\n",
    "\n",
    "net = Net(n_feature=4, n_hidden=9, n_hidden1=19, n_output=4)\n",
    "\n",
    "NNtrain(\n",
    "    X=iris.data, \n",
    "    y=iris.target, \n",
    "    model=net, \n",
    "    task='C', \n",
    "    lossf=nn.CrossEntropyLoss(), \n",
    "    optimizer=torch.optim.Adam(net.parameters(), lr=0.01), \n",
    "    epochs=30000, \n",
    "    train_size=0.9, \n",
    "    device = 'CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Train Accurancy:  -18.78186798095703 | Validation Accurancy:  -1.9435911178588867\n"
     ]
    }
   ],
   "source": [
    "# 线性回归\n",
    "x_train_tr = torch.from_numpy(x_train).float()\n",
    "y_train_tr = torch.from_numpy(y_train).float()\n",
    "x_test_tr = torch.from_numpy(x_test).float()\n",
    "y_test_tr = torch.from_numpy(y_test).float()\n",
    "\n",
    "class LinearRegress(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegress, self).__init__()\n",
    "        self.predict = torch.nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.predict(x)\n",
    "\n",
    "lreg = LinearRegress()\n",
    "\n",
    "# optimizer 是训练的工具\n",
    "optimizer = torch.optim.SGD(lreg.parameters(), lr=0.01)  # 传入 net 的所有参数, 学习率\n",
    "loss_func = torch.nn.MSELoss()      # 预测值和真实值的误差计算公式 (均方差)\n",
    "\n",
    "for epoch in range(100000):   # 训练所有!整套!数据 N 次\n",
    "    out = lreg(x_train_tr)\n",
    "    loss = loss_func(out, y_train_tr)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    out_val = lreg(x_test_tr)\n",
    "    loss_val = loss_func(out_val, y_test_tr)\n",
    "    print('Epoch: ', epoch, '| Train Accurancy: ', 1-float(loss), '| Validation Accurancy: ', 1-float(loss_val))\n",
    "    \n",
    "    loss_val_past = -9999\n",
    "    if float(loss_val) > float(loss_val_past) or (float(loss_val_past)-float(loss_val))<1e-7:\n",
    "        break\n",
    "    else:\n",
    "        loss_val_past = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNtrain(X, y, model, task, lossf, optimizer, epochs, train_size, device = 'CPU'):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=1, train_size=train_size)\n",
    "    \n",
    "    if task == 'C':\n",
    "        x_train_tr = torch.from_numpy(x_train).float()\n",
    "        y_train_tr = torch.from_numpy(y_train).long()\n",
    "        x_test_tr = torch.from_numpy(x_test).float()\n",
    "        y_test_tr = torch.from_numpy(y_test).long()\n",
    "    if task == 'R':\n",
    "        x_train_tr = torch.from_numpy(x_train).float()\n",
    "        y_train_tr = torch.from_numpy(y_train).float()\n",
    "        x_test_tr = torch.from_numpy(x_test).float()\n",
    "        y_test_tr = torch.from_numpy(y_test).float()\n",
    "        \n",
    "    if device =='GPU':\n",
    "        model_used = model.cuda()\n",
    "        x_train_tr_used = x_train_tr.cuda()\n",
    "        y_train_tr_used = y_train_tr.cuda()\n",
    "        x_test_tr_used = x_test_tr.cuda()\n",
    "        y_test_tr_used = y_test_tr.cuda()\n",
    "    if device == 'CPU':\n",
    "        model_used = model\n",
    "        x_train_tr_used = x_train_tr\n",
    "        y_train_tr_used = y_train_tr\n",
    "        x_test_tr_used = x_test_tr\n",
    "        y_test_tr_used = y_test_tr\n",
    "    \n",
    "    optimizer = optimizer\n",
    "    loss_func = lossf\n",
    "    loss_val_past = 9999\n",
    "    loss_past = 9999\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        predict = model_used(x_train_tr_used)\n",
    "        loss = loss_func(predict, y_train_tr_used)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        out_val = model_used(x_test_tr_used)\n",
    "        loss_val = loss_func(out_val, y_test_tr_used)\n",
    "        print('Epoch: ', epoch+1, '| Train Accurancy: ', 1-float(loss), '| Validation Accurancy: ', 1-float(loss_val))\n",
    "\n",
    "        if (float(loss_val) > float(loss_val_past) and epoch>99) or ((float(loss_past)-float(loss))<1e-7 and epoch>99):\n",
    "            break\n",
    "        else:\n",
    "            loss_val_past = loss_val\n",
    "            loss_past = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=4, out_features=15, bias=True)\n",
      "  (out): Linear(in_features=15, out_features=4, bias=True)\n",
      ")\n",
      "Epoch:  1 | Train Accurancy:  -0.47152066230773926 | Validation Accurancy:  -0.45536673069000244\n",
      "Epoch:  2 | Train Accurancy:  -0.4187411069869995 | Validation Accurancy:  -0.4240950345993042\n",
      "Epoch:  3 | Train Accurancy:  -0.37412238121032715 | Validation Accurancy:  -0.39763617515563965\n",
      "Epoch:  4 | Train Accurancy:  -0.3362773656845093 | Validation Accurancy:  -0.3747828006744385\n",
      "Epoch:  5 | Train Accurancy:  -0.3039745092391968 | Validation Accurancy:  -0.35467469692230225\n",
      "Epoch:  6 | Train Accurancy:  -0.27610182762145996 | Validation Accurancy:  -0.3367575407028198\n",
      "Epoch:  7 | Train Accurancy:  -0.251808762550354 | Validation Accurancy:  -0.32056355476379395\n",
      "Epoch:  8 | Train Accurancy:  -0.230401873588562 | Validation Accurancy:  -0.3057277202606201\n",
      "Epoch:  9 | Train Accurancy:  -0.21135318279266357 | Validation Accurancy:  -0.2919117212295532\n",
      "Epoch:  10 | Train Accurancy:  -0.19425857067108154 | Validation Accurancy:  -0.2789701223373413\n",
      "Epoch:  11 | Train Accurancy:  -0.17874252796173096 | Validation Accurancy:  -0.2667555809020996\n",
      "Epoch:  12 | Train Accurancy:  -0.16453778743743896 | Validation Accurancy:  -0.2551610469818115\n",
      "Epoch:  13 | Train Accurancy:  -0.15143442153930664 | Validation Accurancy:  -0.24410653114318848\n",
      "Epoch:  14 | Train Accurancy:  -0.13926458358764648 | Validation Accurancy:  -0.23353302478790283\n",
      "Epoch:  15 | Train Accurancy:  -0.12789320945739746 | Validation Accurancy:  -0.22339403629302979\n",
      "Epoch:  16 | Train Accurancy:  -0.11721158027648926 | Validation Accurancy:  -0.21365272998809814\n",
      "Epoch:  17 | Train Accurancy:  -0.10713720321655273 | Validation Accurancy:  -0.20417606830596924\n",
      "Epoch:  18 | Train Accurancy:  -0.09760785102844238 | Validation Accurancy:  -0.19505727291107178\n",
      "Epoch:  19 | Train Accurancy:  -0.08854401111602783 | Validation Accurancy:  -0.1862722635269165\n",
      "Epoch:  20 | Train Accurancy:  -0.07989645004272461 | Validation Accurancy:  -0.1777433156967163\n",
      "Epoch:  21 | Train Accurancy:  -0.0716254711151123 | Validation Accurancy:  -0.16951322555541992\n",
      "Epoch:  22 | Train Accurancy:  -0.06368815898895264 | Validation Accurancy:  -0.1615617275238037\n",
      "Epoch:  23 | Train Accurancy:  -0.0560605525970459 | Validation Accurancy:  -0.1538177728652954\n",
      "Epoch:  24 | Train Accurancy:  -0.04872739315032959 | Validation Accurancy:  -0.14632916450500488\n",
      "Epoch:  25 | Train Accurancy:  -0.04163956642150879 | Validation Accurancy:  -0.1390758752822876\n",
      "Epoch:  26 | Train Accurancy:  -0.03477585315704346 | Validation Accurancy:  -0.1320410966873169\n",
      "Epoch:  27 | Train Accurancy:  -0.028116941452026367 | Validation Accurancy:  -0.12520790100097656\n",
      "Epoch:  28 | Train Accurancy:  -0.02164614200592041 | Validation Accurancy:  -0.11856245994567871\n",
      "Epoch:  29 | Train Accurancy:  -0.015351653099060059 | Validation Accurancy:  -0.11203491687774658\n",
      "Epoch:  30 | Train Accurancy:  -0.00923454761505127 | Validation Accurancy:  -0.10568368434906006\n",
      "Epoch:  31 | Train Accurancy:  -0.0032712221145629883 | Validation Accurancy:  -0.09942924976348877\n",
      "Epoch:  32 | Train Accurancy:  0.0025447607040405273 | Validation Accurancy:  -0.09334135055541992\n",
      "Epoch:  33 | Train Accurancy:  0.0082358717918396 | Validation Accurancy:  -0.08740508556365967\n",
      "Epoch:  34 | Train Accurancy:  0.013810575008392334 | Validation Accurancy:  -0.08160674571990967\n",
      "Epoch:  35 | Train Accurancy:  0.01927638053894043 | Validation Accurancy:  -0.07593512535095215\n",
      "Epoch:  36 | Train Accurancy:  0.024640977382659912 | Validation Accurancy:  -0.07037997245788574\n",
      "Epoch:  37 | Train Accurancy:  0.029909968376159668 | Validation Accurancy:  -0.06493258476257324\n",
      "Epoch:  38 | Train Accurancy:  0.03508955240249634 | Validation Accurancy:  -0.059584736824035645\n",
      "Epoch:  39 | Train Accurancy:  0.04018491506576538 | Validation Accurancy:  -0.054329752922058105\n",
      "Epoch:  40 | Train Accurancy:  0.04520106315612793 | Validation Accurancy:  -0.04916083812713623\n",
      "Epoch:  41 | Train Accurancy:  0.050142109394073486 | Validation Accurancy:  -0.04407310485839844\n",
      "Epoch:  42 | Train Accurancy:  0.055012047290802 | Validation Accurancy:  -0.03906118869781494\n",
      "Epoch:  43 | Train Accurancy:  0.05981510877609253 | Validation Accurancy:  -0.03412008285522461\n",
      "Epoch:  44 | Train Accurancy:  0.06455421447753906 | Validation Accurancy:  -0.029246091842651367\n",
      "Epoch:  45 | Train Accurancy:  0.06923294067382812 | Validation Accurancy:  -0.02443528175354004\n",
      "Epoch:  46 | Train Accurancy:  0.07385450601577759 | Validation Accurancy:  -0.019684195518493652\n",
      "Epoch:  47 | Train Accurancy:  0.07842069864273071 | Validation Accurancy:  -0.014989495277404785\n",
      "Epoch:  48 | Train Accurancy:  0.08293360471725464 | Validation Accurancy:  -0.010285496711730957\n",
      "Epoch:  49 | Train Accurancy:  0.08739668130874634 | Validation Accurancy:  -0.005648136138916016\n",
      "Epoch:  50 | Train Accurancy:  0.09181207418441772 | Validation Accurancy:  -0.0010718107223510742\n",
      "Epoch:  51 | Train Accurancy:  0.09618252515792847 | Validation Accurancy:  0.003386199474334717\n",
      "Epoch:  52 | Train Accurancy:  0.10050731897354126 | Validation Accurancy:  0.007928848266601562\n",
      "Epoch:  53 | Train Accurancy:  0.1047930121421814 | Validation Accurancy:  0.01226586103439331\n",
      "Epoch:  54 | Train Accurancy:  0.10903763771057129 | Validation Accurancy:  0.01663869619369507\n",
      "Epoch:  55 | Train Accurancy:  0.1132427453994751 | Validation Accurancy:  0.020966410636901855\n",
      "Epoch:  56 | Train Accurancy:  0.11741083860397339 | Validation Accurancy:  0.0251886248588562\n",
      "Epoch:  57 | Train Accurancy:  0.12154263257980347 | Validation Accurancy:  0.029451429843902588\n",
      "Epoch:  58 | Train Accurancy:  0.1256401538848877 | Validation Accurancy:  0.03367304801940918\n",
      "Epoch:  59 | Train Accurancy:  0.12970411777496338 | Validation Accurancy:  0.037793517112731934\n",
      "Epoch:  60 | Train Accurancy:  0.13373452425003052 | Validation Accurancy:  0.0419580340385437\n",
      "Epoch:  61 | Train Accurancy:  0.13773447275161743 | Validation Accurancy:  0.04608464241027832\n",
      "Epoch:  62 | Train Accurancy:  0.1417028307914734 | Validation Accurancy:  0.0501134991645813\n",
      "Epoch:  63 | Train Accurancy:  0.14564114809036255 | Validation Accurancy:  0.054240286350250244\n",
      "Epoch:  64 | Train Accurancy:  0.14954251050949097 | Validation Accurancy:  0.05825912952423096\n",
      "Epoch:  65 | Train Accurancy:  0.15341609716415405 | Validation Accurancy:  0.06225419044494629\n",
      "Epoch:  66 | Train Accurancy:  0.15726107358932495 | Validation Accurancy:  0.0662875771522522\n",
      "Epoch:  67 | Train Accurancy:  0.16108042001724243 | Validation Accurancy:  0.07021796703338623\n",
      "Epoch:  68 | Train Accurancy:  0.16487306356430054 | Validation Accurancy:  0.07412880659103394\n",
      "Epoch:  69 | Train Accurancy:  0.16864013671875 | Validation Accurancy:  0.07808125019073486\n",
      "Epoch:  70 | Train Accurancy:  0.1723824143409729 | Validation Accurancy:  0.08193415403366089\n",
      "Epoch:  71 | Train Accurancy:  0.17609989643096924 | Validation Accurancy:  0.08577024936676025\n",
      "Epoch:  72 | Train Accurancy:  0.1797933578491211 | Validation Accurancy:  0.08964943885803223\n",
      "Epoch:  73 | Train Accurancy:  0.18346327543258667 | Validation Accurancy:  0.09343212842941284\n",
      "Epoch:  74 | Train Accurancy:  0.18711018562316895 | Validation Accurancy:  0.09719932079315186\n",
      "Epoch:  75 | Train Accurancy:  0.19073402881622314 | Validation Accurancy:  0.10095036029815674\n",
      "Epoch:  76 | Train Accurancy:  0.19433563947677612 | Validation Accurancy:  0.10468411445617676\n",
      "Epoch:  77 | Train Accurancy:  0.19791537523269653 | Validation Accurancy:  0.10840004682540894\n",
      "Epoch:  78 | Train Accurancy:  0.20147299766540527 | Validation Accurancy:  0.11215794086456299\n",
      "Epoch:  79 | Train Accurancy:  0.205008864402771 | Validation Accurancy:  0.11582016944885254\n",
      "Epoch:  80 | Train Accurancy:  0.20852434635162354 | Validation Accurancy:  0.1194678544998169\n",
      "Epoch:  81 | Train Accurancy:  0.21201825141906738 | Validation Accurancy:  0.1230999231338501\n",
      "Epoch:  82 | Train Accurancy:  0.21549206972122192 | Validation Accurancy:  0.12671560049057007\n",
      "Epoch:  83 | Train Accurancy:  0.2189449667930603 | Validation Accurancy:  0.13031423091888428\n",
      "Epoch:  84 | Train Accurancy:  0.22237765789031982 | Validation Accurancy:  0.1338956356048584\n",
      "Epoch:  85 | Train Accurancy:  0.22579044103622437 | Validation Accurancy:  0.13745951652526855\n",
      "Epoch:  86 | Train Accurancy:  0.22918301820755005 | Validation Accurancy:  0.1410055160522461\n",
      "Epoch:  87 | Train Accurancy:  0.23255646228790283 | Validation Accurancy:  0.14453357458114624\n",
      "Epoch:  88 | Train Accurancy:  0.23590970039367676 | Validation Accurancy:  0.148043692111969\n",
      "Epoch:  89 | Train Accurancy:  0.23924386501312256 | Validation Accurancy:  0.1515359878540039\n",
      "Epoch:  90 | Train Accurancy:  0.24255865812301636 | Validation Accurancy:  0.15501046180725098\n",
      "Epoch:  91 | Train Accurancy:  0.24585413932800293 | Validation Accurancy:  0.15846657752990723\n",
      "Epoch:  92 | Train Accurancy:  0.24913078546524048 | Validation Accurancy:  0.16190505027770996\n",
      "Epoch:  93 | Train Accurancy:  0.25238823890686035 | Validation Accurancy:  0.16532570123672485\n",
      "Epoch:  94 | Train Accurancy:  0.2556266188621521 | Validation Accurancy:  0.16872847080230713\n",
      "Epoch:  95 | Train Accurancy:  0.25884658098220825 | Validation Accurancy:  0.17211323976516724\n",
      "Epoch:  96 | Train Accurancy:  0.26204752922058105 | Validation Accurancy:  0.1754804253578186\n",
      "Epoch:  97 | Train Accurancy:  0.26523005962371826 | Validation Accurancy:  0.17882955074310303\n",
      "Epoch:  98 | Train Accurancy:  0.2683938145637512 | Validation Accurancy:  0.1821613907814026\n",
      "Epoch:  99 | Train Accurancy:  0.27153903245925903 | Validation Accurancy:  0.18547528982162476\n",
      "Epoch:  100 | Train Accurancy:  0.27466559410095215 | Validation Accurancy:  0.1887715458869934\n",
      "Epoch:  101 | Train Accurancy:  0.27777403593063354 | Validation Accurancy:  0.192050039768219\n",
      "Epoch:  102 | Train Accurancy:  0.28086382150650024 | Validation Accurancy:  0.19531071186065674\n",
      "Epoch:  103 | Train Accurancy:  0.2839353680610657 | Validation Accurancy:  0.19855380058288574\n",
      "Epoch:  104 | Train Accurancy:  0.28698837757110596 | Validation Accurancy:  0.201779305934906\n",
      "Epoch:  105 | Train Accurancy:  0.2900230884552002 | Validation Accurancy:  0.20498698949813843\n",
      "Epoch:  106 | Train Accurancy:  0.2930394411087036 | Validation Accurancy:  0.20817720890045166\n",
      "Epoch:  107 | Train Accurancy:  0.2960379123687744 | Validation Accurancy:  0.21134960651397705\n",
      "Epoch:  108 | Train Accurancy:  0.29901808500289917 | Validation Accurancy:  0.21450424194335938\n",
      "Epoch:  109 | Train Accurancy:  0.3019798994064331 | Validation Accurancy:  0.21764111518859863\n",
      "Epoch:  110 | Train Accurancy:  0.30492377281188965 | Validation Accurancy:  0.22076034545898438\n",
      "Epoch:  111 | Train Accurancy:  0.30784910917282104 | Validation Accurancy:  0.22386175394058228\n",
      "Epoch:  112 | Train Accurancy:  0.3107566833496094 | Validation Accurancy:  0.22694534063339233\n",
      "Epoch:  113 | Train Accurancy:  0.31364601850509644 | Validation Accurancy:  0.23001128435134888\n",
      "Epoch:  114 | Train Accurancy:  0.3165172338485718 | Validation Accurancy:  0.23305916786193848\n",
      "Epoch:  115 | Train Accurancy:  0.3193703889846802 | Validation Accurancy:  0.23608940839767456\n",
      "Epoch:  116 | Train Accurancy:  0.3222055435180664 | Validation Accurancy:  0.2391018271446228\n",
      "Epoch:  117 | Train Accurancy:  0.32502245903015137 | Validation Accurancy:  0.2420961856842041\n",
      "Epoch:  118 | Train Accurancy:  0.3278217911720276 | Validation Accurancy:  0.24507278203964233\n",
      "Epoch:  119 | Train Accurancy:  0.3306027054786682 | Validation Accurancy:  0.24803167581558228\n",
      "Epoch:  120 | Train Accurancy:  0.3333659768104553 | Validation Accurancy:  0.25097233057022095\n",
      "Epoch:  121 | Train Accurancy:  0.3361108899116516 | Validation Accurancy:  0.2538950443267822\n",
      "Epoch:  122 | Train Accurancy:  0.3388383388519287 | Validation Accurancy:  0.2568000555038452\n",
      "Epoch:  123 | Train Accurancy:  0.3415476083755493 | Validation Accurancy:  0.25968706607818604\n",
      "Epoch:  124 | Train Accurancy:  0.344238817691803 | Validation Accurancy:  0.26260602474212646\n",
      "Epoch:  125 | Train Accurancy:  0.34691232442855835 | Validation Accurancy:  0.2654411792755127\n",
      "Epoch:  126 | Train Accurancy:  0.34956812858581543 | Validation Accurancy:  0.26826274394989014\n",
      "Epoch:  127 | Train Accurancy:  0.35220593214035034 | Validation Accurancy:  0.2710695266723633\n",
      "Epoch:  128 | Train Accurancy:  0.35482627153396606 | Validation Accurancy:  0.2738605737686157\n",
      "Epoch:  129 | Train Accurancy:  0.3574288487434387 | Validation Accurancy:  0.27663522958755493\n",
      "Epoch:  130 | Train Accurancy:  0.36001336574554443 | Validation Accurancy:  0.27939319610595703\n",
      "Epoch:  131 | Train Accurancy:  0.36258018016815186 | Validation Accurancy:  0.28218257427215576\n",
      "Epoch:  132 | Train Accurancy:  0.36512982845306396 | Validation Accurancy:  0.2848905324935913\n",
      "Epoch:  133 | Train Accurancy:  0.3676615357398987 | Validation Accurancy:  0.28758543729782104\n",
      "Epoch:  134 | Train Accurancy:  0.3701757788658142 | Validation Accurancy:  0.2902657985687256\n",
      "Epoch:  135 | Train Accurancy:  0.3726728558540344 | Validation Accurancy:  0.29293060302734375\n",
      "Epoch:  136 | Train Accurancy:  0.37515193223953247 | Validation Accurancy:  0.2956264615058899\n",
      "Epoch:  137 | Train Accurancy:  0.37761378288269043 | Validation Accurancy:  0.29824352264404297\n",
      "Epoch:  138 | Train Accurancy:  0.3800584077835083 | Validation Accurancy:  0.300847589969635\n",
      "Epoch:  139 | Train Accurancy:  0.38248568773269653 | Validation Accurancy:  0.30343759059906006\n",
      "Epoch:  140 | Train Accurancy:  0.38489532470703125 | Validation Accurancy:  0.30605900287628174\n",
      "Epoch:  141 | Train Accurancy:  0.3872882127761841 | Validation Accurancy:  0.30860304832458496\n",
      "Epoch:  142 | Train Accurancy:  0.3896639347076416 | Validation Accurancy:  0.31113487482070923\n",
      "Epoch:  143 | Train Accurancy:  0.39202219247817993 | Validation Accurancy:  0.3136988878250122\n",
      "Epoch:  144 | Train Accurancy:  0.39436352252960205 | Validation Accurancy:  0.31618732213974\n",
      "Epoch:  145 | Train Accurancy:  0.39668840169906616 | Validation Accurancy:  0.31866455078125\n",
      "Epoch:  146 | Train Accurancy:  0.3989957571029663 | Validation Accurancy:  0.3211737275123596\n",
      "Epoch:  147 | Train Accurancy:  0.40128636360168457 | Validation Accurancy:  0.3236083388328552\n",
      "Epoch:  148 | Train Accurancy:  0.40356069803237915 | Validation Accurancy:  0.32603228092193604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  149 | Train Accurancy:  0.4058181643486023 | Validation Accurancy:  0.3284878134727478\n",
      "Epoch:  150 | Train Accurancy:  0.4080583453178406 | Validation Accurancy:  0.33087027072906494\n",
      "Epoch:  151 | Train Accurancy:  0.41028279066085815 | Validation Accurancy:  0.3332415819168091\n",
      "Epoch:  152 | Train Accurancy:  0.41249024868011475 | Validation Accurancy:  0.33564454317092896\n",
      "Epoch:  153 | Train Accurancy:  0.41468149423599243 | Validation Accurancy:  0.33797508478164673\n",
      "Epoch:  154 | Train Accurancy:  0.41685670614242554 | Validation Accurancy:  0.34033840894699097\n",
      "Epoch:  155 | Train Accurancy:  0.4190152883529663 | Validation Accurancy:  0.34263134002685547\n",
      "Epoch:  156 | Train Accurancy:  0.4211580157279968 | Validation Accurancy:  0.3449145555496216\n",
      "Epoch:  157 | Train Accurancy:  0.42328447103500366 | Validation Accurancy:  0.34722912311553955\n",
      "Epoch:  158 | Train Accurancy:  0.425395131111145 | Validation Accurancy:  0.34947335720062256\n",
      "Epoch:  159 | Train Accurancy:  0.4274895191192627 | Validation Accurancy:  0.35175007581710815\n",
      "Epoch:  160 | Train Accurancy:  0.4295682907104492 | Validation Accurancy:  0.35395801067352295\n",
      "Epoch:  161 | Train Accurancy:  0.431631863117218 | Validation Accurancy:  0.3561992645263672\n",
      "Epoch:  162 | Train Accurancy:  0.4336792230606079 | Validation Accurancy:  0.3583725690841675\n",
      "Epoch:  163 | Train Accurancy:  0.4357112646102905 | Validation Accurancy:  0.36057931184768677\n",
      "Epoch:  164 | Train Accurancy:  0.437727689743042 | Validation Accurancy:  0.3627191185951233\n",
      "Epoch:  165 | Train Accurancy:  0.43972909450531006 | Validation Accurancy:  0.3648924231529236\n",
      "Epoch:  166 | Train Accurancy:  0.4417151212692261 | Validation Accurancy:  0.3669992685317993\n",
      "Epoch:  167 | Train Accurancy:  0.44368594884872437 | Validation Accurancy:  0.36913949251174927\n",
      "Epoch:  168 | Train Accurancy:  0.44564181566238403 | Validation Accurancy:  0.3712140917778015\n",
      "Epoch:  169 | Train Accurancy:  0.44758278131484985 | Validation Accurancy:  0.37332189083099365\n",
      "Epoch:  170 | Train Accurancy:  0.4495088458061218 | Validation Accurancy:  0.37536466121673584\n",
      "Epoch:  171 | Train Accurancy:  0.45142000913619995 | Validation Accurancy:  0.37744033336639404\n",
      "Epoch:  172 | Train Accurancy:  0.453316867351532 | Validation Accurancy:  0.3794515132904053\n",
      "Epoch:  173 | Train Accurancy:  0.45519882440567017 | Validation Accurancy:  0.3814956545829773\n",
      "Epoch:  174 | Train Accurancy:  0.4570668935775757 | Validation Accurancy:  0.3835160732269287\n",
      "Epoch:  175 | Train Accurancy:  0.45892006158828735 | Validation Accurancy:  0.3854750990867615\n",
      "Epoch:  176 | Train Accurancy:  0.4607592821121216 | Validation Accurancy:  0.3874685764312744\n",
      "Epoch:  177 | Train Accurancy:  0.46258455514907837 | Validation Accurancy:  0.3893999457359314\n",
      "Epoch:  178 | Train Accurancy:  0.46439558267593384 | Validation Accurancy:  0.3913647532463074\n",
      "Epoch:  179 | Train Accurancy:  0.46619296073913574 | Validation Accurancy:  0.3933071494102478\n",
      "Epoch:  180 | Train Accurancy:  0.46797627210617065 | Validation Accurancy:  0.3951898217201233\n",
      "Epoch:  181 | Train Accurancy:  0.4697459936141968 | Validation Accurancy:  0.39710694551467896\n",
      "Epoch:  182 | Train Accurancy:  0.47150254249572754 | Validation Accurancy:  0.39900273084640503\n",
      "Epoch:  183 | Train Accurancy:  0.47324496507644653 | Validation Accurancy:  0.4008401036262512\n",
      "Epoch:  184 | Train Accurancy:  0.47497451305389404 | Validation Accurancy:  0.4027121067047119\n",
      "Epoch:  185 | Train Accurancy:  0.4766908884048462 | Validation Accurancy:  0.40452468395233154\n",
      "Epoch:  186 | Train Accurancy:  0.47839367389678955 | Validation Accurancy:  0.4063705801963806\n",
      "Epoch:  187 | Train Accurancy:  0.4800838828086853 | Validation Accurancy:  0.408195436000824\n",
      "Epoch:  188 | Train Accurancy:  0.4817608594894409 | Validation Accurancy:  0.40996265411376953\n",
      "Epoch:  189 | Train Accurancy:  0.4834252595901489 | Validation Accurancy:  0.41176390647888184\n",
      "Epoch:  190 | Train Accurancy:  0.485076904296875 | Validation Accurancy:  0.41354507207870483\n",
      "Epoch:  191 | Train Accurancy:  0.4867161512374878 | Validation Accurancy:  0.41530823707580566\n",
      "Epoch:  192 | Train Accurancy:  0.4883424639701843 | Validation Accurancy:  0.4170162081718445\n",
      "Epoch:  193 | Train Accurancy:  0.48995673656463623 | Validation Accurancy:  0.41875964403152466\n",
      "Epoch:  194 | Train Accurancy:  0.4915590286254883 | Validation Accurancy:  0.42048418521881104\n",
      "Epoch:  195 | Train Accurancy:  0.4931485652923584 | Validation Accurancy:  0.4221538305282593\n",
      "Epoch:  196 | Train Accurancy:  0.4947264790534973 | Validation Accurancy:  0.4238584041595459\n",
      "Epoch:  197 | Train Accurancy:  0.4962925314903259 | Validation Accurancy:  0.42554420232772827\n",
      "Epoch:  198 | Train Accurancy:  0.497846782207489 | Validation Accurancy:  0.42721283435821533\n",
      "Epoch:  199 | Train Accurancy:  0.49938905239105225 | Validation Accurancy:  0.4288283586502075\n",
      "Epoch:  200 | Train Accurancy:  0.5009199678897858 | Validation Accurancy:  0.43047964572906494\n",
      "Epoch:  201 | Train Accurancy:  0.5024393498897552 | Validation Accurancy:  0.43211275339126587\n",
      "Epoch:  202 | Train Accurancy:  0.5039472877979279 | Validation Accurancy:  0.43369269371032715\n",
      "Epoch:  203 | Train Accurancy:  0.5054439306259155 | Validation Accurancy:  0.43530750274658203\n",
      "Epoch:  204 | Train Accurancy:  0.5069295465946198 | Validation Accurancy:  0.4369043707847595\n",
      "Epoch:  205 | Train Accurancy:  0.5084041655063629 | Validation Accurancy:  0.4384852647781372\n",
      "Epoch:  206 | Train Accurancy:  0.5098678767681122 | Validation Accurancy:  0.4400142431259155\n",
      "Epoch:  207 | Train Accurancy:  0.5113203227519989 | Validation Accurancy:  0.44157886505126953\n",
      "Epoch:  208 | Train Accurancy:  0.5127625167369843 | Validation Accurancy:  0.4431266784667969\n",
      "Epoch:  209 | Train Accurancy:  0.5141938924789429 | Validation Accurancy:  0.44465893507003784\n",
      "Epoch:  210 | Train Accurancy:  0.5156148970127106 | Validation Accurancy:  0.4461768865585327\n",
      "Epoch:  211 | Train Accurancy:  0.5170251429080963 | Validation Accurancy:  0.4476451873779297\n",
      "Epoch:  212 | Train Accurancy:  0.5184253454208374 | Validation Accurancy:  0.4491499662399292\n",
      "Epoch:  213 | Train Accurancy:  0.5198151469230652 | Validation Accurancy:  0.45063871145248413\n",
      "Epoch:  214 | Train Accurancy:  0.5211951434612274 | Validation Accurancy:  0.45211297273635864\n",
      "Epoch:  215 | Train Accurancy:  0.5225648581981659 | Validation Accurancy:  0.4535377621650696\n",
      "Epoch:  216 | Train Accurancy:  0.5239247977733612 | Validation Accurancy:  0.4549986720085144\n",
      "Epoch:  217 | Train Accurancy:  0.525274783372879 | Validation Accurancy:  0.456443727016449\n",
      "Epoch:  218 | Train Accurancy:  0.5266153216362 | Validation Accurancy:  0.457874596118927\n",
      "Epoch:  219 | Train Accurancy:  0.5279461443424225 | Validation Accurancy:  0.45929235219955444\n",
      "Epoch:  220 | Train Accurancy:  0.5292672514915466 | Validation Accurancy:  0.4606621265411377\n",
      "Epoch:  221 | Train Accurancy:  0.5305791199207306 | Validation Accurancy:  0.46206867694854736\n",
      "Epoch:  222 | Train Accurancy:  0.531881719827652 | Validation Accurancy:  0.46346014738082886\n",
      "Epoch:  223 | Train Accurancy:  0.5331752002239227 | Validation Accurancy:  0.4648382067680359\n",
      "Epoch:  224 | Train Accurancy:  0.5344594120979309 | Validation Accurancy:  0.4662036895751953\n",
      "Epoch:  225 | Train Accurancy:  0.5357343554496765 | Validation Accurancy:  0.4675222635269165\n",
      "Epoch:  226 | Train Accurancy:  0.5370006263256073 | Validation Accurancy:  0.4688776731491089\n",
      "Epoch:  227 | Train Accurancy:  0.5382581353187561 | Validation Accurancy:  0.4702186584472656\n",
      "Epoch:  228 | Train Accurancy:  0.5395067036151886 | Validation Accurancy:  0.47154688835144043\n",
      "Epoch:  229 | Train Accurancy:  0.5407468378543854 | Validation Accurancy:  0.4728631377220154\n",
      "Epoch:  230 | Train Accurancy:  0.5419780910015106 | Validation Accurancy:  0.4741329550743103\n",
      "Epoch:  231 | Train Accurancy:  0.5432010889053345 | Validation Accurancy:  0.47543996572494507\n",
      "Epoch:  232 | Train Accurancy:  0.5444156527519226 | Validation Accurancy:  0.47673338651657104\n",
      "Epoch:  233 | Train Accurancy:  0.5456218421459198 | Validation Accurancy:  0.47801411151885986\n",
      "Epoch:  234 | Train Accurancy:  0.5468201041221619 | Validation Accurancy:  0.47928351163864136\n",
      "Epoch:  235 | Train Accurancy:  0.5480098724365234 | Validation Accurancy:  0.4805071949958801\n",
      "Epoch:  236 | Train Accurancy:  0.5491916239261627 | Validation Accurancy:  0.4817683696746826\n",
      "Epoch:  237 | Train Accurancy:  0.5503656268119812 | Validation Accurancy:  0.4830161929130554\n",
      "Epoch:  238 | Train Accurancy:  0.5515317320823669 | Validation Accurancy:  0.4842521548271179\n",
      "Epoch:  239 | Train Accurancy:  0.5526900589466095 | Validation Accurancy:  0.485477089881897\n",
      "Epoch:  240 | Train Accurancy:  0.5538405776023865 | Validation Accurancy:  0.4866570830345154\n",
      "Epoch:  241 | Train Accurancy:  0.5549836158752441 | Validation Accurancy:  0.4878746271133423\n",
      "Epoch:  242 | Train Accurancy:  0.5561190545558929 | Validation Accurancy:  0.48907923698425293\n",
      "Epoch:  243 | Train Accurancy:  0.5572470128536224 | Validation Accurancy:  0.4902724027633667\n",
      "Epoch:  244 | Train Accurancy:  0.5583674609661102 | Validation Accurancy:  0.4914551377296448\n",
      "Epoch:  245 | Train Accurancy:  0.5594806671142578 | Validation Accurancy:  0.4925936460494995\n",
      "Epoch:  246 | Train Accurancy:  0.5605868101119995 | Validation Accurancy:  0.49376988410949707\n",
      "Epoch:  247 | Train Accurancy:  0.5616857707500458 | Validation Accurancy:  0.4949336647987366\n",
      "Epoch:  248 | Train Accurancy:  0.5627776682376862 | Validation Accurancy:  0.4960864186286926\n",
      "Epoch:  249 | Train Accurancy:  0.5638626217842102 | Validation Accurancy:  0.4972292184829712\n",
      "Epoch:  250 | Train Accurancy:  0.564940333366394 | Validation Accurancy:  0.4983280897140503\n",
      "Epoch:  251 | Train Accurancy:  0.5660114586353302 | Validation Accurancy:  0.4994651675224304\n",
      "Epoch:  252 | Train Accurancy:  0.5670758187770844 | Validation Accurancy:  0.5005902349948883\n",
      "Epoch:  253 | Train Accurancy:  0.568133533000946 | Validation Accurancy:  0.5017045736312866\n",
      "Epoch:  254 | Train Accurancy:  0.5691844820976257 | Validation Accurancy:  0.5028094053268433\n",
      "Epoch:  255 | Train Accurancy:  0.5702289342880249 | Validation Accurancy:  0.5038710236549377\n",
      "Epoch:  256 | Train Accurancy:  0.5712669193744659 | Validation Accurancy:  0.5049709677696228\n",
      "Epoch:  257 | Train Accurancy:  0.5722984969615936 | Validation Accurancy:  0.5060592591762543\n",
      "Epoch:  258 | Train Accurancy:  0.5733238160610199 | Validation Accurancy:  0.5071373879909515\n",
      "Epoch:  259 | Train Accurancy:  0.574342668056488 | Validation Accurancy:  0.5081719756126404\n",
      "Epoch:  260 | Train Accurancy:  0.5753553509712219 | Validation Accurancy:  0.5092446208000183\n",
      "Epoch:  261 | Train Accurancy:  0.5763619244098663 | Validation Accurancy:  0.5103055238723755\n",
      "Epoch:  262 | Train Accurancy:  0.5773623883724213 | Validation Accurancy:  0.5113563537597656\n",
      "Epoch:  263 | Train Accurancy:  0.5783568918704987 | Validation Accurancy:  0.5123982429504395\n",
      "Epoch:  264 | Train Accurancy:  0.5793456435203552 | Validation Accurancy:  0.5133975744247437\n",
      "Epoch:  265 | Train Accurancy:  0.5803282856941223 | Validation Accurancy:  0.5144355893135071\n",
      "Epoch:  266 | Train Accurancy:  0.5813049972057343 | Validation Accurancy:  0.5154625475406647\n",
      "Epoch:  267 | Train Accurancy:  0.5822760164737701 | Validation Accurancy:  0.5164800584316254\n",
      "Epoch:  268 | Train Accurancy:  0.5832415819168091 | Validation Accurancy:  0.5174547731876373\n",
      "Epoch:  269 | Train Accurancy:  0.5842013359069824 | Validation Accurancy:  0.5184680223464966\n",
      "Epoch:  270 | Train Accurancy:  0.5851556360721588 | Validation Accurancy:  0.5194702744483948\n",
      "Epoch:  271 | Train Accurancy:  0.5861042141914368 | Validation Accurancy:  0.5204630196094513\n",
      "Epoch:  272 | Train Accurancy:  0.5870474576950073 | Validation Accurancy:  0.5214131772518158\n",
      "Epoch:  273 | Train Accurancy:  0.5879850089550018 | Validation Accurancy:  0.5224020183086395\n",
      "Epoch:  274 | Train Accurancy:  0.5889177322387695 | Validation Accurancy:  0.5233801007270813\n",
      "Epoch:  275 | Train Accurancy:  0.5898447632789612 | Validation Accurancy:  0.5243487358093262\n",
      "Epoch:  276 | Train Accurancy:  0.5907668173313141 | Validation Accurancy:  0.5252753496170044\n",
      "Epoch:  277 | Train Accurancy:  0.59168341755867 | Validation Accurancy:  0.5262405276298523\n",
      "Epoch:  278 | Train Accurancy:  0.5925951898097992 | Validation Accurancy:  0.5271952450275421\n",
      "Epoch:  279 | Train Accurancy:  0.5935017764568329 | Validation Accurancy:  0.5281407535076141\n",
      "Epoch:  280 | Train Accurancy:  0.5944033563137054 | Validation Accurancy:  0.5290445983409882\n",
      "Epoch:  281 | Train Accurancy:  0.5952998399734497 | Validation Accurancy:  0.5299872756004333\n",
      "Epoch:  282 | Train Accurancy:  0.5961917042732239 | Validation Accurancy:  0.5309195220470428\n",
      "Epoch:  283 | Train Accurancy:  0.5970786511898041 | Validation Accurancy:  0.5318430662155151\n",
      "Epoch:  284 | Train Accurancy:  0.5979604721069336 | Validation Accurancy:  0.5327250063419342\n",
      "Epoch:  285 | Train Accurancy:  0.5988377928733826 | Validation Accurancy:  0.5336460173130035\n",
      "Epoch:  286 | Train Accurancy:  0.5997103750705719 | Validation Accurancy:  0.5345569252967834\n",
      "Epoch:  287 | Train Accurancy:  0.6005783379077911 | Validation Accurancy:  0.5354591906070709\n",
      "Epoch:  288 | Train Accurancy:  0.6014416515827179 | Validation Accurancy:  0.5363201797008514\n",
      "Epoch:  289 | Train Accurancy:  0.6023003160953522 | Validation Accurancy:  0.5372205376625061\n",
      "Epoch:  290 | Train Accurancy:  0.6031545400619507 | Validation Accurancy:  0.5381109118461609\n",
      "Epoch:  291 | Train Accurancy:  0.6040044128894806 | Validation Accurancy:  0.5389591157436371\n",
      "Epoch:  292 | Train Accurancy:  0.6048494577407837 | Validation Accurancy:  0.5398460626602173\n",
      "Epoch:  293 | Train Accurancy:  0.6056905090808868 | Validation Accurancy:  0.5407225787639618\n",
      "Epoch:  294 | Train Accurancy:  0.6065272092819214 | Validation Accurancy:  0.541590690612793\n",
      "Epoch:  295 | Train Accurancy:  0.6073594093322754 | Validation Accurancy:  0.5424176752567291\n",
      "Epoch:  296 | Train Accurancy:  0.608187347650528 | Validation Accurancy:  0.5432840287685394\n",
      "Epoch:  297 | Train Accurancy:  0.6090112924575806 | Validation Accurancy:  0.5441406965255737\n",
      "Epoch:  298 | Train Accurancy:  0.6098311245441437 | Validation Accurancy:  0.5449555814266205\n",
      "Epoch:  299 | Train Accurancy:  0.6106464564800262 | Validation Accurancy:  0.545809417963028\n",
      "Epoch:  300 | Train Accurancy:  0.6114582419395447 | Validation Accurancy:  0.5466532409191132\n",
      "Epoch:  301 | Train Accurancy:  0.6122657060623169 | Validation Accurancy:  0.5474550127983093\n",
      "Epoch:  302 | Train Accurancy:  0.6130689680576324 | Validation Accurancy:  0.548295795917511\n",
      "Epoch:  303 | Train Accurancy:  0.6138688027858734 | Validation Accurancy:  0.5491265058517456\n",
      "Epoch:  304 | Train Accurancy:  0.6146641969680786 | Validation Accurancy:  0.5499489605426788\n",
      "Epoch:  305 | Train Accurancy:  0.6154557466506958 | Validation Accurancy:  0.55073082447052\n",
      "Epoch:  306 | Train Accurancy:  0.6162437498569489 | Validation Accurancy:  0.5515525937080383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  307 | Train Accurancy:  0.6170278787612915 | Validation Accurancy:  0.5523649156093597\n",
      "Epoch:  308 | Train Accurancy:  0.617808073759079 | Validation Accurancy:  0.5531359612941742\n",
      "Epoch:  309 | Train Accurancy:  0.6185846626758575 | Validation Accurancy:  0.5539463460445404\n",
      "Epoch:  310 | Train Accurancy:  0.6193577349185944 | Validation Accurancy:  0.5547471344470978\n",
      "Epoch:  311 | Train Accurancy:  0.6201268136501312 | Validation Accurancy:  0.5555064380168915\n",
      "Epoch:  312 | Train Accurancy:  0.6208924353122711 | Validation Accurancy:  0.5563051998615265\n",
      "Epoch:  313 | Train Accurancy:  0.6216545701026917 | Validation Accurancy:  0.557094156742096\n",
      "Epoch:  314 | Train Accurancy:  0.6224129796028137 | Validation Accurancy:  0.5578417778015137\n",
      "Epoch:  315 | Train Accurancy:  0.6231679916381836 | Validation Accurancy:  0.5586287081241608\n",
      "Epoch:  316 | Train Accurancy:  0.6239195466041565 | Validation Accurancy:  0.5594061017036438\n",
      "Epoch:  317 | Train Accurancy:  0.6246675550937653 | Validation Accurancy:  0.5601420402526855\n",
      "Epoch:  318 | Train Accurancy:  0.6254121363162994 | Validation Accurancy:  0.5609175860881805\n",
      "Epoch:  319 | Train Accurancy:  0.6261534690856934 | Validation Accurancy:  0.5616836547851562\n",
      "Epoch:  320 | Train Accurancy:  0.6268911063671112 | Validation Accurancy:  0.5624083876609802\n",
      "Epoch:  321 | Train Accurancy:  0.6276259124279022 | Validation Accurancy:  0.5631727874279022\n",
      "Epoch:  322 | Train Accurancy:  0.6283572614192963 | Validation Accurancy:  0.5638943016529083\n",
      "Epoch:  323 | Train Accurancy:  0.6290850341320038 | Validation Accurancy:  0.5646542012691498\n",
      "Epoch:  324 | Train Accurancy:  0.6298100352287292 | Validation Accurancy:  0.5654036402702332\n",
      "Epoch:  325 | Train Accurancy:  0.630531519651413 | Validation Accurancy:  0.5661117434501648\n",
      "Epoch:  326 | Train Accurancy:  0.6312499940395355 | Validation Accurancy:  0.566859096288681\n",
      "Epoch:  327 | Train Accurancy:  0.631965309381485 | Validation Accurancy:  0.5675969123840332\n",
      "Epoch:  328 | Train Accurancy:  0.6326774060726166 | Validation Accurancy:  0.5682936608791351\n",
      "Epoch:  329 | Train Accurancy:  0.6333865523338318 | Validation Accurancy:  0.5690301954746246\n",
      "Epoch:  330 | Train Accurancy:  0.6340927481651306 | Validation Accurancy:  0.5697239339351654\n",
      "Epoch:  331 | Train Accurancy:  0.634795606136322 | Validation Accurancy:  0.5704560577869415\n",
      "Epoch:  332 | Train Accurancy:  0.6354957222938538 | Validation Accurancy:  0.5711784660816193\n",
      "Epoch:  333 | Train Accurancy:  0.636192798614502 | Validation Accurancy:  0.5718595087528229\n",
      "Epoch:  334 | Train Accurancy:  0.6368869543075562 | Validation Accurancy:  0.5725800096988678\n",
      "Epoch:  335 | Train Accurancy:  0.6375783085823059 | Validation Accurancy:  0.5732576549053192\n",
      "Epoch:  336 | Train Accurancy:  0.6382662951946259 | Validation Accurancy:  0.5739740431308746\n",
      "Epoch:  337 | Train Accurancy:  0.6389519572257996 | Validation Accurancy:  0.574680507183075\n",
      "Epoch:  338 | Train Accurancy:  0.6396346092224121 | Validation Accurancy:  0.5753457844257355\n",
      "Epoch:  339 | Train Accurancy:  0.640314370393753 | Validation Accurancy:  0.5760505795478821\n",
      "Epoch:  340 | Train Accurancy:  0.6409915089607239 | Validation Accurancy:  0.5767127871513367\n",
      "Epoch:  341 | Train Accurancy:  0.6416655480861664 | Validation Accurancy:  0.5774137377738953\n",
      "Epoch:  342 | Train Accurancy:  0.6423371732234955 | Validation Accurancy:  0.5781049132347107\n",
      "Epoch:  343 | Train Accurancy:  0.6430058479309082 | Validation Accurancy:  0.5787548720836639\n",
      "Epoch:  344 | Train Accurancy:  0.6436719596385956 | Validation Accurancy:  0.5794447660446167\n",
      "Epoch:  345 | Train Accurancy:  0.6443355679512024 | Validation Accurancy:  0.5800921618938446\n",
      "Epoch:  346 | Train Accurancy:  0.6449962556362152 | Validation Accurancy:  0.5807783901691437\n",
      "Epoch:  347 | Train Accurancy:  0.6456544697284698 | Validation Accurancy:  0.5814548134803772\n",
      "Epoch:  348 | Train Accurancy:  0.6463099122047424 | Validation Accurancy:  0.5820904672145844\n",
      "Epoch:  349 | Train Accurancy:  0.6469630599021912 | Validation Accurancy:  0.5827659964561462\n",
      "Epoch:  350 | Train Accurancy:  0.6476133763790131 | Validation Accurancy:  0.5833992063999176\n",
      "Epoch:  351 | Train Accurancy:  0.6482612490653992 | Validation Accurancy:  0.5840713083744049\n",
      "Epoch:  352 | Train Accurancy:  0.6489067673683167 | Validation Accurancy:  0.5847004652023315\n",
      "Epoch:  353 | Train Accurancy:  0.6495494842529297 | Validation Accurancy:  0.5853681564331055\n",
      "Epoch:  354 | Train Accurancy:  0.6501899361610413 | Validation Accurancy:  0.5860258340835571\n",
      "Epoch:  355 | Train Accurancy:  0.6508278250694275 | Validation Accurancy:  0.58664271235466\n",
      "Epoch:  356 | Train Accurancy:  0.6514635384082794 | Validation Accurancy:  0.5872995555400848\n",
      "Epoch:  357 | Train Accurancy:  0.6520965695381165 | Validation Accurancy:  0.5879140496253967\n",
      "Epoch:  358 | Train Accurancy:  0.6527271866798401 | Validation Accurancy:  0.5885677337646484\n",
      "Epoch:  359 | Train Accurancy:  0.6533555686473846 | Validation Accurancy:  0.5891784131526947\n",
      "Epoch:  360 | Train Accurancy:  0.653981477022171 | Validation Accurancy:  0.5898277163505554\n",
      "Epoch:  361 | Train Accurancy:  0.6546052694320679 | Validation Accurancy:  0.5904340147972107\n",
      "Epoch:  362 | Train Accurancy:  0.6552264392375946 | Validation Accurancy:  0.5910787284374237\n",
      "Epoch:  363 | Train Accurancy:  0.6558456420898438 | Validation Accurancy:  0.591713547706604\n",
      "Epoch:  364 | Train Accurancy:  0.6564622223377228 | Validation Accurancy:  0.5923076570034027\n",
      "Epoch:  365 | Train Accurancy:  0.6570768058300018 | Validation Accurancy:  0.5929417908191681\n",
      "Epoch:  366 | Train Accurancy:  0.6576888859272003 | Validation Accurancy:  0.593533843755722\n",
      "Epoch:  367 | Train Accurancy:  0.6582989990711212 | Validation Accurancy:  0.594165027141571\n",
      "Epoch:  368 | Train Accurancy:  0.6589068174362183 | Validation Accurancy:  0.5947536528110504\n",
      "Epoch:  369 | Train Accurancy:  0.6595124006271362 | Validation Accurancy:  0.5953809916973114\n",
      "Epoch:  370 | Train Accurancy:  0.6601158082485199 | Validation Accurancy:  0.5959654450416565\n",
      "Epoch:  371 | Train Accurancy:  0.6607170104980469 | Validation Accurancy:  0.5965886116027832\n",
      "Epoch:  372 | Train Accurancy:  0.661316305398941 | Validation Accurancy:  0.5971685945987701\n",
      "Epoch:  373 | Train Accurancy:  0.6619132161140442 | Validation Accurancy:  0.5977872908115387\n",
      "Epoch:  374 | Train Accurancy:  0.6625081300735474 | Validation Accurancy:  0.598362922668457\n",
      "Epoch:  375 | Train Accurancy:  0.6631008386611938 | Validation Accurancy:  0.598977118730545\n",
      "Epoch:  376 | Train Accurancy:  0.6636918485164642 | Validation Accurancy:  0.5995816290378571\n",
      "Epoch:  377 | Train Accurancy:  0.6642802059650421 | Validation Accurancy:  0.6001456677913666\n",
      "Epoch:  378 | Train Accurancy:  0.6648669838905334 | Validation Accurancy:  0.6007497906684875\n",
      "Epoch:  379 | Train Accurancy:  0.6654513776302338 | Validation Accurancy:  0.6013122498989105\n",
      "Epoch:  380 | Train Accurancy:  0.6660340130329132 | Validation Accurancy:  0.6019140183925629\n",
      "Epoch:  381 | Train Accurancy:  0.666614443063736 | Validation Accurancy:  0.6024733483791351\n",
      "Epoch:  382 | Train Accurancy:  0.6671930551528931 | Validation Accurancy:  0.6030718088150024\n",
      "Epoch:  383 | Train Accurancy:  0.6677696108818054 | Validation Accurancy:  0.6036275625228882\n",
      "Epoch:  384 | Train Accurancy:  0.6683441698551178 | Validation Accurancy:  0.6042221188545227\n",
      "Epoch:  385 | Train Accurancy:  0.6689170002937317 | Validation Accurancy:  0.6047738790512085\n",
      "Epoch:  386 | Train Accurancy:  0.6694875657558441 | Validation Accurancy:  0.6053645014762878\n",
      "Epoch:  387 | Train Accurancy:  0.6700564920902252 | Validation Accurancy:  0.6059122681617737\n",
      "Epoch:  388 | Train Accurancy:  0.6706233322620392 | Validation Accurancy:  0.6064989268779755\n",
      "Epoch:  389 | Train Accurancy:  0.6711883246898651 | Validation Accurancy:  0.6070428192615509\n",
      "Epoch:  390 | Train Accurancy:  0.6717515289783478 | Validation Accurancy:  0.607625424861908\n",
      "Epoch:  391 | Train Accurancy:  0.6723128259181976 | Validation Accurancy:  0.6081653535366058\n",
      "Epoch:  392 | Train Accurancy:  0.6728720963001251 | Validation Accurancy:  0.6087439954280853\n",
      "Epoch:  393 | Train Accurancy:  0.6734297573566437 | Validation Accurancy:  0.6092800498008728\n",
      "Epoch:  394 | Train Accurancy:  0.6739853024482727 | Validation Accurancy:  0.6098547875881195\n",
      "Epoch:  395 | Train Accurancy:  0.6745394468307495 | Validation Accurancy:  0.610386997461319\n",
      "Epoch:  396 | Train Accurancy:  0.675091415643692 | Validation Accurancy:  0.6109579205513\n",
      "Epoch:  397 | Train Accurancy:  0.6756417453289032 | Validation Accurancy:  0.6114863157272339\n",
      "Epoch:  398 | Train Accurancy:  0.676190197467804 | Validation Accurancy:  0.6120535433292389\n",
      "Epoch:  399 | Train Accurancy:  0.6767369508743286 | Validation Accurancy:  0.6125782132148743\n",
      "Epoch:  400 | Train Accurancy:  0.6772820055484772 | Validation Accurancy:  0.6131415665149689\n",
      "Epoch:  401 | Train Accurancy:  0.6778251826763153 | Validation Accurancy:  0.6136626303195953\n",
      "Epoch:  402 | Train Accurancy:  0.6783667802810669 | Validation Accurancy:  0.614222377538681\n",
      "Epoch:  403 | Train Accurancy:  0.6789067089557648 | Validation Accurancy:  0.6147397756576538\n",
      "Epoch:  404 | Train Accurancy:  0.6794446408748627 | Validation Accurancy:  0.6152958869934082\n",
      "Epoch:  405 | Train Accurancy:  0.6799811124801636 | Validation Accurancy:  0.615809828042984\n",
      "Epoch:  406 | Train Accurancy:  0.6805157363414764 | Validation Accurancy:  0.6163622438907623\n",
      "Epoch:  407 | Train Accurancy:  0.681048572063446 | Validation Accurancy:  0.6168726980686188\n",
      "Epoch:  408 | Train Accurancy:  0.6815800368785858 | Validation Accurancy:  0.6174218058586121\n",
      "Epoch:  409 | Train Accurancy:  0.6821096539497375 | Validation Accurancy:  0.6179288327693939\n",
      "Epoch:  410 | Train Accurancy:  0.6826378703117371 | Validation Accurancy:  0.6184744238853455\n",
      "Epoch:  411 | Train Accurancy:  0.6831642091274261 | Validation Accurancy:  0.6189778745174408\n",
      "Epoch:  412 | Train Accurancy:  0.6836888492107391 | Validation Accurancy:  0.6195200979709625\n",
      "Epoch:  413 | Train Accurancy:  0.6842119991779327 | Validation Accurancy:  0.620020180940628\n",
      "Epoch:  414 | Train Accurancy:  0.6847335696220398 | Validation Accurancy:  0.6205590665340424\n",
      "Epoch:  415 | Train Accurancy:  0.6852533519268036 | Validation Accurancy:  0.6210558116436005\n",
      "Epoch:  416 | Train Accurancy:  0.6857718825340271 | Validation Accurancy:  0.6215913891792297\n",
      "Epoch:  417 | Train Accurancy:  0.6862885355949402 | Validation Accurancy:  0.6220849454402924\n",
      "Epoch:  418 | Train Accurancy:  0.6868037283420563 | Validation Accurancy:  0.6226172149181366\n",
      "Epoch:  419 | Train Accurancy:  0.6873174905776978 | Validation Accurancy:  0.6231075525283813\n",
      "Epoch:  420 | Train Accurancy:  0.6878295242786407 | Validation Accurancy:  0.6236366331577301\n",
      "Epoch:  421 | Train Accurancy:  0.68833988904953 | Validation Accurancy:  0.6241238415241241\n",
      "Epoch:  422 | Train Accurancy:  0.6888490319252014 | Validation Accurancy:  0.6246496737003326\n",
      "Epoch:  423 | Train Accurancy:  0.6893563568592072 | Validation Accurancy:  0.6251335740089417\n",
      "Epoch:  424 | Train Accurancy:  0.689862459897995 | Validation Accurancy:  0.6256564557552338\n",
      "Epoch:  425 | Train Accurancy:  0.6903666853904724 | Validation Accurancy:  0.6261372864246368\n",
      "Epoch:  426 | Train Accurancy:  0.690869927406311 | Validation Accurancy:  0.6266570091247559\n",
      "Epoch:  427 | Train Accurancy:  0.6913711428642273 | Validation Accurancy:  0.6271349191665649\n",
      "Epoch:  428 | Train Accurancy:  0.6918712556362152 | Validation Accurancy:  0.6276514828205109\n",
      "Epoch:  429 | Train Accurancy:  0.6923695802688599 | Validation Accurancy:  0.628126323223114\n",
      "Epoch:  430 | Train Accurancy:  0.6928667426109314 | Validation Accurancy:  0.6286070942878723\n",
      "Epoch:  431 | Train Accurancy:  0.6933621466159821 | Validation Accurancy:  0.6291242837905884\n",
      "Epoch:  432 | Train Accurancy:  0.693856418132782 | Validation Accurancy:  0.6295978724956512\n",
      "Epoch:  433 | Train Accurancy:  0.6943489015102386 | Validation Accurancy:  0.6301091015338898\n",
      "Epoch:  434 | Train Accurancy:  0.6948402523994446 | Validation Accurancy:  0.6305779218673706\n",
      "Epoch:  435 | Train Accurancy:  0.6953299343585968 | Validation Accurancy:  0.6310850381851196\n",
      "Epoch:  436 | Train Accurancy:  0.6958183348178864 | Validation Accurancy:  0.6315501928329468\n",
      "Epoch:  437 | Train Accurancy:  0.6963053047657013 | Validation Accurancy:  0.6320538818836212\n",
      "Epoch:  438 | Train Accurancy:  0.6967909634113312 | Validation Accurancy:  0.6325157880783081\n",
      "Epoch:  439 | Train Accurancy:  0.6972751021385193 | Validation Accurancy:  0.6330162882804871\n",
      "Epoch:  440 | Train Accurancy:  0.6977578401565552 | Validation Accurancy:  0.6334753334522247\n",
      "Epoch:  441 | Train Accurancy:  0.698239266872406 | Validation Accurancy:  0.6339729726314545\n",
      "Epoch:  442 | Train Accurancy:  0.6987192034721375 | Validation Accurancy:  0.6344292461872101\n",
      "Epoch:  443 | Train Accurancy:  0.6991978883743286 | Validation Accurancy:  0.6349240243434906\n",
      "Epoch:  444 | Train Accurancy:  0.6996750831604004 | Validation Accurancy:  0.6353773772716522\n",
      "Epoch:  445 | Train Accurancy:  0.7001510560512543 | Validation Accurancy:  0.6358693838119507\n",
      "Epoch:  446 | Train Accurancy:  0.7006255090236664 | Validation Accurancy:  0.6363201141357422\n",
      "Epoch:  447 | Train Accurancy:  0.7010989189147949 | Validation Accurancy:  0.6368094384670258\n",
      "Epoch:  448 | Train Accurancy:  0.7015706896781921 | Validation Accurancy:  0.63725745677948\n",
      "Epoch:  449 | Train Accurancy:  0.7020413279533386 | Validation Accurancy:  0.6377440392971039\n",
      "Epoch:  450 | Train Accurancy:  0.7025103569030762 | Validation Accurancy:  0.638189435005188\n",
      "Epoch:  451 | Train Accurancy:  0.7029784917831421 | Validation Accurancy:  0.6386734247207642\n",
      "Epoch:  452 | Train Accurancy:  0.7034449279308319 | Validation Accurancy:  0.6391161978244781\n",
      "Epoch:  453 | Train Accurancy:  0.7039104700088501 | Validation Accurancy:  0.6395975053310394\n",
      "Epoch:  454 | Train Accurancy:  0.7043743133544922 | Validation Accurancy:  0.6400378048419952\n",
      "Epoch:  455 | Train Accurancy:  0.7048372328281403 | Validation Accurancy:  0.6404841244220734\n",
      "Epoch:  456 | Train Accurancy:  0.7052985429763794 | Validation Accurancy:  0.6409664452075958\n",
      "Epoch:  457 | Train Accurancy:  0.7057587504386902 | Validation Accurancy:  0.6414061486721039\n",
      "Epoch:  458 | Train Accurancy:  0.7062174379825592 | Validation Accurancy:  0.6418830454349518\n",
      "Epoch:  459 | Train Accurancy:  0.7066753208637238 | Validation Accurancy:  0.6423183083534241\n",
      "Epoch:  460 | Train Accurancy:  0.7071314454078674 | Validation Accurancy:  0.6427914500236511\n",
      "Epoch:  461 | Train Accurancy:  0.7075866162776947 | Validation Accurancy:  0.6432234942913055\n",
      "Epoch:  462 | Train Accurancy:  0.708039402961731 | Validation Accurancy:  0.6436365246772766\n",
      "Epoch:  463 | Train Accurancy:  0.7084890902042389 | Validation Accurancy:  0.6440270841121674\n",
      "Epoch:  464 | Train Accurancy:  0.7089374363422394 | Validation Accurancy:  0.6444682478904724\n",
      "Epoch:  465 | Train Accurancy:  0.7093846201896667 | Validation Accurancy:  0.6448764801025391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  466 | Train Accurancy:  0.7098305523395538 | Validation Accurancy:  0.6452965140342712\n",
      "Epoch:  467 | Train Accurancy:  0.7102750539779663 | Validation Accurancy:  0.6457559466362\n",
      "Epoch:  468 | Train Accurancy:  0.7107184827327728 | Validation Accurancy:  0.6461752653121948\n",
      "Epoch:  469 | Train Accurancy:  0.7111606895923615 | Validation Accurancy:  0.6466013491153717\n",
      "Epoch:  470 | Train Accurancy:  0.711601585149765 | Validation Accurancy:  0.6470635831356049\n",
      "Epoch:  471 | Train Accurancy:  0.7120413780212402 | Validation Accurancy:  0.6474834978580475\n",
      "Epoch:  472 | Train Accurancy:  0.7124799191951752 | Validation Accurancy:  0.6479089856147766\n",
      "Epoch:  473 | Train Accurancy:  0.712917298078537 | Validation Accurancy:  0.6483694016933441\n",
      "Epoch:  474 | Train Accurancy:  0.7133534550666809 | Validation Accurancy:  0.6487872302532196\n",
      "Epoch:  475 | Train Accurancy:  0.7137884199619293 | Validation Accurancy:  0.6492100059986115\n",
      "Epoch:  476 | Train Accurancy:  0.7142222821712494 | Validation Accurancy:  0.6496355831623077\n",
      "Epoch:  477 | Train Accurancy:  0.7146548628807068 | Validation Accurancy:  0.6500945091247559\n",
      "Epoch:  478 | Train Accurancy:  0.7150862514972687 | Validation Accurancy:  0.650509774684906\n",
      "Epoch:  479 | Train Accurancy:  0.7155166268348694 | Validation Accurancy:  0.6509293019771576\n",
      "Epoch:  480 | Train Accurancy:  0.7159457504749298 | Validation Accurancy:  0.6513513028621674\n",
      "Epoch:  481 | Train Accurancy:  0.7163736522197723 | Validation Accurancy:  0.6518060863018036\n",
      "Epoch:  482 | Train Accurancy:  0.7168004810810089 | Validation Accurancy:  0.6522123217582703\n",
      "Epoch:  483 | Train Accurancy:  0.7172261476516724 | Validation Accurancy:  0.6526224911212921\n",
      "Epoch:  484 | Train Accurancy:  0.7176507115364075 | Validation Accurancy:  0.6530666947364807\n",
      "Epoch:  485 | Train Accurancy:  0.7180740535259247 | Validation Accurancy:  0.653468132019043\n",
      "Epoch:  486 | Train Accurancy:  0.7184965908527374 | Validation Accurancy:  0.6538740992546082\n",
      "Epoch:  487 | Train Accurancy:  0.718917578458786 | Validation Accurancy:  0.6542826592922211\n",
      "Epoch:  488 | Train Accurancy:  0.7193375527858734 | Validation Accurancy:  0.6547241806983948\n",
      "Epoch:  489 | Train Accurancy:  0.7197564542293549 | Validation Accurancy:  0.6551222801208496\n",
      "Epoch:  490 | Train Accurancy:  0.7201743721961975 | Validation Accurancy:  0.6555247604846954\n",
      "Epoch:  491 | Train Accurancy:  0.720591127872467 | Validation Accurancy:  0.6559610664844513\n",
      "Epoch:  492 | Train Accurancy:  0.7210066020488739 | Validation Accurancy:  0.6563547849655151\n",
      "Epoch:  493 | Train Accurancy:  0.7214211225509644 | Validation Accurancy:  0.6567531824111938\n",
      "Epoch:  494 | Train Accurancy:  0.7218345999717712 | Validation Accurancy:  0.6571542024612427\n",
      "Epoch:  495 | Train Accurancy:  0.7222468256950378 | Validation Accurancy:  0.6575880646705627\n",
      "Epoch:  496 | Train Accurancy:  0.722658097743988 | Validation Accurancy:  0.6579789519309998\n",
      "Epoch:  497 | Train Accurancy:  0.7230682075023651 | Validation Accurancy:  0.6583738327026367\n",
      "Epoch:  498 | Train Accurancy:  0.7234773337841034 | Validation Accurancy:  0.6587713360786438\n",
      "Epoch:  499 | Train Accurancy:  0.7238853573799133 | Validation Accurancy:  0.6592011451721191\n",
      "Epoch:  500 | Train Accurancy:  0.7242922186851501 | Validation Accurancy:  0.6595880687236786\n",
      "Epoch:  501 | Train Accurancy:  0.7246981859207153 | Validation Accurancy:  0.6599791347980499\n",
      "Epoch:  502 | Train Accurancy:  0.7251029908657074 | Validation Accurancy:  0.6604037582874298\n",
      "Epoch:  503 | Train Accurancy:  0.7255066633224487 | Validation Accurancy:  0.6607861816883087\n",
      "Epoch:  504 | Train Accurancy:  0.725909411907196 | Validation Accurancy:  0.6611733734607697\n",
      "Epoch:  505 | Train Accurancy:  0.7263111174106598 | Validation Accurancy:  0.6615630984306335\n",
      "Epoch:  506 | Train Accurancy:  0.726711630821228 | Validation Accurancy:  0.6619853973388672\n",
      "Epoch:  507 | Train Accurancy:  0.7271112501621246 | Validation Accurancy:  0.6623650789260864\n",
      "Epoch:  508 | Train Accurancy:  0.7275098264217377 | Validation Accurancy:  0.6627489626407623\n",
      "Epoch:  509 | Train Accurancy:  0.7279073596000671 | Validation Accurancy:  0.6631662547588348\n",
      "Epoch:  510 | Train Accurancy:  0.728303849697113 | Validation Accurancy:  0.6635418832302094\n",
      "Epoch:  511 | Train Accurancy:  0.7286992967128754 | Validation Accurancy:  0.6639221608638763\n",
      "Epoch:  512 | Train Accurancy:  0.7290937602519989 | Validation Accurancy:  0.6643048822879791\n",
      "Epoch:  513 | Train Accurancy:  0.7294870316982269 | Validation Accurancy:  0.6647202372550964\n",
      "Epoch:  514 | Train Accurancy:  0.7298794984817505 | Validation Accurancy:  0.6650930345058441\n",
      "Epoch:  515 | Train Accurancy:  0.7302709519863129 | Validation Accurancy:  0.6654701828956604\n",
      "Epoch:  516 | Train Accurancy:  0.7306614220142365 | Validation Accurancy:  0.6658806502819061\n",
      "Epoch:  517 | Train Accurancy:  0.7310506105422974 | Validation Accurancy:  0.666249543428421\n",
      "Epoch:  518 | Train Accurancy:  0.7314391136169434 | Validation Accurancy:  0.6666230261325836\n",
      "Epoch:  519 | Train Accurancy:  0.7318265736103058 | Validation Accurancy:  0.6669992208480835\n",
      "Epoch:  520 | Train Accurancy:  0.7322129011154175 | Validation Accurancy:  0.6674076020717621\n",
      "Epoch:  521 | Train Accurancy:  0.7325983345508575 | Validation Accurancy:  0.6677740216255188\n",
      "Epoch:  522 | Train Accurancy:  0.7329827845096588 | Validation Accurancy:  0.6681445240974426\n",
      "Epoch:  523 | Train Accurancy:  0.7333662211894989 | Validation Accurancy:  0.6685481667518616\n",
      "Epoch:  524 | Train Accurancy:  0.7337486445903778 | Validation Accurancy:  0.6689105331897736\n",
      "Epoch:  525 | Train Accurancy:  0.7341301739215851 | Validation Accurancy:  0.6692776381969452\n",
      "Epoch:  526 | Train Accurancy:  0.734510749578476 | Validation Accurancy:  0.6696779429912567\n",
      "Epoch:  527 | Train Accurancy:  0.7348902523517609 | Validation Accurancy:  0.6700372397899628\n",
      "Epoch:  528 | Train Accurancy:  0.7352688908576965 | Validation Accurancy:  0.670401394367218\n",
      "Epoch:  529 | Train Accurancy:  0.7356466054916382 | Validation Accurancy:  0.6707988381385803\n",
      "Epoch:  530 | Train Accurancy:  0.7360230982303619 | Validation Accurancy:  0.6711554527282715\n",
      "Epoch:  531 | Train Accurancy:  0.7363988757133484 | Validation Accurancy:  0.6715168058872223\n",
      "Epoch:  532 | Train Accurancy:  0.7367737591266632 | Validation Accurancy:  0.6718810498714447\n",
      "Epoch:  533 | Train Accurancy:  0.7371474802494049 | Validation Accurancy:  0.6722771227359772\n",
      "Epoch:  534 | Train Accurancy:  0.7375203967094421 | Validation Accurancy:  0.6726316809654236\n",
      "Epoch:  535 | Train Accurancy:  0.737892359495163 | Validation Accurancy:  0.6729906499385834\n",
      "Epoch:  536 | Train Accurancy:  0.7382634282112122 | Validation Accurancy:  0.6733822524547577\n",
      "Epoch:  537 | Train Accurancy:  0.7386334240436554 | Validation Accurancy:  0.6737331449985504\n",
      "Epoch:  538 | Train Accurancy:  0.7390025854110718 | Validation Accurancy:  0.6740886270999908\n",
      "Epoch:  539 | Train Accurancy:  0.7393707633018494 | Validation Accurancy:  0.6744769811630249\n",
      "Epoch:  540 | Train Accurancy:  0.7397380173206329 | Validation Accurancy:  0.674825131893158\n",
      "Epoch:  541 | Train Accurancy:  0.740104466676712 | Validation Accurancy:  0.6751778721809387\n",
      "Epoch:  542 | Train Accurancy:  0.7404698431491852 | Validation Accurancy:  0.6755635142326355\n",
      "Epoch:  543 | Train Accurancy:  0.7408343553543091 | Validation Accurancy:  0.6759089529514313\n",
      "Epoch:  544 | Train Accurancy:  0.7411980330944061 | Validation Accurancy:  0.6762591898441315\n",
      "Epoch:  545 | Train Accurancy:  0.7415606677532196 | Validation Accurancy:  0.676642119884491\n",
      "Epoch:  546 | Train Accurancy:  0.7419224977493286 | Validation Accurancy:  0.6769849956035614\n",
      "Epoch:  547 | Train Accurancy:  0.7422833442687988 | Validation Accurancy:  0.6773326992988586\n",
      "Epoch:  548 | Train Accurancy:  0.7426433861255646 | Validation Accurancy:  0.6777130961418152\n",
      "Epoch:  549 | Train Accurancy:  0.7430024147033691 | Validation Accurancy:  0.678053468465805\n",
      "Epoch:  550 | Train Accurancy:  0.7433606684207916 | Validation Accurancy:  0.6783985197544098\n",
      "Epoch:  551 | Train Accurancy:  0.7437179386615753 | Validation Accurancy:  0.678776204586029\n",
      "Epoch:  552 | Train Accurancy:  0.7440742254257202 | Validation Accurancy:  0.679114043712616\n",
      "Epoch:  553 | Train Accurancy:  0.744429886341095 | Validation Accurancy:  0.6794566810131073\n",
      "Epoch:  554 | Train Accurancy:  0.7447844445705414 | Validation Accurancy:  0.6798317730426788\n",
      "Epoch:  555 | Train Accurancy:  0.7451381683349609 | Validation Accurancy:  0.6801671981811523\n",
      "Epoch:  556 | Train Accurancy:  0.7454911172389984 | Validation Accurancy:  0.6805073916912079\n",
      "Epoch:  557 | Train Accurancy:  0.745843231678009 | Validation Accurancy:  0.6808800399303436\n",
      "Epoch:  558 | Train Accurancy:  0.7461941838264465 | Validation Accurancy:  0.6812130808830261\n",
      "Epoch:  559 | Train Accurancy:  0.746544599533081 | Validation Accurancy:  0.681550920009613\n",
      "Epoch:  560 | Train Accurancy:  0.7468938231468201 | Validation Accurancy:  0.6819210946559906\n",
      "Epoch:  561 | Train Accurancy:  0.7472423315048218 | Validation Accurancy:  0.6822518110275269\n",
      "Epoch:  562 | Train Accurancy:  0.7475900948047638 | Validation Accurancy:  0.6825872361660004\n",
      "Epoch:  563 | Train Accurancy:  0.7479367852210999 | Validation Accurancy:  0.6829548478126526\n",
      "Epoch:  564 | Train Accurancy:  0.748282790184021 | Validation Accurancy:  0.6832832098007202\n",
      "Epoch:  565 | Train Accurancy:  0.7486279606819153 | Validation Accurancy:  0.6836163699626923\n",
      "Epoch:  566 | Train Accurancy:  0.7489720284938812 | Validation Accurancy:  0.6839815378189087\n",
      "Epoch:  567 | Train Accurancy:  0.7493155002593994 | Validation Accurancy:  0.6843075454235077\n",
      "Epoch:  568 | Train Accurancy:  0.7496579885482788 | Validation Accurancy:  0.684667557477951\n",
      "Epoch:  569 | Train Accurancy:  0.749999612569809 | Validation Accurancy:  0.684989869594574\n",
      "Epoch:  570 | Train Accurancy:  0.750340461730957 | Validation Accurancy:  0.6853176653385162\n",
      "Epoch:  571 | Train Accurancy:  0.7506804913282394 | Validation Accurancy:  0.6856779456138611\n",
      "Epoch:  572 | Train Accurancy:  0.7510196566581726 | Validation Accurancy:  0.6859996020793915\n",
      "Epoch:  573 | Train Accurancy:  0.7513580024242401 | Validation Accurancy:  0.6863262951374054\n",
      "Epoch:  574 | Train Accurancy:  0.7516954392194748 | Validation Accurancy:  0.6866849362850189\n",
      "Epoch:  575 | Train Accurancy:  0.7520322203636169 | Validation Accurancy:  0.6870047450065613\n",
      "Epoch:  576 | Train Accurancy:  0.7523680478334427 | Validation Accurancy:  0.6873583495616913\n",
      "Epoch:  577 | Train Accurancy:  0.752702996134758 | Validation Accurancy:  0.6876746714115143\n",
      "Epoch:  578 | Train Accurancy:  0.7530373185873032 | Validation Accurancy:  0.6879964172840118\n",
      "Epoch:  579 | Train Accurancy:  0.7533705532550812 | Validation Accurancy:  0.6883504986763\n",
      "Epoch:  580 | Train Accurancy:  0.7537031471729279 | Validation Accurancy:  0.6886662542819977\n",
      "Epoch:  581 | Train Accurancy:  0.7540349066257477 | Validation Accurancy:  0.6889869272708893\n",
      "Epoch:  582 | Train Accurancy:  0.7543656826019287 | Validation Accurancy:  0.6893393695354462\n",
      "Epoch:  583 | Train Accurancy:  0.7546958774328232 | Validation Accurancy:  0.6896534264087677\n",
      "Epoch:  584 | Train Accurancy:  0.7550252079963684 | Validation Accurancy:  0.6900008618831635\n",
      "Epoch:  585 | Train Accurancy:  0.7553537338972092 | Validation Accurancy:  0.6903114318847656\n",
      "Epoch:  586 | Train Accurancy:  0.7556814551353455 | Validation Accurancy:  0.6906274259090424\n",
      "Epoch:  587 | Train Accurancy:  0.7560083270072937 | Validation Accurancy:  0.6909752488136292\n",
      "Epoch:  588 | Train Accurancy:  0.7563344389200211 | Validation Accurancy:  0.6912852823734283\n",
      "Epoch:  589 | Train Accurancy:  0.7566597312688828 | Validation Accurancy:  0.6916288137435913\n",
      "Epoch:  590 | Train Accurancy:  0.75698421895504 | Validation Accurancy:  0.6919355392456055\n",
      "Epoch:  591 | Train Accurancy:  0.7573080062866211 | Validation Accurancy:  0.6922478973865509\n",
      "Epoch:  592 | Train Accurancy:  0.7576307952404022 | Validation Accurancy:  0.6925919651985168\n",
      "Epoch:  593 | Train Accurancy:  0.7579530775547028 | Validation Accurancy:  0.6928984522819519\n",
      "Epoch:  594 | Train Accurancy:  0.7582743763923645 | Validation Accurancy:  0.6932381987571716\n",
      "Epoch:  595 | Train Accurancy:  0.7585948407649994 | Validation Accurancy:  0.6935414969921112\n",
      "Epoch:  596 | Train Accurancy:  0.7589147537946701 | Validation Accurancy:  0.6938504278659821\n",
      "Epoch:  597 | Train Accurancy:  0.7592336684465408 | Validation Accurancy:  0.6941907107830048\n",
      "Epoch:  598 | Train Accurancy:  0.759552001953125 | Validation Accurancy:  0.6944937407970428\n",
      "Epoch:  599 | Train Accurancy:  0.7598693817853928 | Validation Accurancy:  0.6948298215866089\n",
      "Epoch:  600 | Train Accurancy:  0.760186105966568 | Validation Accurancy:  0.6951296627521515\n",
      "Epoch:  601 | Train Accurancy:  0.7605020999908447 | Validation Accurancy:  0.6954632699489594\n",
      "Epoch:  602 | Train Accurancy:  0.7608171254396439 | Validation Accurancy:  0.6957609951496124\n",
      "Epoch:  603 | Train Accurancy:  0.7611316740512848 | Validation Accurancy:  0.6960645616054535\n",
      "Epoch:  604 | Train Accurancy:  0.7614451497793198 | Validation Accurancy:  0.6963995397090912\n",
      "Epoch:  605 | Train Accurancy:  0.7617580145597458 | Validation Accurancy:  0.6966977417469025\n",
      "Epoch:  606 | Train Accurancy:  0.7620701342821121 | Validation Accurancy:  0.6970285773277283\n",
      "Epoch:  607 | Train Accurancy:  0.76238152384758 | Validation Accurancy:  0.6973238289356232\n",
      "Epoch:  608 | Train Accurancy:  0.7626921385526657 | Validation Accurancy:  0.6976523399353027\n",
      "Epoch:  609 | Train Accurancy:  0.7630018591880798 | Validation Accurancy:  0.6979454755783081\n",
      "Epoch:  610 | Train Accurancy:  0.7633109837770462 | Validation Accurancy:  0.6982720196247101\n",
      "Epoch:  611 | Train Accurancy:  0.7636193335056305 | Validation Accurancy:  0.6985636353492737\n",
      "Epoch:  612 | Train Accurancy:  0.7639269232749939 | Validation Accurancy:  0.6988611221313477\n",
      "Epoch:  613 | Train Accurancy:  0.764233723282814 | Validation Accurancy:  0.6991895735263824\n",
      "Epoch:  614 | Train Accurancy:  0.7645398527383804 | Validation Accurancy:  0.6994818150997162\n",
      "Epoch:  615 | Train Accurancy:  0.7648451924324036 | Validation Accurancy:  0.6998063325881958\n",
      "Epoch:  616 | Train Accurancy:  0.7651498317718506 | Validation Accurancy:  0.7000956237316132\n",
      "Epoch:  617 | Train Accurancy:  0.7654537260532379 | Validation Accurancy:  0.7004178464412689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  618 | Train Accurancy:  0.7657569199800491 | Validation Accurancy:  0.7007051706314087\n",
      "Epoch:  619 | Train Accurancy:  0.7660593390464783 | Validation Accurancy:  0.7010256052017212\n",
      "Epoch:  620 | Train Accurancy:  0.7663609534502029 | Validation Accurancy:  0.7013114392757416\n",
      "Epoch:  621 | Train Accurancy:  0.7666618973016739 | Validation Accurancy:  0.7016302943229675\n",
      "Epoch:  622 | Train Accurancy:  0.7669621109962463 | Validation Accurancy:  0.7019147872924805\n",
      "Epoch:  623 | Train Accurancy:  0.7672612220048904 | Validation Accurancy:  0.7021694779396057\n",
      "Epoch:  624 | Train Accurancy:  0.7675577700138092 | Validation Accurancy:  0.7024117410182953\n",
      "Epoch:  625 | Train Accurancy:  0.7678535133600235 | Validation Accurancy:  0.7026741206645966\n",
      "Epoch:  626 | Train Accurancy:  0.7681484073400497 | Validation Accurancy:  0.7029762864112854\n",
      "Epoch:  627 | Train Accurancy:  0.7684425413608551 | Validation Accurancy:  0.7032487690448761\n",
      "Epoch:  628 | Train Accurancy:  0.7687361389398575 | Validation Accurancy:  0.7035298645496368\n",
      "Epoch:  629 | Train Accurancy:  0.7690289169549942 | Validation Accurancy:  0.7038162052631378\n",
      "Epoch:  630 | Train Accurancy:  0.7693209499120712 | Validation Accurancy:  0.7041328251361847\n",
      "Epoch:  631 | Train Accurancy:  0.7696122825145721 | Validation Accurancy:  0.7044138014316559\n",
      "Epoch:  632 | Train Accurancy:  0.7699028849601746 | Validation Accurancy:  0.7046995162963867\n",
      "Epoch:  633 | Train Accurancy:  0.7701928913593292 | Validation Accurancy:  0.7049880921840668\n",
      "Epoch:  634 | Train Accurancy:  0.770482137799263 | Validation Accurancy:  0.705278217792511\n",
      "Epoch:  635 | Train Accurancy:  0.7707706838846207 | Validation Accurancy:  0.7055691182613373\n",
      "Epoch:  636 | Train Accurancy:  0.7710584998130798 | Validation Accurancy:  0.705886960029602\n",
      "Epoch:  637 | Train Accurancy:  0.7713456451892853 | Validation Accurancy:  0.7061676681041718\n",
      "Epoch:  638 | Train Accurancy:  0.7716320008039474 | Validation Accurancy:  0.7064519822597504\n",
      "Epoch:  639 | Train Accurancy:  0.771917849779129 | Validation Accurancy:  0.706738144159317\n",
      "Epoch:  640 | Train Accurancy:  0.7722029983997345 | Validation Accurancy:  0.7070254683494568\n",
      "Epoch:  641 | Train Accurancy:  0.7724874019622803 | Validation Accurancy:  0.70731320977211\n",
      "Epoch:  642 | Train Accurancy:  0.772771030664444 | Validation Accurancy:  0.7076275646686554\n",
      "Epoch:  643 | Train Accurancy:  0.7730540484189987 | Validation Accurancy:  0.7079048752784729\n",
      "Epoch:  644 | Train Accurancy:  0.7733363062143326 | Validation Accurancy:  0.7081855833530426\n",
      "Epoch:  645 | Train Accurancy:  0.7736179828643799 | Validation Accurancy:  0.7084683179855347\n",
      "Epoch:  646 | Train Accurancy:  0.7738989740610123 | Validation Accurancy:  0.7087520658969879\n",
      "Epoch:  647 | Train Accurancy:  0.7741792649030685 | Validation Accurancy:  0.7090362310409546\n",
      "Epoch:  648 | Train Accurancy:  0.7744589000940323 | Validation Accurancy:  0.7093467116355896\n",
      "Epoch:  649 | Train Accurancy:  0.7747379094362259 | Validation Accurancy:  0.709620475769043\n",
      "Epoch:  650 | Train Accurancy:  0.775016114115715 | Validation Accurancy:  0.7098976373672485\n",
      "Epoch:  651 | Train Accurancy:  0.7752936780452728 | Validation Accurancy:  0.7101767957210541\n",
      "Epoch:  652 | Train Accurancy:  0.7755707055330276 | Validation Accurancy:  0.7104569673538208\n",
      "Epoch:  653 | Train Accurancy:  0.7758469432592392 | Validation Accurancy:  0.710737556219101\n",
      "Epoch:  654 | Train Accurancy:  0.7761218994855881 | Validation Accurancy:  0.7109798491001129\n",
      "Epoch:  655 | Train Accurancy:  0.7763960808515549 | Validation Accurancy:  0.7112083733081818\n",
      "Epoch:  656 | Train Accurancy:  0.776669442653656 | Validation Accurancy:  0.7114546597003937\n",
      "Epoch:  657 | Train Accurancy:  0.7769419103860855 | Validation Accurancy:  0.7117123305797577\n",
      "Epoch:  658 | Train Accurancy:  0.7772137671709061 | Validation Accurancy:  0.7119770348072052\n",
      "Epoch:  659 | Train Accurancy:  0.7774849534034729 | Validation Accurancy:  0.7122460603713989\n",
      "Epoch:  660 | Train Accurancy:  0.7777555137872696 | Validation Accurancy:  0.7125176787376404\n",
      "Epoch:  661 | Train Accurancy:  0.7780254185199738 | Validation Accurancy:  0.7127907574176788\n",
      "Epoch:  662 | Train Accurancy:  0.7782945930957794 | Validation Accurancy:  0.713064581155777\n",
      "Epoch:  663 | Train Accurancy:  0.7785632014274597 | Validation Accurancy:  0.7133386731147766\n",
      "Epoch:  664 | Train Accurancy:  0.7788310199975967 | Validation Accurancy:  0.7136127054691315\n",
      "Epoch:  665 | Train Accurancy:  0.7790984213352203 | Validation Accurancy:  0.7138865888118744\n",
      "Epoch:  666 | Train Accurancy:  0.7793648988008499 | Validation Accurancy:  0.7141600549221039\n",
      "Epoch:  667 | Train Accurancy:  0.7796310037374496 | Validation Accurancy:  0.71443310379982\n",
      "Epoch:  668 | Train Accurancy:  0.7798962891101837 | Validation Accurancy:  0.714705765247345\n",
      "Epoch:  669 | Train Accurancy:  0.7801610678434372 | Validation Accurancy:  0.7149778604507446\n",
      "Epoch:  670 | Train Accurancy:  0.7804250717163086 | Validation Accurancy:  0.7152495384216309\n",
      "Epoch:  671 | Train Accurancy:  0.780688464641571 | Validation Accurancy:  0.7155205607414246\n",
      "Epoch:  672 | Train Accurancy:  0.7809513062238693 | Validation Accurancy:  0.7157911360263824\n",
      "Epoch:  673 | Train Accurancy:  0.7812134325504303 | Validation Accurancy:  0.716061145067215\n",
      "Epoch:  674 | Train Accurancy:  0.7814749330282211 | Validation Accurancy:  0.7163305580615997\n",
      "Epoch:  675 | Train Accurancy:  0.7817359119653702 | Validation Accurancy:  0.7165994346141815\n",
      "Epoch:  676 | Train Accurancy:  0.781996101140976 | Validation Accurancy:  0.7168678045272827\n",
      "Epoch:  677 | Train Accurancy:  0.7822557389736176 | Validation Accurancy:  0.7171356976032257\n",
      "Epoch:  678 | Train Accurancy:  0.7825147956609726 | Validation Accurancy:  0.7174028754234314\n",
      "Epoch:  679 | Train Accurancy:  0.7827732115983963 | Validation Accurancy:  0.7176695466041565\n",
      "Epoch:  680 | Train Accurancy:  0.7830310165882111 | Validation Accurancy:  0.7179358303546906\n",
      "Epoch:  681 | Train Accurancy:  0.7832881510257721 | Validation Accurancy:  0.7182013690471649\n",
      "Epoch:  682 | Train Accurancy:  0.7835447192192078 | Validation Accurancy:  0.7184664607048035\n",
      "Epoch:  683 | Train Accurancy:  0.7838006466627121 | Validation Accurancy:  0.7187309265136719\n",
      "Epoch:  684 | Train Accurancy:  0.7840559482574463 | Validation Accurancy:  0.7189949750900269\n",
      "Epoch:  685 | Train Accurancy:  0.784310594201088 | Validation Accurancy:  0.7192584276199341\n",
      "Epoch:  686 | Train Accurancy:  0.7845648378133774 | Validation Accurancy:  0.7195213139057159\n",
      "Epoch:  687 | Train Accurancy:  0.78481824696064 | Validation Accurancy:  0.719783753156662\n",
      "Epoch:  688 | Train Accurancy:  0.7850711196660995 | Validation Accurancy:  0.7200455367565155\n",
      "Epoch:  689 | Train Accurancy:  0.785323441028595 | Validation Accurancy:  0.7203068435192108\n",
      "Epoch:  690 | Train Accurancy:  0.7855751067399979 | Validation Accurancy:  0.7205676436424255\n",
      "Epoch:  691 | Train Accurancy:  0.7858261168003082 | Validation Accurancy:  0.7208279371261597\n",
      "Epoch:  692 | Train Accurancy:  0.7860766351222992 | Validation Accurancy:  0.7210875749588013\n",
      "Epoch:  693 | Train Accurancy:  0.7863265126943588 | Validation Accurancy:  0.7213467359542847\n",
      "Epoch:  694 | Train Accurancy:  0.7865758538246155 | Validation Accurancy:  0.7216053605079651\n",
      "Epoch:  695 | Train Accurancy:  0.7868244647979736 | Validation Accurancy:  0.7218634784221649\n",
      "Epoch:  696 | Train Accurancy:  0.7870725840330124 | Validation Accurancy:  0.7221210598945618\n",
      "Epoch:  697 | Train Accurancy:  0.787320077419281 | Validation Accurancy:  0.722378134727478\n",
      "Epoch:  698 | Train Accurancy:  0.7875669896602631 | Validation Accurancy:  0.7226347029209137\n",
      "Epoch:  699 | Train Accurancy:  0.7878133356571198 | Validation Accurancy:  0.7228906750679016\n",
      "Epoch:  700 | Train Accurancy:  0.7880590409040451 | Validation Accurancy:  0.7231462299823761\n",
      "Epoch:  701 | Train Accurancy:  0.7883042395114899 | Validation Accurancy:  0.7234011590480804\n",
      "Epoch:  702 | Train Accurancy:  0.7885488122701645 | Validation Accurancy:  0.7236555814743042\n",
      "Epoch:  703 | Train Accurancy:  0.7887928038835526 | Validation Accurancy:  0.723909467458725\n",
      "Epoch:  704 | Train Accurancy:  0.7890362590551376 | Validation Accurancy:  0.7241629362106323\n",
      "Epoch:  705 | Train Accurancy:  0.7892789989709854 | Validation Accurancy:  0.7244150936603546\n",
      "Epoch:  706 | Train Accurancy:  0.7895212024450302 | Validation Accurancy:  0.724667102098465\n",
      "Epoch:  707 | Train Accurancy:  0.789762869477272 | Validation Accurancy:  0.7249187529087067\n",
      "Epoch:  708 | Train Accurancy:  0.7900038212537766 | Validation Accurancy:  0.7251700758934021\n",
      "Epoch:  709 | Train Accurancy:  0.7902443259954453 | Validation Accurancy:  0.7254208028316498\n",
      "Epoch:  710 | Train Accurancy:  0.7904842048883438 | Validation Accurancy:  0.725671112537384\n",
      "Epoch:  711 | Train Accurancy:  0.7907235026359558 | Validation Accurancy:  0.7259210050106049\n",
      "Epoch:  712 | Train Accurancy:  0.790962278842926 | Validation Accurancy:  0.7261702716350555\n",
      "Epoch:  713 | Train Accurancy:  0.7912004142999649 | Validation Accurancy:  0.7264191508293152\n",
      "Epoch:  714 | Train Accurancy:  0.7914381176233292 | Validation Accurancy:  0.7266675233840942\n",
      "Epoch:  715 | Train Accurancy:  0.7916751056909561 | Validation Accurancy:  0.7269153594970703\n",
      "Epoch:  716 | Train Accurancy:  0.7919116318225861 | Validation Accurancy:  0.727162778377533\n",
      "Epoch:  717 | Train Accurancy:  0.7921475917100906 | Validation Accurancy:  0.7274095416069031\n",
      "Epoch:  718 | Train Accurancy:  0.7923830151557922 | Validation Accurancy:  0.7276559472084045\n",
      "Epoch:  719 | Train Accurancy:  0.7926177680492401 | Validation Accurancy:  0.7279017567634583\n",
      "Epoch:  720 | Train Accurancy:  0.7928521186113358 | Validation Accurancy:  0.7281470596790314\n",
      "Epoch:  721 | Train Accurancy:  0.7930858582258224 | Validation Accurancy:  0.7283919751644135\n",
      "Epoch:  722 | Train Accurancy:  0.793318971991539 | Validation Accurancy:  0.7286362648010254\n",
      "Epoch:  723 | Train Accurancy:  0.793551579117775 | Validation Accurancy:  0.7288800477981567\n",
      "Epoch:  724 | Train Accurancy:  0.7937837094068527 | Validation Accurancy:  0.729123443365097\n",
      "Epoch:  725 | Train Accurancy:  0.7940152138471603 | Validation Accurancy:  0.7293663322925568\n",
      "Epoch:  726 | Train Accurancy:  0.7942462861537933 | Validation Accurancy:  0.7296087145805359\n",
      "Epoch:  727 | Train Accurancy:  0.7944766581058502 | Validation Accurancy:  0.7298501133918762\n",
      "Epoch:  728 | Train Accurancy:  0.7947065383195877 | Validation Accurancy:  0.7300913035869598\n",
      "Epoch:  729 | Train Accurancy:  0.7949357628822327 | Validation Accurancy:  0.73033207654953\n",
      "Epoch:  730 | Train Accurancy:  0.7951646149158478 | Validation Accurancy:  0.730572372674942\n",
      "Epoch:  731 | Train Accurancy:  0.7953928261995316 | Validation Accurancy:  0.7308123409748077\n",
      "Epoch:  732 | Train Accurancy:  0.7956205308437347 | Validation Accurancy:  0.7310517430305481\n",
      "Epoch:  733 | Train Accurancy:  0.795847624540329 | Validation Accurancy:  0.7312907576560974\n",
      "Epoch:  734 | Train Accurancy:  0.7960743308067322 | Validation Accurancy:  0.7315292656421661\n",
      "Epoch:  735 | Train Accurancy:  0.7963003665208817 | Validation Accurancy:  0.7317672669887543\n",
      "Epoch:  736 | Train Accurancy:  0.7965259850025177 | Validation Accurancy:  0.732004851102829\n",
      "Epoch:  737 | Train Accurancy:  0.7967510521411896 | Validation Accurancy:  0.7322418987751007\n",
      "Epoch:  738 | Train Accurancy:  0.7969755679368973 | Validation Accurancy:  0.7324784994125366\n",
      "Epoch:  739 | Train Accurancy:  0.7971995621919632 | Validation Accurancy:  0.7327146530151367\n",
      "Epoch:  740 | Train Accurancy:  0.7974229753017426 | Validation Accurancy:  0.732950359582901\n",
      "Epoch:  741 | Train Accurancy:  0.7976459562778473 | Validation Accurancy:  0.7331854403018951\n",
      "Epoch:  742 | Train Accurancy:  0.7978682368993759 | Validation Accurancy:  0.733420193195343\n",
      "Epoch:  743 | Train Accurancy:  0.7980902045965195 | Validation Accurancy:  0.7336544096469879\n",
      "Epoch:  744 | Train Accurancy:  0.79831163585186 | Validation Accurancy:  0.7338881492614746\n",
      "Epoch:  745 | Train Accurancy:  0.7985324561595917 | Validation Accurancy:  0.7341214716434479\n",
      "Epoch:  746 | Train Accurancy:  0.7987528145313263 | Validation Accurancy:  0.7343543171882629\n",
      "Epoch:  747 | Train Accurancy:  0.7989726364612579 | Validation Accurancy:  0.734586626291275\n",
      "Epoch:  748 | Train Accurancy:  0.7991920113563538 | Validation Accurancy:  0.7348186075687408\n",
      "Epoch:  749 | Train Accurancy:  0.7994108200073242 | Validation Accurancy:  0.7350500822067261\n",
      "Epoch:  750 | Train Accurancy:  0.7996290177106857 | Validation Accurancy:  0.7352810204029083\n",
      "Epoch:  751 | Train Accurancy:  0.7998466938734055 | Validation Accurancy:  0.7354533672332764\n",
      "Epoch:  752 | Train Accurancy:  0.800063744187355 | Validation Accurancy:  0.7357038855552673\n",
      "Epoch:  753 | Train Accurancy:  0.8002803921699524 | Validation Accurancy:  0.7358886003494263\n",
      "Epoch:  754 | Train Accurancy:  0.8004963248968124 | Validation Accurancy:  0.7361465096473694\n",
      "Epoch:  755 | Train Accurancy:  0.8007118403911591 | Validation Accurancy:  0.7363357245922089\n",
      "Epoch:  756 | Train Accurancy:  0.800926998257637 | Validation Accurancy:  0.7365382015705109\n",
      "Epoch:  757 | Train Accurancy:  0.8011412471532822 | Validation Accurancy:  0.736806720495224\n",
      "Epoch:  758 | Train Accurancy:  0.8013553023338318 | Validation Accurancy:  0.7370026707649231\n",
      "Epoch:  759 | Train Accurancy:  0.8015689104795456 | Validation Accurancy:  0.7372089922428131\n",
      "Epoch:  760 | Train Accurancy:  0.801781639456749 | Validation Accurancy:  0.73747918009758\n",
      "Epoch:  761 | Train Accurancy:  0.801994264125824 | Validation Accurancy:  0.7376760244369507\n",
      "Epoch:  762 | Train Accurancy:  0.8022063076496124 | Validation Accurancy:  0.7378824353218079\n",
      "Epoch:  763 | Train Accurancy:  0.8024176210165024 | Validation Accurancy:  0.7381517589092255\n",
      "Epoch:  764 | Train Accurancy:  0.8026286512613297 | Validation Accurancy:  0.738348126411438\n",
      "Epoch:  765 | Train Accurancy:  0.8028391301631927 | Validation Accurancy:  0.7385537326335907\n",
      "Epoch:  766 | Train Accurancy:  0.8030491918325424 | Validation Accurancy:  0.7388217747211456\n",
      "Epoch:  767 | Train Accurancy:  0.8032585978507996 | Validation Accurancy:  0.7390170693397522\n",
      "Epoch:  768 | Train Accurancy:  0.8034677058458328 | Validation Accurancy:  0.7392215430736542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  769 | Train Accurancy:  0.8036762773990631 | Validation Accurancy:  0.7394316494464874\n",
      "Epoch:  770 | Train Accurancy:  0.8038842976093292 | Validation Accurancy:  0.7397013902664185\n",
      "Epoch:  771 | Train Accurancy:  0.8040917366743088 | Validation Accurancy:  0.739897608757019\n",
      "Epoch:  772 | Train Accurancy:  0.8042988628149033 | Validation Accurancy:  0.7401019632816315\n",
      "Epoch:  773 | Train Accurancy:  0.8045055717229843 | Validation Accurancy:  0.740311473608017\n",
      "Epoch:  774 | Train Accurancy:  0.8047115802764893 | Validation Accurancy:  0.7405798733234406\n",
      "Epoch:  775 | Train Accurancy:  0.8049170970916748 | Validation Accurancy:  0.740774929523468\n",
      "Epoch:  776 | Train Accurancy:  0.8051223605871201 | Validation Accurancy:  0.7409780323505402\n",
      "Epoch:  777 | Train Accurancy:  0.8053270429372787 | Validation Accurancy:  0.7411861717700958\n",
      "Epoch:  778 | Train Accurancy:  0.8055312782526016 | Validation Accurancy:  0.741397351026535\n",
      "Epoch:  779 | Train Accurancy:  0.8057348877191544 | Validation Accurancy:  0.7416654527187347\n",
      "Epoch:  780 | Train Accurancy:  0.8059381544589996 | Validation Accurancy:  0.7418602705001831\n",
      "Epoch:  781 | Train Accurancy:  0.806140810251236 | Validation Accurancy:  0.7420624494552612\n",
      "Epoch:  782 | Train Accurancy:  0.8063431829214096 | Validation Accurancy:  0.7422691881656647\n",
      "Epoch:  783 | Train Accurancy:  0.8065450191497803 | Validation Accurancy:  0.7424787282943726\n",
      "Epoch:  784 | Train Accurancy:  0.806746318936348 | Validation Accurancy:  0.7427445650100708\n",
      "Epoch:  785 | Train Accurancy:  0.8069472312927246 | Validation Accurancy:  0.7429376244544983\n",
      "Epoch:  786 | Train Accurancy:  0.8071475774049759 | Validation Accurancy:  0.7431380152702332\n",
      "Epoch:  787 | Train Accurancy:  0.8073475807905197 | Validation Accurancy:  0.7433429956436157\n",
      "Epoch:  788 | Train Accurancy:  0.807547003030777 | Validation Accurancy:  0.7435505986213684\n",
      "Epoch:  789 | Train Accurancy:  0.8077460676431656 | Validation Accurancy:  0.74375981092453\n",
      "Epoch:  790 | Train Accurancy:  0.8079446852207184 | Validation Accurancy:  0.744023859500885\n",
      "Epoch:  791 | Train Accurancy:  0.8081426322460175 | Validation Accurancy:  0.7442156076431274\n",
      "Epoch:  792 | Train Accurancy:  0.808340385556221 | Validation Accurancy:  0.7444142401218414\n",
      "Epoch:  793 | Train Accurancy:  0.8085374981164932 | Validation Accurancy:  0.7446171641349792\n",
      "Epoch:  794 | Train Accurancy:  0.8087342530488968 | Validation Accurancy:  0.7448228001594543\n",
      "Epoch:  795 | Train Accurancy:  0.8089304864406586 | Validation Accurancy:  0.7450298070907593\n",
      "Epoch:  796 | Train Accurancy:  0.8091263025999069 | Validation Accurancy:  0.7452376186847687\n",
      "Epoch:  797 | Train Accurancy:  0.8093216866254807 | Validation Accurancy:  0.7454458773136139\n",
      "Epoch:  798 | Train Accurancy:  0.809516504406929 | Validation Accurancy:  0.7457071542739868\n",
      "Epoch:  799 | Train Accurancy:  0.8097109496593475 | Validation Accurancy:  0.7458969354629517\n",
      "Epoch:  800 | Train Accurancy:  0.8099049776792526 | Validation Accurancy:  0.7460932433605194\n",
      "Epoch:  801 | Train Accurancy:  0.8100985735654831 | Validation Accurancy:  0.7462934851646423\n",
      "Epoch:  802 | Train Accurancy:  0.8102916181087494 | Validation Accurancy:  0.7464962005615234\n",
      "Epoch:  803 | Train Accurancy:  0.8104843348264694 | Validation Accurancy:  0.7467002868652344\n",
      "Epoch:  804 | Train Accurancy:  0.8106765300035477 | Validation Accurancy:  0.7469051480293274\n",
      "Epoch:  805 | Train Accurancy:  0.8108682930469513 | Validation Accurancy:  0.7471103370189667\n",
      "Epoch:  806 | Train Accurancy:  0.8110596388578415 | Validation Accurancy:  0.7473155558109283\n",
      "Epoch:  807 | Train Accurancy:  0.8112505078315735 | Validation Accurancy:  0.7475207448005676\n",
      "Epoch:  808 | Train Accurancy:  0.8114409446716309 | Validation Accurancy:  0.7477256655693054\n",
      "Epoch:  809 | Train Accurancy:  0.8116309642791748 | Validation Accurancy:  0.7479303777217865\n",
      "Epoch:  810 | Train Accurancy:  0.8118205666542053 | Validation Accurancy:  0.7481348812580109\n",
      "Epoch:  811 | Train Accurancy:  0.8120096176862717 | Validation Accurancy:  0.748338907957077\n",
      "Epoch:  812 | Train Accurancy:  0.8121984153985977 | Validation Accurancy:  0.7485426366329193\n",
      "Epoch:  813 | Train Accurancy:  0.8123867362737656 | Validation Accurancy:  0.7487459778785706\n",
      "Epoch:  814 | Train Accurancy:  0.8125744462013245 | Validation Accurancy:  0.7489489316940308\n",
      "Epoch:  815 | Train Accurancy:  0.8127618432044983 | Validation Accurancy:  0.7491515874862671\n",
      "Epoch:  816 | Train Accurancy:  0.8129487633705139 | Validation Accurancy:  0.7493538558483124\n",
      "Epoch:  817 | Train Accurancy:  0.8131353557109833 | Validation Accurancy:  0.7495557069778442\n",
      "Epoch:  818 | Train Accurancy:  0.8133214563131332 | Validation Accurancy:  0.7497572600841522\n",
      "Epoch:  819 | Train Accurancy:  0.8135071396827698 | Validation Accurancy:  0.7499583959579468\n",
      "Epoch:  820 | Train Accurancy:  0.8136923909187317 | Validation Accurancy:  0.7501590400934219\n",
      "Epoch:  821 | Train Accurancy:  0.8138772547245026 | Validation Accurancy:  0.7503594309091568\n",
      "Epoch:  822 | Train Accurancy:  0.8140615820884705 | Validation Accurancy:  0.7505594342947006\n",
      "Epoch:  823 | Train Accurancy:  0.8142456263303757 | Validation Accurancy:  0.7507591247558594\n",
      "Epoch:  824 | Train Accurancy:  0.8144291490316391 | Validation Accurancy:  0.7509583085775375\n",
      "Epoch:  825 | Train Accurancy:  0.8146122992038727 | Validation Accurancy:  0.751157283782959\n",
      "Epoch:  826 | Train Accurancy:  0.8147950321435928 | Validation Accurancy:  0.7513557374477386\n",
      "Epoch:  827 | Train Accurancy:  0.8149773329496384 | Validation Accurancy:  0.751553863286972\n",
      "Epoch:  828 | Train Accurancy:  0.8151591718196869 | Validation Accurancy:  0.751751646399498\n",
      "Epoch:  829 | Train Accurancy:  0.8153406828641891 | Validation Accurancy:  0.7519490569829941\n",
      "Epoch:  830 | Train Accurancy:  0.8155217468738556 | Validation Accurancy:  0.7521460801362991\n",
      "Epoch:  831 | Train Accurancy:  0.8157023936510086 | Validation Accurancy:  0.7523427456617355\n",
      "Epoch:  832 | Train Accurancy:  0.8158826678991318 | Validation Accurancy:  0.7525390237569809\n",
      "Epoch:  833 | Train Accurancy:  0.8160624206066132 | Validation Accurancy:  0.75273497402668\n",
      "Epoch:  834 | Train Accurancy:  0.8162419348955154 | Validation Accurancy:  0.7529305666685104\n",
      "Epoch:  835 | Train Accurancy:  0.8164208233356476 | Validation Accurancy:  0.7531257569789886\n",
      "Epoch:  836 | Train Accurancy:  0.816599428653717 | Validation Accurancy:  0.7533205896615982\n",
      "Epoch:  837 | Train Accurancy:  0.8167777210474014 | Validation Accurancy:  0.7535150498151779\n",
      "Epoch:  838 | Train Accurancy:  0.816955491900444 | Validation Accurancy:  0.753709226846695\n",
      "Epoch:  839 | Train Accurancy:  0.8171328753232956 | Validation Accurancy:  0.7539028823375702\n",
      "Epoch:  840 | Train Accurancy:  0.8173098415136337 | Validation Accurancy:  0.7540962845087051\n",
      "Epoch:  841 | Train Accurancy:  0.8174864202737808 | Validation Accurancy:  0.7542893439531326\n",
      "Epoch:  842 | Train Accurancy:  0.8176625669002533 | Validation Accurancy:  0.7544820159673691\n",
      "Epoch:  843 | Train Accurancy:  0.8178382962942123 | Validation Accurancy:  0.7546743005514145\n",
      "Epoch:  844 | Train Accurancy:  0.8180138021707535 | Validation Accurancy:  0.754866287112236\n",
      "Epoch:  845 | Train Accurancy:  0.8181886076927185 | Validation Accurancy:  0.7550578713417053\n",
      "Epoch:  846 | Train Accurancy:  0.8183633536100388 | Validation Accurancy:  0.7552491575479507\n",
      "Epoch:  847 | Train Accurancy:  0.8185374736785889 | Validation Accurancy:  0.7554400116205215\n",
      "Epoch:  848 | Train Accurancy:  0.8187112361192703 | Validation Accurancy:  0.7556305080652237\n",
      "Epoch:  849 | Train Accurancy:  0.8188846558332443 | Validation Accurancy:  0.7558207213878632\n",
      "Epoch:  850 | Train Accurancy:  0.8190577477216721 | Validation Accurancy:  0.7560105621814728\n",
      "Epoch:  851 | Train Accurancy:  0.8192303329706192 | Validation Accurancy:  0.7562000304460526\n",
      "Epoch:  852 | Train Accurancy:  0.8194026052951813 | Validation Accurancy:  0.7563891559839249\n",
      "Epoch:  853 | Train Accurancy:  0.8195743560791016 | Validation Accurancy:  0.7565779983997345\n",
      "Epoch:  854 | Train Accurancy:  0.8197458386421204 | Validation Accurancy:  0.7567663490772247\n",
      "Epoch:  855 | Train Accurancy:  0.8199168890714645 | Validation Accurancy:  0.7569544464349747\n",
      "Epoch:  856 | Train Accurancy:  0.8200875371694565 | Validation Accurancy:  0.7571422010660172\n",
      "Epoch:  857 | Train Accurancy:  0.8202578276395798 | Validation Accurancy:  0.7573294937610626\n",
      "Epoch:  858 | Train Accurancy:  0.8204277902841568 | Validation Accurancy:  0.757516548037529\n",
      "Epoch:  859 | Train Accurancy:  0.8205973505973816 | Validation Accurancy:  0.7577032893896103\n",
      "Epoch:  860 | Train Accurancy:  0.8207664489746094 | Validation Accurancy:  0.7578895837068558\n",
      "Epoch:  861 | Train Accurancy:  0.8209352642297745 | Validation Accurancy:  0.7580756098031998\n",
      "Epoch:  862 | Train Accurancy:  0.8211037218570709 | Validation Accurancy:  0.7582612335681915\n",
      "Epoch:  863 | Train Accurancy:  0.8212716728448868 | Validation Accurancy:  0.7584466189146042\n",
      "Epoch:  864 | Train Accurancy:  0.8214393258094788 | Validation Accurancy:  0.7586315721273422\n",
      "Epoch:  865 | Train Accurancy:  0.8216066062450409 | Validation Accurancy:  0.7588162422180176\n",
      "Epoch:  866 | Train Accurancy:  0.8217734545469284 | Validation Accurancy:  0.7590005248785019\n",
      "Epoch:  867 | Train Accurancy:  0.8219399750232697 | Validation Accurancy:  0.7591844499111176\n",
      "Epoch:  868 | Train Accurancy:  0.8221061378717422 | Validation Accurancy:  0.7593681216239929\n",
      "Epoch:  869 | Train Accurancy:  0.8222718834877014 | Validation Accurancy:  0.7595514357089996\n",
      "Epoch:  870 | Train Accurancy:  0.8224373757839203 | Validation Accurancy:  0.7597343623638153\n",
      "Epoch:  871 | Train Accurancy:  0.8226023316383362 | Validation Accurancy:  0.7599169760942459\n",
      "Epoch:  872 | Train Accurancy:  0.8227670639753342 | Validation Accurancy:  0.7600992172956467\n",
      "Epoch:  873 | Train Accurancy:  0.8229312300682068 | Validation Accurancy:  0.7602811902761459\n",
      "Epoch:  874 | Train Accurancy:  0.8230952322483063 | Validation Accurancy:  0.7604627311229706\n",
      "Epoch:  875 | Train Accurancy:  0.8232587426900864 | Validation Accurancy:  0.7606440484523773\n",
      "Epoch:  876 | Train Accurancy:  0.8234219551086426 | Validation Accurancy:  0.7608250081539154\n",
      "Epoch:  877 | Train Accurancy:  0.8235847800970078 | Validation Accurancy:  0.7610056549310684\n",
      "Epoch:  878 | Train Accurancy:  0.8237472176551819 | Validation Accurancy:  0.7611858993768692\n",
      "Epoch:  879 | Train Accurancy:  0.8239093571901321 | Validation Accurancy:  0.7613658905029297\n",
      "Epoch:  880 | Train Accurancy:  0.8240710943937302 | Validation Accurancy:  0.7615455240011215\n",
      "Epoch:  881 | Train Accurancy:  0.8242325037717819 | Validation Accurancy:  0.7617248594760895\n",
      "Epoch:  882 | Train Accurancy:  0.8243934959173203 | Validation Accurancy:  0.76190385222435\n",
      "Epoch:  883 | Train Accurancy:  0.8245542049407959 | Validation Accurancy:  0.7620824426412582\n",
      "Epoch:  884 | Train Accurancy:  0.8247144669294357 | Validation Accurancy:  0.7622608095407486\n",
      "Epoch:  885 | Train Accurancy:  0.8248744904994965 | Validation Accurancy:  0.7624388039112091\n",
      "Epoch:  886 | Train Accurancy:  0.8250340819358826 | Validation Accurancy:  0.7626164704561234\n",
      "Epoch:  887 | Train Accurancy:  0.8251932561397552 | Validation Accurancy:  0.7627938389778137\n",
      "Epoch:  888 | Train Accurancy:  0.8253521919250488 | Validation Accurancy:  0.7629707902669907\n",
      "Epoch:  889 | Train Accurancy:  0.8255107700824738 | Validation Accurancy:  0.7631475627422333\n",
      "Epoch:  890 | Train Accurancy:  0.8256688863039017 | Validation Accurancy:  0.763324037194252\n",
      "Epoch:  891 | Train Accurancy:  0.8258267790079117 | Validation Accurancy:  0.7635000348091125\n",
      "Epoch:  892 | Train Accurancy:  0.825984314084053 | Validation Accurancy:  0.7636758387088776\n",
      "Epoch:  893 | Train Accurancy:  0.8261414170265198 | Validation Accurancy:  0.763851210474968\n",
      "Epoch:  894 | Train Accurancy:  0.826298177242279 | Validation Accurancy:  0.7640263438224792\n",
      "Epoch:  895 | Train Accurancy:  0.826454684138298 | Validation Accurancy:  0.7642011195421219\n",
      "Epoch:  896 | Train Accurancy:  0.8266107589006424 | Validation Accurancy:  0.7643756568431854\n",
      "Epoch:  897 | Train Accurancy:  0.8267665505409241 | Validation Accurancy:  0.7645497918128967\n",
      "Epoch:  898 | Train Accurancy:  0.8269219696521759 | Validation Accurancy:  0.7647236883640289\n",
      "Epoch:  899 | Train Accurancy:  0.8270770460367203 | Validation Accurancy:  0.7648971974849701\n",
      "Epoch:  900 | Train Accurancy:  0.8272317945957184 | Validation Accurancy:  0.7650703936815262\n",
      "Epoch:  901 | Train Accurancy:  0.8273861408233643 | Validation Accurancy:  0.7652433812618256\n",
      "Epoch:  902 | Train Accurancy:  0.8275401890277863 | Validation Accurancy:  0.7654158920049667\n",
      "Epoch:  903 | Train Accurancy:  0.827693909406662 | Validation Accurancy:  0.7655881494283676\n",
      "Epoch:  904 | Train Accurancy:  0.8278473019599915 | Validation Accurancy:  0.7657601237297058\n",
      "Epoch:  905 | Train Accurancy:  0.8280003219842911 | Validation Accurancy:  0.7659318000078201\n",
      "Epoch:  906 | Train Accurancy:  0.8281530439853668 | Validation Accurancy:  0.7661032229661942\n",
      "Epoch:  907 | Train Accurancy:  0.8283054530620575 | Validation Accurancy:  0.7662743180990219\n",
      "Epoch:  908 | Train Accurancy:  0.8284574151039124 | Validation Accurancy:  0.7664451003074646\n",
      "Epoch:  909 | Train Accurancy:  0.8286092132329941 | Validation Accurancy:  0.7666154950857162\n",
      "Epoch:  910 | Train Accurancy:  0.82876056432724 | Validation Accurancy:  0.7667856365442276\n",
      "Epoch:  911 | Train Accurancy:  0.8289115875959396 | Validation Accurancy:  0.7669554203748703\n",
      "Epoch:  912 | Train Accurancy:  0.8290622979402542 | Validation Accurancy:  0.7671250402927399\n",
      "Epoch:  913 | Train Accurancy:  0.8292126506567001 | Validation Accurancy:  0.7672941833734512\n",
      "Epoch:  914 | Train Accurancy:  0.8293626755475998 | Validation Accurancy:  0.7674631327390671\n",
      "Epoch:  915 | Train Accurancy:  0.829512432217598 | Validation Accurancy:  0.7676317691802979\n",
      "Epoch:  916 | Train Accurancy:  0.8296618312597275 | Validation Accurancy:  0.7678000628948212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  917 | Train Accurancy:  0.8298108875751495 | Validation Accurancy:  0.767968162894249\n",
      "Epoch:  918 | Train Accurancy:  0.8299595862627029 | Validation Accurancy:  0.7681358158588409\n",
      "Epoch:  919 | Train Accurancy:  0.8301080912351608 | Validation Accurancy:  0.7683032304048538\n",
      "Epoch:  920 | Train Accurancy:  0.8302561789751053 | Validation Accurancy:  0.7684703469276428\n",
      "Epoch:  921 | Train Accurancy:  0.8304039686918259 | Validation Accurancy:  0.7686371356248856\n",
      "Epoch:  922 | Train Accurancy:  0.8305514007806778 | Validation Accurancy:  0.7688036412000656\n",
      "Epoch:  923 | Train Accurancy:  0.8306984752416611 | Validation Accurancy:  0.7689699530601501\n",
      "Epoch:  924 | Train Accurancy:  0.8308453261852264 | Validation Accurancy:  0.7691358923912048\n",
      "Epoch:  925 | Train Accurancy:  0.8309918940067291 | Validation Accurancy:  0.7693014591932297\n",
      "Epoch:  926 | Train Accurancy:  0.8311379551887512 | Validation Accurancy:  0.7694668620824814\n",
      "Epoch:  927 | Train Accurancy:  0.8312837928533554 | Validation Accurancy:  0.7696318924427032\n",
      "Epoch:  928 | Train Accurancy:  0.8314294219017029 | Validation Accurancy:  0.7697966992855072\n",
      "Epoch:  929 | Train Accurancy:  0.8315746635198593 | Validation Accurancy:  0.7699611485004425\n",
      "Epoch:  930 | Train Accurancy:  0.8317195326089859 | Validation Accurancy:  0.7701253443956375\n",
      "Epoch:  931 | Train Accurancy:  0.8318640738725662 | Validation Accurancy:  0.7702890932559967\n",
      "Epoch:  932 | Train Accurancy:  0.8320083618164062 | Validation Accurancy:  0.7704526633024216\n",
      "Epoch:  933 | Train Accurancy:  0.8321523368358612 | Validation Accurancy:  0.7706159204244614\n",
      "Epoch:  934 | Train Accurancy:  0.8322959989309311 | Validation Accurancy:  0.7707789540290833\n",
      "Epoch:  935 | Train Accurancy:  0.8324394077062607 | Validation Accurancy:  0.7709415853023529\n",
      "Epoch:  936 | Train Accurancy:  0.8325823396444321 | Validation Accurancy:  0.7711040079593658\n",
      "Epoch:  937 | Train Accurancy:  0.8327250778675079 | Validation Accurancy:  0.7712661474943161\n",
      "Epoch:  938 | Train Accurancy:  0.8328675627708435 | Validation Accurancy:  0.7714280039072037\n",
      "Epoch:  939 | Train Accurancy:  0.8330096304416656 | Validation Accurancy:  0.771589532494545\n",
      "Epoch:  940 | Train Accurancy:  0.8331514745950699 | Validation Accurancy:  0.7717507630586624\n",
      "Epoch:  941 | Train Accurancy:  0.8332929015159607 | Validation Accurancy:  0.7719117701053619\n",
      "Epoch:  942 | Train Accurancy:  0.8334340751171112 | Validation Accurancy:  0.7720725238323212\n",
      "Epoch:  943 | Train Accurancy:  0.8335750550031662 | Validation Accurancy:  0.7722328752279282\n",
      "Epoch:  944 | Train Accurancy:  0.8337156027555466 | Validation Accurancy:  0.7723930925130844\n",
      "Epoch:  945 | Train Accurancy:  0.8338558822870255 | Validation Accurancy:  0.772552952170372\n",
      "Epoch:  946 | Train Accurancy:  0.8339958786964417 | Validation Accurancy:  0.7727124691009521\n",
      "Epoch:  947 | Train Accurancy:  0.8341355174779892 | Validation Accurancy:  0.7728717178106308\n",
      "Epoch:  948 | Train Accurancy:  0.8342749774456024 | Validation Accurancy:  0.7730307579040527\n",
      "Epoch:  949 | Train Accurancy:  0.834414005279541 | Validation Accurancy:  0.7731894999742508\n",
      "Epoch:  950 | Train Accurancy:  0.8345528095960617 | Validation Accurancy:  0.7733479589223862\n",
      "Epoch:  951 | Train Accurancy:  0.8346913158893585 | Validation Accurancy:  0.7735061794519424\n",
      "Epoch:  952 | Train Accurancy:  0.8348294645547867 | Validation Accurancy:  0.7736640423536301\n",
      "Epoch:  953 | Train Accurancy:  0.8349673599004745 | Validation Accurancy:  0.7738216370344162\n",
      "Epoch:  954 | Train Accurancy:  0.835104912519455 | Validation Accurancy:  0.7739790380001068\n",
      "Epoch:  955 | Train Accurancy:  0.8352422565221786 | Validation Accurancy:  0.7741361260414124\n",
      "Epoch:  956 | Train Accurancy:  0.8353793323040009 | Validation Accurancy:  0.7742929756641388\n",
      "Epoch:  957 | Train Accurancy:  0.8355160057544708 | Validation Accurancy:  0.7744495272636414\n",
      "Epoch:  958 | Train Accurancy:  0.8356524109840393 | Validation Accurancy:  0.7746057510375977\n",
      "Epoch:  959 | Train Accurancy:  0.8357885628938675 | Validation Accurancy:  0.7747617363929749\n",
      "Epoch:  960 | Train Accurancy:  0.8359243869781494 | Validation Accurancy:  0.7749174535274506\n",
      "Epoch:  961 | Train Accurancy:  0.8360599130392075 | Validation Accurancy:  0.775072917342186\n",
      "Epoch:  962 | Train Accurancy:  0.8361951857805252 | Validation Accurancy:  0.7752280682325363\n",
      "Epoch:  963 | Train Accurancy:  0.8363301455974579 | Validation Accurancy:  0.7753829956054688\n",
      "Epoch:  964 | Train Accurancy:  0.8364648967981339 | Validation Accurancy:  0.7755376547574997\n",
      "Epoch:  965 | Train Accurancy:  0.8365992158651352 | Validation Accurancy:  0.7756919264793396\n",
      "Epoch:  966 | Train Accurancy:  0.836733341217041 | Validation Accurancy:  0.7758460640907288\n",
      "Epoch:  967 | Train Accurancy:  0.836867019534111 | Validation Accurancy:  0.7759595215320587\n",
      "Epoch:  968 | Train Accurancy:  0.8370004743337631 | Validation Accurancy:  0.7761271297931671\n",
      "Epoch:  969 | Train Accurancy:  0.8371335417032242 | Validation Accurancy:  0.7762492150068283\n",
      "Epoch:  970 | Train Accurancy:  0.8372664600610733 | Validation Accurancy:  0.7763816863298416\n",
      "Epoch:  971 | Train Accurancy:  0.8373989462852478 | Validation Accurancy:  0.7765611559152603\n",
      "Epoch:  972 | Train Accurancy:  0.8375311642885208 | Validation Accurancy:  0.7766905874013901\n",
      "Epoch:  973 | Train Accurancy:  0.8376632779836655 | Validation Accurancy:  0.7768676578998566\n",
      "Epoch:  974 | Train Accurancy:  0.8377948850393295 | Validation Accurancy:  0.7769956141710281\n",
      "Epoch:  975 | Train Accurancy:  0.8379263877868652 | Validation Accurancy:  0.7771314531564713\n",
      "Epoch:  976 | Train Accurancy:  0.8380575776100159 | Validation Accurancy:  0.7773120850324631\n",
      "Epoch:  977 | Train Accurancy:  0.8381883054971695 | Validation Accurancy:  0.7774422913789749\n",
      "Epoch:  978 | Train Accurancy:  0.8383188843727112 | Validation Accurancy:  0.7775790989398956\n",
      "Epoch:  979 | Train Accurancy:  0.8384491950273514 | Validation Accurancy:  0.7777202725410461\n",
      "Epoch:  980 | Train Accurancy:  0.8385792225599289 | Validation Accurancy:  0.7779038697481155\n",
      "Epoch:  981 | Train Accurancy:  0.8387089371681213 | Validation Accurancy:  0.7780357450246811\n",
      "Epoch:  982 | Train Accurancy:  0.8388383090496063 | Validation Accurancy:  0.7781736254692078\n",
      "Epoch:  983 | Train Accurancy:  0.8389676213264465 | Validation Accurancy:  0.7783151268959045\n",
      "Epoch:  984 | Train Accurancy:  0.8390964567661285 | Validation Accurancy:  0.7784981280565262\n",
      "Epoch:  985 | Train Accurancy:  0.839225098490715 | Validation Accurancy:  0.7786297649145126\n",
      "Epoch:  986 | Train Accurancy:  0.8393534272909164 | Validation Accurancy:  0.7787668853998184\n",
      "Epoch:  987 | Train Accurancy:  0.8394815474748611 | Validation Accurancy:  0.7789077460765839\n",
      "Epoch:  988 | Train Accurancy:  0.8396093398332596 | Validation Accurancy:  0.7790896445512772\n",
      "Epoch:  989 | Train Accurancy:  0.839736744761467 | Validation Accurancy:  0.7792204767465591\n",
      "Epoch:  990 | Train Accurancy:  0.8398640602827072 | Validation Accurancy:  0.7793568968772888\n",
      "Epoch:  991 | Train Accurancy:  0.839991107583046 | Validation Accurancy:  0.7794967442750931\n",
      "Epoch:  992 | Train Accurancy:  0.8401178568601608 | Validation Accurancy:  0.7796774953603745\n",
      "Epoch:  993 | Train Accurancy:  0.840244248509407 | Validation Accurancy:  0.7798074930906296\n",
      "Epoch:  994 | Train Accurancy:  0.8403704464435577 | Validation Accurancy:  0.7799430042505264\n",
      "Epoch:  995 | Train Accurancy:  0.840496376156807 | Validation Accurancy:  0.7800819873809814\n",
      "Epoch:  996 | Train Accurancy:  0.8406220525503159 | Validation Accurancy:  0.780223160982132\n",
      "Epoch:  997 | Train Accurancy:  0.8407474011182785 | Validation Accurancy:  0.7804038971662521\n",
      "Epoch:  998 | Train Accurancy:  0.8408725410699844 | Validation Accurancy:  0.7805338203907013\n",
      "Epoch:  999 | Train Accurancy:  0.8409974128007889 | Validation Accurancy:  0.7806688696146011\n",
      "Epoch:  1000 | Train Accurancy:  0.8411219865083694 | Validation Accurancy:  0.7808070480823517\n",
      "Epoch:  1001 | Train Accurancy:  0.8412463217973709 | Validation Accurancy:  0.7809473127126694\n",
      "Epoch:  1002 | Train Accurancy:  0.8413704186677933 | Validation Accurancy:  0.7810887843370438\n",
      "Epoch:  1003 | Train Accurancy:  0.841494232416153 | Validation Accurancy:  0.781268760561943\n",
      "Epoch:  1004 | Train Accurancy:  0.8416177481412888 | Validation Accurancy:  0.7813981175422668\n",
      "Epoch:  1005 | Train Accurancy:  0.8417410403490067 | Validation Accurancy:  0.7815323173999786\n",
      "Epoch:  1006 | Train Accurancy:  0.8418640047311783 | Validation Accurancy:  0.7816695421934128\n",
      "Epoch:  1007 | Train Accurancy:  0.8419868797063828 | Validation Accurancy:  0.781808540225029\n",
      "Epoch:  1008 | Train Accurancy:  0.8421093821525574 | Validation Accurancy:  0.7819487154483795\n",
      "Epoch:  1009 | Train Accurancy:  0.8422315865755081 | Validation Accurancy:  0.7820894420146942\n",
      "Epoch:  1010 | Train Accurancy:  0.8423536270856857 | Validation Accurancy:  0.7822305560112\n",
      "Epoch:  1011 | Train Accurancy:  0.8424753844738007 | Validation Accurancy:  0.7824090868234634\n",
      "Epoch:  1012 | Train Accurancy:  0.8425967842340469 | Validation Accurancy:  0.7825374454259872\n",
      "Epoch:  1013 | Train Accurancy:  0.8427180498838425 | Validation Accurancy:  0.7826702296733856\n",
      "Epoch:  1014 | Train Accurancy:  0.8428390473127365 | Validation Accurancy:  0.782806009054184\n",
      "Epoch:  1015 | Train Accurancy:  0.8429597318172455 | Validation Accurancy:  0.78294338285923\n",
      "Epoch:  1016 | Train Accurancy:  0.8430801928043365 | Validation Accurancy:  0.7830817848443985\n",
      "Epoch:  1017 | Train Accurancy:  0.8432004600763321 | Validation Accurancy:  0.7832207232713699\n",
      "Epoch:  1018 | Train Accurancy:  0.843320444226265 | Validation Accurancy:  0.7833600044250488\n",
      "Epoch:  1019 | Train Accurancy:  0.8434401154518127 | Validation Accurancy:  0.7834994345903397\n",
      "Epoch:  1020 | Train Accurancy:  0.843559592962265 | Validation Accurancy:  0.7836387753486633\n",
      "Epoch:  1021 | Train Accurancy:  0.8436787873506546 | Validation Accurancy:  0.7837780863046646\n",
      "Epoch:  1022 | Train Accurancy:  0.8437977731227875 | Validation Accurancy:  0.7839172929525375\n",
      "Epoch:  1023 | Train Accurancy:  0.84391650557518 | Validation Accurancy:  0.7840562760829926\n",
      "Epoch:  1024 | Train Accurancy:  0.8440349847078323 | Validation Accurancy:  0.7842315286397934\n",
      "Epoch:  1025 | Train Accurancy:  0.8441531211137772 | Validation Accurancy:  0.7843576371669769\n",
      "Epoch:  1026 | Train Accurancy:  0.84427110850811 | Validation Accurancy:  0.7844878882169724\n",
      "Epoch:  1027 | Train Accurancy:  0.8443888872861862 | Validation Accurancy:  0.7846208959817886\n",
      "Epoch:  1028 | Train Accurancy:  0.8445063978433609 | Validation Accurancy:  0.7847554832696915\n",
      "Epoch:  1029 | Train Accurancy:  0.8446236401796341 | Validation Accurancy:  0.7848911136388779\n",
      "Epoch:  1030 | Train Accurancy:  0.844740629196167 | Validation Accurancy:  0.7850273251533508\n",
      "Epoch:  1031 | Train Accurancy:  0.844857394695282 | Validation Accurancy:  0.7851636707782745\n",
      "Epoch:  1032 | Train Accurancy:  0.8449739515781403 | Validation Accurancy:  0.7853001803159714\n",
      "Epoch:  1033 | Train Accurancy:  0.8450901508331299 | Validation Accurancy:  0.785436600446701\n",
      "Epoch:  1034 | Train Accurancy:  0.8452061712741852 | Validation Accurancy:  0.7855730503797531\n",
      "Epoch:  1035 | Train Accurancy:  0.845321923494339 | Validation Accurancy:  0.7857092171907425\n",
      "Epoch:  1036 | Train Accurancy:  0.845437541604042 | Validation Accurancy:  0.7858452945947647\n",
      "Epoch:  1037 | Train Accurancy:  0.8455528616905212 | Validation Accurancy:  0.7859811782836914\n",
      "Epoch:  1038 | Train Accurancy:  0.8456679135560989 | Validation Accurancy:  0.7861163914203644\n",
      "Epoch:  1039 | Train Accurancy:  0.8457826972007751 | Validation Accurancy:  0.7862516194581985\n",
      "Epoch:  1040 | Train Accurancy:  0.8458972573280334 | Validation Accurancy:  0.786386638879776\n",
      "Epoch:  1041 | Train Accurancy:  0.8460115492343903 | Validation Accurancy:  0.7865216434001923\n",
      "Epoch:  1042 | Train Accurancy:  0.8461256325244904 | Validation Accurancy:  0.7866565436124802\n",
      "Epoch:  1043 | Train Accurancy:  0.8462394922971725 | Validation Accurancy:  0.7867910861968994\n",
      "Epoch:  1044 | Train Accurancy:  0.8463530987501144 | Validation Accurancy:  0.7869255095720291\n",
      "Epoch:  1045 | Train Accurancy:  0.8464665114879608 | Validation Accurancy:  0.7870597392320633\n",
      "Epoch:  1046 | Train Accurancy:  0.8465796858072281 | Validation Accurancy:  0.7871938049793243\n",
      "Epoch:  1047 | Train Accurancy:  0.8466926068067551 | Validation Accurancy:  0.7873276025056839\n",
      "Epoch:  1048 | Train Accurancy:  0.8468051850795746 | Validation Accurancy:  0.7874607890844345\n",
      "Epoch:  1049 | Train Accurancy:  0.8469176590442657 | Validation Accurancy:  0.7875938415527344\n",
      "Epoch:  1050 | Train Accurancy:  0.8470298647880554 | Validation Accurancy:  0.7877268344163895\n",
      "Epoch:  1051 | Train Accurancy:  0.8471417725086212 | Validation Accurancy:  0.7878597527742386\n",
      "Epoch:  1052 | Train Accurancy:  0.8472535163164139 | Validation Accurancy:  0.7879923731088638\n",
      "Epoch:  1053 | Train Accurancy:  0.8473649770021439 | Validation Accurancy:  0.7881248742341995\n",
      "Epoch:  1054 | Train Accurancy:  0.8474762737751007 | Validation Accurancy:  0.7882572114467621\n",
      "Epoch:  1055 | Train Accurancy:  0.8475873470306396 | Validation Accurancy:  0.7883894145488739\n",
      "Epoch:  1056 | Train Accurancy:  0.8476981222629547 | Validation Accurancy:  0.7885211557149887\n",
      "Epoch:  1057 | Train Accurancy:  0.8478087037801743 | Validation Accurancy:  0.7886528819799423\n",
      "Epoch:  1058 | Train Accurancy:  0.8479190766811371 | Validation Accurancy:  0.788784459233284\n",
      "Epoch:  1059 | Train Accurancy:  0.8480292111635208 | Validation Accurancy:  0.7889157831668854\n",
      "Epoch:  1060 | Train Accurancy:  0.8481392115354538 | Validation Accurancy:  0.7890468537807465\n",
      "Epoch:  1061 | Train Accurancy:  0.8482488244771957 | Validation Accurancy:  0.7891777455806732\n",
      "Epoch:  1062 | Train Accurancy:  0.8483583331108093 | Validation Accurancy:  0.7893083393573761\n",
      "Epoch:  1063 | Train Accurancy:  0.8484675884246826 | Validation Accurancy:  0.7894387692213058\n",
      "Epoch:  1064 | Train Accurancy:  0.8485765904188156 | Validation Accurancy:  0.7895689308643341\n",
      "Epoch:  1065 | Train Accurancy:  0.8486854285001755 | Validation Accurancy:  0.78969906270504\n",
      "Epoch:  1066 | Train Accurancy:  0.8487939834594727 | Validation Accurancy:  0.7898287326097488\n",
      "Epoch:  1067 | Train Accurancy:  0.8489022850990295 | Validation Accurancy:  0.7899583429098129\n",
      "Epoch:  1068 | Train Accurancy:  0.8490104675292969 | Validation Accurancy:  0.7900877147912979\n",
      "Epoch:  1069 | Train Accurancy:  0.8491184115409851 | Validation Accurancy:  0.790216937661171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1070 | Train Accurancy:  0.8492261320352554 | Validation Accurancy:  0.7903458774089813\n",
      "Epoch:  1071 | Train Accurancy:  0.8493335396051407 | Validation Accurancy:  0.790474608540535\n",
      "Epoch:  1072 | Train Accurancy:  0.8494408279657364 | Validation Accurancy:  0.7906031161546707\n",
      "Epoch:  1073 | Train Accurancy:  0.8495478630065918 | Validation Accurancy:  0.7907313704490662\n",
      "Epoch:  1074 | Train Accurancy:  0.8496547043323517 | Validation Accurancy:  0.7908596694469452\n",
      "Epoch:  1075 | Train Accurancy:  0.8497613221406937 | Validation Accurancy:  0.7909875065088272\n",
      "Epoch:  1076 | Train Accurancy:  0.8498677611351013 | Validation Accurancy:  0.7911152541637421\n",
      "Epoch:  1077 | Train Accurancy:  0.8499738723039627 | Validation Accurancy:  0.791242703795433\n",
      "Epoch:  1078 | Train Accurancy:  0.8500798791646957 | Validation Accurancy:  0.7913700491189957\n",
      "Epoch:  1079 | Train Accurancy:  0.8501856476068497 | Validation Accurancy:  0.7914971560239792\n",
      "Epoch:  1080 | Train Accurancy:  0.8502912074327469 | Validation Accurancy:  0.7916240245103836\n",
      "Epoch:  1081 | Train Accurancy:  0.8503965437412262 | Validation Accurancy:  0.7917507737874985\n",
      "Epoch:  1082 | Train Accurancy:  0.850501611828804 | Validation Accurancy:  0.7918772250413895\n",
      "Epoch:  1083 | Train Accurancy:  0.8506065011024475 | Validation Accurancy:  0.7920034974813461\n",
      "Epoch:  1084 | Train Accurancy:  0.8507112860679626 | Validation Accurancy:  0.7921295613050461\n",
      "Epoch:  1085 | Train Accurancy:  0.8508157581090927 | Validation Accurancy:  0.7922554463148117\n",
      "Epoch:  1086 | Train Accurancy:  0.8509200364351273 | Validation Accurancy:  0.7923810929059982\n",
      "Epoch:  1087 | Train Accurancy:  0.8510241657495499 | Validation Accurancy:  0.7925066649913788\n",
      "Epoch:  1088 | Train Accurancy:  0.8511279076337814 | Validation Accurancy:  0.7926318794488907\n",
      "Epoch:  1089 | Train Accurancy:  0.8512316346168518 | Validation Accurancy:  0.7927569597959518\n",
      "Epoch:  1090 | Train Accurancy:  0.8513350784778595 | Validation Accurancy:  0.7928818762302399\n",
      "Epoch:  1091 | Train Accurancy:  0.8514382839202881 | Validation Accurancy:  0.7930065095424652\n",
      "Epoch:  1092 | Train Accurancy:  0.8515413850545883 | Validation Accurancy:  0.7931310832500458\n",
      "Epoch:  1093 | Train Accurancy:  0.8516442328691483 | Validation Accurancy:  0.7932552844285965\n",
      "Epoch:  1094 | Train Accurancy:  0.8517468124628067 | Validation Accurancy:  0.79337939620018\n",
      "Epoch:  1095 | Train Accurancy:  0.8518492430448532 | Validation Accurancy:  0.7935032993555069\n",
      "Epoch:  1096 | Train Accurancy:  0.851951465010643 | Validation Accurancy:  0.7936270236968994\n",
      "Epoch:  1097 | Train Accurancy:  0.8520534485578537 | Validation Accurancy:  0.793750450015068\n",
      "Epoch:  1098 | Train Accurancy:  0.8521552532911301 | Validation Accurancy:  0.7938738316297531\n",
      "Epoch:  1099 | Train Accurancy:  0.8522569239139557 | Validation Accurancy:  0.7939968556165695\n",
      "Epoch:  1100 | Train Accurancy:  0.8523582369089127 | Validation Accurancy:  0.7941198199987411\n",
      "Epoch:  1101 | Train Accurancy:  0.8524594902992249 | Validation Accurancy:  0.7942424863576889\n",
      "Epoch:  1102 | Train Accurancy:  0.852560430765152 | Validation Accurancy:  0.7943650782108307\n",
      "Epoch:  1103 | Train Accurancy:  0.8526612818241119 | Validation Accurancy:  0.7944873720407486\n",
      "Epoch:  1104 | Train Accurancy:  0.852761909365654 | Validation Accurancy:  0.7946095019578934\n",
      "Epoch:  1105 | Train Accurancy:  0.8528622984886169 | Validation Accurancy:  0.7947314232587814\n",
      "Epoch:  1106 | Train Accurancy:  0.8529624789953232 | Validation Accurancy:  0.7948532700538635\n",
      "Epoch:  1107 | Train Accurancy:  0.8530625253915787 | Validation Accurancy:  0.7949747741222382\n",
      "Epoch:  1108 | Train Accurancy:  0.8531622588634491 | Validation Accurancy:  0.7950960695743561\n",
      "Epoch:  1109 | Train Accurancy:  0.8532618880271912 | Validation Accurancy:  0.7952171862125397\n",
      "Epoch:  1110 | Train Accurancy:  0.8533613234758377 | Validation Accurancy:  0.7953380197286606\n",
      "Epoch:  1111 | Train Accurancy:  0.8534605205059052 | Validation Accurancy:  0.7954588383436203\n",
      "Epoch:  1112 | Train Accurancy:  0.8535594940185547 | Validation Accurancy:  0.795579344034195\n",
      "Epoch:  1113 | Train Accurancy:  0.8536583483219147 | Validation Accurancy:  0.7956996709108353\n",
      "Epoch:  1114 | Train Accurancy:  0.8537569791078568 | Validation Accurancy:  0.7958199232816696\n",
      "Epoch:  1115 | Train Accurancy:  0.8538554161787033 | Validation Accurancy:  0.7959397882223129\n",
      "Epoch:  1116 | Train Accurancy:  0.8539536744356155 | Validation Accurancy:  0.7960595637559891\n",
      "Epoch:  1117 | Train Accurancy:  0.8540517240762711 | Validation Accurancy:  0.7961792498826981\n",
      "Epoch:  1118 | Train Accurancy:  0.8541495651006699 | Validation Accurancy:  0.7962985932826996\n",
      "Epoch:  1119 | Train Accurancy:  0.8542472422122955 | Validation Accurancy:  0.796417847275734\n",
      "Epoch:  1120 | Train Accurancy:  0.8543447405099869 | Validation Accurancy:  0.7965369075536728\n",
      "Epoch:  1121 | Train Accurancy:  0.8544419407844543 | Validation Accurancy:  0.796655684709549\n",
      "Epoch:  1122 | Train Accurancy:  0.8545390516519547 | Validation Accurancy:  0.7967743873596191\n",
      "Epoch:  1123 | Train Accurancy:  0.8546359986066818 | Validation Accurancy:  0.7968928813934326\n",
      "Epoch:  1124 | Train Accurancy:  0.8547327220439911 | Validation Accurancy:  0.7970112264156342\n",
      "Epoch:  1125 | Train Accurancy:  0.8548291772603989 | Validation Accurancy:  0.7971292585134506\n",
      "Epoch:  1126 | Train Accurancy:  0.8549255430698395 | Validation Accurancy:  0.797247126698494\n",
      "Epoch:  1127 | Train Accurancy:  0.8550216406583786 | Validation Accurancy:  0.7973649650812149\n",
      "Epoch:  1128 | Train Accurancy:  0.8551176190376282 | Validation Accurancy:  0.7974825501441956\n",
      "Epoch:  1129 | Train Accurancy:  0.8552133589982986 | Validation Accurancy:  0.7975998520851135\n",
      "Epoch:  1130 | Train Accurancy:  0.855309009552002 | Validation Accurancy:  0.7977170795202255\n",
      "Epoch:  1131 | Train Accurancy:  0.8554043769836426 | Validation Accurancy:  0.7978341579437256\n",
      "Epoch:  1132 | Train Accurancy:  0.8554995357990265 | Validation Accurancy:  0.7979509830474854\n",
      "Epoch:  1133 | Train Accurancy:  0.8555945307016373 | Validation Accurancy:  0.7980676144361496\n",
      "Epoch:  1134 | Train Accurancy:  0.8556894212961197 | Validation Accurancy:  0.7981841266155243\n",
      "Epoch:  1135 | Train Accurancy:  0.8557839691638947 | Validation Accurancy:  0.7983004301786423\n",
      "Epoch:  1136 | Train Accurancy:  0.8558785170316696 | Validation Accurancy:  0.79841648042202\n",
      "Epoch:  1137 | Train Accurancy:  0.8559728115797043 | Validation Accurancy:  0.7985323816537857\n",
      "Epoch:  1138 | Train Accurancy:  0.8560668379068375 | Validation Accurancy:  0.7986482083797455\n",
      "Epoch:  1139 | Train Accurancy:  0.8561607748270035 | Validation Accurancy:  0.7987637519836426\n",
      "Epoch:  1140 | Train Accurancy:  0.8562545329332352 | Validation Accurancy:  0.7988791912794113\n",
      "Epoch:  1141 | Train Accurancy:  0.8563481122255325 | Validation Accurancy:  0.7989944368600845\n",
      "Epoch:  1142 | Train Accurancy:  0.8564414232969284 | Validation Accurancy:  0.7991095334291458\n",
      "Epoch:  1143 | Train Accurancy:  0.8565346151590347 | Validation Accurancy:  0.7992243766784668\n",
      "Epoch:  1144 | Train Accurancy:  0.8566276580095291 | Validation Accurancy:  0.7993389666080475\n",
      "Epoch:  1145 | Train Accurancy:  0.8567204475402832 | Validation Accurancy:  0.7994535118341446\n",
      "Epoch:  1146 | Train Accurancy:  0.8568131178617477 | Validation Accurancy:  0.799567848443985\n",
      "Epoch:  1147 | Train Accurancy:  0.8569055944681168 | Validation Accurancy:  0.7996819913387299\n",
      "Epoch:  1148 | Train Accurancy:  0.8569978922605515 | Validation Accurancy:  0.7997960299253464\n",
      "Epoch:  1149 | Train Accurancy:  0.857089951634407 | Validation Accurancy:  0.7999094128608704\n",
      "Epoch:  1150 | Train Accurancy:  0.8571818917989731 | Validation Accurancy:  0.8000227808952332\n",
      "Epoch:  1151 | Train Accurancy:  0.8572736233472824 | Validation Accurancy:  0.8001361340284348\n",
      "Epoch:  1152 | Train Accurancy:  0.8573652356863022 | Validation Accurancy:  0.8002493679523468\n",
      "Epoch:  1153 | Train Accurancy:  0.8574565500020981 | Validation Accurancy:  0.8003625273704529\n",
      "Epoch:  1154 | Train Accurancy:  0.8575477451086044 | Validation Accurancy:  0.8004754036664963\n",
      "Epoch:  1155 | Train Accurancy:  0.8576388210058212 | Validation Accurancy:  0.8005881607532501\n",
      "Epoch:  1156 | Train Accurancy:  0.8577296584844589 | Validation Accurancy:  0.8007008582353592\n",
      "Epoch:  1157 | Train Accurancy:  0.8578203469514847 | Validation Accurancy:  0.8008133471012115\n",
      "Epoch:  1158 | Train Accurancy:  0.8579108417034149 | Validation Accurancy:  0.800925686955452\n",
      "Epoch:  1159 | Train Accurancy:  0.8580012023448944 | Validation Accurancy:  0.8010376989841461\n",
      "Epoch:  1160 | Train Accurancy:  0.8580913245677948 | Validation Accurancy:  0.8011497110128403\n",
      "Epoch:  1161 | Train Accurancy:  0.8581813722848892 | Validation Accurancy:  0.8012614697217941\n",
      "Epoch:  1162 | Train Accurancy:  0.8582711815834045 | Validation Accurancy:  0.8013731092214584\n",
      "Epoch:  1163 | Train Accurancy:  0.858360767364502 | Validation Accurancy:  0.801484540104866\n",
      "Epoch:  1164 | Train Accurancy:  0.8584502190351486 | Validation Accurancy:  0.8015958666801453\n",
      "Epoch:  1165 | Train Accurancy:  0.8585395514965057 | Validation Accurancy:  0.8017068803310394\n",
      "Epoch:  1166 | Train Accurancy:  0.8586287051439285 | Validation Accurancy:  0.8018179684877396\n",
      "Epoch:  1167 | Train Accurancy:  0.858717605471611 | Validation Accurancy:  0.8019282668828964\n",
      "Epoch:  1168 | Train Accurancy:  0.8588064610958099 | Validation Accurancy:  0.8020386546850204\n",
      "Epoch:  1169 | Train Accurancy:  0.858895018696785 | Validation Accurancy:  0.8021489977836609\n",
      "Epoch:  1170 | Train Accurancy:  0.8589834570884705 | Validation Accurancy:  0.8022592067718506\n",
      "Epoch:  1171 | Train Accurancy:  0.8590717017650604 | Validation Accurancy:  0.8023693561553955\n",
      "Epoch:  1172 | Train Accurancy:  0.8591597825288773 | Validation Accurancy:  0.8024792373180389\n",
      "Epoch:  1173 | Train Accurancy:  0.8592477142810822 | Validation Accurancy:  0.8025890737771988\n",
      "Epoch:  1174 | Train Accurancy:  0.8593355119228363 | Validation Accurancy:  0.8026985824108124\n",
      "Epoch:  1175 | Train Accurancy:  0.8594230711460114 | Validation Accurancy:  0.802808091044426\n",
      "Epoch:  1176 | Train Accurancy:  0.8595105558633804 | Validation Accurancy:  0.802917405962944\n",
      "Epoch:  1177 | Train Accurancy:  0.8595978319644928 | Validation Accurancy:  0.8030266314744949\n",
      "Epoch:  1178 | Train Accurancy:  0.8596849143505096 | Validation Accurancy:  0.8031354695558548\n",
      "Epoch:  1179 | Train Accurancy:  0.8597718328237534 | Validation Accurancy:  0.8032443672418594\n",
      "Epoch:  1180 | Train Accurancy:  0.8598585724830627 | Validation Accurancy:  0.803353026509285\n",
      "Epoch:  1181 | Train Accurancy:  0.8599451929330826 | Validation Accurancy:  0.8034615367650986\n",
      "Epoch:  1182 | Train Accurancy:  0.8600316345691681 | Validation Accurancy:  0.8035697788000107\n",
      "Epoch:  1183 | Train Accurancy:  0.8601178675889969 | Validation Accurancy:  0.8036779463291168\n",
      "Epoch:  1184 | Train Accurancy:  0.8602040410041809 | Validation Accurancy:  0.803785964846611\n",
      "Epoch:  1185 | Train Accurancy:  0.8602899461984634 | Validation Accurancy:  0.8038934618234634\n",
      "Epoch:  1186 | Train Accurancy:  0.8603757321834564 | Validation Accurancy:  0.8040009438991547\n",
      "Epoch:  1187 | Train Accurancy:  0.8604613244533539 | Validation Accurancy:  0.8041083812713623\n",
      "Epoch:  1188 | Train Accurancy:  0.8605467826128006 | Validation Accurancy:  0.8042156398296356\n",
      "Epoch:  1189 | Train Accurancy:  0.8606320768594742 | Validation Accurancy:  0.804322749376297\n",
      "Epoch:  1190 | Train Accurancy:  0.8607172071933746 | Validation Accurancy:  0.8044297695159912\n",
      "Epoch:  1191 | Train Accurancy:  0.860802173614502 | Validation Accurancy:  0.8045366704463959\n",
      "Epoch:  1192 | Train Accurancy:  0.8608870208263397 | Validation Accurancy:  0.8046433925628662\n",
      "Epoch:  1193 | Train Accurancy:  0.8609716445207596 | Validation Accurancy:  0.8047499805688858\n",
      "Epoch:  1194 | Train Accurancy:  0.8610561341047287 | Validation Accurancy:  0.8048563301563263\n",
      "Epoch:  1195 | Train Accurancy:  0.8611404746770859 | Validation Accurancy:  0.8049625903367996\n",
      "Epoch:  1196 | Train Accurancy:  0.8612246215343475 | Validation Accurancy:  0.8050686419010162\n",
      "Epoch:  1197 | Train Accurancy:  0.8613086342811584 | Validation Accurancy:  0.8051746040582657\n",
      "Epoch:  1198 | Train Accurancy:  0.8613924831151962 | Validation Accurancy:  0.8052803426980972\n",
      "Epoch:  1199 | Train Accurancy:  0.8614761829376221 | Validation Accurancy:  0.8053860366344452\n",
      "Epoch:  1200 | Train Accurancy:  0.861559733748436 | Validation Accurancy:  0.8055011928081512\n",
      "Epoch:  1201 | Train Accurancy:  0.8616430908441544 | Validation Accurancy:  0.8056028783321381\n",
      "Epoch:  1202 | Train Accurancy:  0.8617264181375504 | Validation Accurancy:  0.8057153820991516\n",
      "Epoch:  1203 | Train Accurancy:  0.8618094176054001 | Validation Accurancy:  0.8058152198791504\n",
      "Epoch:  1204 | Train Accurancy:  0.8618923276662827 | Validation Accurancy:  0.8059167861938477\n",
      "Epoch:  1205 | Train Accurancy:  0.8619751036167145 | Validation Accurancy:  0.8060289174318314\n",
      "Epoch:  1206 | Train Accurancy:  0.8620577305555344 | Validation Accurancy:  0.8061285316944122\n",
      "Epoch:  1207 | Train Accurancy:  0.8621401786804199 | Validation Accurancy:  0.8062392622232437\n",
      "Epoch:  1208 | Train Accurancy:  0.8622224181890488 | Validation Accurancy:  0.8063377887010574\n",
      "Epoch:  1209 | Train Accurancy:  0.8623045980930328 | Validation Accurancy:  0.806438222527504\n",
      "Epoch:  1210 | Train Accurancy:  0.8623866140842438 | Validation Accurancy:  0.8065493106842041\n",
      "Epoch:  1211 | Train Accurancy:  0.8624683767557144 | Validation Accurancy:  0.806647926568985\n",
      "Epoch:  1212 | Train Accurancy:  0.8625500947237015 | Validation Accurancy:  0.8067578226327896\n",
      "Epoch:  1213 | Train Accurancy:  0.862631618976593 | Validation Accurancy:  0.8068555742502213\n",
      "Epoch:  1214 | Train Accurancy:  0.8627130091190338 | Validation Accurancy:  0.8069647997617722\n",
      "Epoch:  1215 | Train Accurancy:  0.8627942353487015 | Validation Accurancy:  0.8070620894432068\n",
      "Epoch:  1216 | Train Accurancy:  0.8628753274679184 | Validation Accurancy:  0.8071707636117935\n",
      "Epoch:  1217 | Train Accurancy:  0.862956240773201 | Validation Accurancy:  0.80726757645607\n",
      "Epoch:  1218 | Train Accurancy:  0.863037034869194 | Validation Accurancy:  0.8073759377002716\n",
      "Epoch:  1219 | Train Accurancy:  0.8631176799535751 | Validation Accurancy:  0.8074724674224854\n",
      "Epoch:  1220 | Train Accurancy:  0.8631981164216995 | Validation Accurancy:  0.8075394034385681\n",
      "Epoch:  1221 | Train Accurancy:  0.8632782995700836 | Validation Accurancy:  0.8076592087745667\n",
      "Epoch:  1222 | Train Accurancy:  0.8633584678173065 | Validation Accurancy:  0.8077316433191299\n",
      "Epoch:  1223 | Train Accurancy:  0.8634383380413055 | Validation Accurancy:  0.8078549057245255\n",
      "Epoch:  1224 | Train Accurancy:  0.863518163561821 | Validation Accurancy:  0.807929515838623\n",
      "Epoch:  1225 | Train Accurancy:  0.8635978400707245 | Validation Accurancy:  0.8080445379018784\n",
      "Epoch:  1226 | Train Accurancy:  0.8636773079633713 | Validation Accurancy:  0.8081234842538834\n",
      "Epoch:  1227 | Train Accurancy:  0.8637566864490509 | Validation Accurancy:  0.8082098066806793\n",
      "Epoch:  1228 | Train Accurancy:  0.8638358414173126 | Validation Accurancy:  0.8083414435386658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1229 | Train Accurancy:  0.8639148771762848 | Validation Accurancy:  0.8084216713905334\n",
      "Epoch:  1230 | Train Accurancy:  0.863993838429451 | Validation Accurancy:  0.8085086047649384\n",
      "Epoch:  1231 | Train Accurancy:  0.8640725910663605 | Validation Accurancy:  0.8086312115192413\n",
      "Epoch:  1232 | Train Accurancy:  0.8641511350870132 | Validation Accurancy:  0.8087149113416672\n",
      "Epoch:  1233 | Train Accurancy:  0.864229679107666 | Validation Accurancy:  0.8088040202856064\n",
      "Epoch:  1234 | Train Accurancy:  0.8643079549074173 | Validation Accurancy:  0.8088967204093933\n",
      "Epoch:  1235 | Train Accurancy:  0.864386111497879 | Validation Accurancy:  0.8090225160121918\n",
      "Epoch:  1236 | Train Accurancy:  0.864464059472084 | Validation Accurancy:  0.8091085106134415\n",
      "Epoch:  1237 | Train Accurancy:  0.8645419776439667 | Validation Accurancy:  0.809198796749115\n",
      "Epoch:  1238 | Train Accurancy:  0.8646197319030762 | Validation Accurancy:  0.8092921078205109\n",
      "Epoch:  1239 | Train Accurancy:  0.8646974265575409 | Validation Accurancy:  0.8094178736209869\n",
      "Epoch:  1240 | Train Accurancy:  0.8647747784852982 | Validation Accurancy:  0.8095037341117859\n",
      "Epoch:  1241 | Train Accurancy:  0.8648520857095718 | Validation Accurancy:  0.8095939308404922\n",
      "Epoch:  1242 | Train Accurancy:  0.8649292588233948 | Validation Accurancy:  0.8096958845853806\n",
      "Epoch:  1243 | Train Accurancy:  0.8650063425302505 | Validation Accurancy:  0.8097871392965317\n",
      "Epoch:  1244 | Train Accurancy:  0.8650831580162048 | Validation Accurancy:  0.8099112510681152\n",
      "Epoch:  1245 | Train Accurancy:  0.8651599287986755 | Validation Accurancy:  0.8099959790706635\n",
      "Epoch:  1246 | Train Accurancy:  0.8652364760637283 | Validation Accurancy:  0.8100852072238922\n",
      "Epoch:  1247 | Train Accurancy:  0.8653130382299423 | Validation Accurancy:  0.8101772516965866\n",
      "Epoch:  1248 | Train Accurancy:  0.8653892874717712 | Validation Accurancy:  0.8102710843086243\n",
      "Epoch:  1249 | Train Accurancy:  0.8654654175043106 | Validation Accurancy:  0.8103963881731033\n",
      "Epoch:  1250 | Train Accurancy:  0.8655414581298828 | Validation Accurancy:  0.8104819357395172\n",
      "Epoch:  1251 | Train Accurancy:  0.8656173348426819 | Validation Accurancy:  0.8105713874101639\n",
      "Epoch:  1252 | Train Accurancy:  0.865693137049675 | Validation Accurancy:  0.8106632828712463\n",
      "Epoch:  1253 | Train Accurancy:  0.8657687306404114 | Validation Accurancy:  0.8107569068670273\n",
      "Epoch:  1254 | Train Accurancy:  0.8658442199230194 | Validation Accurancy:  0.8108514696359634\n",
      "Epoch:  1255 | Train Accurancy:  0.8659195899963379 | Validation Accurancy:  0.8109466433525085\n",
      "Epoch:  1256 | Train Accurancy:  0.8659947961568832 | Validation Accurancy:  0.8110722154378891\n",
      "Epoch:  1257 | Train Accurancy:  0.8660697638988495 | Validation Accurancy:  0.8111577928066254\n",
      "Epoch:  1258 | Train Accurancy:  0.8661447316408157 | Validation Accurancy:  0.8112470358610153\n",
      "Epoch:  1259 | Train Accurancy:  0.86621955037117 | Validation Accurancy:  0.8113384693861008\n",
      "Epoch:  1260 | Train Accurancy:  0.8662942349910736 | Validation Accurancy:  0.8114314377307892\n",
      "Epoch:  1261 | Train Accurancy:  0.8663687407970428 | Validation Accurancy:  0.811525359749794\n",
      "Epoch:  1262 | Train Accurancy:  0.8664431124925613 | Validation Accurancy:  0.8116196841001511\n",
      "Epoch:  1263 | Train Accurancy:  0.8665173202753067 | Validation Accurancy:  0.8117143213748932\n",
      "Epoch:  1264 | Train Accurancy:  0.8665914535522461 | Validation Accurancy:  0.8118388056755066\n",
      "Epoch:  1265 | Train Accurancy:  0.8666654229164124 | Validation Accurancy:  0.8119236677885056\n",
      "Epoch:  1266 | Train Accurancy:  0.8667392432689667 | Validation Accurancy:  0.8120120316743851\n",
      "Epoch:  1267 | Train Accurancy:  0.866812989115715 | Validation Accurancy:  0.8121113479137421\n",
      "Epoch:  1268 | Train Accurancy:  0.8668865710496902 | Validation Accurancy:  0.812200129032135\n",
      "Epoch:  1269 | Train Accurancy:  0.8669600337743759 | Validation Accurancy:  0.8122908920049667\n",
      "Epoch:  1270 | Train Accurancy:  0.8670333176851273 | Validation Accurancy:  0.8123828321695328\n",
      "Epoch:  1271 | Train Accurancy:  0.867106482386589 | Validation Accurancy:  0.8124755769968033\n",
      "Epoch:  1272 | Train Accurancy:  0.8671795427799225 | Validation Accurancy:  0.8125688433647156\n",
      "Epoch:  1273 | Train Accurancy:  0.8672524094581604 | Validation Accurancy:  0.8126916587352753\n",
      "Epoch:  1274 | Train Accurancy:  0.8673251569271088 | Validation Accurancy:  0.8127754628658295\n",
      "Epoch:  1275 | Train Accurancy:  0.8673978000879288 | Validation Accurancy:  0.8128626346588135\n",
      "Epoch:  1276 | Train Accurancy:  0.8674704134464264 | Validation Accurancy:  0.8129521310329437\n",
      "Epoch:  1277 | Train Accurancy:  0.8675427436828613 | Validation Accurancy:  0.8130428940057755\n",
      "Epoch:  1278 | Train Accurancy:  0.8676149994134903 | Validation Accurancy:  0.8131431192159653\n",
      "Epoch:  1279 | Train Accurancy:  0.8676870763301849 | Validation Accurancy:  0.8132322281599045\n",
      "Epoch:  1280 | Train Accurancy:  0.8677591234445572 | Validation Accurancy:  0.8133226335048676\n",
      "Epoch:  1281 | Train Accurancy:  0.8678309768438339 | Validation Accurancy:  0.8134139329195023\n",
      "Epoch:  1282 | Train Accurancy:  0.8679026812314987 | Validation Accurancy:  0.8135056644678116\n",
      "Epoch:  1283 | Train Accurancy:  0.8679742515087128 | Validation Accurancy:  0.813597783446312\n",
      "Epoch:  1284 | Train Accurancy:  0.8680457323789597 | Validation Accurancy:  0.8136900216341019\n",
      "Epoch:  1285 | Train Accurancy:  0.8681170642375946 | Validation Accurancy:  0.8137823641300201\n",
      "Epoch:  1286 | Train Accurancy:  0.8681883215904236 | Validation Accurancy:  0.8138746321201324\n",
      "Epoch:  1287 | Train Accurancy:  0.8682593703269958 | Validation Accurancy:  0.8139668554067612\n",
      "Epoch:  1288 | Train Accurancy:  0.8683303892612457 | Validation Accurancy:  0.8140590935945511\n",
      "Epoch:  1289 | Train Accurancy:  0.8684012144804001 | Validation Accurancy:  0.8141511529684067\n",
      "Epoch:  1290 | Train Accurancy:  0.8684719204902649 | Validation Accurancy:  0.8142430931329727\n",
      "Epoch:  1291 | Train Accurancy:  0.8685424774885178 | Validation Accurancy:  0.8143350183963776\n",
      "Epoch:  1292 | Train Accurancy:  0.8686129599809647 | Validation Accurancy:  0.8144267350435257\n",
      "Epoch:  1293 | Train Accurancy:  0.868683248758316 | Validation Accurancy:  0.8145183622837067\n",
      "Epoch:  1294 | Train Accurancy:  0.8687534630298615 | Validation Accurancy:  0.8146178424358368\n",
      "Epoch:  1295 | Train Accurancy:  0.8688234835863113 | Validation Accurancy:  0.8147059231996536\n",
      "Epoch:  1296 | Train Accurancy:  0.8688933998346329 | Validation Accurancy:  0.8147950321435928\n",
      "Epoch:  1297 | Train Accurancy:  0.8689632266759872 | Validation Accurancy:  0.8148844093084335\n",
      "Epoch:  1298 | Train Accurancy:  0.8690329194068909 | Validation Accurancy:  0.8149742484092712\n",
      "Epoch:  1299 | Train Accurancy:  0.8691024929285049 | Validation Accurancy:  0.8150644153356552\n",
      "Epoch:  1300 | Train Accurancy:  0.8691718727350235 | Validation Accurancy:  0.8151548951864243\n",
      "Epoch:  1301 | Train Accurancy:  0.8692411631345749 | Validation Accurancy:  0.8152452260255814\n",
      "Epoch:  1302 | Train Accurancy:  0.8693103045225143 | Validation Accurancy:  0.8153356462717056\n",
      "Epoch:  1303 | Train Accurancy:  0.8693794459104538 | Validation Accurancy:  0.8154260367155075\n",
      "Epoch:  1304 | Train Accurancy:  0.8694483488798141 | Validation Accurancy:  0.8155161887407303\n",
      "Epoch:  1305 | Train Accurancy:  0.869517132639885 | Validation Accurancy:  0.8156146705150604\n",
      "Epoch:  1306 | Train Accurancy:  0.8695858716964722 | Validation Accurancy:  0.8157016783952713\n",
      "Epoch:  1307 | Train Accurancy:  0.8696543872356415 | Validation Accurancy:  0.815789669752121\n",
      "Epoch:  1308 | Train Accurancy:  0.8697227984666824 | Validation Accurancy:  0.8158783316612244\n",
      "Epoch:  1309 | Train Accurancy:  0.869791179895401 | Validation Accurancy:  0.8159671425819397\n",
      "Epoch:  1310 | Train Accurancy:  0.869859367609024 | Validation Accurancy:  0.8160563409328461\n",
      "Epoch:  1311 | Train Accurancy:  0.8699274361133575 | Validation Accurancy:  0.8161454349756241\n",
      "Epoch:  1312 | Train Accurancy:  0.8699953854084015 | Validation Accurancy:  0.8162346184253693\n",
      "Epoch:  1313 | Train Accurancy:  0.8700631707906723 | Validation Accurancy:  0.8163237273693085\n",
      "Epoch:  1314 | Train Accurancy:  0.8701309710741043 | Validation Accurancy:  0.816420778632164\n",
      "Epoch:  1315 | Train Accurancy:  0.8701984882354736 | Validation Accurancy:  0.8165068328380585\n",
      "Epoch:  1316 | Train Accurancy:  0.870266005396843 | Validation Accurancy:  0.8165937960147858\n",
      "Epoch:  1317 | Train Accurancy:  0.8703334033489227 | Validation Accurancy:  0.8166812360286713\n",
      "Epoch:  1318 | Train Accurancy:  0.8704005926847458 | Validation Accurancy:  0.8167690336704254\n",
      "Epoch:  1319 | Train Accurancy:  0.8704677075147629 | Validation Accurancy:  0.8168570697307587\n",
      "Epoch:  1320 | Train Accurancy:  0.8705347031354904 | Validation Accurancy:  0.8169451802968979\n",
      "Epoch:  1321 | Train Accurancy:  0.8706016689538956 | Validation Accurancy:  0.8170411437749863\n",
      "Epoch:  1322 | Train Accurancy:  0.8706683814525604 | Validation Accurancy:  0.8171262145042419\n",
      "Epoch:  1323 | Train Accurancy:  0.8707350641489029 | Validation Accurancy:  0.8172122985124588\n",
      "Epoch:  1324 | Train Accurancy:  0.8708016127347946 | Validation Accurancy:  0.8172989785671234\n",
      "Epoch:  1325 | Train Accurancy:  0.8708680272102356 | Validation Accurancy:  0.8173858672380447\n",
      "Epoch:  1326 | Train Accurancy:  0.8709343373775482 | Validation Accurancy:  0.8174731135368347\n",
      "Epoch:  1327 | Train Accurancy:  0.8710004538297653 | Validation Accurancy:  0.8175603598356247\n",
      "Epoch:  1328 | Train Accurancy:  0.8710666000843048 | Validation Accurancy:  0.8176554143428802\n",
      "Epoch:  1329 | Train Accurancy:  0.8711325228214264 | Validation Accurancy:  0.8177396655082703\n",
      "Epoch:  1330 | Train Accurancy:  0.8711983263492584 | Validation Accurancy:  0.8178249299526215\n",
      "Epoch:  1331 | Train Accurancy:  0.8712640553712845 | Validation Accurancy:  0.817910760641098\n",
      "Epoch:  1332 | Train Accurancy:  0.8713296502828598 | Validation Accurancy:  0.8179968446493149\n",
      "Epoch:  1333 | Train Accurancy:  0.871395155787468 | Validation Accurancy:  0.8180909305810928\n",
      "Epoch:  1334 | Train Accurancy:  0.871460497379303 | Validation Accurancy:  0.8181745409965515\n",
      "Epoch:  1335 | Train Accurancy:  0.8715257793664932 | Validation Accurancy:  0.8182590901851654\n",
      "Epoch:  1336 | Train Accurancy:  0.8715909868478775 | Validation Accurancy:  0.8183442950248718\n",
      "Epoch:  1337 | Train Accurancy:  0.8716560304164886 | Validation Accurancy:  0.8184298127889633\n",
      "Epoch:  1338 | Train Accurancy:  0.8717209547758102 | Validation Accurancy:  0.8185231983661652\n",
      "Epoch:  1339 | Train Accurancy:  0.8717857748270035 | Validation Accurancy:  0.8186061829328537\n",
      "Epoch:  1340 | Train Accurancy:  0.8718504011631012 | Validation Accurancy:  0.8186901658773422\n",
      "Epoch:  1341 | Train Accurancy:  0.8719150722026825 | Validation Accurancy:  0.8187747746706009\n",
      "Epoch:  1342 | Train Accurancy:  0.8719795346260071 | Validation Accurancy:  0.8188598155975342\n",
      "Epoch:  1343 | Train Accurancy:  0.8720439225435257 | Validation Accurancy:  0.8189524859189987\n",
      "Epoch:  1344 | Train Accurancy:  0.8721081167459488 | Validation Accurancy:  0.8190349191427231\n",
      "Epoch:  1345 | Train Accurancy:  0.8721722960472107 | Validation Accurancy:  0.8191183060407639\n",
      "Epoch:  1346 | Train Accurancy:  0.8722362518310547 | Validation Accurancy:  0.8192023783922195\n",
      "Epoch:  1347 | Train Accurancy:  0.8723002225160599 | Validation Accurancy:  0.8192867338657379\n",
      "Epoch:  1348 | Train Accurancy:  0.8723639845848083 | Validation Accurancy:  0.8193789273500443\n",
      "Epoch:  1349 | Train Accurancy:  0.8724277466535568 | Validation Accurancy:  0.8194608241319656\n",
      "Epoch:  1350 | Train Accurancy:  0.8724913001060486 | Validation Accurancy:  0.8195437043905258\n",
      "Epoch:  1351 | Train Accurancy:  0.8725548386573792 | Validation Accurancy:  0.8196271806955338\n",
      "Epoch:  1352 | Train Accurancy:  0.872618168592453 | Validation Accurancy:  0.8197184354066849\n",
      "Epoch:  1353 | Train Accurancy:  0.8726813793182373 | Validation Accurancy:  0.8197997212409973\n",
      "Epoch:  1354 | Train Accurancy:  0.8727445155382156 | Validation Accurancy:  0.8198820948600769\n",
      "Epoch:  1355 | Train Accurancy:  0.8728076070547104 | Validation Accurancy:  0.8199649602174759\n",
      "Epoch:  1356 | Train Accurancy:  0.872870534658432 | Validation Accurancy:  0.8200558871030807\n",
      "Epoch:  1357 | Train Accurancy:  0.8729333430528641 | Validation Accurancy:  0.8201363980770111\n",
      "Epoch:  1358 | Train Accurancy:  0.8729961067438126 | Validation Accurancy:  0.8202181756496429\n",
      "Epoch:  1359 | Train Accurancy:  0.8730586916208267 | Validation Accurancy:  0.8203005194664001\n",
      "Epoch:  1360 | Train Accurancy:  0.8731211721897125 | Validation Accurancy:  0.8203907907009125\n",
      "Epoch:  1361 | Train Accurancy:  0.8731835782527924 | Validation Accurancy:  0.8204709440469742\n",
      "Epoch:  1362 | Train Accurancy:  0.8732458800077438 | Validation Accurancy:  0.8205522149801254\n",
      "Epoch:  1363 | Train Accurancy:  0.873308002948761 | Validation Accurancy:  0.8206416070461273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1364 | Train Accurancy:  0.8733700960874557 | Validation Accurancy:  0.8207213282585144\n",
      "Epoch:  1365 | Train Accurancy:  0.8734320253133774 | Validation Accurancy:  0.8208022564649582\n",
      "Epoch:  1366 | Train Accurancy:  0.873493880033493 | Validation Accurancy:  0.8208837807178497\n",
      "Epoch:  1367 | Train Accurancy:  0.8735556155443192 | Validation Accurancy:  0.8209731578826904\n",
      "Epoch:  1368 | Train Accurancy:  0.8736172616481781 | Validation Accurancy:  0.8210527896881104\n",
      "Epoch:  1369 | Train Accurancy:  0.8736788332462311 | Validation Accurancy:  0.8211334645748138\n",
      "Epoch:  1370 | Train Accurancy:  0.8737402111291885 | Validation Accurancy:  0.8212220966815948\n",
      "Epoch:  1371 | Train Accurancy:  0.8738015741109848 | Validation Accurancy:  0.8213011920452118\n",
      "Epoch:  1372 | Train Accurancy:  0.8738627433776855 | Validation Accurancy:  0.8213813453912735\n",
      "Epoch:  1373 | Train Accurancy:  0.8739238828420639 | Validation Accurancy:  0.8214622437953949\n",
      "Epoch:  1374 | Train Accurancy:  0.8739849030971527 | Validation Accurancy:  0.8215508460998535\n",
      "Epoch:  1375 | Train Accurancy:  0.8740457892417908 | Validation Accurancy:  0.8216297477483749\n",
      "Epoch:  1376 | Train Accurancy:  0.8741066157817841 | Validation Accurancy:  0.8217096775770187\n",
      "Epoch:  1377 | Train Accurancy:  0.8741673082113266 | Validation Accurancy:  0.82179756462574\n",
      "Epoch:  1378 | Train Accurancy:  0.8742278665304184 | Validation Accurancy:  0.8218759149312973\n",
      "Epoch:  1379 | Train Accurancy:  0.8742883950471878 | Validation Accurancy:  0.8219553381204605\n",
      "Epoch:  1380 | Train Accurancy:  0.8743488043546677 | Validation Accurancy:  0.8220426142215729\n",
      "Epoch:  1381 | Train Accurancy:  0.874409094452858 | Validation Accurancy:  0.8221206218004227\n",
      "Epoch:  1382 | Train Accurancy:  0.8744692653417587 | Validation Accurancy:  0.8221997916698456\n",
      "Epoch:  1383 | Train Accurancy:  0.8745293766260147 | Validation Accurancy:  0.8222866505384445\n",
      "Epoch:  1384 | Train Accurancy:  0.8745893985033035 | Validation Accurancy:  0.822364330291748\n",
      "Epoch:  1385 | Train Accurancy:  0.8746492266654968 | Validation Accurancy:  0.8224431723356247\n",
      "Epoch:  1386 | Train Accurancy:  0.8747090399265289 | Validation Accurancy:  0.8225297331809998\n",
      "Epoch:  1387 | Train Accurancy:  0.8747686743736267 | Validation Accurancy:  0.8226069957017899\n",
      "Epoch:  1388 | Train Accurancy:  0.8748282790184021 | Validation Accurancy:  0.8226855844259262\n",
      "Epoch:  1389 | Train Accurancy:  0.8748877793550491 | Validation Accurancy:  0.8227717578411102\n",
      "Epoch:  1390 | Train Accurancy:  0.8749471306800842 | Validation Accurancy:  0.8228488266468048\n",
      "Epoch:  1391 | Train Accurancy:  0.8750064373016357 | Validation Accurancy:  0.822926938533783\n",
      "Epoch:  1392 | Train Accurancy:  0.8750655651092529 | Validation Accurancy:  0.8230128586292267\n",
      "Epoch:  1393 | Train Accurancy:  0.8751246780157089 | Validation Accurancy:  0.8230896294116974\n",
      "Epoch:  1394 | Train Accurancy:  0.8751836493611336 | Validation Accurancy:  0.82316754758358\n",
      "Epoch:  1395 | Train Accurancy:  0.8752425163984299 | Validation Accurancy:  0.8232531100511551\n",
      "Epoch:  1396 | Train Accurancy:  0.875301331281662 | Validation Accurancy:  0.8233294636011124\n",
      "Epoch:  1397 | Train Accurancy:  0.875359982252121 | Validation Accurancy:  0.8234071433544159\n",
      "Epoch:  1398 | Train Accurancy:  0.8754185810685158 | Validation Accurancy:  0.8234923332929611\n",
      "Epoch:  1399 | Train Accurancy:  0.875477060675621 | Validation Accurancy:  0.8235685229301453\n",
      "Epoch:  1400 | Train Accurancy:  0.8755354955792427 | Validation Accurancy:  0.8236457705497742\n",
      "Epoch:  1401 | Train Accurancy:  0.8755937963724136 | Validation Accurancy:  0.8237306475639343\n",
      "Epoch:  1402 | Train Accurancy:  0.8756519332528114 | Validation Accurancy:  0.8238065540790558\n",
      "Epoch:  1403 | Train Accurancy:  0.8757101073861122 | Validation Accurancy:  0.8238904029130936\n",
      "Epoch:  1404 | Train Accurancy:  0.8757681027054787 | Validation Accurancy:  0.8239655047655106\n",
      "Epoch:  1405 | Train Accurancy:  0.8758259639143944 | Validation Accurancy:  0.8240419775247574\n",
      "Epoch:  1406 | Train Accurancy:  0.8758837729692459 | Validation Accurancy:  0.8241260200738907\n",
      "Epoch:  1407 | Train Accurancy:  0.8759415000677109 | Validation Accurancy:  0.8242013603448868\n",
      "Epoch:  1408 | Train Accurancy:  0.8759991228580475 | Validation Accurancy:  0.8242844939231873\n",
      "Epoch:  1409 | Train Accurancy:  0.8760566711425781 | Validation Accurancy:  0.8243592530488968\n",
      "Epoch:  1410 | Train Accurancy:  0.876114048063755 | Validation Accurancy:  0.824435219168663\n",
      "Epoch:  1411 | Train Accurancy:  0.8761713951826096 | Validation Accurancy:  0.8245186656713486\n",
      "Epoch:  1412 | Train Accurancy:  0.8762286528944969 | Validation Accurancy:  0.8245934993028641\n",
      "Epoch:  1413 | Train Accurancy:  0.8762858211994171 | Validation Accurancy:  0.824676126241684\n",
      "Epoch:  1414 | Train Accurancy:  0.8763427585363388 | Validation Accurancy:  0.8247503489255905\n",
      "Epoch:  1415 | Train Accurancy:  0.8763997554779053 | Validation Accurancy:  0.8248256146907806\n",
      "Epoch:  1416 | Train Accurancy:  0.8764566406607628 | Validation Accurancy:  0.8249086737632751\n",
      "Epoch:  1417 | Train Accurancy:  0.8765133395791054 | Validation Accurancy:  0.8249829709529877\n",
      "Epoch:  1418 | Train Accurancy:  0.8765700310468674 | Validation Accurancy:  0.8250651657581329\n",
      "Epoch:  1419 | Train Accurancy:  0.8766266256570816 | Validation Accurancy:  0.8251388520002365\n",
      "Epoch:  1420 | Train Accurancy:  0.8766830787062645 | Validation Accurancy:  0.8252205103635788\n",
      "Epoch:  1421 | Train Accurancy:  0.876739501953125 | Validation Accurancy:  0.8252938389778137\n",
      "Epoch:  1422 | Train Accurancy:  0.8767957612872124 | Validation Accurancy:  0.8253684937953949\n",
      "Epoch:  1423 | Train Accurancy:  0.8768520280718803 | Validation Accurancy:  0.8254506438970566\n",
      "Epoch:  1424 | Train Accurancy:  0.8769080862402916 | Validation Accurancy:  0.8255242705345154\n",
      "Epoch:  1425 | Train Accurancy:  0.8769640475511551 | Validation Accurancy:  0.8256056159734726\n",
      "Epoch:  1426 | Train Accurancy:  0.8770200535655022 | Validation Accurancy:  0.8256786465644836\n",
      "Epoch:  1427 | Train Accurancy:  0.8770758286118507 | Validation Accurancy:  0.8257595747709274\n",
      "Epoch:  1428 | Train Accurancy:  0.8771315887570381 | Validation Accurancy:  0.8258100599050522\n",
      "Epoch:  1429 | Train Accurancy:  0.8771871775388718 | Validation Accurancy:  0.8258979916572571\n",
      "Epoch:  1430 | Train Accurancy:  0.877242773771286 | Validation Accurancy:  0.8259751498699188\n",
      "Epoch:  1431 | Train Accurancy:  0.8772982135415077 | Validation Accurancy:  0.826052114367485\n",
      "Epoch:  1432 | Train Accurancy:  0.8773535639047623 | Validation Accurancy:  0.8261132836341858\n",
      "Epoch:  1433 | Train Accurancy:  0.8774088397622108 | Validation Accurancy:  0.8261948376893997\n",
      "Epoch:  1434 | Train Accurancy:  0.8774640262126923 | Validation Accurancy:  0.8262743353843689\n",
      "Epoch:  1435 | Train Accurancy:  0.8775190785527229 | Validation Accurancy:  0.8263371884822845\n",
      "Epoch:  1436 | Train Accurancy:  0.8775740414857864 | Validation Accurancy:  0.8264195322990417\n",
      "Epoch:  1437 | Train Accurancy:  0.8776289746165276 | Validation Accurancy:  0.8264997154474258\n",
      "Epoch:  1438 | Train Accurancy:  0.8776837512850761 | Validation Accurancy:  0.8265563100576401\n",
      "Epoch:  1439 | Train Accurancy:  0.8777385056018829 | Validation Accurancy:  0.8266475945711136\n",
      "Epoch:  1440 | Train Accurancy:  0.877793125808239 | Validation Accurancy:  0.8267050534486771\n",
      "Epoch:  1441 | Train Accurancy:  0.8778476640582085 | Validation Accurancy:  0.8267901092767715\n",
      "Epoch:  1442 | Train Accurancy:  0.8779021427035332 | Validation Accurancy:  0.8268718272447586\n",
      "Epoch:  1443 | Train Accurancy:  0.8779564723372459 | Validation Accurancy:  0.8269360661506653\n",
      "Epoch:  1444 | Train Accurancy:  0.8780107498168945 | Validation Accurancy:  0.8270189017057419\n",
      "Epoch:  1445 | Train Accurancy:  0.8780649602413177 | Validation Accurancy:  0.8270773589611053\n",
      "Epoch:  1446 | Train Accurancy:  0.8781190291047096 | Validation Accurancy:  0.827162891626358\n",
      "Epoch:  1447 | Train Accurancy:  0.8781730458140373 | Validation Accurancy:  0.82722307741642\n",
      "Epoch:  1448 | Train Accurancy:  0.8782269284129143 | Validation Accurancy:  0.8273159861564636\n",
      "Epoch:  1449 | Train Accurancy:  0.8782807663083076 | Validation Accurancy:  0.8273746371269226\n",
      "Epoch:  1450 | Train Accurancy:  0.8783344775438309 | Validation Accurancy:  0.8274598866701126\n",
      "Epoch:  1451 | Train Accurancy:  0.8783882483839989 | Validation Accurancy:  0.8275416046380997\n",
      "Epoch:  1452 | Train Accurancy:  0.878441758453846 | Validation Accurancy:  0.827599287033081\n",
      "Epoch:  1453 | Train Accurancy:  0.8784952014684677 | Validation Accurancy:  0.8276901692152023\n",
      "Epoch:  1454 | Train Accurancy:  0.8785486668348312 | Validation Accurancy:  0.8277474939823151\n",
      "Epoch:  1455 | Train Accurancy:  0.8786019161343575 | Validation Accurancy:  0.8278315216302872\n",
      "Epoch:  1456 | Train Accurancy:  0.8786550983786583 | Validation Accurancy:  0.827890932559967\n",
      "Epoch:  1457 | Train Accurancy:  0.8787082880735397 | Validation Accurancy:  0.8279826641082764\n",
      "Epoch:  1458 | Train Accurancy:  0.8787613362073898 | Validation Accurancy:  0.8280405551195145\n",
      "Epoch:  1459 | Train Accurancy:  0.8788142502307892 | Validation Accurancy:  0.8281248509883881\n",
      "Epoch:  1460 | Train Accurancy:  0.8788671791553497 | Validation Accurancy:  0.8281843364238739\n",
      "Epoch:  1461 | Train Accurancy:  0.8789199516177177 | Validation Accurancy:  0.8282757699489594\n",
      "Epoch:  1462 | Train Accurancy:  0.8789726793766022 | Validation Accurancy:  0.8283335417509079\n",
      "Epoch:  1463 | Train Accurancy:  0.879025287926197 | Validation Accurancy:  0.8284175544977188\n",
      "Epoch:  1464 | Train Accurancy:  0.8790777772665024 | Validation Accurancy:  0.8284767419099808\n",
      "Epoch:  1465 | Train Accurancy:  0.8791302368044853 | Validation Accurancy:  0.8285616934299469\n",
      "Epoch:  1466 | Train Accurancy:  0.8791826069355011 | Validation Accurancy:  0.8286276906728745\n",
      "Epoch:  1467 | Train Accurancy:  0.8792348727583885 | Validation Accurancy:  0.828710526227951\n",
      "Epoch:  1468 | Train Accurancy:  0.879287101328373 | Validation Accurancy:  0.8287690132856369\n",
      "Epoch:  1469 | Train Accurancy:  0.8793392330408096 | Validation Accurancy:  0.8288530558347702\n",
      "Epoch:  1470 | Train Accurancy:  0.8793911933898926 | Validation Accurancy:  0.8289185613393784\n",
      "Epoch:  1471 | Train Accurancy:  0.8794431462883949 | Validation Accurancy:  0.829000785946846\n",
      "Epoch:  1472 | Train Accurancy:  0.8794950172305107 | Validation Accurancy:  0.8290589153766632\n",
      "Epoch:  1473 | Train Accurancy:  0.8795467838644981 | Validation Accurancy:  0.8291425555944443\n",
      "Epoch:  1474 | Train Accurancy:  0.8795984610915184 | Validation Accurancy:  0.829207643866539\n",
      "Epoch:  1475 | Train Accurancy:  0.8796501159667969 | Validation Accurancy:  0.8292894810438156\n",
      "Epoch:  1476 | Train Accurancy:  0.8797015845775604 | Validation Accurancy:  0.8293473720550537\n",
      "Epoch:  1477 | Train Accurancy:  0.8797530606389046 | Validation Accurancy:  0.8294305950403214\n",
      "Epoch:  1478 | Train Accurancy:  0.8798043578863144 | Validation Accurancy:  0.8294953554868698\n",
      "Epoch:  1479 | Train Accurancy:  0.8798556625843048 | Validation Accurancy:  0.8295561671257019\n",
      "Epoch:  1480 | Train Accurancy:  0.8799068406224251 | Validation Accurancy:  0.8296411633491516\n",
      "Epoch:  1481 | Train Accurancy:  0.8799579963088036 | Validation Accurancy:  0.8297009617090225\n",
      "Epoch:  1482 | Train Accurancy:  0.8800089359283447 | Validation Accurancy:  0.8297912627458572\n",
      "Epoch:  1483 | Train Accurancy:  0.8800599575042725 | Validation Accurancy:  0.8298484981060028\n",
      "Epoch:  1484 | Train Accurancy:  0.8801108375191689 | Validation Accurancy:  0.8299308717250824\n",
      "Epoch:  1485 | Train Accurancy:  0.8801615685224533 | Validation Accurancy:  0.8299890160560608\n",
      "Epoch:  1486 | Train Accurancy:  0.880212277173996 | Validation Accurancy:  0.8300574421882629\n",
      "Epoch:  1487 | Train Accurancy:  0.8802628666162491 | Validation Accurancy:  0.8301409631967545\n",
      "Epoch:  1488 | Train Accurancy:  0.8803134486079216 | Validation Accurancy:  0.8301998525857925\n",
      "Epoch:  1489 | Train Accurancy:  0.8803639113903046 | Validation Accurancy:  0.8302830159664154\n",
      "Epoch:  1490 | Train Accurancy:  0.8804142773151398 | Validation Accurancy:  0.8303477019071579\n",
      "Epoch:  1491 | Train Accurancy:  0.8804645612835884 | Validation Accurancy:  0.8304285705089569\n",
      "Epoch:  1492 | Train Accurancy:  0.8805148303508759 | Validation Accurancy:  0.8304856568574905\n",
      "Epoch:  1493 | Train Accurancy:  0.880564957857132 | Validation Accurancy:  0.8305531889200211\n",
      "Epoch:  1494 | Train Accurancy:  0.8806149810552597 | Validation Accurancy:  0.8306356072425842\n",
      "Epoch:  1495 | Train Accurancy:  0.8806649595499039 | Validation Accurancy:  0.8306939601898193\n",
      "Epoch:  1496 | Train Accurancy:  0.880714938044548 | Validation Accurancy:  0.8307762742042542\n",
      "Epoch:  1497 | Train Accurancy:  0.8807646930217743 | Validation Accurancy:  0.8308403491973877\n",
      "Epoch:  1498 | Train Accurancy:  0.8808144852519035 | Validation Accurancy:  0.8309003859758377\n",
      "Epoch:  1499 | Train Accurancy:  0.880864106118679 | Validation Accurancy:  0.830983579158783\n",
      "Epoch:  1500 | Train Accurancy:  0.8809137046337128 | Validation Accurancy:  0.8310424834489822\n",
      "Epoch:  1501 | Train Accurancy:  0.8809631988406181 | Validation Accurancy:  0.831130638718605\n",
      "Epoch:  1502 | Train Accurancy:  0.8810125514864922 | Validation Accurancy:  0.8311868757009506\n",
      "Epoch:  1503 | Train Accurancy:  0.8810620009899139 | Validation Accurancy:  0.8312474191188812\n",
      "Epoch:  1504 | Train Accurancy:  0.8811111897230148 | Validation Accurancy:  0.8313367515802383\n",
      "Epoch:  1505 | Train Accurancy:  0.8811604306101799 | Validation Accurancy:  0.8313934952020645\n",
      "Epoch:  1506 | Train Accurancy:  0.8812095001339912 | Validation Accurancy:  0.8314544558525085\n",
      "Epoch:  1507 | Train Accurancy:  0.881258599460125 | Validation Accurancy:  0.8315379470586777\n",
      "Epoch:  1508 | Train Accurancy:  0.8813075050711632 | Validation Accurancy:  0.8316026329994202\n",
      "Epoch:  1509 | Train Accurancy:  0.8813564330339432 | Validation Accurancy:  0.8316628485918045\n",
      "Epoch:  1510 | Train Accurancy:  0.8814052045345306 | Validation Accurancy:  0.8317456245422363\n",
      "Epoch:  1511 | Train Accurancy:  0.8814539536833763 | Validation Accurancy:  0.8318041265010834\n",
      "Epoch:  1512 | Train Accurancy:  0.8815026059746742 | Validation Accurancy:  0.831871896982193\n",
      "Epoch:  1513 | Train Accurancy:  0.8815511539578438 | Validation Accurancy:  0.8319535851478577\n",
      "Epoch:  1514 | Train Accurancy:  0.8815996497869492 | Validation Accurancy:  0.8320112824440002\n",
      "Epoch:  1515 | Train Accurancy:  0.8816481083631516 | Validation Accurancy:  0.8320784270763397\n",
      "Epoch:  1516 | Train Accurancy:  0.8816964328289032 | Validation Accurancy:  0.8321596831083298\n",
      "Epoch:  1517 | Train Accurancy:  0.8817447200417519 | Validation Accurancy:  0.8322170525789261\n",
      "Epoch:  1518 | Train Accurancy:  0.8817929103970528 | Validation Accurancy:  0.8322779834270477\n",
      "Epoch:  1519 | Train Accurancy:  0.8818409591913223 | Validation Accurancy:  0.8323666751384735\n",
      "Epoch:  1520 | Train Accurancy:  0.8818890303373337 | Validation Accurancy:  0.8324232697486877\n",
      "Epoch:  1521 | Train Accurancy:  0.8819370418787003 | Validation Accurancy:  0.8324834704399109\n",
      "Epoch:  1522 | Train Accurancy:  0.8819849044084549 | Validation Accurancy:  0.8325715363025665\n",
      "Epoch:  1523 | Train Accurancy:  0.8820327147841454 | Validation Accurancy:  0.8326275050640106\n",
      "Epoch:  1524 | Train Accurancy:  0.8820804581046104 | Validation Accurancy:  0.8326875418424606\n",
      "Epoch:  1525 | Train Accurancy:  0.882128156721592 | Validation Accurancy:  0.8327750563621521\n",
      "Epoch:  1526 | Train Accurancy:  0.8821756839752197 | Validation Accurancy:  0.8328309655189514\n",
      "Epoch:  1527 | Train Accurancy:  0.8822232857346535 | Validation Accurancy:  0.8328906148672104\n",
      "Epoch:  1528 | Train Accurancy:  0.8822707161307335 | Validation Accurancy:  0.8329778164625168\n",
      "Epoch:  1529 | Train Accurancy:  0.8823180645704269 | Validation Accurancy:  0.833033487200737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1530 | Train Accurancy:  0.8823653981089592 | Validation Accurancy:  0.8330930769443512\n",
      "Epoch:  1531 | Train Accurancy:  0.8824126645922661 | Validation Accurancy:  0.8331606984138489\n",
      "Epoch:  1532 | Train Accurancy:  0.8824597075581551 | Validation Accurancy:  0.8332415968179703\n",
      "Epoch:  1533 | Train Accurancy:  0.8825068175792694 | Validation Accurancy:  0.8332987874746323\n",
      "Epoch:  1534 | Train Accurancy:  0.8825538083910942 | Validation Accurancy:  0.8333648592233658\n",
      "Epoch:  1535 | Train Accurancy:  0.8826007917523384 | Validation Accurancy:  0.8334445059299469\n",
      "Epoch:  1536 | Train Accurancy:  0.8826475813984871 | Validation Accurancy:  0.8335009217262268\n",
      "Epoch:  1537 | Train Accurancy:  0.8826943784952164 | Validation Accurancy:  0.8335662931203842\n",
      "Epoch:  1538 | Train Accurancy:  0.8827411383390427 | Validation Accurancy:  0.8336263000965118\n",
      "Epoch:  1539 | Train Accurancy:  0.8827877044677734 | Validation Accurancy:  0.8337075114250183\n",
      "Epoch:  1540 | Train Accurancy:  0.882834292948246 | Validation Accurancy:  0.8337650448083878\n",
      "Epoch:  1541 | Train Accurancy:  0.8828807845711708 | Validation Accurancy:  0.8338309228420258\n",
      "Epoch:  1542 | Train Accurancy:  0.8829272091388702 | Validation Accurancy:  0.8338913321495056\n",
      "Epoch:  1543 | Train Accurancy:  0.8829735592007637 | Validation Accurancy:  0.8339724838733673\n",
      "Epoch:  1544 | Train Accurancy:  0.8830197900533676 | Validation Accurancy:  0.8340354263782501\n",
      "Epoch:  1545 | Train Accurancy:  0.8830660954117775 | Validation Accurancy:  0.83409383893013\n",
      "Epoch:  1546 | Train Accurancy:  0.8831121250987053 | Validation Accurancy:  0.8341546803712845\n",
      "Epoch:  1547 | Train Accurancy:  0.8831582814455032 | Validation Accurancy:  0.8342414647340775\n",
      "Epoch:  1548 | Train Accurancy:  0.883204273879528 | Validation Accurancy:  0.8342969715595245\n",
      "Epoch:  1549 | Train Accurancy:  0.8832501098513603 | Validation Accurancy:  0.8343559056520462\n",
      "Epoch:  1550 | Train Accurancy:  0.8832960352301598 | Validation Accurancy:  0.8344224989414215\n",
      "Epoch:  1551 | Train Accurancy:  0.8833417594432831 | Validation Accurancy:  0.8344832509756088\n",
      "Epoch:  1552 | Train Accurancy:  0.8833874389529228 | Validation Accurancy:  0.834564208984375\n",
      "Epoch:  1553 | Train Accurancy:  0.8834330812096596 | Validation Accurancy:  0.8346268683671951\n",
      "Epoch:  1554 | Train Accurancy:  0.8834786787629128 | Validation Accurancy:  0.834684893488884\n",
      "Epoch:  1555 | Train Accurancy:  0.883524164557457 | Validation Accurancy:  0.8347453624010086\n",
      "Epoch:  1556 | Train Accurancy:  0.883569672703743 | Validation Accurancy:  0.8348312377929688\n",
      "Epoch:  1557 | Train Accurancy:  0.8836149349808693 | Validation Accurancy:  0.8348864167928696\n",
      "Epoch:  1558 | Train Accurancy:  0.883660264313221 | Validation Accurancy:  0.8349502980709076\n",
      "Epoch:  1559 | Train Accurancy:  0.8837054893374443 | Validation Accurancy:  0.8350088894367218\n",
      "Epoch:  1560 | Train Accurancy:  0.8837506622076035 | Validation Accurancy:  0.8350696116685867\n",
      "Epoch:  1561 | Train Accurancy:  0.8837957233190536 | Validation Accurancy:  0.8351555168628693\n",
      "Epoch:  1562 | Train Accurancy:  0.8838407024741173 | Validation Accurancy:  0.835210531949997\n",
      "Epoch:  1563 | Train Accurancy:  0.8838856592774391 | Validation Accurancy:  0.8352689296007156\n",
      "Epoch:  1564 | Train Accurancy:  0.8839305713772774 | Validation Accurancy:  0.8353345692157745\n",
      "Epoch:  1565 | Train Accurancy:  0.8839753642678261 | Validation Accurancy:  0.8353945165872574\n",
      "Epoch:  1566 | Train Accurancy:  0.88402009755373 | Validation Accurancy:  0.8354558646678925\n",
      "Epoch:  1567 | Train Accurancy:  0.884064756333828 | Validation Accurancy:  0.8355417251586914\n",
      "Epoch:  1568 | Train Accurancy:  0.88410934060812 | Validation Accurancy:  0.8355970084667206\n",
      "Epoch:  1569 | Train Accurancy:  0.8841538652777672 | Validation Accurancy:  0.8356551676988602\n",
      "Epoch:  1570 | Train Accurancy:  0.8841983899474144 | Validation Accurancy:  0.8357206135988235\n",
      "Epoch:  1571 | Train Accurancy:  0.8842426985502243 | Validation Accurancy:  0.8357802927494049\n",
      "Epoch:  1572 | Train Accurancy:  0.8842870891094208 | Validation Accurancy:  0.8358413577079773\n",
      "Epoch:  1573 | Train Accurancy:  0.8843313381075859 | Validation Accurancy:  0.8359266072511673\n",
      "Epoch:  1574 | Train Accurancy:  0.8843755200505257 | Validation Accurancy:  0.835981473326683\n",
      "Epoch:  1575 | Train Accurancy:  0.8844196647405624 | Validation Accurancy:  0.836044654250145\n",
      "Epoch:  1576 | Train Accurancy:  0.8844637349247932 | Validation Accurancy:  0.8361025303602219\n",
      "Epoch:  1577 | Train Accurancy:  0.8845077082514763 | Validation Accurancy:  0.8361623883247375\n",
      "Epoch:  1578 | Train Accurancy:  0.8845516219735146 | Validation Accurancy:  0.8362286686897278\n",
      "Epoch:  1579 | Train Accurancy:  0.884595513343811 | Validation Accurancy:  0.8362886011600494\n",
      "Epoch:  1580 | Train Accurancy:  0.8846392780542374 | Validation Accurancy:  0.8363678008317947\n",
      "Epoch:  1581 | Train Accurancy:  0.8846830353140831 | Validation Accurancy:  0.8364290148019791\n",
      "Epoch:  1582 | Train Accurancy:  0.8847266882658005 | Validation Accurancy:  0.8364855647087097\n",
      "Epoch:  1583 | Train Accurancy:  0.8847702518105507 | Validation Accurancy:  0.8365495353937149\n",
      "Epoch:  1584 | Train Accurancy:  0.8848137930035591 | Validation Accurancy:  0.8366079926490784\n",
      "Epoch:  1585 | Train Accurancy:  0.8848572447896004 | Validation Accurancy:  0.8366679102182388\n",
      "Epoch:  1586 | Train Accurancy:  0.8849006444215775 | Validation Accurancy:  0.8367339670658112\n",
      "Epoch:  1587 | Train Accurancy:  0.8849440142512321 | Validation Accurancy:  0.8367937505245209\n",
      "Epoch:  1588 | Train Accurancy:  0.8849872425198555 | Validation Accurancy:  0.8368722945451736\n",
      "Epoch:  1589 | Train Accurancy:  0.8850304186344147 | Validation Accurancy:  0.8369330614805222\n",
      "Epoch:  1590 | Train Accurancy:  0.8850735649466515 | Validation Accurancy:  0.8369893431663513\n",
      "Epoch:  1591 | Train Accurancy:  0.8851166665554047 | Validation Accurancy:  0.8370527476072311\n",
      "Epoch:  1592 | Train Accurancy:  0.8851596266031265 | Validation Accurancy:  0.83711077272892\n",
      "Epoch:  1593 | Train Accurancy:  0.8852025344967842 | Validation Accurancy:  0.8371753096580505\n",
      "Epoch:  1594 | Train Accurancy:  0.8852454423904419 | Validation Accurancy:  0.8372339606285095\n",
      "Epoch:  1595 | Train Accurancy:  0.8852883353829384 | Validation Accurancy:  0.837293729186058\n",
      "Epoch:  1596 | Train Accurancy:  0.8853310644626617 | Validation Accurancy:  0.8373595327138901\n",
      "Epoch:  1597 | Train Accurancy:  0.8853737041354179 | Validation Accurancy:  0.8374188393354416\n",
      "Epoch:  1598 | Train Accurancy:  0.8854163214564323 | Validation Accurancy:  0.8374790698289871\n",
      "Epoch:  1599 | Train Accurancy:  0.8854588344693184 | Validation Accurancy:  0.8375624269247055\n",
      "Epoch:  1600 | Train Accurancy:  0.8855013400316238 | Validation Accurancy:  0.8376162201166153\n",
      "Epoch:  1601 | Train Accurancy:  0.8855437785387039 | Validation Accurancy:  0.8376778215169907\n",
      "Epoch:  1602 | Train Accurancy:  0.8855861350893974 | Validation Accurancy:  0.8377343267202377\n",
      "Epoch:  1603 | Train Accurancy:  0.8856284469366074 | Validation Accurancy:  0.8377975821495056\n",
      "Epoch:  1604 | Train Accurancy:  0.8856706470251083 | Validation Accurancy:  0.8378552496433258\n",
      "Epoch:  1605 | Train Accurancy:  0.8857128620147705 | Validation Accurancy:  0.8379141837358475\n",
      "Epoch:  1606 | Train Accurancy:  0.8857549801468849 | Validation Accurancy:  0.8379790335893631\n",
      "Epoch:  1607 | Train Accurancy:  0.8857970163226128 | Validation Accurancy:  0.8380376249551773\n",
      "Epoch:  1608 | Train Accurancy:  0.8858389779925346 | Validation Accurancy:  0.8381021618843079\n",
      "Epoch:  1609 | Train Accurancy:  0.8858809024095535 | Validation Accurancy:  0.8381605595350266\n",
      "Epoch:  1610 | Train Accurancy:  0.8859227895736694 | Validation Accurancy:  0.8382199257612228\n",
      "Epoch:  1611 | Train Accurancy:  0.8859645500779152 | Validation Accurancy:  0.8382848799228668\n",
      "Epoch:  1612 | Train Accurancy:  0.8860062882304192 | Validation Accurancy:  0.8383434563875198\n",
      "Epoch:  1613 | Train Accurancy:  0.8860479891300201 | Validation Accurancy:  0.8384028077125549\n",
      "Epoch:  1614 | Train Accurancy:  0.8860895931720734 | Validation Accurancy:  0.8384677320718765\n",
      "Epoch:  1615 | Train Accurancy:  0.88613111525774 | Validation Accurancy:  0.8385262340307236\n",
      "Epoch:  1616 | Train Accurancy:  0.8861726000905037 | Validation Accurancy:  0.8385904282331467\n",
      "Epoch:  1617 | Train Accurancy:  0.8862140700221062 | Validation Accurancy:  0.8386485874652863\n",
      "Epoch:  1618 | Train Accurancy:  0.8862553536891937 | Validation Accurancy:  0.8387076109647751\n",
      "Epoch:  1619 | Train Accurancy:  0.8862966820597649 | Validation Accurancy:  0.838771864771843\n",
      "Epoch:  1620 | Train Accurancy:  0.8863379508256912 | Validation Accurancy:  0.8388300389051437\n",
      "Epoch:  1621 | Train Accurancy:  0.8863791078329086 | Validation Accurancy:  0.8388938903808594\n",
      "Epoch:  1622 | Train Accurancy:  0.8864202052354813 | Validation Accurancy:  0.8389516025781631\n",
      "Epoch:  1623 | Train Accurancy:  0.8864612877368927 | Validation Accurancy:  0.8390101939439774\n",
      "Epoch:  1624 | Train Accurancy:  0.8865022212266922 | Validation Accurancy:  0.8390742838382721\n",
      "Epoch:  1625 | Train Accurancy:  0.8865431919693947 | Validation Accurancy:  0.839132159948349\n",
      "Epoch:  1626 | Train Accurancy:  0.8865840509533882 | Validation Accurancy:  0.83919557929039\n",
      "Epoch:  1627 | Train Accurancy:  0.8866248950362206 | Validation Accurancy:  0.8392529636621475\n",
      "Epoch:  1628 | Train Accurancy:  0.8866656199097633 | Validation Accurancy:  0.8393161296844482\n",
      "Epoch:  1629 | Train Accurancy:  0.8867063298821449 | Validation Accurancy:  0.8393732607364655\n",
      "Epoch:  1630 | Train Accurancy:  0.8867469653487206 | Validation Accurancy:  0.8394362926483154\n",
      "Epoch:  1631 | Train Accurancy:  0.8867875337600708 | Validation Accurancy:  0.8394931703805923\n",
      "Epoch:  1632 | Train Accurancy:  0.8868280872702599 | Validation Accurancy:  0.8395511209964752\n",
      "Epoch:  1633 | Train Accurancy:  0.8868685141205788 | Validation Accurancy:  0.8396140187978745\n",
      "Epoch:  1634 | Train Accurancy:  0.8869089335203171 | Validation Accurancy:  0.8396710604429245\n",
      "Epoch:  1635 | Train Accurancy:  0.886949211359024 | Validation Accurancy:  0.8397337049245834\n",
      "Epoch:  1636 | Train Accurancy:  0.8869895115494728 | Validation Accurancy:  0.8397902697324753\n",
      "Epoch:  1637 | Train Accurancy:  0.8870296999812126 | Validation Accurancy:  0.8398528397083282\n",
      "Epoch:  1638 | Train Accurancy:  0.887069895863533 | Validation Accurancy:  0.8399093598127365\n",
      "Epoch:  1639 | Train Accurancy:  0.8871100172400475 | Validation Accurancy:  0.8399717062711716\n",
      "Epoch:  1640 | Train Accurancy:  0.8871500343084335 | Validation Accurancy:  0.8400281816720963\n",
      "Epoch:  1641 | Train Accurancy:  0.8871899619698524 | Validation Accurancy:  0.8400854468345642\n",
      "Epoch:  1642 | Train Accurancy:  0.8872298821806908 | Validation Accurancy:  0.8401481360197067\n",
      "Epoch:  1643 | Train Accurancy:  0.8872697874903679 | Validation Accurancy:  0.8402048945426941\n",
      "Epoch:  1644 | Train Accurancy:  0.8873095735907555 | Validation Accurancy:  0.8402671366930008\n",
      "Epoch:  1645 | Train Accurancy:  0.8873493373394012 | Validation Accurancy:  0.8403234034776688\n",
      "Epoch:  1646 | Train Accurancy:  0.8873889893293381 | Validation Accurancy:  0.8403853476047516\n",
      "Epoch:  1647 | Train Accurancy:  0.8874285966157913 | Validation Accurancy:  0.8404413759708405\n",
      "Epoch:  1648 | Train Accurancy:  0.8874682411551476 | Validation Accurancy:  0.8405031859874725\n",
      "Epoch:  1649 | Train Accurancy:  0.8875076994299889 | Validation Accurancy:  0.8405590504407883\n",
      "Epoch:  1650 | Train Accurancy:  0.8875471502542496 | Validation Accurancy:  0.8406205922365189\n",
      "Epoch:  1651 | Train Accurancy:  0.8875865638256073 | Validation Accurancy:  0.8406762927770615\n",
      "Epoch:  1652 | Train Accurancy:  0.8876258581876755 | Validation Accurancy:  0.8407376110553741\n",
      "Epoch:  1653 | Train Accurancy:  0.8876651674509048 | Validation Accurancy:  0.8407933562994003\n",
      "Epoch:  1654 | Train Accurancy:  0.8877043798565865 | Validation Accurancy:  0.8408545851707458\n",
      "Epoch:  1655 | Train Accurancy:  0.8877435922622681 | Validation Accurancy:  0.8409100919961929\n",
      "Epoch:  1656 | Train Accurancy:  0.8877826631069183 | Validation Accurancy:  0.8409711718559265\n",
      "Epoch:  1657 | Train Accurancy:  0.8878217414021492 | Validation Accurancy:  0.8410265892744064\n",
      "Epoch:  1658 | Train Accurancy:  0.8878607451915741 | Validation Accurancy:  0.8410875797271729\n",
      "Epoch:  1659 | Train Accurancy:  0.88789963722229 | Validation Accurancy:  0.8411428481340408\n",
      "Epoch:  1660 | Train Accurancy:  0.8879385218024254 | Validation Accurancy:  0.8412036299705505\n",
      "Epoch:  1661 | Train Accurancy:  0.8879773691296577 | Validation Accurancy:  0.8412588536739349\n",
      "Epoch:  1662 | Train Accurancy:  0.8880161121487617 | Validation Accurancy:  0.8413195908069611\n",
      "Epoch:  1663 | Train Accurancy:  0.888054832816124 | Validation Accurancy:  0.8413744568824768\n",
      "Epoch:  1664 | Train Accurancy:  0.8880934938788414 | Validation Accurancy:  0.8414351046085358\n",
      "Epoch:  1665 | Train Accurancy:  0.8881321102380753 | Validation Accurancy:  0.8414900451898575\n",
      "Epoch:  1666 | Train Accurancy:  0.8881706893444061 | Validation Accurancy:  0.8415503650903702\n",
      "Epoch:  1667 | Train Accurancy:  0.888209193944931 | Validation Accurancy:  0.8416052311658859\n",
      "Epoch:  1668 | Train Accurancy:  0.8882476314902306 | Validation Accurancy:  0.8416655361652374\n",
      "Epoch:  1669 | Train Accurancy:  0.8882859647274017 | Validation Accurancy:  0.8417201638221741\n",
      "Epoch:  1670 | Train Accurancy:  0.8883243426680565 | Validation Accurancy:  0.8417803794145584\n",
      "Epoch:  1671 | Train Accurancy:  0.8883625790476799 | Validation Accurancy:  0.8418349176645279\n",
      "Epoch:  1672 | Train Accurancy:  0.8884007558226585 | Validation Accurancy:  0.8418949395418167\n",
      "Epoch:  1673 | Train Accurancy:  0.8884389623999596 | Validation Accurancy:  0.8419540375471115\n",
      "Epoch:  1674 | Train Accurancy:  0.8884770050644875 | Validation Accurancy:  0.8420078009366989\n",
      "Epoch:  1675 | Train Accurancy:  0.8885150775313377 | Validation Accurancy:  0.8420671671628952\n",
      "Epoch:  1676 | Train Accurancy:  0.8885531201958656 | Validation Accurancy:  0.8421211838722229\n",
      "Epoch:  1677 | Train Accurancy:  0.888591006398201 | Validation Accurancy:  0.8421806991100311\n",
      "Epoch:  1678 | Train Accurancy:  0.8886289373040199 | Validation Accurancy:  0.8422347754240036\n",
      "Epoch:  1679 | Train Accurancy:  0.8886667862534523 | Validation Accurancy:  0.8422941863536835\n",
      "Epoch:  1680 | Train Accurancy:  0.8887045159935951 | Validation Accurancy:  0.8423526734113693\n",
      "Epoch:  1681 | Train Accurancy:  0.8887422531843185 | Validation Accurancy:  0.8424060940742493\n",
      "Epoch:  1682 | Train Accurancy:  0.888779915869236 | Validation Accurancy:  0.842464953660965\n",
      "Epoch:  1683 | Train Accurancy:  0.8888175711035728 | Validation Accurancy:  0.8425185680389404\n",
      "Epoch:  1684 | Train Accurancy:  0.8888551145792007 | Validation Accurancy:  0.8425775915384293\n",
      "Epoch:  1685 | Train Accurancy:  0.8888926133513451 | Validation Accurancy:  0.8426311612129211\n",
      "Epoch:  1686 | Train Accurancy:  0.8889300748705864 | Validation Accurancy:  0.84269018471241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1687 | Train Accurancy:  0.8889674246311188 | Validation Accurancy:  0.8427481800317764\n",
      "Epoch:  1688 | Train Accurancy:  0.8890048265457153 | Validation Accurancy:  0.8428011685609818\n",
      "Epoch:  1689 | Train Accurancy:  0.8890421316027641 | Validation Accurancy:  0.842859610915184\n",
      "Epoch:  1690 | Train Accurancy:  0.8890793398022652 | Validation Accurancy:  0.8429128378629684\n",
      "Epoch:  1691 | Train Accurancy:  0.889116495847702 | Validation Accurancy:  0.8429715037345886\n",
      "Epoch:  1692 | Train Accurancy:  0.8891537114977837 | Validation Accurancy:  0.8430291265249252\n",
      "Epoch:  1693 | Train Accurancy:  0.889190785586834 | Validation Accurancy:  0.8430817127227783\n",
      "Epoch:  1694 | Train Accurancy:  0.8892278373241425 | Validation Accurancy:  0.8431398868560791\n",
      "Epoch:  1695 | Train Accurancy:  0.889264814555645 | Validation Accurancy:  0.8431972116231918\n",
      "Epoch:  1696 | Train Accurancy:  0.8893017247319221 | Validation Accurancy:  0.8432495146989822\n",
      "Epoch:  1697 | Train Accurancy:  0.8893385753035545 | Validation Accurancy:  0.8433073312044144\n",
      "Epoch:  1698 | Train Accurancy:  0.8893754035234451 | Validation Accurancy:  0.8433600813150406\n",
      "Epoch:  1699 | Train Accurancy:  0.889412172138691 | Validation Accurancy:  0.8434180915355682\n",
      "Epoch:  1700 | Train Accurancy:  0.8894489258527756 | Validation Accurancy:  0.8434752523899078\n",
      "Epoch:  1701 | Train Accurancy:  0.88948555290699 | Validation Accurancy:  0.8435273915529251\n",
      "Epoch:  1702 | Train Accurancy:  0.8895221725106239 | Validation Accurancy:  0.8435849696397781\n",
      "Epoch:  1703 | Train Accurancy:  0.8895587027072906 | Validation Accurancy:  0.8436417728662491\n",
      "Epoch:  1704 | Train Accurancy:  0.889595240354538 | Validation Accurancy:  0.8436936885118484\n",
      "Epoch:  1705 | Train Accurancy:  0.8896316662430763 | Validation Accurancy:  0.8437511473894119\n",
      "Epoch:  1706 | Train Accurancy:  0.8896681070327759 | Validation Accurancy:  0.8438076227903366\n",
      "Epoch:  1707 | Train Accurancy:  0.8897044807672501 | Validation Accurancy:  0.8438593298196793\n",
      "Epoch:  1708 | Train Accurancy:  0.8897407725453377 | Validation Accurancy:  0.8439164012670517\n",
      "Epoch:  1709 | Train Accurancy:  0.8897769749164581 | Validation Accurancy:  0.84397292137146\n",
      "Epoch:  1710 | Train Accurancy:  0.8898132145404816 | Validation Accurancy:  0.8440244048833847\n",
      "Epoch:  1711 | Train Accurancy:  0.8898494094610214 | Validation Accurancy:  0.8440813422203064\n",
      "Epoch:  1712 | Train Accurancy:  0.8898854926228523 | Validation Accurancy:  0.8441374599933624\n",
      "Epoch:  1713 | Train Accurancy:  0.8899214789271355 | Validation Accurancy:  0.84418885409832\n",
      "Epoch:  1714 | Train Accurancy:  0.889957495033741 | Validation Accurancy:  0.8442456275224686\n",
      "Epoch:  1715 | Train Accurancy:  0.8899934813380241 | Validation Accurancy:  0.8443017154932022\n",
      "Epoch:  1716 | Train Accurancy:  0.8900293111801147 | Validation Accurancy:  0.8443529605865479\n",
      "Epoch:  1717 | Train Accurancy:  0.890065148472786 | Validation Accurancy:  0.8444094955921173\n",
      "Epoch:  1718 | Train Accurancy:  0.8901010379195213 | Validation Accurancy:  0.8444653302431107\n",
      "Epoch:  1719 | Train Accurancy:  0.8901367336511612 | Validation Accurancy:  0.8445163369178772\n",
      "Epoch:  1720 | Train Accurancy:  0.8901723995804787 | Validation Accurancy:  0.8445727974176407\n",
      "Epoch:  1721 | Train Accurancy:  0.8902080580592155 | Validation Accurancy:  0.8446284085512161\n",
      "Epoch:  1722 | Train Accurancy:  0.8902436792850494 | Validation Accurancy:  0.8446836024522781\n",
      "Epoch:  1723 | Train Accurancy:  0.8902792036533356 | Validation Accurancy:  0.8447341620922089\n",
      "Epoch:  1724 | Train Accurancy:  0.8903147056698799 | Validation Accurancy:  0.8447901159524918\n",
      "Epoch:  1725 | Train Accurancy:  0.8903501704335213 | Validation Accurancy:  0.8448453396558762\n",
      "Epoch:  1726 | Train Accurancy:  0.8903855234384537 | Validation Accurancy:  0.8448960781097412\n",
      "Epoch:  1727 | Train Accurancy:  0.8904209211468697 | Validation Accurancy:  0.8449520021677017\n",
      "Epoch:  1728 | Train Accurancy:  0.8904562219977379 | Validation Accurancy:  0.8450071066617966\n",
      "Epoch:  1729 | Train Accurancy:  0.8904914632439613 | Validation Accurancy:  0.8450618386268616\n",
      "Epoch:  1730 | Train Accurancy:  0.8905266672372818 | Validation Accurancy:  0.8451119959354401\n",
      "Epoch:  1731 | Train Accurancy:  0.8905618041753769 | Validation Accurancy:  0.8451675623655319\n",
      "Epoch:  1732 | Train Accurancy:  0.8905968889594078 | Validation Accurancy:  0.8452223390340805\n",
      "Epoch:  1733 | Train Accurancy:  0.8906319513916969 | Validation Accurancy:  0.8452768325805664\n",
      "Epoch:  1734 | Train Accurancy:  0.8906669840216637 | Validation Accurancy:  0.8453268110752106\n",
      "Epoch:  1735 | Train Accurancy:  0.890701912343502 | Validation Accurancy:  0.8453819900751114\n",
      "Epoch:  1736 | Train Accurancy:  0.8907368332147598 | Validation Accurancy:  0.8454366773366928\n",
      "Epoch:  1737 | Train Accurancy:  0.8907716944813728 | Validation Accurancy:  0.8454907536506653\n",
      "Epoch:  1738 | Train Accurancy:  0.8908065110445023 | Validation Accurancy:  0.8455405086278915\n",
      "Epoch:  1739 | Train Accurancy:  0.8908412605524063 | Validation Accurancy:  0.8455955386161804\n",
      "Epoch:  1740 | Train Accurancy:  0.890875980257988 | Validation Accurancy:  0.8456499725580215\n",
      "Epoch:  1741 | Train Accurancy:  0.8909106478095055 | Validation Accurancy:  0.8457038551568985\n",
      "Epoch:  1742 | Train Accurancy:  0.8909452334046364 | Validation Accurancy:  0.8457533419132233\n",
      "Epoch:  1743 | Train Accurancy:  0.8909798339009285 | Validation Accurancy:  0.845808133482933\n",
      "Epoch:  1744 | Train Accurancy:  0.8910143375396729 | Validation Accurancy:  0.8458623290061951\n",
      "Epoch:  1745 | Train Accurancy:  0.8910488039255142 | Validation Accurancy:  0.8459159880876541\n",
      "Epoch:  1746 | Train Accurancy:  0.8910832777619362 | Validation Accurancy:  0.8459652811288834\n",
      "Epoch:  1747 | Train Accurancy:  0.8911176547408104 | Validation Accurancy:  0.8460199534893036\n",
      "Epoch:  1748 | Train Accurancy:  0.8911519795656204 | Validation Accurancy:  0.8460737764835358\n",
      "Epoch:  1749 | Train Accurancy:  0.8911862596869469 | Validation Accurancy:  0.8461273461580276\n",
      "Epoch:  1750 | Train Accurancy:  0.8912205025553703 | Validation Accurancy:  0.8461804836988449\n",
      "Epoch:  1751 | Train Accurancy:  0.8912546932697296 | Validation Accurancy:  0.8462294489145279\n",
      "Epoch:  1752 | Train Accurancy:  0.8912888541817665 | Validation Accurancy:  0.846283569931984\n",
      "Epoch:  1753 | Train Accurancy:  0.8913229256868362 | Validation Accurancy:  0.8463371843099594\n",
      "Epoch:  1754 | Train Accurancy:  0.891356959939003 | Validation Accurancy:  0.8463902622461319\n",
      "Epoch:  1755 | Train Accurancy:  0.8913909867405891 | Validation Accurancy:  0.8464430719614029\n",
      "Epoch:  1756 | Train Accurancy:  0.8914249688386917 | Validation Accurancy:  0.8464917540550232\n",
      "Epoch:  1757 | Train Accurancy:  0.8914588615298271 | Validation Accurancy:  0.8465456366539001\n",
      "Epoch:  1758 | Train Accurancy:  0.8914927095174789 | Validation Accurancy:  0.8465989530086517\n",
      "Epoch:  1759 | Train Accurancy:  0.891526572406292 | Validation Accurancy:  0.8466517478227615\n",
      "Epoch:  1760 | Train Accurancy:  0.8915602937340736 | Validation Accurancy:  0.8467044234275818\n",
      "Epoch:  1761 | Train Accurancy:  0.8915940672159195 | Validation Accurancy:  0.8467567712068558\n",
      "Epoch:  1762 | Train Accurancy:  0.8916277065873146 | Validation Accurancy:  0.846805065870285\n",
      "Epoch:  1763 | Train Accurancy:  0.8916613236069679 | Validation Accurancy:  0.8468584567308426\n",
      "Epoch:  1764 | Train Accurancy:  0.8916949331760406 | Validation Accurancy:  0.8469113856554031\n",
      "Epoch:  1765 | Train Accurancy:  0.891728438436985 | Validation Accurancy:  0.8469639122486115\n",
      "Epoch:  1766 | Train Accurancy:  0.89176195114851 | Validation Accurancy:  0.8470161557197571\n",
      "Epoch:  1767 | Train Accurancy:  0.8917954191565514 | Validation Accurancy:  0.8470681756734848\n",
      "Epoch:  1768 | Train Accurancy:  0.891828790307045 | Validation Accurancy:  0.8471200466156006\n",
      "Epoch:  1769 | Train Accurancy:  0.891862154006958 | Validation Accurancy:  0.8471678197383881\n",
      "Epoch:  1770 | Train Accurancy:  0.8918954432010651 | Validation Accurancy:  0.8472209423780441\n",
      "Epoch:  1771 | Train Accurancy:  0.8919287025928497 | Validation Accurancy:  0.8472733944654465\n",
      "Epoch:  1772 | Train Accurancy:  0.8919619396328926 | Validation Accurancy:  0.847325474023819\n",
      "Epoch:  1773 | Train Accurancy:  0.8919951096177101 | Validation Accurancy:  0.8473773300647736\n",
      "Epoch:  1774 | Train Accurancy:  0.8920282647013664 | Validation Accurancy:  0.847429022192955\n",
      "Epoch:  1775 | Train Accurancy:  0.8920613676309586 | Validation Accurancy:  0.8474805355072021\n",
      "Epoch:  1776 | Train Accurancy:  0.8920943811535835 | Validation Accurancy:  0.8475280851125717\n",
      "Epoch:  1777 | Train Accurancy:  0.8921273574233055 | Validation Accurancy:  0.8475807160139084\n",
      "Epoch:  1778 | Train Accurancy:  0.8921603485941887 | Validation Accurancy:  0.8476328253746033\n",
      "Epoch:  1779 | Train Accurancy:  0.8921932876110077 | Validation Accurancy:  0.8476846814155579\n",
      "Epoch:  1780 | Train Accurancy:  0.8922261148691177 | Validation Accurancy:  0.8477361053228378\n",
      "Epoch:  1781 | Train Accurancy:  0.892258957028389 | Validation Accurancy:  0.8477873057126999\n",
      "Epoch:  1782 | Train Accurancy:  0.8922917321324348 | Validation Accurancy:  0.847838506102562\n",
      "Epoch:  1783 | Train Accurancy:  0.8923244401812553 | Validation Accurancy:  0.8478895127773285\n",
      "Epoch:  1784 | Train Accurancy:  0.8923571184277534 | Validation Accurancy:  0.8479404747486115\n",
      "Epoch:  1785 | Train Accurancy:  0.8923897370696068 | Validation Accurancy:  0.8479913175106049\n",
      "Epoch:  1786 | Train Accurancy:  0.8924223557114601 | Validation Accurancy:  0.8480382710695267\n",
      "Epoch:  1787 | Train Accurancy:  0.8924548476934433 | Validation Accurancy:  0.848090335726738\n",
      "Epoch:  1788 | Train Accurancy:  0.892487421631813 | Validation Accurancy:  0.8481418341398239\n",
      "Epoch:  1789 | Train Accurancy:  0.8925198689103127 | Validation Accurancy:  0.848193034529686\n",
      "Epoch:  1790 | Train Accurancy:  0.8925522714853287 | Validation Accurancy:  0.8482439815998077\n",
      "Epoch:  1791 | Train Accurancy:  0.8925846740603447 | Validation Accurancy:  0.8482947796583176\n",
      "Epoch:  1792 | Train Accurancy:  0.8926169648766518 | Validation Accurancy:  0.8483454585075378\n",
      "Epoch:  1793 | Train Accurancy:  0.8926493152976036 | Validation Accurancy:  0.848395973443985\n",
      "Epoch:  1794 | Train Accurancy:  0.8926815241575241 | Validation Accurancy:  0.8484463691711426\n",
      "Epoch:  1795 | Train Accurancy:  0.8927136957645416 | Validation Accurancy:  0.8484966903924942\n",
      "Epoch:  1796 | Train Accurancy:  0.8927458822727203 | Validation Accurancy:  0.8485469818115234\n",
      "Epoch:  1797 | Train Accurancy:  0.8927779495716095 | Validation Accurancy:  0.8485971838235855\n",
      "Epoch:  1798 | Train Accurancy:  0.8928100541234016 | Validation Accurancy:  0.8486472815275192\n",
      "Epoch:  1799 | Train Accurancy:  0.8928420692682266 | Validation Accurancy:  0.8486973792314529\n",
      "Epoch:  1800 | Train Accurancy:  0.8928740471601486 | Validation Accurancy:  0.8487475365400314\n",
      "Epoch:  1801 | Train Accurancy:  0.892905980348587 | Validation Accurancy:  0.8487974107265472\n",
      "Epoch:  1802 | Train Accurancy:  0.8929378911852837 | Validation Accurancy:  0.8488436490297318\n",
      "Epoch:  1803 | Train Accurancy:  0.8929697647690773 | Validation Accurancy:  0.8488948047161102\n",
      "Epoch:  1804 | Train Accurancy:  0.8930015861988068 | Validation Accurancy:  0.8489455282688141\n",
      "Epoch:  1805 | Train Accurancy:  0.8930334076285362 | Validation Accurancy:  0.8489959090948105\n",
      "Epoch:  1806 | Train Accurancy:  0.8930650651454926 | Validation Accurancy:  0.8490460962057114\n",
      "Epoch:  1807 | Train Accurancy:  0.8930967971682549 | Validation Accurancy:  0.8490959852933884\n",
      "Epoch:  1808 | Train Accurancy:  0.8931284174323082 | Validation Accurancy:  0.8491457551717758\n",
      "Epoch:  1809 | Train Accurancy:  0.8931600004434586 | Validation Accurancy:  0.8491954952478409\n",
      "Epoch:  1810 | Train Accurancy:  0.8931916207075119 | Validation Accurancy:  0.8492451608181\n",
      "Epoch:  1811 | Train Accurancy:  0.8932231292128563 | Validation Accurancy:  0.8492946773767471\n",
      "Epoch:  1812 | Train Accurancy:  0.8932545930147171 | Validation Accurancy:  0.8493441641330719\n",
      "Epoch:  1813 | Train Accurancy:  0.8932859897613525 | Validation Accurancy:  0.8493936061859131\n",
      "Epoch:  1814 | Train Accurancy:  0.8933174386620522 | Validation Accurancy:  0.8494428992271423\n",
      "Epoch:  1815 | Train Accurancy:  0.8933487311005592 | Validation Accurancy:  0.8494922369718552\n",
      "Epoch:  1816 | Train Accurancy:  0.8933800682425499 | Validation Accurancy:  0.8495414704084396\n",
      "Epoch:  1817 | Train Accurancy:  0.8934113532304764 | Validation Accurancy:  0.8495907187461853\n",
      "Epoch:  1818 | Train Accurancy:  0.8934425562620163 | Validation Accurancy:  0.8496398329734802\n",
      "Epoch:  1819 | Train Accurancy:  0.8934737145900726 | Validation Accurancy:  0.8496888726949692\n",
      "Epoch:  1820 | Train Accurancy:  0.893504872918129 | Validation Accurancy:  0.8497380316257477\n",
      "Epoch:  1821 | Train Accurancy:  0.8935359716415405 | Validation Accurancy:  0.8497869223356247\n",
      "Epoch:  1822 | Train Accurancy:  0.8935670703649521 | Validation Accurancy:  0.8498357832431793\n",
      "Epoch:  1823 | Train Accurancy:  0.8935980871319771 | Validation Accurancy:  0.8498845845460892\n",
      "Epoch:  1824 | Train Accurancy:  0.8936290964484215 | Validation Accurancy:  0.849933460354805\n",
      "Epoch:  1825 | Train Accurancy:  0.8936599865555763 | Validation Accurancy:  0.849982276558876\n",
      "Epoch:  1826 | Train Accurancy:  0.8936909064650536 | Validation Accurancy:  0.8500310331583023\n",
      "Epoch:  1827 | Train Accurancy:  0.893721729516983 | Validation Accurancy:  0.8500797152519226\n",
      "Epoch:  1828 | Train Accurancy:  0.8937525451183319 | Validation Accurancy:  0.8501283675432205\n",
      "Epoch:  1829 | Train Accurancy:  0.893783301115036 | Validation Accurancy:  0.8501769751310349\n",
      "Epoch:  1830 | Train Accurancy:  0.8938140496611595 | Validation Accurancy:  0.8502255827188492\n",
      "Epoch:  1831 | Train Accurancy:  0.8938447311520576 | Validation Accurancy:  0.8502741158008575\n",
      "Epoch:  1832 | Train Accurancy:  0.893875353038311 | Validation Accurancy:  0.8503226637840271\n",
      "Epoch:  1833 | Train Accurancy:  0.8939060270786285 | Validation Accurancy:  0.8503711074590683\n",
      "Epoch:  1834 | Train Accurancy:  0.8939365372061729 | Validation Accurancy:  0.8504194766283035\n",
      "Epoch:  1835 | Train Accurancy:  0.8939670771360397 | Validation Accurancy:  0.8504677563905716\n",
      "Epoch:  1836 | Train Accurancy:  0.8939975798130035 | Validation Accurancy:  0.8505160808563232\n",
      "Epoch:  1837 | Train Accurancy:  0.894028052687645 | Validation Accurancy:  0.8505641520023346\n",
      "Epoch:  1838 | Train Accurancy:  0.8940584510564804 | Validation Accurancy:  0.8506124466657639\n",
      "Epoch:  1839 | Train Accurancy:  0.8940888345241547 | Validation Accurancy:  0.8506604582071304\n",
      "Epoch:  1840 | Train Accurancy:  0.89411910623312 | Validation Accurancy:  0.8507085144519806\n",
      "Epoch:  1841 | Train Accurancy:  0.8941494524478912 | Validation Accurancy:  0.8507564663887024\n",
      "Epoch:  1842 | Train Accurancy:  0.8941796720027924 | Validation Accurancy:  0.8508044630289078\n",
      "Epoch:  1843 | Train Accurancy:  0.8942099064588547 | Validation Accurancy:  0.8508524894714355\n",
      "Epoch:  1844 | Train Accurancy:  0.8942400440573692 | Validation Accurancy:  0.850900337100029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1845 | Train Accurancy:  0.8942701742053032 | Validation Accurancy:  0.8509481996297836\n",
      "Epoch:  1846 | Train Accurancy:  0.8943003341555595 | Validation Accurancy:  0.850996121764183\n",
      "Epoch:  1847 | Train Accurancy:  0.8943303152918816 | Validation Accurancy:  0.8510438799858093\n",
      "Epoch:  1848 | Train Accurancy:  0.8943603783845901 | Validation Accurancy:  0.8510915189981461\n",
      "Epoch:  1849 | Train Accurancy:  0.8943903297185898 | Validation Accurancy:  0.851139172911644\n",
      "Epoch:  1850 | Train Accurancy:  0.8944202959537506 | Validation Accurancy:  0.8511869162321091\n",
      "Epoch:  1851 | Train Accurancy:  0.8944501653313637 | Validation Accurancy:  0.8512344658374786\n",
      "Epoch:  1852 | Train Accurancy:  0.8944800421595573 | Validation Accurancy:  0.8512823283672333\n",
      "Epoch:  1853 | Train Accurancy:  0.8945098370313644 | Validation Accurancy:  0.8513297289609909\n",
      "Epoch:  1854 | Train Accurancy:  0.8945396468043327 | Validation Accurancy:  0.8513770699501038\n",
      "Epoch:  1855 | Train Accurancy:  0.8945693299174309 | Validation Accurancy:  0.8514245450496674\n",
      "Epoch:  1856 | Train Accurancy:  0.8945990949869156 | Validation Accurancy:  0.8514719009399414\n",
      "Epoch:  1857 | Train Accurancy:  0.8946287482976913 | Validation Accurancy:  0.8515191525220871\n",
      "Epoch:  1858 | Train Accurancy:  0.8946583420038223 | Validation Accurancy:  0.8515664041042328\n",
      "Epoch:  1859 | Train Accurancy:  0.8946879431605339 | Validation Accurancy:  0.8516136258840561\n",
      "Epoch:  1860 | Train Accurancy:  0.8947174698114395 | Validation Accurancy:  0.8516607582569122\n",
      "Epoch:  1861 | Train Accurancy:  0.8947469666600227 | Validation Accurancy:  0.8517079651355743\n",
      "Epoch:  1862 | Train Accurancy:  0.894776426255703 | Validation Accurancy:  0.8517550826072693\n",
      "Epoch:  1863 | Train Accurancy:  0.8948059007525444 | Validation Accurancy:  0.8518021553754807\n",
      "Epoch:  1864 | Train Accurancy:  0.8948352709412575 | Validation Accurancy:  0.8518491685390472\n",
      "Epoch:  1865 | Train Accurancy:  0.8948646485805511 | Validation Accurancy:  0.8518960922956467\n",
      "Epoch:  1866 | Train Accurancy:  0.8948939666152 | Validation Accurancy:  0.8519429862499237\n",
      "Epoch:  1867 | Train Accurancy:  0.8949232846498489 | Validation Accurancy:  0.8519899100065231\n",
      "Epoch:  1868 | Train Accurancy:  0.8949524462223053 | Validation Accurancy:  0.8520368039608002\n",
      "Epoch:  1869 | Train Accurancy:  0.8949816599488258 | Validation Accurancy:  0.8520836383104324\n",
      "Epoch:  1870 | Train Accurancy:  0.8950108513236046 | Validation Accurancy:  0.8521303236484528\n",
      "Epoch:  1871 | Train Accurancy:  0.8950400203466415 | Validation Accurancy:  0.8521768599748611\n",
      "Epoch:  1872 | Train Accurancy:  0.8950690850615501 | Validation Accurancy:  0.852223590016365\n",
      "Epoch:  1873 | Train Accurancy:  0.8950981646776199 | Validation Accurancy:  0.8522701263427734\n",
      "Epoch:  1874 | Train Accurancy:  0.895127110183239 | Validation Accurancy:  0.8523166626691818\n",
      "Epoch:  1875 | Train Accurancy:  0.895156130194664 | Validation Accurancy:  0.8523631393909454\n",
      "Epoch:  1876 | Train Accurancy:  0.8951850682497025 | Validation Accurancy:  0.8524095714092255\n",
      "Epoch:  1877 | Train Accurancy:  0.8952139914035797 | Validation Accurancy:  0.8524560481309891\n",
      "Epoch:  1878 | Train Accurancy:  0.895242840051651 | Validation Accurancy:  0.8524872213602066\n",
      "Epoch:  1879 | Train Accurancy:  0.8952716365456581 | Validation Accurancy:  0.8525383323431015\n",
      "Epoch:  1880 | Train Accurancy:  0.895300418138504 | Validation Accurancy:  0.8525726646184921\n",
      "Epoch:  1881 | Train Accurancy:  0.8953291401267052 | Validation Accurancy:  0.8526258170604706\n",
      "Epoch:  1882 | Train Accurancy:  0.8953578621149063 | Validation Accurancy:  0.852676659822464\n",
      "Epoch:  1883 | Train Accurancy:  0.8953864648938179 | Validation Accurancy:  0.8527107834815979\n",
      "Epoch:  1884 | Train Accurancy:  0.8954151794314384 | Validation Accurancy:  0.8527638167142868\n",
      "Epoch:  1885 | Train Accurancy:  0.8954437077045441 | Validation Accurancy:  0.8527994155883789\n",
      "Epoch:  1886 | Train Accurancy:  0.8954722881317139 | Validation Accurancy:  0.8528533279895782\n",
      "Epoch:  1887 | Train Accurancy:  0.8955008015036583 | Validation Accurancy:  0.8528894931077957\n",
      "Epoch:  1888 | Train Accurancy:  0.8955292627215385 | Validation Accurancy:  0.8529438376426697\n",
      "Epoch:  1889 | Train Accurancy:  0.8955577090382576 | Validation Accurancy:  0.852980226278305\n",
      "Epoch:  1890 | Train Accurancy:  0.8955861032009125 | Validation Accurancy:  0.853034570813179\n",
      "Epoch:  1891 | Train Accurancy:  0.8956144750118256 | Validation Accurancy:  0.8530710339546204\n",
      "Epoch:  1892 | Train Accurancy:  0.8956428319215775 | Validation Accurancy:  0.8531253933906555\n",
      "Epoch:  1893 | Train Accurancy:  0.8956711515784264 | Validation Accurancy:  0.8531619757413864\n",
      "Epoch:  1894 | Train Accurancy:  0.8956993967294693 | Validation Accurancy:  0.8532161861658096\n",
      "Epoch:  1895 | Train Accurancy:  0.8957276195287704 | Validation Accurancy:  0.8532526791095734\n",
      "Epoch:  1896 | Train Accurancy:  0.8957557678222656 | Validation Accurancy:  0.8532919585704803\n",
      "Epoch:  1897 | Train Accurancy:  0.8957839161157608 | Validation Accurancy:  0.8533479422330856\n",
      "Epoch:  1898 | Train Accurancy:  0.8958120718598366 | Validation Accurancy:  0.8533856421709061\n",
      "Epoch:  1899 | Train Accurancy:  0.8958401381969452 | Validation Accurancy:  0.8534405678510666\n",
      "Epoch:  1900 | Train Accurancy:  0.895868182182312 | Validation Accurancy:  0.8534774482250214\n",
      "Epoch:  1901 | Train Accurancy:  0.89589624106884 | Validation Accurancy:  0.8535284996032715\n",
      "Epoch:  1902 | Train Accurancy:  0.8959241658449173 | Validation Accurancy:  0.8535662144422531\n",
      "Epoch:  1903 | Train Accurancy:  0.8959520682692528 | Validation Accurancy:  0.8536061197519302\n",
      "Epoch:  1904 | Train Accurancy:  0.8959800004959106 | Validation Accurancy:  0.853659138083458\n",
      "Epoch:  1905 | Train Accurancy:  0.8960078433156013 | Validation Accurancy:  0.853698119521141\n",
      "Epoch:  1906 | Train Accurancy:  0.8960356488823891 | Validation Accurancy:  0.8537537306547165\n",
      "Epoch:  1907 | Train Accurancy:  0.8960634917020798 | Validation Accurancy:  0.8537878096103668\n",
      "Epoch:  1908 | Train Accurancy:  0.8960912600159645 | Validation Accurancy:  0.8538286983966827\n",
      "Epoch:  1909 | Train Accurancy:  0.8961189165711403 | Validation Accurancy:  0.8538854271173477\n",
      "Epoch:  1910 | Train Accurancy:  0.8961466774344444 | Validation Accurancy:  0.8539204448461533\n",
      "Epoch:  1911 | Train Accurancy:  0.8961743116378784 | Validation Accurancy:  0.8539763391017914\n",
      "Epoch:  1912 | Train Accurancy:  0.8962019234895706 | Validation Accurancy:  0.8540140986442566\n",
      "Epoch:  1913 | Train Accurancy:  0.8962295278906822 | Validation Accurancy:  0.8540506064891815\n",
      "Epoch:  1914 | Train Accurancy:  0.8962570354342461 | Validation Accurancy:  0.8541076630353928\n",
      "Epoch:  1915 | Train Accurancy:  0.8962845355272293 | Validation Accurancy:  0.8541427999734879\n",
      "Epoch:  1916 | Train Accurancy:  0.8963120132684708 | Validation Accurancy:  0.8541842103004456\n",
      "Epoch:  1917 | Train Accurancy:  0.8963394537568092 | Validation Accurancy:  0.8542411625385284\n",
      "Epoch:  1918 | Train Accurancy:  0.8963668867945671 | Validation Accurancy:  0.854276180267334\n",
      "Epoch:  1919 | Train Accurancy:  0.8963942527770996 | Validation Accurancy:  0.854331910610199\n",
      "Epoch:  1920 | Train Accurancy:  0.8964215666055679 | Validation Accurancy:  0.8543695956468582\n",
      "Epoch:  1921 | Train Accurancy:  0.8964488729834557 | Validation Accurancy:  0.8544059246778488\n",
      "Epoch:  1922 | Train Accurancy:  0.8964761346578598 | Validation Accurancy:  0.8544626235961914\n",
      "Epoch:  1923 | Train Accurancy:  0.8965033665299416 | Validation Accurancy:  0.8545008599758148\n",
      "Epoch:  1924 | Train Accurancy:  0.8965306058526039 | Validation Accurancy:  0.8545376509428024\n",
      "Epoch:  1925 | Train Accurancy:  0.8965577632188797 | Validation Accurancy:  0.8545944094657898\n",
      "Epoch:  1926 | Train Accurancy:  0.8965848609805107 | Validation Accurancy:  0.8546326607465744\n",
      "Epoch:  1927 | Train Accurancy:  0.8966119512915611 | Validation Accurancy:  0.8546695709228516\n",
      "Epoch:  1928 | Train Accurancy:  0.8966390267014503 | Validation Accurancy:  0.8547263890504837\n",
      "Epoch:  1929 | Train Accurancy:  0.8966660499572754 | Validation Accurancy:  0.8547614365816116\n",
      "Epoch:  1930 | Train Accurancy:  0.8966930210590363 | Validation Accurancy:  0.8548024296760559\n",
      "Epoch:  1931 | Train Accurancy:  0.8967199996113777 | Validation Accurancy:  0.8548586666584015\n",
      "Epoch:  1932 | Train Accurancy:  0.8967469185590744 | Validation Accurancy:  0.8548934757709503\n",
      "Epoch:  1933 | Train Accurancy:  0.8967738151550293 | Validation Accurancy:  0.8549342155456543\n",
      "Epoch:  1934 | Train Accurancy:  0.8968007117509842 | Validation Accurancy:  0.8549902886152267\n",
      "Epoch:  1935 | Train Accurancy:  0.8968274742364883 | Validation Accurancy:  0.8550248295068741\n",
      "Epoch:  1936 | Train Accurancy:  0.8968543037772179 | Validation Accurancy:  0.8550654798746109\n",
      "Epoch:  1937 | Train Accurancy:  0.896881103515625 | Validation Accurancy:  0.8551213592290878\n",
      "Epoch:  1938 | Train Accurancy:  0.8969077914953232 | Validation Accurancy:  0.855155810713768\n",
      "Epoch:  1939 | Train Accurancy:  0.8969344794750214 | Validation Accurancy:  0.8551962375640869\n",
      "Epoch:  1940 | Train Accurancy:  0.8969611302018166 | Validation Accurancy:  0.8552518934011459\n",
      "Epoch:  1941 | Train Accurancy:  0.8969877734780312 | Validation Accurancy:  0.8552863299846649\n",
      "Epoch:  1942 | Train Accurancy:  0.8970143422484398 | Validation Accurancy:  0.8553266525268555\n",
      "Epoch:  1943 | Train Accurancy:  0.897040918469429 | Validation Accurancy:  0.8553822040557861\n",
      "Epoch:  1944 | Train Accurancy:  0.8970674276351929 | Validation Accurancy:  0.8554165363311768\n",
      "Epoch:  1945 | Train Accurancy:  0.8970939144492149 | Validation Accurancy:  0.8554568439722061\n",
      "Epoch:  1946 | Train Accurancy:  0.8971203416585922 | Validation Accurancy:  0.8554979264736176\n",
      "Epoch:  1947 | Train Accurancy:  0.8971467763185501 | Validation Accurancy:  0.8555507659912109\n",
      "Epoch:  1948 | Train Accurancy:  0.8971731662750244 | Validation Accurancy:  0.8555894494056702\n",
      "Epoch:  1949 | Train Accurancy:  0.8971994891762733 | Validation Accurancy:  0.8556295186281204\n",
      "Epoch:  1950 | Train Accurancy:  0.897225871682167 | Validation Accurancy:  0.855681523680687\n",
      "Epoch:  1951 | Train Accurancy:  0.8972521647810936 | Validation Accurancy:  0.8557198196649551\n",
      "Epoch:  1952 | Train Accurancy:  0.8972784131765366 | Validation Accurancy:  0.8557594269514084\n",
      "Epoch:  1953 | Train Accurancy:  0.8973046615719795 | Validation Accurancy:  0.8558110594749451\n",
      "Epoch:  1954 | Train Accurancy:  0.8973308131098747 | Validation Accurancy:  0.8558490425348282\n",
      "Epoch:  1955 | Train Accurancy:  0.8973569571971893 | Validation Accurancy:  0.8558885306119919\n",
      "Epoch:  1956 | Train Accurancy:  0.8973831832408905 | Validation Accurancy:  0.8559289425611496\n",
      "Epoch:  1957 | Train Accurancy:  0.8974092155694962 | Validation Accurancy:  0.8559810817241669\n",
      "Epoch:  1958 | Train Accurancy:  0.8974352553486824 | Validation Accurancy:  0.8560192883014679\n",
      "Epoch:  1959 | Train Accurancy:  0.8974612802267075 | Validation Accurancy:  0.8560589104890823\n",
      "Epoch:  1960 | Train Accurancy:  0.8974873274564743 | Validation Accurancy:  0.8560964167118073\n",
      "Epoch:  1961 | Train Accurancy:  0.8975132405757904 | Validation Accurancy:  0.8561525344848633\n",
      "Epoch:  1962 | Train Accurancy:  0.8975392356514931 | Validation Accurancy:  0.8561873883008957\n",
      "Epoch:  1963 | Train Accurancy:  0.897565133869648 | Validation Accurancy:  0.856227770447731\n",
      "Epoch:  1964 | Train Accurancy:  0.8975909799337387 | Validation Accurancy:  0.8562826067209244\n",
      "Epoch:  1965 | Train Accurancy:  0.8976168110966682 | Validation Accurancy:  0.8563166260719299\n",
      "Epoch:  1966 | Train Accurancy:  0.897642582654953 | Validation Accurancy:  0.8563563227653503\n",
      "Epoch:  1967 | Train Accurancy:  0.8976683914661407 | Validation Accurancy:  0.8563968986272812\n",
      "Epoch:  1968 | Train Accurancy:  0.8976941406726837 | Validation Accurancy:  0.8564517796039581\n",
      "Epoch:  1969 | Train Accurancy:  0.8977198526263237 | Validation Accurancy:  0.8564858883619308\n",
      "Epoch:  1970 | Train Accurancy:  0.8977455273270607 | Validation Accurancy:  0.8565256297588348\n",
      "Epoch:  1971 | Train Accurancy:  0.8977711573243141 | Validation Accurancy:  0.856565922498703\n",
      "Epoch:  1972 | Train Accurancy:  0.8977967649698257 | Validation Accurancy:  0.8566176742315292\n",
      "Epoch:  1973 | Train Accurancy:  0.897822342813015 | Validation Accurancy:  0.8566557019948959\n",
      "Epoch:  1974 | Train Accurancy:  0.8978478834033012 | Validation Accurancy:  0.8566949218511581\n",
      "Epoch:  1975 | Train Accurancy:  0.8978734537959099 | Validation Accurancy:  0.8567350804805756\n",
      "Epoch:  1976 | Train Accurancy:  0.8978989198803902 | Validation Accurancy:  0.8567865192890167\n",
      "Epoch:  1977 | Train Accurancy:  0.8979243487119675 | Validation Accurancy:  0.8568241894245148\n",
      "Epoch:  1978 | Train Accurancy:  0.8979498073458672 | Validation Accurancy:  0.8568633198738098\n",
      "Epoch:  1979 | Train Accurancy:  0.8979751542210579 | Validation Accurancy:  0.8569002151489258\n",
      "Epoch:  1980 | Train Accurancy:  0.8980005607008934 | Validation Accurancy:  0.8569553643465042\n",
      "Epoch:  1981 | Train Accurancy:  0.8980258703231812 | Validation Accurancy:  0.8569926470518112\n",
      "Epoch:  1982 | Train Accurancy:  0.8980511277914047 | Validation Accurancy:  0.8570313155651093\n",
      "Epoch:  1983 | Train Accurancy:  0.8980765119194984 | Validation Accurancy:  0.857067883014679\n",
      "Epoch:  1984 | Train Accurancy:  0.8981016725301743 | Validation Accurancy:  0.8571091592311859\n",
      "Epoch:  1985 | Train Accurancy:  0.8981268927454948 | Validation Accurancy:  0.85716412961483\n",
      "Epoch:  1986 | Train Accurancy:  0.8981520682573318 | Validation Accurancy:  0.8571982085704803\n",
      "Epoch:  1987 | Train Accurancy:  0.8981772288680077 | Validation Accurancy:  0.8572378009557724\n",
      "Epoch:  1988 | Train Accurancy:  0.8982023224234581 | Validation Accurancy:  0.8572778403759003\n",
      "Epoch:  1989 | Train Accurancy:  0.8982274159789085 | Validation Accurancy:  0.8573289662599564\n",
      "Epoch:  1990 | Train Accurancy:  0.8982524424791336 | Validation Accurancy:  0.8573665171861649\n",
      "Epoch:  1991 | Train Accurancy:  0.8982774764299393 | Validation Accurancy:  0.8574052900075912\n",
      "Epoch:  1992 | Train Accurancy:  0.8983024880290031 | Validation Accurancy:  0.8574448376893997\n",
      "Epoch:  1993 | Train Accurancy:  0.8983274772763252 | Validation Accurancy:  0.857481986284256\n",
      "Epoch:  1994 | Train Accurancy:  0.8983523398637772 | Validation Accurancy:  0.8575369417667389\n",
      "Epoch:  1995 | Train Accurancy:  0.8983772248029709 | Validation Accurancy:  0.8575740307569504\n",
      "Epoch:  1996 | Train Accurancy:  0.8984021246433258 | Validation Accurancy:  0.8576125204563141\n",
      "Epoch:  1997 | Train Accurancy:  0.8984269201755524 | Validation Accurancy:  0.8576488196849823\n",
      "Epoch:  1998 | Train Accurancy:  0.8984517306089401 | Validation Accurancy:  0.8576895147562027\n",
      "Epoch:  1999 | Train Accurancy:  0.8984765559434891 | Validation Accurancy:  0.8577438741922379\n",
      "Epoch:  2000 | Train Accurancy:  0.8985012546181679 | Validation Accurancy:  0.8577777594327927\n",
      "Epoch:  2001 | Train Accurancy:  0.8985260277986526 | Validation Accurancy:  0.8578167706727982\n",
      "Epoch:  2002 | Train Accurancy:  0.8985507041215897 | Validation Accurancy:  0.8578564673662186\n",
      "Epoch:  2003 | Train Accurancy:  0.8985753431916237 | Validation Accurancy:  0.8578963875770569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2004 | Train Accurancy:  0.8986000120639801 | Validation Accurancy:  0.8579338043928146\n",
      "Epoch:  2005 | Train Accurancy:  0.8986245766282082 | Validation Accurancy:  0.8579885214567184\n",
      "Epoch:  2006 | Train Accurancy:  0.898649163544178 | Validation Accurancy:  0.858025535941124\n",
      "Epoch:  2007 | Train Accurancy:  0.8986736759543419 | Validation Accurancy:  0.8580608814954758\n",
      "Epoch:  2008 | Train Accurancy:  0.8986982330679893 | Validation Accurancy:  0.8581008911132812\n",
      "Epoch:  2009 | Train Accurancy:  0.8987226858735085 | Validation Accurancy:  0.8581411242485046\n",
      "Epoch:  2010 | Train Accurancy:  0.8987471237778664 | Validation Accurancy:  0.8581946194171906\n",
      "Epoch:  2011 | Train Accurancy:  0.8987715542316437 | Validation Accurancy:  0.8582280576229095\n",
      "Epoch:  2012 | Train Accurancy:  0.898795947432518 | Validation Accurancy:  0.8582666218280792\n",
      "Epoch:  2013 | Train Accurancy:  0.89882031083107 | Validation Accurancy:  0.8583058267831802\n",
      "Epoch:  2014 | Train Accurancy:  0.8988446667790413 | Validation Accurancy:  0.8583454191684723\n",
      "Epoch:  2015 | Train Accurancy:  0.8988689556717873 | Validation Accurancy:  0.8583824336528778\n",
      "Epoch:  2016 | Train Accurancy:  0.8988931849598885 | Validation Accurancy:  0.8584366887807846\n",
      "Epoch:  2017 | Train Accurancy:  0.8989174291491508 | Validation Accurancy:  0.8584733009338379\n",
      "Epoch:  2018 | Train Accurancy:  0.8989416360855103 | Validation Accurancy:  0.8585111647844315\n",
      "Epoch:  2019 | Train Accurancy:  0.8989658281207085 | Validation Accurancy:  0.8585470020771027\n",
      "Epoch:  2020 | Train Accurancy:  0.8989900201559067 | Validation Accurancy:  0.8585871011018753\n",
      "Epoch:  2021 | Train Accurancy:  0.8990141078829765 | Validation Accurancy:  0.8586272299289703\n",
      "Epoch:  2022 | Train Accurancy:  0.89903824031353 | Validation Accurancy:  0.8586673140525818\n",
      "Epoch:  2023 | Train Accurancy:  0.8990622833371162 | Validation Accurancy:  0.858717754483223\n",
      "Epoch:  2024 | Train Accurancy:  0.8990863412618637 | Validation Accurancy:  0.8587548285722733\n",
      "Epoch:  2025 | Train Accurancy:  0.899110347032547 | Validation Accurancy:  0.8587927967309952\n",
      "Epoch:  2026 | Train Accurancy:  0.8991343304514885 | Validation Accurancy:  0.8588313013315201\n",
      "Epoch:  2027 | Train Accurancy:  0.8991582691669464 | Validation Accurancy:  0.8588676303625107\n",
      "Epoch:  2028 | Train Accurancy:  0.8991821855306625 | Validation Accurancy:  0.8589079529047012\n",
      "Epoch:  2029 | Train Accurancy:  0.899206131696701 | Validation Accurancy:  0.8589481562376022\n",
      "Epoch:  2030 | Train Accurancy:  0.899229921400547 | Validation Accurancy:  0.8589985072612762\n",
      "Epoch:  2031 | Train Accurancy:  0.8992537781596184 | Validation Accurancy:  0.8590354025363922\n",
      "Epoch:  2032 | Train Accurancy:  0.8992776051163673 | Validation Accurancy:  0.8590731918811798\n",
      "Epoch:  2033 | Train Accurancy:  0.8993014022707939 | Validation Accurancy:  0.8591117411851883\n",
      "Epoch:  2034 | Train Accurancy:  0.8993251621723175 | Validation Accurancy:  0.8591506034135818\n",
      "Epoch:  2035 | Train Accurancy:  0.8993489220738411 | Validation Accurancy:  0.8591869175434113\n",
      "Epoch:  2036 | Train Accurancy:  0.8993725553154945 | Validation Accurancy:  0.8592271953821182\n",
      "Epoch:  2037 | Train Accurancy:  0.899396263062954 | Validation Accurancy:  0.8592671751976013\n",
      "Epoch:  2038 | Train Accurancy:  0.8994198590517044 | Validation Accurancy:  0.8593199551105499\n",
      "Epoch:  2039 | Train Accurancy:  0.8994434624910355 | Validation Accurancy:  0.8593530803918839\n",
      "Epoch:  2040 | Train Accurancy:  0.8994670882821083 | Validation Accurancy:  0.8593910336494446\n",
      "Epoch:  2041 | Train Accurancy:  0.8994905799627304 | Validation Accurancy:  0.8594294190406799\n",
      "Epoch:  2042 | Train Accurancy:  0.8995141685009003 | Validation Accurancy:  0.8594682514667511\n",
      "Epoch:  2043 | Train Accurancy:  0.8995376303792 | Validation Accurancy:  0.8595070689916611\n",
      "Epoch:  2044 | Train Accurancy:  0.8995611146092415 | Validation Accurancy:  0.8595435917377472\n",
      "Epoch:  2045 | Train Accurancy:  0.8995845541357994 | Validation Accurancy:  0.8595836907625198\n",
      "Epoch:  2046 | Train Accurancy:  0.8996079713106155 | Validation Accurancy:  0.8596235662698746\n",
      "Epoch:  2047 | Train Accurancy:  0.8996313288807869 | Validation Accurancy:  0.859673261642456\n",
      "Epoch:  2048 | Train Accurancy:  0.8996547237038612 | Validation Accurancy:  0.8597097396850586\n",
      "Epoch:  2049 | Train Accurancy:  0.899677999317646 | Validation Accurancy:  0.8597471415996552\n",
      "Epoch:  2050 | Train Accurancy:  0.8997013345360756 | Validation Accurancy:  0.8597852289676666\n",
      "Epoch:  2051 | Train Accurancy:  0.8997246026992798 | Validation Accurancy:  0.8598234802484512\n",
      "Epoch:  2052 | Train Accurancy:  0.8997478187084198 | Validation Accurancy:  0.8598620295524597\n",
      "Epoch:  2053 | Train Accurancy:  0.8997710645198822 | Validation Accurancy:  0.85989810526371\n",
      "Epoch:  2054 | Train Accurancy:  0.8997942581772804 | Validation Accurancy:  0.8599378615617752\n",
      "Epoch:  2055 | Train Accurancy:  0.8998173996806145 | Validation Accurancy:  0.8599774539470673\n",
      "Epoch:  2056 | Train Accurancy:  0.8998405858874321 | Validation Accurancy:  0.8600167483091354\n",
      "Epoch:  2057 | Train Accurancy:  0.899863712489605 | Validation Accurancy:  0.8600532859563828\n",
      "Epoch:  2058 | Train Accurancy:  0.899886779487133 | Validation Accurancy:  0.8601060658693314\n",
      "Epoch:  2059 | Train Accurancy:  0.8999098017811775 | Validation Accurancy:  0.8601417243480682\n",
      "Epoch:  2060 | Train Accurancy:  0.8999328389763832 | Validation Accurancy:  0.8601785451173782\n",
      "Epoch:  2061 | Train Accurancy:  0.8999558389186859 | Validation Accurancy:  0.8602159768342972\n",
      "Epoch:  2062 | Train Accurancy:  0.8999788388609886 | Validation Accurancy:  0.8602537661790848\n",
      "Epoch:  2063 | Train Accurancy:  0.9000017866492271 | Validation Accurancy:  0.8602892756462097\n",
      "Epoch:  2064 | Train Accurancy:  0.9000246748328209 | Validation Accurancy:  0.8603284657001495\n",
      "Epoch:  2065 | Train Accurancy:  0.900047555565834 | Validation Accurancy:  0.8603675067424774\n",
      "Epoch:  2066 | Train Accurancy:  0.9000704362988472 | Validation Accurancy:  0.8604064732789993\n",
      "Epoch:  2067 | Train Accurancy:  0.9000932723283768 | Validation Accurancy:  0.8604452759027481\n",
      "Epoch:  2068 | Train Accurancy:  0.9001160636544228 | Validation Accurancy:  0.860481470823288\n",
      "Epoch:  2069 | Train Accurancy:  0.9001388773322105 | Validation Accurancy:  0.8605208992958069\n",
      "Epoch:  2070 | Train Accurancy:  0.9001616537570953 | Validation Accurancy:  0.8605601489543915\n",
      "Epoch:  2071 | Train Accurancy:  0.9001843705773354 | Validation Accurancy:  0.8605992347002029\n",
      "Epoch:  2072 | Train Accurancy:  0.9002070799469948 | Validation Accurancy:  0.8606353551149368\n",
      "Epoch:  2073 | Train Accurancy:  0.90022973716259 | Validation Accurancy:  0.8606874644756317\n",
      "Epoch:  2074 | Train Accurancy:  0.9002524092793465 | Validation Accurancy:  0.8607228100299835\n",
      "Epoch:  2075 | Train Accurancy:  0.9002749845385551 | Validation Accurancy:  0.8607591986656189\n",
      "Epoch:  2076 | Train Accurancy:  0.9002975970506668 | Validation Accurancy:  0.8607961088418961\n",
      "Epoch:  2077 | Train Accurancy:  0.9003202170133591 | Validation Accurancy:  0.860833540558815\n",
      "Epoch:  2078 | Train Accurancy:  0.9003427252173424 | Validation Accurancy:  0.8608712255954742\n",
      "Epoch:  2079 | Train Accurancy:  0.9003652259707451 | Validation Accurancy:  0.8609064221382141\n",
      "Epoch:  2080 | Train Accurancy:  0.9003876894712448 | Validation Accurancy:  0.8609452247619629\n",
      "Epoch:  2081 | Train Accurancy:  0.9004102647304535 | Validation Accurancy:  0.8609838783740997\n",
      "Epoch:  2082 | Train Accurancy:  0.9004326313734055 | Validation Accurancy:  0.861022338271141\n",
      "Epoch:  2083 | Train Accurancy:  0.9004550725221634 | Validation Accurancy:  0.861060693860054\n",
      "Epoch:  2084 | Train Accurancy:  0.900477446615696 | Validation Accurancy:  0.8610964119434357\n",
      "Epoch:  2085 | Train Accurancy:  0.9004997834563255 | Validation Accurancy:  0.8611353933811188\n",
      "Epoch:  2086 | Train Accurancy:  0.9005221650004387 | Validation Accurancy:  0.8611741811037064\n",
      "Epoch:  2087 | Train Accurancy:  0.9005444496870041 | Validation Accurancy:  0.8612127155065536\n",
      "Epoch:  2088 | Train Accurancy:  0.9005667120218277 | Validation Accurancy:  0.8612510710954666\n",
      "Epoch:  2089 | Train Accurancy:  0.9005889818072319 | Validation Accurancy:  0.8612865805625916\n",
      "Epoch:  2090 | Train Accurancy:  0.9006111770868301 | Validation Accurancy:  0.8613255620002747\n",
      "Epoch:  2091 | Train Accurancy:  0.9006334245204926 | Validation Accurancy:  0.8613641560077667\n",
      "Epoch:  2092 | Train Accurancy:  0.9006555899977684 | Validation Accurancy:  0.8614024817943573\n",
      "Epoch:  2093 | Train Accurancy:  0.9006777703762054 | Validation Accurancy:  0.8614406734704971\n",
      "Epoch:  2094 | Train Accurancy:  0.9006999060511589 | Validation Accurancy:  0.8614760786294937\n",
      "Epoch:  2095 | Train Accurancy:  0.9007219299674034 | Validation Accurancy:  0.8615149408578873\n",
      "Epoch:  2096 | Train Accurancy:  0.9007440730929375 | Validation Accurancy:  0.8615532964468002\n",
      "Epoch:  2097 | Train Accurancy:  0.9007661193609238 | Validation Accurancy:  0.8615916520357132\n",
      "Epoch:  2098 | Train Accurancy:  0.9007881358265877 | Validation Accurancy:  0.861629530787468\n",
      "Epoch:  2099 | Train Accurancy:  0.9008101224899292 | Validation Accurancy:  0.8616674691438675\n",
      "Epoch:  2100 | Train Accurancy:  0.9008321017026901 | Validation Accurancy:  0.8617026954889297\n",
      "Epoch:  2101 | Train Accurancy:  0.9008540138602257 | Validation Accurancy:  0.8617413192987442\n",
      "Epoch:  2102 | Train Accurancy:  0.9008759334683418 | Validation Accurancy:  0.8617794364690781\n",
      "Epoch:  2103 | Train Accurancy:  0.9008978605270386 | Validation Accurancy:  0.8618174344301224\n",
      "Epoch:  2104 | Train Accurancy:  0.900919683277607 | Validation Accurancy:  0.8618552088737488\n",
      "Epoch:  2105 | Train Accurancy:  0.9009415656328201 | Validation Accurancy:  0.8618929386138916\n",
      "Epoch:  2106 | Train Accurancy:  0.9009633585810661 | Validation Accurancy:  0.8619279563426971\n",
      "Epoch:  2107 | Train Accurancy:  0.9009851515293121 | Validation Accurancy:  0.8619663566350937\n",
      "Epoch:  2108 | Train Accurancy:  0.9010069668292999 | Validation Accurancy:  0.8620044589042664\n",
      "Epoch:  2109 | Train Accurancy:  0.9010287001729012 | Validation Accurancy:  0.8620422035455704\n",
      "Epoch:  2110 | Train Accurancy:  0.9010504335165024 | Validation Accurancy:  0.8620796948671341\n",
      "Epoch:  2111 | Train Accurancy:  0.9010720774531364 | Validation Accurancy:  0.8621172159910202\n",
      "Epoch:  2112 | Train Accurancy:  0.9010937735438347 | Validation Accurancy:  0.8621545881032944\n",
      "Epoch:  2113 | Train Accurancy:  0.901115395128727 | Validation Accurancy:  0.8621893972158432\n",
      "Epoch:  2114 | Train Accurancy:  0.9011370465159416 | Validation Accurancy:  0.8622275441884995\n",
      "Epoch:  2115 | Train Accurancy:  0.9011586606502533 | Validation Accurancy:  0.862265333533287\n",
      "Epoch:  2116 | Train Accurancy:  0.9011801704764366 | Validation Accurancy:  0.8623028248548508\n",
      "Epoch:  2117 | Train Accurancy:  0.9012017771601677 | Validation Accurancy:  0.8623402863740921\n",
      "Epoch:  2118 | Train Accurancy:  0.9012232348322868 | Validation Accurancy:  0.8623775690793991\n",
      "Epoch:  2119 | Train Accurancy:  0.9012447893619537 | Validation Accurancy:  0.8624146729707718\n",
      "Epoch:  2120 | Train Accurancy:  0.9012662842869759 | Validation Accurancy:  0.8624517768621445\n",
      "Epoch:  2121 | Train Accurancy:  0.9012877121567726 | Validation Accurancy:  0.8624863922595978\n",
      "Epoch:  2122 | Train Accurancy:  0.9013091176748276 | Validation Accurancy:  0.862524226307869\n",
      "Epoch:  2123 | Train Accurancy:  0.9013305157423019 | Validation Accurancy:  0.8625617176294327\n",
      "Epoch:  2124 | Train Accurancy:  0.9013519063591957 | Validation Accurancy:  0.8625990599393845\n",
      "Epoch:  2125 | Train Accurancy:  0.9013732373714447 | Validation Accurancy:  0.8626361042261124\n",
      "Epoch:  2126 | Train Accurancy:  0.9013945311307907 | Validation Accurancy:  0.8626730293035507\n",
      "Epoch:  2127 | Train Accurancy:  0.9014157950878143 | Validation Accurancy:  0.8627100139856339\n",
      "Epoch:  2128 | Train Accurancy:  0.9014370813965797 | Validation Accurancy:  0.862746849656105\n",
      "Epoch:  2129 | Train Accurancy:  0.9014583677053452 | Validation Accurancy:  0.8627835214138031\n",
      "Epoch:  2130 | Train Accurancy:  0.9014796316623688 | Validation Accurancy:  0.8628203868865967\n",
      "Epoch:  2131 | Train Accurancy:  0.901500791311264 | Validation Accurancy:  0.8628571927547455\n",
      "Epoch:  2132 | Train Accurancy:  0.9015219882130623 | Validation Accurancy:  0.8628937751054764\n",
      "Epoch:  2133 | Train Accurancy:  0.9015431180596352 | Validation Accurancy:  0.8629303872585297\n",
      "Epoch:  2134 | Train Accurancy:  0.9015642330050468 | Validation Accurancy:  0.8629645258188248\n",
      "Epoch:  2135 | Train Accurancy:  0.9015853181481361 | Validation Accurancy:  0.8630019873380661\n",
      "Epoch:  2136 | Train Accurancy:  0.9016064330935478 | Validation Accurancy:  0.8630390167236328\n",
      "Epoch:  2137 | Train Accurancy:  0.9016274511814117 | Validation Accurancy:  0.8630758970975876\n",
      "Epoch:  2138 | Train Accurancy:  0.901648536324501 | Validation Accurancy:  0.8631126135587692\n",
      "Epoch:  2139 | Train Accurancy:  0.9016695395112038 | Validation Accurancy:  0.8631491810083389\n",
      "Epoch:  2140 | Train Accurancy:  0.9016905501484871 | Validation Accurancy:  0.8631857484579086\n",
      "Epoch:  2141 | Train Accurancy:  0.9017114713788033 | Validation Accurancy:  0.8632222563028336\n",
      "Epoch:  2142 | Train Accurancy:  0.9017324000597 | Validation Accurancy:  0.863258570432663\n",
      "Epoch:  2143 | Train Accurancy:  0.9017532914876938 | Validation Accurancy:  0.8632949441671371\n",
      "Epoch:  2144 | Train Accurancy:  0.901774175465107 | Validation Accurancy:  0.8633311837911606\n",
      "Epoch:  2145 | Train Accurancy:  0.9017950743436813 | Validation Accurancy:  0.86336749792099\n",
      "Epoch:  2146 | Train Accurancy:  0.9018159210681915 | Validation Accurancy:  0.8634037375450134\n",
      "Epoch:  2147 | Train Accurancy:  0.9018367230892181 | Validation Accurancy:  0.8634398728609085\n",
      "Epoch:  2148 | Train Accurancy:  0.901857540011406 | Validation Accurancy:  0.8634761422872543\n",
      "Epoch:  2149 | Train Accurancy:  0.9018783196806908 | Validation Accurancy:  0.863512322306633\n",
      "Epoch:  2150 | Train Accurancy:  0.9018990695476532 | Validation Accurancy:  0.8635483831167221\n",
      "Epoch:  2151 | Train Accurancy:  0.9019197523593903 | Validation Accurancy:  0.8635843843221664\n",
      "Epoch:  2152 | Train Accurancy:  0.9019404798746109 | Validation Accurancy:  0.8636204451322556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2153 | Train Accurancy:  0.9019611924886703 | Validation Accurancy:  0.863656535744667\n",
      "Epoch:  2154 | Train Accurancy:  0.9019817635416985 | Validation Accurancy:  0.863692507147789\n",
      "Epoch:  2155 | Train Accurancy:  0.9020024538040161 | Validation Accurancy:  0.8637284189462662\n",
      "Epoch:  2156 | Train Accurancy:  0.9020230323076248 | Validation Accurancy:  0.8637642860412598\n",
      "Epoch:  2157 | Train Accurancy:  0.9020435884594917 | Validation Accurancy:  0.8638001829385757\n",
      "Epoch:  2158 | Train Accurancy:  0.9020641818642616 | Validation Accurancy:  0.8638359010219574\n",
      "Epoch:  2159 | Train Accurancy:  0.9020847007632256 | Validation Accurancy:  0.8638718575239182\n",
      "Epoch:  2160 | Train Accurancy:  0.9021052345633507 | Validation Accurancy:  0.863907590508461\n",
      "Epoch:  2161 | Train Accurancy:  0.9021257013082504 | Validation Accurancy:  0.8639433532953262\n",
      "Epoch:  2162 | Train Accurancy:  0.9021461829543114 | Validation Accurancy:  0.8639790564775467\n",
      "Epoch:  2163 | Train Accurancy:  0.9021666496992111 | Validation Accurancy:  0.8640148043632507\n",
      "Epoch:  2164 | Train Accurancy:  0.9021869897842407 | Validation Accurancy:  0.8640504479408264\n",
      "Epoch:  2165 | Train Accurancy:  0.9022074043750763 | Validation Accurancy:  0.8640862107276917\n",
      "Epoch:  2166 | Train Accurancy:  0.9022278338670731 | Validation Accurancy:  0.864121824502945\n",
      "Epoch:  2167 | Train Accurancy:  0.9022481292486191 | Validation Accurancy:  0.8641573488712311\n",
      "Epoch:  2168 | Train Accurancy:  0.9022684842348099 | Validation Accurancy:  0.864193007349968\n",
      "Epoch:  2169 | Train Accurancy:  0.9022887498140335 | Validation Accurancy:  0.8642285615205765\n",
      "Epoch:  2170 | Train Accurancy:  0.9023090302944183 | Validation Accurancy:  0.8642641007900238\n",
      "Epoch:  2171 | Train Accurancy:  0.9023293033242226 | Validation Accurancy:  0.864299550652504\n",
      "Epoch:  2172 | Train Accurancy:  0.9023495018482208 | Validation Accurancy:  0.8643350452184677\n",
      "Epoch:  2173 | Train Accurancy:  0.9023697823286057 | Validation Accurancy:  0.8643704354763031\n",
      "Epoch:  2174 | Train Accurancy:  0.9023899585008621 | Validation Accurancy:  0.8644058257341385\n",
      "Epoch:  2175 | Train Accurancy:  0.9024101346731186 | Validation Accurancy:  0.8644411861896515\n",
      "Epoch:  2176 | Train Accurancy:  0.9024302586913109 | Validation Accurancy:  0.8644766211509705\n",
      "Epoch:  2177 | Train Accurancy:  0.902450367808342 | Validation Accurancy:  0.8645119816064835\n",
      "Epoch:  2178 | Train Accurancy:  0.9024704396724701 | Validation Accurancy:  0.8645472079515457\n",
      "Epoch:  2179 | Train Accurancy:  0.9024905115365982 | Validation Accurancy:  0.8645825088024139\n",
      "Epoch:  2180 | Train Accurancy:  0.9025105983018875 | Validation Accurancy:  0.8646177351474762\n",
      "Epoch:  2181 | Train Accurancy:  0.9025306552648544 | Validation Accurancy:  0.8646528720855713\n",
      "Epoch:  2182 | Train Accurancy:  0.9025506600737572 | Validation Accurancy:  0.8646880835294724\n",
      "Epoch:  2183 | Train Accurancy:  0.9025706127285957 | Validation Accurancy:  0.8647231757640839\n",
      "Epoch:  2184 | Train Accurancy:  0.9025905653834343 | Validation Accurancy:  0.8647583574056625\n",
      "Epoch:  2185 | Train Accurancy:  0.9026105403900146 | Validation Accurancy:  0.8647934645414352\n",
      "Epoch:  2186 | Train Accurancy:  0.9026304632425308 | Validation Accurancy:  0.8648284524679184\n",
      "Epoch:  2187 | Train Accurancy:  0.9026503637433052 | Validation Accurancy:  0.8648635596036911\n",
      "Epoch:  2188 | Train Accurancy:  0.902670219540596 | Validation Accurancy:  0.8648985177278519\n",
      "Epoch:  2189 | Train Accurancy:  0.902690090239048 | Validation Accurancy:  0.864933580160141\n",
      "Epoch:  2190 | Train Accurancy:  0.9027099311351776 | Validation Accurancy:  0.8649685233831406\n",
      "Epoch:  2191 | Train Accurancy:  0.9027296975255013 | Validation Accurancy:  0.8650033921003342\n",
      "Epoch:  2192 | Train Accurancy:  0.9027495086193085 | Validation Accurancy:  0.8650383353233337\n",
      "Epoch:  2193 | Train Accurancy:  0.9027692601084709 | Validation Accurancy:  0.8650732189416885\n",
      "Epoch:  2194 | Train Accurancy:  0.9027890115976334 | Validation Accurancy:  0.8651080131530762\n",
      "Epoch:  2195 | Train Accurancy:  0.9028086885809898 | Validation Accurancy:  0.8651428520679474\n",
      "Epoch:  2196 | Train Accurancy:  0.9028284177184105 | Validation Accurancy:  0.865177571773529\n",
      "Epoch:  2197 | Train Accurancy:  0.9028481170535088 | Validation Accurancy:  0.8652124404907227\n",
      "Epoch:  2198 | Train Accurancy:  0.902867779135704 | Validation Accurancy:  0.865247055888176\n",
      "Epoch:  2199 | Train Accurancy:  0.9028874188661575 | Validation Accurancy:  0.8652817755937576\n",
      "Epoch:  2200 | Train Accurancy:  0.9029070362448692 | Validation Accurancy:  0.8653164505958557\n",
      "Epoch:  2201 | Train Accurancy:  0.9029265865683556 | Validation Accurancy:  0.8653511703014374\n",
      "Epoch:  2202 | Train Accurancy:  0.9029462039470673 | Validation Accurancy:  0.8653856664896011\n",
      "Epoch:  2203 | Train Accurancy:  0.9029656946659088 | Validation Accurancy:  0.865420326590538\n",
      "Epoch:  2204 | Train Accurancy:  0.9029852598905563 | Validation Accurancy:  0.8654549419879913\n",
      "Epoch:  2205 | Train Accurancy:  0.9030046910047531 | Validation Accurancy:  0.8654894530773163\n",
      "Epoch:  2206 | Train Accurancy:  0.9030242413282394 | Validation Accurancy:  0.8655238747596741\n",
      "Epoch:  2207 | Train Accurancy:  0.9030437022447586 | Validation Accurancy:  0.8655584305524826\n",
      "Epoch:  2208 | Train Accurancy:  0.9030631706118584 | Validation Accurancy:  0.865592822432518\n",
      "Epoch:  2209 | Train Accurancy:  0.9030825197696686 | Validation Accurancy:  0.8656272143125534\n",
      "Epoch:  2210 | Train Accurancy:  0.9031019508838654 | Validation Accurancy:  0.86566162109375\n",
      "Epoch:  2211 | Train Accurancy:  0.9031213149428368 | Validation Accurancy:  0.8656959533691406\n",
      "Epoch:  2212 | Train Accurancy:  0.9031406790018082 | Validation Accurancy:  0.865730345249176\n",
      "Epoch:  2213 | Train Accurancy:  0.9031600281596184 | Validation Accurancy:  0.8657646030187607\n",
      "Epoch:  2214 | Train Accurancy:  0.9031793177127838 | Validation Accurancy:  0.8657989650964737\n",
      "Epoch:  2215 | Train Accurancy:  0.9031986445188522 | Validation Accurancy:  0.8658330589532852\n",
      "Epoch:  2216 | Train Accurancy:  0.9032178893685341 | Validation Accurancy:  0.865867406129837\n",
      "Epoch:  2217 | Train Accurancy:  0.9032371416687965 | Validation Accurancy:  0.8659016489982605\n",
      "Epoch:  2218 | Train Accurancy:  0.9032563790678978 | Validation Accurancy:  0.8659357875585556\n",
      "Epoch:  2219 | Train Accurancy:  0.9032756015658379 | Validation Accurancy:  0.8659699857234955\n",
      "Epoch:  2220 | Train Accurancy:  0.9032947793602943 | Validation Accurancy:  0.8660040497779846\n",
      "Epoch:  2221 | Train Accurancy:  0.9033139422535896 | Validation Accurancy:  0.8660380989313126\n",
      "Epoch:  2222 | Train Accurancy:  0.9033330529928207 | Validation Accurancy:  0.8660722076892853\n",
      "Epoch:  2223 | Train Accurancy:  0.9033522233366966 | Validation Accurancy:  0.8661062866449356\n",
      "Epoch:  2224 | Train Accurancy:  0.9033713340759277 | Validation Accurancy:  0.8661402612924576\n",
      "Epoch:  2225 | Train Accurancy:  0.9033903405070305 | Validation Accurancy:  0.8661742657423019\n",
      "Epoch:  2226 | Train Accurancy:  0.903409443795681 | Validation Accurancy:  0.8662082105875015\n",
      "Epoch:  2227 | Train Accurancy:  0.9034284576773643 | Validation Accurancy:  0.8662421107292175\n",
      "Epoch:  2228 | Train Accurancy:  0.9034474864602089 | Validation Accurancy:  0.8662759959697723\n",
      "Epoch:  2229 | Train Accurancy:  0.9034665077924728 | Validation Accurancy:  0.866309866309166\n",
      "Epoch:  2230 | Train Accurancy:  0.903485469520092 | Validation Accurancy:  0.866343691945076\n",
      "Epoch:  2231 | Train Accurancy:  0.9035044685006142 | Validation Accurancy:  0.866377517580986\n",
      "Epoch:  2232 | Train Accurancy:  0.9035233408212662 | Validation Accurancy:  0.8664113432168961\n",
      "Epoch:  2233 | Train Accurancy:  0.9035422876477242 | Validation Accurancy:  0.8664451986551285\n",
      "Epoch:  2234 | Train Accurancy:  0.9035611972212791 | Validation Accurancy:  0.8664788901805878\n",
      "Epoch:  2235 | Train Accurancy:  0.9035800397396088 | Validation Accurancy:  0.8665125966072083\n",
      "Epoch:  2236 | Train Accurancy:  0.9035988971590996 | Validation Accurancy:  0.8665462285280228\n",
      "Epoch:  2237 | Train Accurancy:  0.9036177322268486 | Validation Accurancy:  0.8665799498558044\n",
      "Epoch:  2238 | Train Accurancy:  0.903636559844017 | Validation Accurancy:  0.8666136413812637\n",
      "Epoch:  2239 | Train Accurancy:  0.9036553129553795 | Validation Accurancy:  0.866647258400917\n",
      "Epoch:  2240 | Train Accurancy:  0.9036741182208061 | Validation Accurancy:  0.8666807860136032\n",
      "Epoch:  2241 | Train Accurancy:  0.9036928415298462 | Validation Accurancy:  0.8667142689228058\n",
      "Epoch:  2242 | Train Accurancy:  0.9037115722894669 | Validation Accurancy:  0.8667478561401367\n",
      "Epoch:  2243 | Train Accurancy:  0.9037302955985069 | Validation Accurancy:  0.8667813688516617\n",
      "Epoch:  2244 | Train Accurancy:  0.9037489965558052 | Validation Accurancy:  0.8668148666620255\n",
      "Epoch:  2245 | Train Accurancy:  0.9037677049636841 | Validation Accurancy:  0.8668482154607773\n",
      "Epoch:  2246 | Train Accurancy:  0.903786338865757 | Validation Accurancy:  0.8668817430734634\n",
      "Epoch:  2247 | Train Accurancy:  0.9038049653172493 | Validation Accurancy:  0.8669150471687317\n",
      "Epoch:  2248 | Train Accurancy:  0.9038235023617744 | Validation Accurancy:  0.8669484108686447\n",
      "Epoch:  2249 | Train Accurancy:  0.9038421958684921 | Validation Accurancy:  0.8669818192720413\n",
      "Epoch:  2250 | Train Accurancy:  0.9038607403635979 | Validation Accurancy:  0.8670151382684708\n",
      "Epoch:  2251 | Train Accurancy:  0.9038792550563812 | Validation Accurancy:  0.867048442363739\n",
      "Epoch:  2252 | Train Accurancy:  0.9038978144526482 | Validation Accurancy:  0.8670815974473953\n",
      "Epoch:  2253 | Train Accurancy:  0.9039163142442703 | Validation Accurancy:  0.8671148866415024\n",
      "Epoch:  2254 | Train Accurancy:  0.9039348512887955 | Validation Accurancy:  0.8671480268239975\n",
      "Epoch:  2255 | Train Accurancy:  0.9039532765746117 | Validation Accurancy:  0.867181271314621\n",
      "Epoch:  2256 | Train Accurancy:  0.9039717018604279 | Validation Accurancy:  0.8672143965959549\n",
      "Epoch:  2257 | Train Accurancy:  0.9039901345968246 | Validation Accurancy:  0.867247611284256\n",
      "Epoch:  2258 | Train Accurancy:  0.904008537530899 | Validation Accurancy:  0.8672806918621063\n",
      "Epoch:  2259 | Train Accurancy:  0.9040269404649734 | Validation Accurancy:  0.867313802242279\n",
      "Epoch:  2260 | Train Accurancy:  0.9040453433990479 | Validation Accurancy:  0.867346927523613\n",
      "Epoch:  2261 | Train Accurancy:  0.9040636643767357 | Validation Accurancy:  0.8673798739910126\n",
      "Epoch:  2262 | Train Accurancy:  0.9040820151567459 | Validation Accurancy:  0.8674128949642181\n",
      "Epoch:  2263 | Train Accurancy:  0.904100276529789 | Validation Accurancy:  0.8674458712339401\n",
      "Epoch:  2264 | Train Accurancy:  0.9041185602545738 | Validation Accurancy:  0.8674787878990173\n",
      "Epoch:  2265 | Train Accurancy:  0.9041368737816811 | Validation Accurancy:  0.8675117641687393\n",
      "Epoch:  2266 | Train Accurancy:  0.9041550979018211 | Validation Accurancy:  0.8675446957349777\n",
      "Epoch:  2267 | Train Accurancy:  0.9041732922196388 | Validation Accurancy:  0.8675774931907654\n",
      "Epoch:  2268 | Train Accurancy:  0.9041915461421013 | Validation Accurancy:  0.8676103800535202\n",
      "Epoch:  2269 | Train Accurancy:  0.904209740459919 | Validation Accurancy:  0.8676431626081467\n",
      "Epoch:  2270 | Train Accurancy:  0.9042279273271561 | Validation Accurancy:  0.8676760047674179\n",
      "Epoch:  2271 | Train Accurancy:  0.904246099293232 | Validation Accurancy:  0.8677088767290115\n",
      "Epoch:  2272 | Train Accurancy:  0.9042642116546631 | Validation Accurancy:  0.8677415251731873\n",
      "Epoch:  2273 | Train Accurancy:  0.9042823165655136 | Validation Accurancy:  0.8677742332220078\n",
      "Epoch:  2274 | Train Accurancy:  0.9043004736304283 | Validation Accurancy:  0.8678068518638611\n",
      "Epoch:  2275 | Train Accurancy:  0.9043185636401176 | Validation Accurancy:  0.8678395599126816\n",
      "Epoch:  2276 | Train Accurancy:  0.9043365716934204 | Validation Accurancy:  0.8678722381591797\n",
      "Epoch:  2277 | Train Accurancy:  0.904354602098465 | Validation Accurancy:  0.867904931306839\n",
      "Epoch:  2278 | Train Accurancy:  0.9043726772069931 | Validation Accurancy:  0.8679375052452087\n",
      "Epoch:  2279 | Train Accurancy:  0.9043906256556511 | Validation Accurancy:  0.8679699599742889\n",
      "Epoch:  2280 | Train Accurancy:  0.9044086188077927 | Validation Accurancy:  0.8680025339126587\n",
      "Epoch:  2281 | Train Accurancy:  0.9044265598058701 | Validation Accurancy:  0.8680351078510284\n",
      "Epoch:  2282 | Train Accurancy:  0.9044445231556892 | Validation Accurancy:  0.8680674880743027\n",
      "Epoch:  2283 | Train Accurancy:  0.9044624418020248 | Validation Accurancy:  0.86810003221035\n",
      "Epoch:  2284 | Train Accurancy:  0.9044803380966187 | Validation Accurancy:  0.868132546544075\n",
      "Epoch:  2285 | Train Accurancy:  0.9044982418417931 | Validation Accurancy:  0.8681649267673492\n",
      "Epoch:  2286 | Train Accurancy:  0.9045160934329033 | Validation Accurancy:  0.8681973069906235\n",
      "Epoch:  2287 | Train Accurancy:  0.9045339822769165 | Validation Accurancy:  0.8682296872138977\n",
      "Epoch:  2288 | Train Accurancy:  0.9045517668128014 | Validation Accurancy:  0.8682620525360107\n",
      "Epoch:  2289 | Train Accurancy:  0.9045695587992668 | Validation Accurancy:  0.8682943433523178\n",
      "Epoch:  2290 | Train Accurancy:  0.9045873805880547 | Validation Accurancy:  0.8683266490697861\n",
      "Epoch:  2291 | Train Accurancy:  0.9046051725745201 | Validation Accurancy:  0.8683588802814484\n",
      "Epoch:  2292 | Train Accurancy:  0.9046228975057602 | Validation Accurancy:  0.8683910816907883\n",
      "Epoch:  2293 | Train Accurancy:  0.9046406596899033 | Validation Accurancy:  0.8684232532978058\n",
      "Epoch:  2294 | Train Accurancy:  0.9046583622694016 | Validation Accurancy:  0.8684555292129517\n",
      "Epoch:  2295 | Train Accurancy:  0.904676042497158 | Validation Accurancy:  0.8684877455234528\n",
      "Epoch:  2296 | Train Accurancy:  0.9046936482191086 | Validation Accurancy:  0.8685198128223419\n",
      "Epoch:  2297 | Train Accurancy:  0.9047114178538322 | Validation Accurancy:  0.868551954627037\n",
      "Epoch:  2298 | Train Accurancy:  0.9047290459275246 | Validation Accurancy:  0.8685841113328934\n",
      "Epoch:  2299 | Train Accurancy:  0.9047466143965721 | Validation Accurancy:  0.8686161488294601\n",
      "Epoch:  2300 | Train Accurancy:  0.9047642573714256 | Validation Accurancy:  0.8686482310295105\n",
      "Epoch:  2301 | Train Accurancy:  0.9047818258404732 | Validation Accurancy:  0.8686802089214325\n",
      "Epoch:  2302 | Train Accurancy:  0.9047994464635849 | Validation Accurancy:  0.8687122911214828\n",
      "Epoch:  2303 | Train Accurancy:  0.9048169627785683 | Validation Accurancy:  0.8687442243099213\n",
      "Epoch:  2304 | Train Accurancy:  0.9048345163464546 | Validation Accurancy:  0.8687761276960373\n",
      "Epoch:  2305 | Train Accurancy:  0.9048519507050514 | Validation Accurancy:  0.8688081055879593\n",
      "Epoch:  2306 | Train Accurancy:  0.9048694595694542 | Validation Accurancy:  0.8688399791717529\n",
      "Epoch:  2307 | Train Accurancy:  0.9048869535326958 | Validation Accurancy:  0.8688718527555466\n",
      "Epoch:  2308 | Train Accurancy:  0.9049043729901314 | Validation Accurancy:  0.8689036667346954\n",
      "Epoch:  2309 | Train Accurancy:  0.904921792447567 | Validation Accurancy:  0.8689354807138443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2310 | Train Accurancy:  0.9049392640590668 | Validation Accurancy:  0.8689673095941544\n",
      "Epoch:  2311 | Train Accurancy:  0.9049566760659218 | Validation Accurancy:  0.8689990490674973\n",
      "Epoch:  2312 | Train Accurancy:  0.9049740508198738 | Validation Accurancy:  0.8690308332443237\n",
      "Epoch:  2313 | Train Accurancy:  0.9049914553761482 | Validation Accurancy:  0.8690624982118607\n",
      "Epoch:  2314 | Train Accurancy:  0.9050087556242943 | Validation Accurancy:  0.8690942227840424\n",
      "Epoch:  2315 | Train Accurancy:  0.9050260558724403 | Validation Accurancy:  0.8691259175539017\n",
      "Epoch:  2316 | Train Accurancy:  0.9050433859229088 | Validation Accurancy:  0.869157612323761\n",
      "Epoch:  2317 | Train Accurancy:  0.9050606563687325 | Validation Accurancy:  0.8691892027854919\n",
      "Epoch:  2318 | Train Accurancy:  0.9050779417157173 | Validation Accurancy:  0.8692208826541901\n",
      "Epoch:  2319 | Train Accurancy:  0.9050952196121216 | Validation Accurancy:  0.8692524135112762\n",
      "Epoch:  2320 | Train Accurancy:  0.9051124677062035 | Validation Accurancy:  0.8692840039730072\n",
      "Epoch:  2321 | Train Accurancy:  0.9051296561956406 | Validation Accurancy:  0.8693155348300934\n",
      "Epoch:  2322 | Train Accurancy:  0.9051468595862389 | Validation Accurancy:  0.8693469017744064\n",
      "Epoch:  2323 | Train Accurancy:  0.9051641076803207 | Validation Accurancy:  0.869378536939621\n",
      "Epoch:  2324 | Train Accurancy:  0.9051812216639519 | Validation Accurancy:  0.8694099187850952\n",
      "Epoch:  2325 | Train Accurancy:  0.905198335647583 | Validation Accurancy:  0.8694415092468262\n",
      "Epoch:  2326 | Train Accurancy:  0.9052154868841171 | Validation Accurancy:  0.8694727867841721\n",
      "Epoch:  2327 | Train Accurancy:  0.9052326008677483 | Validation Accurancy:  0.8695042431354523\n",
      "Epoch:  2328 | Train Accurancy:  0.9052497297525406 | Validation Accurancy:  0.8695356398820877\n",
      "Epoch:  2329 | Train Accurancy:  0.9052667692303658 | Validation Accurancy:  0.869566947221756\n",
      "Epoch:  2330 | Train Accurancy:  0.9052838385105133 | Validation Accurancy:  0.8695982843637466\n",
      "Epoch:  2331 | Train Accurancy:  0.9053008854389191 | Validation Accurancy:  0.8696295320987701\n",
      "Epoch:  2332 | Train Accurancy:  0.9053179398179054 | Validation Accurancy:  0.8696607798337936\n",
      "Epoch:  2333 | Train Accurancy:  0.905334934592247 | Validation Accurancy:  0.8696921020746231\n",
      "Epoch:  2334 | Train Accurancy:  0.9053519144654274 | Validation Accurancy:  0.869723305106163\n",
      "Epoch:  2335 | Train Accurancy:  0.9053688570857048 | Validation Accurancy:  0.8697544634342194\n",
      "Epoch:  2336 | Train Accurancy:  0.9053858071565628 | Validation Accurancy:  0.8697856813669205\n",
      "Epoch:  2337 | Train Accurancy:  0.9054027423262596 | Validation Accurancy:  0.8698168694972992\n",
      "Epoch:  2338 | Train Accurancy:  0.9054196178913116 | Validation Accurancy:  0.8698479682207108\n",
      "Epoch:  2339 | Train Accurancy:  0.9054365456104279 | Validation Accurancy:  0.8698790371417999\n",
      "Epoch:  2340 | Train Accurancy:  0.9054534658789635 | Validation Accurancy:  0.8699101805686951\n",
      "Epoch:  2341 | Train Accurancy:  0.9054703339934349 | Validation Accurancy:  0.8699412643909454\n",
      "Epoch:  2342 | Train Accurancy:  0.9054871648550034 | Validation Accurancy:  0.8699722737073898\n",
      "Epoch:  2343 | Train Accurancy:  0.9055039882659912 | Validation Accurancy:  0.8700031787157059\n",
      "Epoch:  2344 | Train Accurancy:  0.9055207595229149 | Validation Accurancy:  0.8700342327356339\n",
      "Epoch:  2345 | Train Accurancy:  0.9055375754833221 | Validation Accurancy:  0.8700651824474335\n",
      "Epoch:  2346 | Train Accurancy:  0.90555439889431 | Validation Accurancy:  0.8700960725545883\n",
      "Epoch:  2347 | Train Accurancy:  0.9055711179971695 | Validation Accurancy:  0.8701270967721939\n",
      "Epoch:  2348 | Train Accurancy:  0.905587874352932 | Validation Accurancy:  0.8701579570770264\n",
      "Epoch:  2349 | Train Accurancy:  0.9056046158075333 | Validation Accurancy:  0.8701888471841812\n",
      "Epoch:  2350 | Train Accurancy:  0.9056213051080704 | Validation Accurancy:  0.8702196329832077\n",
      "Epoch:  2351 | Train Accurancy:  0.9056379720568657 | Validation Accurancy:  0.8702505379915237\n",
      "Epoch:  2352 | Train Accurancy:  0.9056546613574028 | Validation Accurancy:  0.8702812939882278\n",
      "Epoch:  2353 | Train Accurancy:  0.9056713283061981 | Validation Accurancy:  0.8703121244907379\n",
      "Epoch:  2354 | Train Accurancy:  0.9056879281997681 | Validation Accurancy:  0.8703428953886032\n",
      "Epoch:  2355 | Train Accurancy:  0.9057046100497246 | Validation Accurancy:  0.8703735768795013\n",
      "Epoch:  2356 | Train Accurancy:  0.9057212173938751 | Validation Accurancy:  0.8704043030738831\n",
      "Epoch:  2357 | Train Accurancy:  0.9057377800345421 | Validation Accurancy:  0.8704350143671036\n",
      "Epoch:  2358 | Train Accurancy:  0.9057543277740479 | Validation Accurancy:  0.8704657256603241\n",
      "Epoch:  2359 | Train Accurancy:  0.9057708829641342 | Validation Accurancy:  0.8704962730407715\n",
      "Epoch:  2360 | Train Accurancy:  0.9057873860001564 | Validation Accurancy:  0.8705269247293472\n",
      "Epoch:  2361 | Train Accurancy:  0.905803956091404 | Validation Accurancy:  0.8705575317144394\n",
      "Epoch:  2362 | Train Accurancy:  0.9058204591274261 | Validation Accurancy:  0.8705881237983704\n",
      "Epoch:  2363 | Train Accurancy:  0.9058369621634483 | Validation Accurancy:  0.8706186413764954\n",
      "Epoch:  2364 | Train Accurancy:  0.9058534130454063 | Validation Accurancy:  0.8706491738557816\n",
      "Epoch:  2365 | Train Accurancy:  0.9058698937296867 | Validation Accurancy:  0.8706796765327454\n",
      "Epoch:  2366 | Train Accurancy:  0.9058863073587418 | Validation Accurancy:  0.8707101494073868\n",
      "Epoch:  2367 | Train Accurancy:  0.9059027656912804 | Validation Accurancy:  0.8707405626773834\n",
      "Epoch:  2368 | Train Accurancy:  0.9059191271662712 | Validation Accurancy:  0.8707710355520248\n",
      "Epoch:  2369 | Train Accurancy:  0.9059355184435844 | Validation Accurancy:  0.8708014935255051\n",
      "Epoch:  2370 | Train Accurancy:  0.9059518799185753 | Validation Accurancy:  0.8708318471908569\n",
      "Epoch:  2371 | Train Accurancy:  0.9059682264924049 | Validation Accurancy:  0.8708622455596924\n",
      "Epoch:  2372 | Train Accurancy:  0.9059845581650734 | Validation Accurancy:  0.8708926141262054\n",
      "Epoch:  2373 | Train Accurancy:  0.9060008749365807 | Validation Accurancy:  0.8709228932857513\n",
      "Epoch:  2374 | Train Accurancy:  0.9060171842575073 | Validation Accurancy:  0.8709532618522644\n",
      "Epoch:  2375 | Train Accurancy:  0.9060334414243698 | Validation Accurancy:  0.8709835708141327\n",
      "Epoch:  2376 | Train Accurancy:  0.9060497507452965 | Validation Accurancy:  0.8710137754678726\n",
      "Epoch:  2377 | Train Accurancy:  0.9060660153627396 | Validation Accurancy:  0.8710439950227737\n",
      "Epoch:  2378 | Train Accurancy:  0.906082272529602 | Validation Accurancy:  0.8710742592811584\n",
      "Epoch:  2379 | Train Accurancy:  0.906098447740078 | Validation Accurancy:  0.871104508638382\n",
      "Epoch:  2380 | Train Accurancy:  0.9061146602034569 | Validation Accurancy:  0.8711346685886383\n",
      "Epoch:  2381 | Train Accurancy:  0.9061308577656746 | Validation Accurancy:  0.8711646795272827\n",
      "Epoch:  2382 | Train Accurancy:  0.9061469957232475 | Validation Accurancy:  0.8711948543787003\n",
      "Epoch:  2383 | Train Accurancy:  0.9061631113290787 | Validation Accurancy:  0.8712250292301178\n",
      "Epoch:  2384 | Train Accurancy:  0.9061792939901352 | Validation Accurancy:  0.8712550103664398\n",
      "Epoch:  2385 | Train Accurancy:  0.9061953872442245 | Validation Accurancy:  0.8712851107120514\n",
      "Epoch:  2386 | Train Accurancy:  0.9062115103006363 | Validation Accurancy:  0.8713150769472122\n",
      "Epoch:  2387 | Train Accurancy:  0.9062276035547256 | Validation Accurancy:  0.8713451772928238\n",
      "Epoch:  2388 | Train Accurancy:  0.9062436744570732 | Validation Accurancy:  0.8713751882314682\n",
      "Epoch:  2389 | Train Accurancy:  0.9062597528100014 | Validation Accurancy:  0.8714050799608231\n",
      "Epoch:  2390 | Train Accurancy:  0.9062757045030594 | Validation Accurancy:  0.8714350163936615\n",
      "Epoch:  2391 | Train Accurancy:  0.9062917679548264 | Validation Accurancy:  0.8714650422334671\n",
      "Epoch:  2392 | Train Accurancy:  0.9063077494502068 | Validation Accurancy:  0.8714948445558548\n",
      "Epoch:  2393 | Train Accurancy:  0.9063237905502319 | Validation Accurancy:  0.8715247511863708\n",
      "Epoch:  2394 | Train Accurancy:  0.9063397496938705 | Validation Accurancy:  0.8715546280145645\n",
      "Epoch:  2395 | Train Accurancy:  0.9063557088375092 | Validation Accurancy:  0.8715844005346298\n",
      "Epoch:  2396 | Train Accurancy:  0.9063716307282448 | Validation Accurancy:  0.8716142177581787\n",
      "Epoch:  2397 | Train Accurancy:  0.9063875526189804 | Validation Accurancy:  0.8716440498828888\n",
      "Epoch:  2398 | Train Accurancy:  0.9064034521579742 | Validation Accurancy:  0.8716738224029541\n",
      "Epoch:  2399 | Train Accurancy:  0.9064193665981293 | Validation Accurancy:  0.8717034459114075\n",
      "Epoch:  2400 | Train Accurancy:  0.9064352810382843 | Validation Accurancy:  0.8717332035303116\n",
      "Epoch:  2401 | Train Accurancy:  0.906451091170311 | Validation Accurancy:  0.8717629164457321\n",
      "Epoch:  2402 | Train Accurancy:  0.9064669385552406 | Validation Accurancy:  0.8717926889657974\n",
      "Epoch:  2403 | Train Accurancy:  0.9064827635884285 | Validation Accurancy:  0.8718222975730896\n",
      "Epoch:  2404 | Train Accurancy:  0.9064985513687134 | Validation Accurancy:  0.8718519508838654\n",
      "Epoch:  2405 | Train Accurancy:  0.9065143018960953 | Validation Accurancy:  0.8718815445899963\n",
      "Epoch:  2406 | Train Accurancy:  0.9065301343798637 | Validation Accurancy:  0.8719112128019333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2407 | Train Accurancy:  0.9065458998084068 | Validation Accurancy:  0.8719407171010971\n",
      "Epoch:  2408 | Train Accurancy:  0.9065616875886917 | Validation Accurancy:  0.8719703555107117\n",
      "Epoch:  2409 | Train Accurancy:  0.906577430665493 | Validation Accurancy:  0.8719998449087143\n",
      "Epoch:  2410 | Train Accurancy:  0.9065931141376495 | Validation Accurancy:  0.8720293492078781\n",
      "Epoch:  2411 | Train Accurancy:  0.9066087752580643 | Validation Accurancy:  0.8720587939023972\n",
      "Epoch:  2412 | Train Accurancy:  0.906624473631382 | Validation Accurancy:  0.8720883131027222\n",
      "Epoch:  2413 | Train Accurancy:  0.9066401645541191 | Validation Accurancy:  0.87211774289608\n",
      "Epoch:  2414 | Train Accurancy:  0.9066558107733727 | Validation Accurancy:  0.8721471130847931\n",
      "Epoch:  2415 | Train Accurancy:  0.9066714122891426 | Validation Accurancy:  0.8721765726804733\n",
      "Epoch:  2416 | Train Accurancy:  0.9066870585083961 | Validation Accurancy:  0.8722059577703476\n",
      "Epoch:  2417 | Train Accurancy:  0.9067027196288109 | Validation Accurancy:  0.8722353279590607\n",
      "Epoch:  2418 | Train Accurancy:  0.9067182689905167 | Validation Accurancy:  0.8722646087408066\n",
      "Epoch:  2419 | Train Accurancy:  0.9067338556051254 | Validation Accurancy:  0.8722939789295197\n",
      "Epoch:  2420 | Train Accurancy:  0.9067494347691536 | Validation Accurancy:  0.872323289513588\n",
      "Epoch:  2421 | Train Accurancy:  0.90676499158144 | Validation Accurancy:  0.8723524808883667\n",
      "Epoch:  2422 | Train Accurancy:  0.9067804887890816 | Validation Accurancy:  0.8723818063735962\n",
      "Epoch:  2423 | Train Accurancy:  0.9067959934473038 | Validation Accurancy:  0.8724110126495361\n",
      "Epoch:  2424 | Train Accurancy:  0.9068114757537842 | Validation Accurancy:  0.8724402785301208\n",
      "Epoch:  2425 | Train Accurancy:  0.906826987862587 | Validation Accurancy:  0.8724694848060608\n",
      "Epoch:  2426 | Train Accurancy:  0.906842403113842 | Validation Accurancy:  0.8724986016750336\n",
      "Epoch:  2427 | Train Accurancy:  0.9068578779697418 | Validation Accurancy:  0.8725277334451675\n",
      "Epoch:  2428 | Train Accurancy:  0.906873308122158 | Validation Accurancy:  0.8725567907094955\n",
      "Epoch:  2429 | Train Accurancy:  0.9068887382745743 | Validation Accurancy:  0.8725859969854355\n",
      "Epoch:  2430 | Train Accurancy:  0.9069041237235069 | Validation Accurancy:  0.8726150393486023\n",
      "Epoch:  2431 | Train Accurancy:  0.906919576227665 | Validation Accurancy:  0.8726441264152527\n",
      "Epoch:  2432 | Train Accurancy:  0.9069349244236946 | Validation Accurancy:  0.8726731240749359\n",
      "Epoch:  2433 | Train Accurancy:  0.9069502726197243 | Validation Accurancy:  0.8727021962404251\n",
      "Epoch:  2434 | Train Accurancy:  0.9069655910134315 | Validation Accurancy:  0.8727311044931412\n",
      "Epoch:  2435 | Train Accurancy:  0.9069809392094612 | Validation Accurancy:  0.8727601021528244\n",
      "Epoch:  2436 | Train Accurancy:  0.9069962799549103 | Validation Accurancy:  0.8727891743183136\n",
      "Epoch:  2437 | Train Accurancy:  0.9070115834474564 | Validation Accurancy:  0.8728180080652237\n",
      "Epoch:  2438 | Train Accurancy:  0.9070268347859383 | Validation Accurancy:  0.8728470057249069\n",
      "Epoch:  2439 | Train Accurancy:  0.9070420786738396 | Validation Accurancy:  0.8728758841753006\n",
      "Epoch:  2440 | Train Accurancy:  0.9070573225617409 | Validation Accurancy:  0.8729047030210495\n",
      "Epoch:  2441 | Train Accurancy:  0.9070725813508034 | Validation Accurancy:  0.8729335367679596\n",
      "Epoch:  2442 | Train Accurancy:  0.9070877656340599 | Validation Accurancy:  0.8729624003171921\n",
      "Epoch:  2443 | Train Accurancy:  0.9071030244231224 | Validation Accurancy:  0.8729911595582962\n",
      "Epoch:  2444 | Train Accurancy:  0.9071181192994118 | Validation Accurancy:  0.8730200082063675\n",
      "Epoch:  2445 | Train Accurancy:  0.9071334078907967 | Validation Accurancy:  0.8730488121509552\n",
      "Epoch:  2446 | Train Accurancy:  0.9071485698223114 | Validation Accurancy:  0.8730775862932205\n",
      "Epoch:  2447 | Train Accurancy:  0.9071636870503426 | Validation Accurancy:  0.8731062412261963\n",
      "Epoch:  2448 | Train Accurancy:  0.9071788489818573 | Validation Accurancy:  0.8731350004673004\n",
      "Epoch:  2449 | Train Accurancy:  0.9071939066052437 | Validation Accurancy:  0.8731636703014374\n",
      "Epoch:  2450 | Train Accurancy:  0.9072090312838554 | Validation Accurancy:  0.8731922507286072\n",
      "Epoch:  2451 | Train Accurancy:  0.9072241112589836 | Validation Accurancy:  0.8732209950685501\n",
      "Epoch:  2452 | Train Accurancy:  0.9072391837835312 | Validation Accurancy:  0.8732496052980423\n",
      "Epoch:  2453 | Train Accurancy:  0.9072542563080788 | Validation Accurancy:  0.8732782006263733\n",
      "Epoch:  2454 | Train Accurancy:  0.9072692692279816 | Validation Accurancy:  0.8733067363500595\n",
      "Epoch:  2455 | Train Accurancy:  0.9072843044996262 | Validation Accurancy:  0.8733353912830353\n",
      "Epoch:  2456 | Train Accurancy:  0.9072993323206902 | Validation Accurancy:  0.8733638674020767\n",
      "Epoch:  2457 | Train Accurancy:  0.907314345240593 | Validation Accurancy:  0.8733922839164734\n",
      "Epoch:  2458 | Train Accurancy:  0.9073292762041092 | Validation Accurancy:  0.8734209984540939\n",
      "Epoch:  2459 | Train Accurancy:  0.9073443114757538 | Validation Accurancy:  0.8734494149684906\n",
      "Epoch:  2460 | Train Accurancy:  0.9073592349886894 | Validation Accurancy:  0.8734779059886932\n",
      "Epoch:  2461 | Train Accurancy:  0.9073741734027863 | Validation Accurancy:  0.8735063225030899\n",
      "Epoch:  2462 | Train Accurancy:  0.9073890522122383 | Validation Accurancy:  0.8735347092151642\n",
      "Epoch:  2463 | Train Accurancy:  0.9074039906263351 | Validation Accurancy:  0.8735630810260773\n",
      "Epoch:  2464 | Train Accurancy:  0.907418854534626 | Validation Accurancy:  0.8735915571451187\n",
      "Epoch:  2465 | Train Accurancy:  0.9074337333440781 | Validation Accurancy:  0.8736199140548706\n",
      "Epoch:  2466 | Train Accurancy:  0.9074486568570137 | Validation Accurancy:  0.8736481815576553\n",
      "Epoch:  2467 | Train Accurancy:  0.9074634835124016 | Validation Accurancy:  0.8736765831708908\n",
      "Epoch:  2468 | Train Accurancy:  0.9074783101677895 | Validation Accurancy:  0.8737048357725143\n",
      "Epoch:  2469 | Train Accurancy:  0.9074931368231773 | Validation Accurancy:  0.8737331926822662\n",
      "Epoch:  2470 | Train Accurancy:  0.907507948577404 | Validation Accurancy:  0.8737614303827286\n",
      "Epoch:  2471 | Train Accurancy:  0.9075227305293083 | Validation Accurancy:  0.8737896382808685\n",
      "Epoch:  2472 | Train Accurancy:  0.9075375124812126 | Validation Accurancy:  0.8738178759813309\n",
      "Epoch:  2473 | Train Accurancy:  0.9075523167848587 | Validation Accurancy:  0.8738460391759872\n",
      "Epoch:  2474 | Train Accurancy:  0.9075670167803764 | Validation Accurancy:  0.8738742917776108\n",
      "Epoch:  2475 | Train Accurancy:  0.9075817838311195 | Validation Accurancy:  0.8739024251699448\n",
      "Epoch:  2476 | Train Accurancy:  0.9075964465737343 | Validation Accurancy:  0.8739305287599564\n",
      "Epoch:  2477 | Train Accurancy:  0.9076111614704132 | Validation Accurancy:  0.8739587366580963\n",
      "Epoch:  2478 | Train Accurancy:  0.9076258689165115 | Validation Accurancy:  0.8739867657423019\n",
      "Epoch:  2479 | Train Accurancy:  0.9076405465602875 | Validation Accurancy:  0.8740148395299911\n",
      "Epoch:  2480 | Train Accurancy:  0.9076552242040634 | Validation Accurancy:  0.8740428239107132\n",
      "Epoch:  2481 | Train Accurancy:  0.9076698943972588 | Validation Accurancy:  0.8740709722042084\n",
      "Epoch:  2482 | Train Accurancy:  0.9076845347881317 | Validation Accurancy:  0.8740989863872528\n",
      "Epoch:  2483 | Train Accurancy:  0.9076991528272629 | Validation Accurancy:  0.8741270154714584\n",
      "Epoch:  2484 | Train Accurancy:  0.9077136889100075 | Validation Accurancy:  0.8741549700498581\n",
      "Epoch:  2485 | Train Accurancy:  0.9077283218502998 | Validation Accurancy:  0.8741828799247742\n",
      "Epoch:  2486 | Train Accurancy:  0.9077428877353668 | Validation Accurancy:  0.8742108941078186\n",
      "Epoch:  2487 | Train Accurancy:  0.9077574387192726 | Validation Accurancy:  0.8742387890815735\n",
      "Epoch:  2488 | Train Accurancy:  0.9077720493078232 | Validation Accurancy:  0.8742667138576508\n",
      "Epoch:  2489 | Train Accurancy:  0.907786525785923 | Validation Accurancy:  0.8742945045232773\n",
      "Epoch:  2490 | Train Accurancy:  0.9078010395169258 | Validation Accurancy:  0.8743222504854202\n",
      "Epoch:  2491 | Train Accurancy:  0.9078155308961868 | Validation Accurancy:  0.874350368976593\n",
      "Epoch:  2492 | Train Accurancy:  0.9078300818800926 | Validation Accurancy:  0.8743780851364136\n",
      "Epoch:  2493 | Train Accurancy:  0.9078445360064507 | Validation Accurancy:  0.8744059205055237\n",
      "Epoch:  2494 | Train Accurancy:  0.9078590124845505 | Validation Accurancy:  0.8744336515665054\n",
      "Epoch:  2495 | Train Accurancy:  0.9078734368085861 | Validation Accurancy:  0.8744614273309708\n",
      "Epoch:  2496 | Train Accurancy:  0.9078878834843636 | Validation Accurancy:  0.8744891732931137\n",
      "Epoch:  2497 | Train Accurancy:  0.9079023078083992 | Validation Accurancy:  0.874516949057579\n",
      "Epoch:  2498 | Train Accurancy:  0.9079167023301125 | Validation Accurancy:  0.8745445758104324\n",
      "Epoch:  2499 | Train Accurancy:  0.9079311043024063 | Validation Accurancy:  0.874572366476059\n",
      "Epoch:  2500 | Train Accurancy:  0.9079454392194748 | Validation Accurancy:  0.8745999038219452\n",
      "Epoch:  2501 | Train Accurancy:  0.9079598560929298 | Validation Accurancy:  0.8746276646852493\n",
      "Epoch:  2502 | Train Accurancy:  0.9079742357134819 | Validation Accurancy:  0.8746551722288132\n",
      "Epoch:  2503 | Train Accurancy:  0.9079885184764862 | Validation Accurancy:  0.874682828783989\n",
      "Epoch:  2504 | Train Accurancy:  0.9080028459429741 | Validation Accurancy:  0.8747103661298752\n",
      "Epoch:  2505 | Train Accurancy:  0.9080171808600426 | Validation Accurancy:  0.8747380524873734\n",
      "Epoch:  2506 | Train Accurancy:  0.9080314338207245 | Validation Accurancy:  0.8747656345367432\n",
      "Epoch:  2507 | Train Accurancy:  0.9080457165837288 | Validation Accurancy:  0.8747931122779846\n",
      "Epoch:  2508 | Train Accurancy:  0.9080600515007973 | Validation Accurancy:  0.8748206496238708\n",
      "Epoch:  2509 | Train Accurancy:  0.9080742597579956 | Validation Accurancy:  0.8748482018709183\n",
      "Epoch:  2510 | Train Accurancy:  0.9080885201692581 | Validation Accurancy:  0.8748757094144821\n",
      "Epoch:  2511 | Train Accurancy:  0.9081027135252953 | Validation Accurancy:  0.8749031126499176\n",
      "Epoch:  2512 | Train Accurancy:  0.9081169292330742 | Validation Accurancy:  0.8749304860830307\n",
      "Epoch:  2513 | Train Accurancy:  0.9081311598420143 | Validation Accurancy:  0.874957948923111\n",
      "Epoch:  2514 | Train Accurancy:  0.908145360648632 | Validation Accurancy:  0.8749852925539017\n",
      "Epoch:  2515 | Train Accurancy:  0.9081595167517662 | Validation Accurancy:  0.8750127106904984\n",
      "Epoch:  2516 | Train Accurancy:  0.9081736654043198 | Validation Accurancy:  0.8750400543212891\n",
      "Epoch:  2517 | Train Accurancy:  0.9081877842545509 | Validation Accurancy:  0.8750674203038216\n",
      "Epoch:  2518 | Train Accurancy:  0.9082019329071045 | Validation Accurancy:  0.8750947862863541\n",
      "Epoch:  2519 | Train Accurancy:  0.9082160666584969 | Validation Accurancy:  0.8751220405101776\n",
      "Epoch:  2520 | Train Accurancy:  0.9082301929593086 | Validation Accurancy:  0.8751493245363235\n",
      "Epoch:  2521 | Train Accurancy:  0.9082442671060562 | Validation Accurancy:  0.8751766011118889\n",
      "Epoch:  2522 | Train Accurancy:  0.9082583338022232 | Validation Accurancy:  0.87520382553339\n",
      "Epoch:  2523 | Train Accurancy:  0.908272422850132 | Validation Accurancy:  0.87523103505373\n",
      "Epoch:  2524 | Train Accurancy:  0.9082864746451378 | Validation Accurancy:  0.875258207321167\n",
      "Epoch:  2525 | Train Accurancy:  0.9083004966378212 | Validation Accurancy:  0.8752854317426682\n",
      "Epoch:  2526 | Train Accurancy:  0.9083145186305046 | Validation Accurancy:  0.8753126040101051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2527 | Train Accurancy:  0.9083285555243492 | Validation Accurancy:  0.8753398135304451\n",
      "Epoch:  2528 | Train Accurancy:  0.9083425253629684 | Validation Accurancy:  0.8753668889403343\n",
      "Epoch:  2529 | Train Accurancy:  0.9083565399050713 | Validation Accurancy:  0.8753940388560295\n",
      "Epoch:  2530 | Train Accurancy:  0.9083705022931099 | Validation Accurancy:  0.8754211738705635\n",
      "Epoch:  2531 | Train Accurancy:  0.9083844572305679 | Validation Accurancy:  0.8754482045769691\n",
      "Epoch:  2532 | Train Accurancy:  0.908398412168026 | Validation Accurancy:  0.8754753023386002\n",
      "Epoch:  2533 | Train Accurancy:  0.9084123224020004 | Validation Accurancy:  0.8755022957921028\n",
      "Epoch:  2534 | Train Accurancy:  0.9084262400865555 | Validation Accurancy:  0.875529333949089\n",
      "Epoch:  2535 | Train Accurancy:  0.908440113067627 | Validation Accurancy:  0.8755563423037529\n",
      "Epoch:  2536 | Train Accurancy:  0.9084540382027626 | Validation Accurancy:  0.8755833134055138\n",
      "Epoch:  2537 | Train Accurancy:  0.9084679111838341 | Validation Accurancy:  0.8756102696061134\n",
      "Epoch:  2538 | Train Accurancy:  0.9084817618131638 | Validation Accurancy:  0.8756372258067131\n",
      "Epoch:  2539 | Train Accurancy:  0.9084956124424934 | Validation Accurancy:  0.8756642267107964\n",
      "Epoch:  2540 | Train Accurancy:  0.9085094928741455 | Validation Accurancy:  0.8756911009550095\n",
      "Epoch:  2541 | Train Accurancy:  0.9085232987999916 | Validation Accurancy:  0.8757179230451584\n",
      "Epoch:  2542 | Train Accurancy:  0.9085370972752571 | Validation Accurancy:  0.8757448866963387\n",
      "Epoch:  2543 | Train Accurancy:  0.9085508733987808 | Validation Accurancy:  0.8757717087864876\n",
      "Epoch:  2544 | Train Accurancy:  0.9085647016763687 | Validation Accurancy:  0.8757984861731529\n",
      "Epoch:  2545 | Train Accurancy:  0.90857844799757 | Validation Accurancy:  0.8758254200220108\n",
      "Epoch:  2546 | Train Accurancy:  0.9085922241210938 | Validation Accurancy:  0.8758521005511284\n",
      "Epoch:  2547 | Train Accurancy:  0.9086059704422951 | Validation Accurancy:  0.8758789002895355\n",
      "Epoch:  2548 | Train Accurancy:  0.908619686961174 | Validation Accurancy:  0.8759057521820068\n",
      "Epoch:  2549 | Train Accurancy:  0.9086333587765694 | Validation Accurancy:  0.8759323880076408\n",
      "Epoch:  2550 | Train Accurancy:  0.9086471274495125 | Validation Accurancy:  0.8759591728448868\n",
      "Epoch:  2551 | Train Accurancy:  0.9086607918143272 | Validation Accurancy:  0.8759858310222626\n",
      "Epoch:  2552 | Train Accurancy:  0.908674493432045 | Validation Accurancy:  0.8760125935077667\n",
      "Epoch:  2553 | Train Accurancy:  0.9086881652474403 | Validation Accurancy:  0.8760392442345619\n",
      "Epoch:  2554 | Train Accurancy:  0.9087017923593521 | Validation Accurancy:  0.8760659471154213\n",
      "Epoch:  2555 | Train Accurancy:  0.9087154120206833 | Validation Accurancy:  0.8760926052927971\n",
      "Epoch:  2556 | Train Accurancy:  0.9087290838360786 | Validation Accurancy:  0.8761191666126251\n",
      "Epoch:  2557 | Train Accurancy:  0.9087426885962486 | Validation Accurancy:  0.8761458322405815\n",
      "Epoch:  2558 | Train Accurancy:  0.9087562784552574 | Validation Accurancy:  0.876172386109829\n",
      "Epoch:  2559 | Train Accurancy:  0.9087698832154274 | Validation Accurancy:  0.8761989250779152\n",
      "Epoch:  2560 | Train Accurancy:  0.9087834432721138 | Validation Accurancy:  0.8762253820896149\n",
      "Epoch:  2561 | Train Accurancy:  0.9087970182299614 | Validation Accurancy:  0.8762519210577011\n",
      "Epoch:  2562 | Train Accurancy:  0.9088105857372284 | Validation Accurancy:  0.876278467476368\n",
      "Epoch:  2563 | Train Accurancy:  0.908824160695076 | Validation Accurancy:  0.8763049021363258\n",
      "Epoch:  2564 | Train Accurancy:  0.9088376238942146 | Validation Accurancy:  0.8763314411044121\n",
      "Epoch:  2565 | Train Accurancy:  0.9088511392474174 | Validation Accurancy:  0.8763578981161118\n",
      "Epoch:  2566 | Train Accurancy:  0.9088646844029427 | Validation Accurancy:  0.8763842731714249\n",
      "Epoch:  2567 | Train Accurancy:  0.9088781550526619 | Validation Accurancy:  0.8764107301831245\n",
      "Epoch:  2568 | Train Accurancy:  0.908891573548317 | Validation Accurancy:  0.8764371797442436\n",
      "Epoch:  2569 | Train Accurancy:  0.908905103802681 | Validation Accurancy:  0.8764635026454926\n",
      "Epoch:  2570 | Train Accurancy:  0.908918522298336 | Validation Accurancy:  0.8764898627996445\n",
      "Epoch:  2571 | Train Accurancy:  0.9089319631457329 | Validation Accurancy:  0.8765163123607635\n",
      "Epoch:  2572 | Train Accurancy:  0.9089453667402267 | Validation Accurancy:  0.8765426203608513\n",
      "Epoch:  2573 | Train Accurancy:  0.908958800137043 | Validation Accurancy:  0.8765689358115196\n",
      "Epoch:  2574 | Train Accurancy:  0.9089721962809563 | Validation Accurancy:  0.8765951246023178\n",
      "Epoch:  2575 | Train Accurancy:  0.9089855924248695 | Validation Accurancy:  0.8766213953495026\n",
      "Epoch:  2576 | Train Accurancy:  0.9089989587664604 | Validation Accurancy:  0.8766477257013321\n",
      "Epoch:  2577 | Train Accurancy:  0.9090123474597931 | Validation Accurancy:  0.8766738921403885\n",
      "Epoch:  2578 | Train Accurancy:  0.9090256541967392 | Validation Accurancy:  0.8767000660300255\n",
      "Epoch:  2579 | Train Accurancy:  0.9090390428900719 | Validation Accurancy:  0.8767263665795326\n",
      "Epoch:  2580 | Train Accurancy:  0.9090523570775986 | Validation Accurancy:  0.8767525479197502\n",
      "Epoch:  2581 | Train Accurancy:  0.9090656414628029 | Validation Accurancy:  0.8767788335680962\n",
      "Epoch:  2582 | Train Accurancy:  0.9090789034962654 | Validation Accurancy:  0.876804918050766\n",
      "Epoch:  2583 | Train Accurancy:  0.9090922400355339 | Validation Accurancy:  0.8768310472369194\n",
      "Epoch:  2584 | Train Accurancy:  0.909105509519577 | Validation Accurancy:  0.8768571764230728\n",
      "Epoch:  2585 | Train Accurancy:  0.9091187566518784 | Validation Accurancy:  0.8768832609057426\n",
      "Epoch:  2586 | Train Accurancy:  0.9091320410370827 | Validation Accurancy:  0.8769092783331871\n",
      "Epoch:  2587 | Train Accurancy:  0.9091452807188034 | Validation Accurancy:  0.8769354149699211\n",
      "Epoch:  2588 | Train Accurancy:  0.9091585129499435 | Validation Accurancy:  0.8769614845514297\n",
      "Epoch:  2589 | Train Accurancy:  0.9091716632246971 | Validation Accurancy:  0.8769874572753906\n",
      "Epoch:  2590 | Train Accurancy:  0.9091848880052567 | Validation Accurancy:  0.8770134747028351\n",
      "Epoch:  2591 | Train Accurancy:  0.909198060631752 | Validation Accurancy:  0.8770394623279572\n",
      "Epoch:  2592 | Train Accurancy:  0.9092112258076668 | Validation Accurancy:  0.8770654574036598\n",
      "Epoch:  2593 | Train Accurancy:  0.9092244207859039 | Validation Accurancy:  0.8770913779735565\n",
      "Epoch:  2594 | Train Accurancy:  0.9092375859618187 | Validation Accurancy:  0.877117395401001\n",
      "Epoch:  2595 | Train Accurancy:  0.9092507138848305 | Validation Accurancy:  0.8771432638168335\n",
      "Epoch:  2596 | Train Accurancy:  0.9092638492584229 | Validation Accurancy:  0.8771691173315048\n",
      "Epoch:  2597 | Train Accurancy:  0.9092769771814346 | Validation Accurancy:  0.8771950155496597\n",
      "Epoch:  2598 | Train Accurancy:  0.9092900231480598 | Validation Accurancy:  0.877220906317234\n",
      "Epoch:  2599 | Train Accurancy:  0.909303106367588 | Validation Accurancy:  0.8772466629743576\n",
      "Epoch:  2600 | Train Accurancy:  0.9093162044882774 | Validation Accurancy:  0.8772725313901901\n",
      "Epoch:  2601 | Train Accurancy:  0.9093292653560638 | Validation Accurancy:  0.8772984519600868\n",
      "Epoch:  2602 | Train Accurancy:  0.9093423262238503 | Validation Accurancy:  0.877324141561985\n",
      "Epoch:  2603 | Train Accurancy:  0.9093553721904755 | Validation Accurancy:  0.8773499578237534\n",
      "Epoch:  2604 | Train Accurancy:  0.9093683883547783 | Validation Accurancy:  0.8773758262395859\n",
      "Epoch:  2605 | Train Accurancy:  0.9093813449144363 | Validation Accurancy:  0.877401553094387\n",
      "Epoch:  2606 | Train Accurancy:  0.9093943610787392 | Validation Accurancy:  0.8774271309375763\n",
      "Epoch:  2607 | Train Accurancy:  0.9094074070453644 | Validation Accurancy:  0.8774529695510864\n",
      "Epoch:  2608 | Train Accurancy:  0.909420371055603 | Validation Accurancy:  0.8774787113070488\n",
      "Epoch:  2609 | Train Accurancy:  0.9094333201646805 | Validation Accurancy:  0.8775043338537216\n",
      "Epoch:  2610 | Train Accurancy:  0.9094463288784027 | Validation Accurancy:  0.8775300160050392\n",
      "Epoch:  2611 | Train Accurancy:  0.9094592407345772 | Validation Accurancy:  0.8775556311011314\n",
      "Epoch:  2612 | Train Accurancy:  0.9094721525907516 | Validation Accurancy:  0.8775813356041908\n",
      "Epoch:  2613 | Train Accurancy:  0.9094851166009903 | Validation Accurancy:  0.877606950700283\n",
      "Epoch:  2614 | Train Accurancy:  0.909498043358326 | Validation Accurancy:  0.8776324614882469\n",
      "Epoch:  2615 | Train Accurancy:  0.9095109328627586 | Validation Accurancy:  0.8776580467820168\n",
      "Epoch:  2616 | Train Accurancy:  0.9095237702131271 | Validation Accurancy:  0.8776836171746254\n",
      "Epoch:  2617 | Train Accurancy:  0.909536637365818 | Validation Accurancy:  0.8777092471718788\n",
      "Epoch:  2618 | Train Accurancy:  0.9095495417714119 | Validation Accurancy:  0.8777346462011337\n",
      "Epoch:  2619 | Train Accurancy:  0.9095623791217804 | Validation Accurancy:  0.8777602091431618\n",
      "Epoch:  2620 | Train Accurancy:  0.9095752164721489 | Validation Accurancy:  0.8777857273817062\n",
      "Epoch:  2621 | Train Accurancy:  0.909588098526001 | Validation Accurancy:  0.8778111636638641\n",
      "Epoch:  2622 | Train Accurancy:  0.9096008539199829 | Validation Accurancy:  0.8778365924954414\n",
      "Epoch:  2623 | Train Accurancy:  0.9096136465668678 | Validation Accurancy:  0.8778620287775993\n",
      "Epoch:  2624 | Train Accurancy:  0.909626416862011 | Validation Accurancy:  0.877887524664402\n",
      "Epoch:  2625 | Train Accurancy:  0.9096392244100571 | Validation Accurancy:  0.8779129013419151\n",
      "Epoch:  2626 | Train Accurancy:  0.9096520096063614 | Validation Accurancy:  0.87793830037117\n",
      "Epoch:  2627 | Train Accurancy:  0.9096647351980209 | Validation Accurancy:  0.8779636844992638\n",
      "Epoch:  2628 | Train Accurancy:  0.9096774831414223 | Validation Accurancy:  0.8779891356825829\n",
      "Epoch:  2629 | Train Accurancy:  0.9096902459859848 | Validation Accurancy:  0.8780144453048706\n",
      "Epoch:  2630 | Train Accurancy:  0.9097029641270638 | Validation Accurancy:  0.8780418485403061\n",
      "Epoch:  2631 | Train Accurancy:  0.9097156375646591 | Validation Accurancy:  0.8780664280056953\n",
      "Epoch:  2632 | Train Accurancy:  0.9097283110022545 | Validation Accurancy:  0.8780933246016502\n",
      "Epoch:  2633 | Train Accurancy:  0.9097410067915916 | Validation Accurancy:  0.8781197145581245\n",
      "Epoch:  2634 | Train Accurancy:  0.9097537025809288 | Validation Accurancy:  0.8781436011195183\n",
      "Epoch:  2635 | Train Accurancy:  0.9097664207220078 | Validation Accurancy:  0.878170020878315\n",
      "Epoch:  2636 | Train Accurancy:  0.909778967499733 | Validation Accurancy:  0.8781958967447281\n",
      "Epoch:  2637 | Train Accurancy:  0.9097916856408119 | Validation Accurancy:  0.8782196119427681\n",
      "Epoch:  2638 | Train Accurancy:  0.9098042249679565 | Validation Accurancy:  0.8782456964254379\n",
      "Epoch:  2639 | Train Accurancy:  0.9098168835043907 | Validation Accurancy:  0.8782715946435928\n",
      "Epoch:  2640 | Train Accurancy:  0.9098294451832771 | Validation Accurancy:  0.8782971948385239\n",
      "Epoch:  2641 | Train Accurancy:  0.9098420664668083 | Validation Accurancy:  0.8783205971121788\n",
      "Epoch:  2642 | Train Accurancy:  0.9098546206951141 | Validation Accurancy:  0.8783465102314949\n",
      "Epoch:  2643 | Train Accurancy:  0.9098671674728394 | Validation Accurancy:  0.8783721253275871\n",
      "Epoch:  2644 | Train Accurancy:  0.9098797366023064 | Validation Accurancy:  0.8783975839614868\n",
      "Epoch:  2645 | Train Accurancy:  0.909892275929451 | Validation Accurancy:  0.8784229308366776\n",
      "Epoch:  2646 | Train Accurancy:  0.9099048599600792 | Validation Accurancy:  0.8784460723400116\n",
      "Epoch:  2647 | Train Accurancy:  0.9099173694849014 | Validation Accurancy:  0.8784718289971352\n",
      "Epoch:  2648 | Train Accurancy:  0.9099298641085625 | Validation Accurancy:  0.8784973695874214\n",
      "Epoch:  2649 | Train Accurancy:  0.9099423810839653 | Validation Accurancy:  0.8785225972533226\n",
      "Epoch:  2650 | Train Accurancy:  0.9099548310041428 | Validation Accurancy:  0.8785477951169014\n",
      "Epoch:  2651 | Train Accurancy:  0.9099673330783844 | Validation Accurancy:  0.8785708472132683\n",
      "Epoch:  2652 | Train Accurancy:  0.9099797755479813 | Validation Accurancy:  0.8785963952541351\n",
      "Epoch:  2653 | Train Accurancy:  0.9099922478199005 | Validation Accurancy:  0.878621868789196\n",
      "Epoch:  2654 | Train Accurancy:  0.9100046902894974 | Validation Accurancy:  0.878647156059742\n",
      "Epoch:  2655 | Train Accurancy:  0.9100170508027077 | Validation Accurancy:  0.8786722049117088\n",
      "Epoch:  2656 | Train Accurancy:  0.9100295305252075 | Validation Accurancy:  0.8786952793598175\n",
      "Epoch:  2657 | Train Accurancy:  0.9100419208407402 | Validation Accurancy:  0.8787208721041679\n",
      "Epoch:  2658 | Train Accurancy:  0.9100543037056923 | Validation Accurancy:  0.8787461668252945\n",
      "Epoch:  2659 | Train Accurancy:  0.9100666865706444 | Validation Accurancy:  0.8787712976336479\n",
      "Epoch:  2660 | Train Accurancy:  0.9100790992379189 | Validation Accurancy:  0.8787962719798088\n",
      "Epoch:  2661 | Train Accurancy:  0.9100914224982262 | Validation Accurancy:  0.8788212761282921\n",
      "Epoch:  2662 | Train Accurancy:  0.9101037755608559 | Validation Accurancy:  0.8788440227508545\n",
      "Epoch:  2663 | Train Accurancy:  0.9101161137223244 | Validation Accurancy:  0.8788694962859154\n",
      "Epoch:  2664 | Train Accurancy:  0.9101284742355347 | Validation Accurancy:  0.8788946866989136\n",
      "Epoch:  2665 | Train Accurancy:  0.910140797495842 | Validation Accurancy:  0.8789197728037834\n",
      "Epoch:  2666 | Train Accurancy:  0.9101530835032463 | Validation Accurancy:  0.8789446204900742\n",
      "Epoch:  2667 | Train Accurancy:  0.9101653546094894 | Validation Accurancy:  0.8789693862199783\n",
      "Epoch:  2668 | Train Accurancy:  0.910177655518055 | Validation Accurancy:  0.8789920955896378\n",
      "Epoch:  2669 | Train Accurancy:  0.9101899191737175 | Validation Accurancy:  0.8790175467729568\n",
      "Epoch:  2670 | Train Accurancy:  0.9102021530270576 | Validation Accurancy:  0.8790426328778267\n",
      "Epoch:  2671 | Train Accurancy:  0.9102144539356232 | Validation Accurancy:  0.8790676221251488\n",
      "Epoch:  2672 | Train Accurancy:  0.9102266728878021 | Validation Accurancy:  0.8790924027562141\n",
      "Epoch:  2673 | Train Accurancy:  0.9102388992905617 | Validation Accurancy:  0.8791170790791512\n",
      "Epoch:  2674 | Train Accurancy:  0.9102511331439018 | Validation Accurancy:  0.879139706492424\n",
      "Epoch:  2675 | Train Accurancy:  0.9102633222937584 | Validation Accurancy:  0.8791650608181953\n",
      "Epoch:  2676 | Train Accurancy:  0.9102755263447762 | Validation Accurancy:  0.8791900128126144\n",
      "Epoch:  2677 | Train Accurancy:  0.9102877452969551 | Validation Accurancy:  0.8792148008942604\n",
      "Epoch:  2678 | Train Accurancy:  0.9102999120950699 | Validation Accurancy:  0.8792395740747452\n",
      "Epoch:  2679 | Train Accurancy:  0.9103120416402817 | Validation Accurancy:  0.8792642205953598\n",
      "Epoch:  2680 | Train Accurancy:  0.9103242233395576 | Validation Accurancy:  0.8792887479066849\n",
      "Epoch:  2681 | Train Accurancy:  0.9103363528847694 | Validation Accurancy:  0.8793133199214935\n",
      "Epoch:  2682 | Train Accurancy:  0.9103484451770782 | Validation Accurancy:  0.8793357536196709\n",
      "Epoch:  2683 | Train Accurancy:  0.9103605821728706 | Validation Accurancy:  0.8793608620762825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2684 | Train Accurancy:  0.9103726372122765 | Validation Accurancy:  0.8793857470154762\n",
      "Epoch:  2685 | Train Accurancy:  0.9103847518563271 | Validation Accurancy:  0.8794104754924774\n",
      "Epoch:  2686 | Train Accurancy:  0.9103968292474747 | Validation Accurancy:  0.8794349804520607\n",
      "Epoch:  2687 | Train Accurancy:  0.9104089364409447 | Validation Accurancy:  0.8794595077633858\n",
      "Epoch:  2688 | Train Accurancy:  0.9104209840297699 | Validation Accurancy:  0.8794838711619377\n",
      "Epoch:  2689 | Train Accurancy:  0.9104330539703369 | Validation Accurancy:  0.8795083537697792\n",
      "Epoch:  2690 | Train Accurancy:  0.9104450792074203 | Validation Accurancy:  0.8795306608080864\n",
      "Epoch:  2691 | Train Accurancy:  0.9104571044445038 | Validation Accurancy:  0.8795555680990219\n",
      "Epoch:  2692 | Train Accurancy:  0.9104691669344902 | Validation Accurancy:  0.8795804083347321\n",
      "Epoch:  2693 | Train Accurancy:  0.9104810953140259 | Validation Accurancy:  0.8796048611402512\n",
      "Epoch:  2694 | Train Accurancy:  0.9104930981993675 | Validation Accurancy:  0.879629373550415\n",
      "Epoch:  2695 | Train Accurancy:  0.9105050936341286 | Validation Accurancy:  0.879653699696064\n",
      "Epoch:  2696 | Train Accurancy:  0.9105171039700508 | Validation Accurancy:  0.8796781152486801\n",
      "Epoch:  2697 | Train Accurancy:  0.9105290248990059 | Validation Accurancy:  0.8797022998332977\n",
      "Epoch:  2698 | Train Accurancy:  0.9105410203337669 | Validation Accurancy:  0.8797265589237213\n",
      "Epoch:  2699 | Train Accurancy:  0.910552941262722 | Validation Accurancy:  0.8797507584095001\n",
      "Epoch:  2700 | Train Accurancy:  0.9105649068951607 | Validation Accurancy:  0.8797749727964401\n",
      "Epoch:  2701 | Train Accurancy:  0.9105768203735352 | Validation Accurancy:  0.8797971457242966\n",
      "Epoch:  2702 | Train Accurancy:  0.9105887413024902 | Validation Accurancy:  0.879821889102459\n",
      "Epoch:  2703 | Train Accurancy:  0.9106006175279617 | Validation Accurancy:  0.8798464089632034\n",
      "Epoch:  2704 | Train Accurancy:  0.9106125384569168 | Validation Accurancy:  0.8798707723617554\n",
      "Epoch:  2705 | Train Accurancy:  0.9106244295835495 | Validation Accurancy:  0.8798950612545013\n",
      "Epoch:  2706 | Train Accurancy:  0.9106362536549568 | Validation Accurancy:  0.8799192383885384\n",
      "Epoch:  2707 | Train Accurancy:  0.9106481522321701 | Validation Accurancy:  0.8799434006214142\n",
      "Epoch:  2708 | Train Accurancy:  0.9106599912047386 | Validation Accurancy:  0.879967451095581\n",
      "Epoch:  2709 | Train Accurancy:  0.9106718301773071 | Validation Accurancy:  0.8799915537238121\n",
      "Epoch:  2710 | Train Accurancy:  0.910683698952198 | Validation Accurancy:  0.8800155967473984\n",
      "Epoch:  2711 | Train Accurancy:  0.9106955081224442 | Validation Accurancy:  0.8800395950675011\n",
      "Epoch:  2712 | Train Accurancy:  0.9107073247432709 | Validation Accurancy:  0.8800636008381844\n",
      "Epoch:  2713 | Train Accurancy:  0.9107190296053886 | Validation Accurancy:  0.8800874799489975\n",
      "Epoch:  2714 | Train Accurancy:  0.9107308611273766 | Validation Accurancy:  0.8801115453243256\n",
      "Epoch:  2715 | Train Accurancy:  0.9107426181435585 | Validation Accurancy:  0.8801334351301193\n",
      "Epoch:  2716 | Train Accurancy:  0.9107544049620628 | Validation Accurancy:  0.8801579773426056\n",
      "Epoch:  2717 | Train Accurancy:  0.9107661247253418 | Validation Accurancy:  0.8801823854446411\n",
      "Epoch:  2718 | Train Accurancy:  0.9107778891921043 | Validation Accurancy:  0.8802064135670662\n",
      "Epoch:  2719 | Train Accurancy:  0.9107895940542221 | Validation Accurancy:  0.880230501294136\n",
      "Epoch:  2720 | Train Accurancy:  0.9108013212680817 | Validation Accurancy:  0.8802545145153999\n",
      "Epoch:  2721 | Train Accurancy:  0.9108131006360054 | Validation Accurancy:  0.8802784755825996\n",
      "Epoch:  2722 | Train Accurancy:  0.9108248129487038 | Validation Accurancy:  0.8803024813532829\n",
      "Epoch:  2723 | Train Accurancy:  0.9108364656567574 | Validation Accurancy:  0.8803262487053871\n",
      "Epoch:  2724 | Train Accurancy:  0.9108481556177139 | Validation Accurancy:  0.8803499564528465\n",
      "Epoch:  2725 | Train Accurancy:  0.9108598530292511 | Validation Accurancy:  0.8803738653659821\n",
      "Epoch:  2726 | Train Accurancy:  0.9108714833855629 | Validation Accurancy:  0.8803976848721504\n",
      "Epoch:  2727 | Train Accurancy:  0.9108830466866493 | Validation Accurancy:  0.8804212883114815\n",
      "Epoch:  2728 | Train Accurancy:  0.9108947440981865 | Validation Accurancy:  0.8804450482130051\n",
      "Epoch:  2729 | Train Accurancy:  0.9109063819050789 | Validation Accurancy:  0.8804688453674316\n",
      "Epoch:  2730 | Train Accurancy:  0.9109180197119713 | Validation Accurancy:  0.8804924115538597\n",
      "Epoch:  2731 | Train Accurancy:  0.9109296053647995 | Validation Accurancy:  0.8805161342024803\n",
      "Epoch:  2732 | Train Accurancy:  0.9109412059187889 | Validation Accurancy:  0.8805397525429726\n",
      "Epoch:  2733 | Train Accurancy:  0.9109528064727783 | Validation Accurancy:  0.880563497543335\n",
      "Epoch:  2734 | Train Accurancy:  0.910964347422123 | Validation Accurancy:  0.880587175488472\n",
      "Epoch:  2735 | Train Accurancy:  0.91097591817379 | Validation Accurancy:  0.8806108236312866\n",
      "Epoch:  2736 | Train Accurancy:  0.9109875187277794 | Validation Accurancy:  0.8806343898177147\n",
      "Epoch:  2737 | Train Accurancy:  0.910999022424221 | Validation Accurancy:  0.8806580081582069\n",
      "Epoch:  2738 | Train Accurancy:  0.9110105708241463 | Validation Accurancy:  0.880681648850441\n",
      "Epoch:  2739 | Train Accurancy:  0.9110221192240715 | Validation Accurancy:  0.8807052224874496\n",
      "Epoch:  2740 | Train Accurancy:  0.9110336154699326 | Validation Accurancy:  0.8807286992669106\n",
      "Epoch:  2741 | Train Accurancy:  0.9110451266169548 | Validation Accurancy:  0.8807522505521774\n",
      "Epoch:  2742 | Train Accurancy:  0.9110566526651382 | Validation Accurancy:  0.8807757571339607\n",
      "Epoch:  2743 | Train Accurancy:  0.9110681340098381 | Validation Accurancy:  0.880799263715744\n",
      "Epoch:  2744 | Train Accurancy:  0.9110796377062798 | Validation Accurancy:  0.8808227404952049\n",
      "Epoch:  2745 | Train Accurancy:  0.911091037094593 | Validation Accurancy:  0.8808462843298912\n",
      "Epoch:  2746 | Train Accurancy:  0.9111025184392929 | Validation Accurancy:  0.8808696568012238\n",
      "Epoch:  2747 | Train Accurancy:  0.9111139327287674 | Validation Accurancy:  0.8808931782841682\n",
      "Epoch:  2748 | Train Accurancy:  0.9111254066228867 | Validation Accurancy:  0.8809165954589844\n",
      "Epoch:  2749 | Train Accurancy:  0.9111368358135223 | Validation Accurancy:  0.8809401020407677\n",
      "Epoch:  2750 | Train Accurancy:  0.9111482575535774 | Validation Accurancy:  0.8809634521603584\n",
      "Epoch:  2751 | Train Accurancy:  0.9111596122384071 | Validation Accurancy:  0.880986824631691\n",
      "Epoch:  2752 | Train Accurancy:  0.9111710265278816 | Validation Accurancy:  0.8810102194547653\n",
      "Epoch:  2753 | Train Accurancy:  0.9111824408173561 | Validation Accurancy:  0.8810334876179695\n",
      "Epoch:  2754 | Train Accurancy:  0.9111938029527664 | Validation Accurancy:  0.8810568526387215\n",
      "Epoch:  2755 | Train Accurancy:  0.9112051725387573 | Validation Accurancy:  0.8810802921652794\n",
      "Epoch:  2756 | Train Accurancy:  0.9112165495753288 | Validation Accurancy:  0.8811035081744194\n",
      "Epoch:  2757 | Train Accurancy:  0.911227859556675 | Validation Accurancy:  0.8811268582940102\n",
      "Epoch:  2758 | Train Accurancy:  0.9112392365932465 | Validation Accurancy:  0.8811501041054726\n",
      "Epoch:  2759 | Train Accurancy:  0.911250539124012 | Validation Accurancy:  0.8811734467744827\n",
      "Epoch:  2760 | Train Accurancy:  0.9112618789076805 | Validation Accurancy:  0.8811967745423317\n",
      "Epoch:  2761 | Train Accurancy:  0.9112731739878654 | Validation Accurancy:  0.8812199980020523\n",
      "Epoch:  2762 | Train Accurancy:  0.9112844690680504 | Validation Accurancy:  0.8812431842088699\n",
      "Epoch:  2763 | Train Accurancy:  0.9112957715988159 | Validation Accurancy:  0.8812663853168488\n",
      "Epoch:  2764 | Train Accurancy:  0.9113069996237755 | Validation Accurancy:  0.8812895640730858\n",
      "Epoch:  2765 | Train Accurancy:  0.911318264901638 | Validation Accurancy:  0.8813128545880318\n",
      "Epoch:  2766 | Train Accurancy:  0.9113295450806618 | Validation Accurancy:  0.8813360705971718\n",
      "Epoch:  2767 | Train Accurancy:  0.9113408029079437 | Validation Accurancy:  0.8813591748476028\n",
      "Epoch:  2768 | Train Accurancy:  0.9113520309329033 | Validation Accurancy:  0.8813823089003563\n",
      "Epoch:  2769 | Train Accurancy:  0.9113632515072823 | Validation Accurancy:  0.8814054504036903\n",
      "Epoch:  2770 | Train Accurancy:  0.9113744795322418 | Validation Accurancy:  0.8814285025000572\n",
      "Epoch:  2771 | Train Accurancy:  0.9113857001066208 | Validation Accurancy:  0.8814516738057137\n",
      "Epoch:  2772 | Train Accurancy:  0.9113969132304192 | Validation Accurancy:  0.8814748600125313\n",
      "Epoch:  2773 | Train Accurancy:  0.9114080667495728 | Validation Accurancy:  0.8814978525042534\n",
      "Epoch:  2774 | Train Accurancy:  0.911419227719307 | Validation Accurancy:  0.8815209046006203\n",
      "Epoch:  2775 | Train Accurancy:  0.9114304333925247 | Validation Accurancy:  0.8815440312027931\n",
      "Epoch:  2776 | Train Accurancy:  0.9114415645599365 | Validation Accurancy:  0.8815669864416122\n",
      "Epoch:  2777 | Train Accurancy:  0.9114527329802513 | Validation Accurancy:  0.8815900310873985\n",
      "Epoch:  2778 | Train Accurancy:  0.9114639088511467 | Validation Accurancy:  0.8816129341721535\n",
      "Epoch:  2779 | Train Accurancy:  0.9114750400185585 | Validation Accurancy:  0.8816360458731651\n",
      "Epoch:  2780 | Train Accurancy:  0.9114861562848091 | Validation Accurancy:  0.881659097969532\n",
      "Epoch:  2781 | Train Accurancy:  0.9114971980452538 | Validation Accurancy:  0.881682001054287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2782 | Train Accurancy:  0.9115083441138268 | Validation Accurancy:  0.8817049488425255\n",
      "Epoch:  2783 | Train Accurancy:  0.9115194007754326 | Validation Accurancy:  0.8817278817296028\n",
      "Epoch:  2784 | Train Accurancy:  0.9115304797887802 | Validation Accurancy:  0.8817508146166801\n",
      "Epoch:  2785 | Train Accurancy:  0.9115415811538696 | Validation Accurancy:  0.8817736729979515\n",
      "Epoch:  2786 | Train Accurancy:  0.9115526750683784 | Validation Accurancy:  0.8817966431379318\n",
      "Epoch:  2787 | Train Accurancy:  0.9115636348724365 | Validation Accurancy:  0.8818195313215256\n",
      "Epoch:  2788 | Train Accurancy:  0.9115747511386871 | Validation Accurancy:  0.8818424269556999\n",
      "Epoch:  2789 | Train Accurancy:  0.9115858003497124 | Validation Accurancy:  0.8818652629852295\n",
      "Epoch:  2790 | Train Accurancy:  0.9115968197584152 | Validation Accurancy:  0.8818880617618561\n",
      "Epoch:  2791 | Train Accurancy:  0.9116078317165375 | Validation Accurancy:  0.881910927593708\n",
      "Epoch:  2792 | Train Accurancy:  0.9116187989711761 | Validation Accurancy:  0.881933718919754\n",
      "Epoch:  2793 | Train Accurancy:  0.9116298258304596 | Validation Accurancy:  0.8819565922021866\n",
      "Epoch:  2794 | Train Accurancy:  0.9116408079862595 | Validation Accurancy:  0.8819792941212654\n",
      "Epoch:  2795 | Train Accurancy:  0.9116517752408981 | Validation Accurancy:  0.8820020779967308\n",
      "Epoch:  2796 | Train Accurancy:  0.911662720143795 | Validation Accurancy:  0.8820248022675514\n",
      "Epoch:  2797 | Train Accurancy:  0.9116736873984337 | Validation Accurancy:  0.8820474818348885\n",
      "Epoch:  2798 | Train Accurancy:  0.9116846397519112 | Validation Accurancy:  0.8820703029632568\n",
      "Epoch:  2799 | Train Accurancy:  0.9116955995559692 | Validation Accurancy:  0.882093071937561\n",
      "Epoch:  2800 | Train Accurancy:  0.9117064923048019 | Validation Accurancy:  0.8821157440543175\n",
      "Epoch:  2801 | Train Accurancy:  0.9117174446582794 | Validation Accurancy:  0.8821383789181709\n",
      "Epoch:  2802 | Train Accurancy:  0.9117283597588539 | Validation Accurancy:  0.8821610510349274\n",
      "Epoch:  2803 | Train Accurancy:  0.911739245057106 | Validation Accurancy:  0.8821837902069092\n",
      "Epoch:  2804 | Train Accurancy:  0.9117501303553581 | Validation Accurancy:  0.8822063431143761\n",
      "Epoch:  2805 | Train Accurancy:  0.9117610082030296 | Validation Accurancy:  0.8822290897369385\n",
      "Epoch:  2806 | Train Accurancy:  0.9117719084024429 | Validation Accurancy:  0.8822515979409218\n",
      "Epoch:  2807 | Train Accurancy:  0.9117828086018562 | Validation Accurancy:  0.88227429240942\n",
      "Epoch:  2808 | Train Accurancy:  0.911793626844883 | Validation Accurancy:  0.8822967857122421\n",
      "Epoch:  2809 | Train Accurancy:  0.9118044003844261 | Validation Accurancy:  0.8823193684220314\n",
      "Epoch:  2810 | Train Accurancy:  0.9118152782320976 | Validation Accurancy:  0.8823419585824013\n",
      "Epoch:  2811 | Train Accurancy:  0.9118261486291885 | Validation Accurancy:  0.8823645785450935\n",
      "Epoch:  2812 | Train Accurancy:  0.9118369519710541 | Validation Accurancy:  0.8823871165513992\n",
      "Epoch:  2813 | Train Accurancy:  0.9118477776646614 | Validation Accurancy:  0.8824095353484154\n",
      "Epoch:  2814 | Train Accurancy:  0.911858581006527 | Validation Accurancy:  0.882432110607624\n",
      "Epoch:  2815 | Train Accurancy:  0.9118693396449089 | Validation Accurancy:  0.882454589009285\n",
      "Epoch:  2816 | Train Accurancy:  0.9118801355361938 | Validation Accurancy:  0.8824771344661713\n",
      "Epoch:  2817 | Train Accurancy:  0.9118909016251564 | Validation Accurancy:  0.8824995458126068\n",
      "Epoch:  2818 | Train Accurancy:  0.9119016230106354 | Validation Accurancy:  0.8825220391154289\n",
      "Epoch:  2819 | Train Accurancy:  0.9119124338030815 | Validation Accurancy:  0.8825444728136063\n",
      "Epoch:  2820 | Train Accurancy:  0.9119231253862381 | Validation Accurancy:  0.8825668469071388\n",
      "Epoch:  2821 | Train Accurancy:  0.9119338765740395 | Validation Accurancy:  0.8825893625617027\n",
      "Epoch:  2822 | Train Accurancy:  0.9119446352124214 | Validation Accurancy:  0.8826116621494293\n",
      "Epoch:  2823 | Train Accurancy:  0.911955326795578 | Validation Accurancy:  0.8826341181993484\n",
      "Epoch:  2824 | Train Accurancy:  0.91196608543396 | Validation Accurancy:  0.8826564848423004\n",
      "Epoch:  2825 | Train Accurancy:  0.9119767621159554 | Validation Accurancy:  0.8826788142323494\n",
      "Epoch:  2826 | Train Accurancy:  0.9119874238967896 | Validation Accurancy:  0.882701151072979\n",
      "Epoch:  2827 | Train Accurancy:  0.9119981750845909 | Validation Accurancy:  0.8827234581112862\n",
      "Epoch:  2828 | Train Accurancy:  0.9120087772607803 | Validation Accurancy:  0.8827458471059799\n",
      "Epoch:  2829 | Train Accurancy:  0.9120193868875504 | Validation Accurancy:  0.8827680870890617\n",
      "Epoch:  2830 | Train Accurancy:  0.9120301231741905 | Validation Accurancy:  0.8827904015779495\n",
      "Epoch:  2831 | Train Accurancy:  0.9120407626032829 | Validation Accurancy:  0.8828127011656761\n",
      "Epoch:  2832 | Train Accurancy:  0.912051372230053 | Validation Accurancy:  0.8828350827097893\n",
      "Epoch:  2833 | Train Accurancy:  0.91206194460392 | Validation Accurancy:  0.8828572258353233\n",
      "Epoch:  2834 | Train Accurancy:  0.912072591483593 | Validation Accurancy:  0.8828794062137604\n",
      "Epoch:  2835 | Train Accurancy:  0.9120831713080406 | Validation Accurancy:  0.882901668548584\n",
      "Epoch:  2836 | Train Accurancy:  0.9120937585830688 | Validation Accurancy:  0.8829239457845688\n",
      "Epoch:  2837 | Train Accurancy:  0.9121043980121613 | Validation Accurancy:  0.8829460814595222\n",
      "Epoch:  2838 | Train Accurancy:  0.9121149927377701 | Validation Accurancy:  0.882968358695507\n",
      "Epoch:  2839 | Train Accurancy:  0.9121255725622177 | Validation Accurancy:  0.8829904124140739\n",
      "Epoch:  2840 | Train Accurancy:  0.9121361151337624 | Validation Accurancy:  0.8830125778913498\n",
      "Epoch:  2841 | Train Accurancy:  0.912146657705307 | Validation Accurancy:  0.883034773170948\n",
      "Epoch:  2842 | Train Accurancy:  0.9121572077274323 | Validation Accurancy:  0.8830569013953209\n",
      "Epoch:  2843 | Train Accurancy:  0.9121677577495575 | Validation Accurancy:  0.8830790296196938\n",
      "Epoch:  2844 | Train Accurancy:  0.9121783003211021 | Validation Accurancy:  0.8831012025475502\n",
      "Epoch:  2845 | Train Accurancy:  0.912188783288002 | Validation Accurancy:  0.8831232562661171\n",
      "Epoch:  2846 | Train Accurancy:  0.9121992886066437 | Validation Accurancy:  0.8831452503800392\n",
      "Epoch:  2847 | Train Accurancy:  0.9122097790241241 | Validation Accurancy:  0.8831673935055733\n",
      "Epoch:  2848 | Train Accurancy:  0.9122203141450882 | Validation Accurancy:  0.8831894248723984\n",
      "Epoch:  2849 | Train Accurancy:  0.9122307375073433 | Validation Accurancy:  0.8832114860415459\n",
      "Epoch:  2850 | Train Accurancy:  0.912241242825985 | Validation Accurancy:  0.8832335025072098\n",
      "Epoch:  2851 | Train Accurancy:  0.9122517108917236 | Validation Accurancy:  0.8832554668188095\n",
      "Epoch:  2852 | Train Accurancy:  0.9122621715068817 | Validation Accurancy:  0.88327756524086\n",
      "Epoch:  2853 | Train Accurancy:  0.9122726023197174 | Validation Accurancy:  0.8832995072007179\n",
      "Epoch:  2854 | Train Accurancy:  0.9122830256819725 | Validation Accurancy:  0.8833215311169624\n",
      "Epoch:  2855 | Train Accurancy:  0.9122934639453888 | Validation Accurancy:  0.8833433762192726\n",
      "Epoch:  2856 | Train Accurancy:  0.9123039096593857 | Validation Accurancy:  0.8833654150366783\n",
      "Epoch:  2857 | Train Accurancy:  0.9123142883181572 | Validation Accurancy:  0.8833874017000198\n",
      "Epoch:  2858 | Train Accurancy:  0.9123247042298317 | Validation Accurancy:  0.8834091648459435\n",
      "Epoch:  2859 | Train Accurancy:  0.9123351275920868 | Validation Accurancy:  0.8834312111139297\n",
      "Epoch:  2860 | Train Accurancy:  0.9123454615473747 | Validation Accurancy:  0.8834530487656593\n",
      "Epoch:  2861 | Train Accurancy:  0.9123558327555656 | Validation Accurancy:  0.8834749236702919\n",
      "Epoch:  2862 | Train Accurancy:  0.9123661890625954 | Validation Accurancy:  0.8834968060255051\n",
      "Epoch:  2863 | Train Accurancy:  0.9123765751719475 | Validation Accurancy:  0.8835186660289764\n",
      "Epoch:  2864 | Train Accurancy:  0.9123869463801384 | Validation Accurancy:  0.8835405334830284\n",
      "Epoch:  2865 | Train Accurancy:  0.9123972654342651 | Validation Accurancy:  0.8835588991641998\n",
      "Epoch:  2866 | Train Accurancy:  0.9124076291918755 | Validation Accurancy:  0.8835818842053413\n",
      "Epoch:  2867 | Train Accurancy:  0.9124179184436798 | Validation Accurancy:  0.8836008086800575\n",
      "Epoch:  2868 | Train Accurancy:  0.912428230047226 | Validation Accurancy:  0.8836208283901215\n",
      "Epoch:  2869 | Train Accurancy:  0.9124385118484497 | Validation Accurancy:  0.8836412280797958\n",
      "Epoch:  2870 | Train Accurancy:  0.9124488085508347 | Validation Accurancy:  0.8836619704961777\n",
      "Epoch:  2871 | Train Accurancy:  0.9124591276049614 | Validation Accurancy:  0.883683018386364\n",
      "Epoch:  2872 | Train Accurancy:  0.912469394505024 | Validation Accurancy:  0.8837076798081398\n",
      "Epoch:  2873 | Train Accurancy:  0.9124796763062477 | Validation Accurancy:  0.88372802734375\n",
      "Epoch:  2874 | Train Accurancy:  0.9124899059534073 | Validation Accurancy:  0.8837486952543259\n",
      "Epoch:  2875 | Train Accurancy:  0.9125001356005669 | Validation Accurancy:  0.8837696239352226\n",
      "Epoch:  2876 | Train Accurancy:  0.9125104770064354 | Validation Accurancy:  0.883790872991085\n",
      "Epoch:  2877 | Train Accurancy:  0.9125206544995308 | Validation Accurancy:  0.8838121518492699\n",
      "Epoch:  2878 | Train Accurancy:  0.9125308245420456 | Validation Accurancy:  0.8838334828615189\n",
      "Epoch:  2879 | Train Accurancy:  0.9125410541892052 | Validation Accurancy:  0.8838548883795738\n",
      "Epoch:  2880 | Train Accurancy:  0.912551261484623 | Validation Accurancy:  0.8838763311505318\n",
      "Epoch:  2881 | Train Accurancy:  0.9125614613294601 | Validation Accurancy:  0.8838978186249733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2882 | Train Accurancy:  0.9125716835260391 | Validation Accurancy:  0.8839192241430283\n",
      "Epoch:  2883 | Train Accurancy:  0.9125818461179733 | Validation Accurancy:  0.8839407414197922\n",
      "Epoch:  2884 | Train Accurancy:  0.9125920310616493 | Validation Accurancy:  0.8839622512459755\n",
      "Epoch:  2885 | Train Accurancy:  0.9126021489501 | Validation Accurancy:  0.8839837461709976\n",
      "Epoch:  2886 | Train Accurancy:  0.9126123487949371 | Validation Accurancy:  0.8840051516890526\n",
      "Epoch:  2887 | Train Accurancy:  0.9126224592328072 | Validation Accurancy:  0.8840266317129135\n",
      "Epoch:  2888 | Train Accurancy:  0.9126326069235802 | Validation Accurancy:  0.8840480968356133\n",
      "Epoch:  2889 | Train Accurancy:  0.9126427620649338 | Validation Accurancy:  0.8840695172548294\n",
      "Epoch:  2890 | Train Accurancy:  0.9126528650522232 | Validation Accurancy:  0.8840908706188202\n",
      "Epoch:  2891 | Train Accurancy:  0.9126629903912544 | Validation Accurancy:  0.8841123431921005\n",
      "Epoch:  2892 | Train Accurancy:  0.9126730635762215 | Validation Accurancy:  0.8841337338089943\n",
      "Epoch:  2893 | Train Accurancy:  0.9126831665635109 | Validation Accurancy:  0.8841551393270493\n",
      "Epoch:  2894 | Train Accurancy:  0.9126932397484779 | Validation Accurancy:  0.8841764852404594\n",
      "Epoch:  2895 | Train Accurancy:  0.9127033427357674 | Validation Accurancy:  0.8841979429125786\n",
      "Epoch:  2896 | Train Accurancy:  0.9127134159207344 | Validation Accurancy:  0.8842191696166992\n",
      "Epoch:  2897 | Train Accurancy:  0.912723496556282 | Validation Accurancy:  0.8842404633760452\n",
      "Epoch:  2898 | Train Accurancy:  0.9127335622906685 | Validation Accurancy:  0.8842618763446808\n",
      "Epoch:  2899 | Train Accurancy:  0.9127435833215714 | Validation Accurancy:  0.884283110499382\n",
      "Epoch:  2900 | Train Accurancy:  0.9127535969018936 | Validation Accurancy:  0.884304404258728\n",
      "Epoch:  2901 | Train Accurancy:  0.9127636253833771 | Validation Accurancy:  0.8843257650732994\n",
      "Epoch:  2902 | Train Accurancy:  0.9127736389636993 | Validation Accurancy:  0.8843470439314842\n",
      "Epoch:  2903 | Train Accurancy:  0.9127837046980858 | Validation Accurancy:  0.8843682706356049\n",
      "Epoch:  2904 | Train Accurancy:  0.9127936512231827 | Validation Accurancy:  0.8843895643949509\n",
      "Epoch:  2905 | Train Accurancy:  0.9128036573529243 | Validation Accurancy:  0.8844108358025551\n",
      "Epoch:  2906 | Train Accurancy:  0.9128136485815048 | Validation Accurancy:  0.8844320252537727\n",
      "Epoch:  2907 | Train Accurancy:  0.9128236100077629 | Validation Accurancy:  0.8844533115625381\n",
      "Epoch:  2908 | Train Accurancy:  0.9128335863351822 | Validation Accurancy:  0.8844744935631752\n",
      "Epoch:  2909 | Train Accurancy:  0.9128435328602791 | Validation Accurancy:  0.8844956532120705\n",
      "Epoch:  2910 | Train Accurancy:  0.9128535464406013 | Validation Accurancy:  0.8845168277621269\n",
      "Epoch:  2911 | Train Accurancy:  0.9128634557127953 | Validation Accurancy:  0.8845380321145058\n",
      "Epoch:  2912 | Train Accurancy:  0.9128734096884727 | Validation Accurancy:  0.8845590874552727\n",
      "Epoch:  2913 | Train Accurancy:  0.912883348762989 | Validation Accurancy:  0.8845802545547485\n",
      "Epoch:  2914 | Train Accurancy:  0.9128932654857635 | Validation Accurancy:  0.884601466357708\n",
      "Epoch:  2915 | Train Accurancy:  0.9129031598567963 | Validation Accurancy:  0.8846226409077644\n",
      "Epoch:  2916 | Train Accurancy:  0.9129131138324738 | Validation Accurancy:  0.8846437186002731\n",
      "Epoch:  2917 | Train Accurancy:  0.9129229784011841 | Validation Accurancy:  0.8846648186445236\n",
      "Epoch:  2918 | Train Accurancy:  0.9129328802227974 | Validation Accurancy:  0.8846858367323875\n",
      "Epoch:  2919 | Train Accurancy:  0.9129427596926689 | Validation Accurancy:  0.8847069516777992\n",
      "Epoch:  2920 | Train Accurancy:  0.9129526168107986 | Validation Accurancy:  0.8847280070185661\n",
      "Epoch:  2921 | Train Accurancy:  0.9129624664783478 | Validation Accurancy:  0.8847490400075912\n",
      "Epoch:  2922 | Train Accurancy:  0.9129723384976387 | Validation Accurancy:  0.8847700729966164\n",
      "Epoch:  2923 | Train Accurancy:  0.9129821360111237 | Validation Accurancy:  0.8847911059856415\n",
      "Epoch:  2924 | Train Accurancy:  0.9129920154809952 | Validation Accurancy:  0.8848121836781502\n",
      "Epoch:  2925 | Train Accurancy:  0.9130018576979637 | Validation Accurancy:  0.8848331496119499\n",
      "Epoch:  2926 | Train Accurancy:  0.9130116775631905 | Validation Accurancy:  0.8848540857434273\n",
      "Epoch:  2927 | Train Accurancy:  0.9130215123295784 | Validation Accurancy:  0.8848750442266464\n",
      "Epoch:  2928 | Train Accurancy:  0.913031317293644 | Validation Accurancy:  0.8848960772156715\n",
      "Epoch:  2929 | Train Accurancy:  0.9130410999059677 | Validation Accurancy:  0.8849169090390205\n",
      "Epoch:  2930 | Train Accurancy:  0.9130509197711945 | Validation Accurancy:  0.8849380016326904\n",
      "Epoch:  2931 | Train Accurancy:  0.9130606576800346 | Validation Accurancy:  0.8849589303135872\n",
      "Epoch:  2932 | Train Accurancy:  0.9130704253911972 | Validation Accurancy:  0.8849797621369362\n",
      "Epoch:  2933 | Train Accurancy:  0.913080245256424 | Validation Accurancy:  0.88499915599823\n",
      "Epoch:  2934 | Train Accurancy:  0.9130899533629417 | Validation Accurancy:  0.8850205168128014\n",
      "Epoch:  2935 | Train Accurancy:  0.9130997359752655 | Validation Accurancy:  0.8850417211651802\n",
      "Epoch:  2936 | Train Accurancy:  0.9131094664335251 | Validation Accurancy:  0.8850629478693008\n",
      "Epoch:  2937 | Train Accurancy:  0.9131192117929459 | Validation Accurancy:  0.885083943605423\n",
      "Epoch:  2938 | Train Accurancy:  0.9131289273500443 | Validation Accurancy:  0.8851049318909645\n",
      "Epoch:  2939 | Train Accurancy:  0.9131385907530785 | Validation Accurancy:  0.8851258307695389\n",
      "Epoch:  2940 | Train Accurancy:  0.913148321211338 | Validation Accurancy:  0.8851451724767685\n",
      "Epoch:  2941 | Train Accurancy:  0.913158044219017 | Validation Accurancy:  0.8851664960384369\n",
      "Epoch:  2942 | Train Accurancy:  0.9131677448749542 | Validation Accurancy:  0.8851876929402351\n",
      "Epoch:  2943 | Train Accurancy:  0.9131774678826332 | Validation Accurancy:  0.8852086886763573\n",
      "Epoch:  2944 | Train Accurancy:  0.9131871089339256 | Validation Accurancy:  0.8852297067642212\n",
      "Epoch:  2945 | Train Accurancy:  0.9131967797875404 | Validation Accurancy:  0.885250598192215\n",
      "Epoch:  2946 | Train Accurancy:  0.913206435739994 | Validation Accurancy:  0.8852714374661446\n",
      "Epoch:  2947 | Train Accurancy:  0.9132160916924477 | Validation Accurancy:  0.8852906450629234\n",
      "Epoch:  2948 | Train Accurancy:  0.9132257550954819 | Validation Accurancy:  0.8853118717670441\n",
      "Epoch:  2949 | Train Accurancy:  0.9132353812456131 | Validation Accurancy:  0.885332964360714\n",
      "Epoch:  2950 | Train Accurancy:  0.9132450148463249 | Validation Accurancy:  0.8853539377450943\n",
      "Epoch:  2951 | Train Accurancy:  0.9132546558976173 | Validation Accurancy:  0.8853747844696045\n",
      "Epoch:  2952 | Train Accurancy:  0.9132642671465874 | Validation Accurancy:  0.8853956386446953\n",
      "Epoch:  2953 | Train Accurancy:  0.913273885846138 | Validation Accurancy:  0.8854164332151413\n",
      "Epoch:  2954 | Train Accurancy:  0.913283459842205 | Validation Accurancy:  0.8854370564222336\n",
      "Epoch:  2955 | Train Accurancy:  0.9132930487394333 | Validation Accurancy:  0.8854562789201736\n",
      "Epoch:  2956 | Train Accurancy:  0.9133026599884033 | Validation Accurancy:  0.8854773864150047\n",
      "Epoch:  2957 | Train Accurancy:  0.9133122190833092 | Validation Accurancy:  0.8854984194040298\n",
      "Epoch:  2958 | Train Accurancy:  0.9133217856287956 | Validation Accurancy:  0.8855193331837654\n",
      "Epoch:  2959 | Train Accurancy:  0.9133313372731209 | Validation Accurancy:  0.8855400383472443\n",
      "Epoch:  2960 | Train Accurancy:  0.9133408889174461 | Validation Accurancy:  0.8855607211589813\n",
      "Epoch:  2961 | Train Accurancy:  0.9133504629135132 | Validation Accurancy:  0.885581411421299\n",
      "Epoch:  2962 | Train Accurancy:  0.9133600443601608 | Validation Accurancy:  0.8856021240353584\n",
      "Epoch:  2963 | Train Accurancy:  0.9133694916963577 | Validation Accurancy:  0.8856209814548492\n",
      "Epoch:  2964 | Train Accurancy:  0.9133789986371994 | Validation Accurancy:  0.8856421858072281\n",
      "Epoch:  2965 | Train Accurancy:  0.9133885055780411 | Validation Accurancy:  0.8856629133224487\n",
      "Epoch:  2966 | Train Accurancy:  0.9133981019258499 | Validation Accurancy:  0.8856838420033455\n",
      "Epoch:  2967 | Train Accurancy:  0.9134075790643692 | Validation Accurancy:  0.8857045471668243\n",
      "Epoch:  2968 | Train Accurancy:  0.9134170636534691 | Validation Accurancy:  0.8857251033186913\n",
      "Epoch:  2969 | Train Accurancy:  0.9134265035390854 | Validation Accurancy:  0.8857457190752029\n",
      "Epoch:  2970 | Train Accurancy:  0.9134360030293465 | Validation Accurancy:  0.8857662752270699\n",
      "Epoch:  2971 | Train Accurancy:  0.913445457816124 | Validation Accurancy:  0.8857866749167442\n",
      "Epoch:  2972 | Train Accurancy:  0.9134549349546432 | Validation Accurancy:  0.8858072683215141\n",
      "Epoch:  2973 | Train Accurancy:  0.9134643897414207 | Validation Accurancy:  0.8858260661363602\n",
      "Epoch:  2974 | Train Accurancy:  0.9134738445281982 | Validation Accurancy:  0.8858470767736435\n",
      "Epoch:  2975 | Train Accurancy:  0.9134832546114922 | Validation Accurancy:  0.8858679234981537\n",
      "Epoch:  2976 | Train Accurancy:  0.9134926572442055 | Validation Accurancy:  0.8858885616064072\n",
      "Epoch:  2977 | Train Accurancy:  0.9135020673274994 | Validation Accurancy:  0.8859089985489845\n",
      "Epoch:  2978 | Train Accurancy:  0.9135115444660187 | Validation Accurancy:  0.8859295323491096\n",
      "Epoch:  2979 | Train Accurancy:  0.9135209321975708 | Validation Accurancy:  0.8859500214457512\n",
      "Epoch:  2980 | Train Accurancy:  0.9135303646326065 | Validation Accurancy:  0.8859703466296196\n",
      "Epoch:  2981 | Train Accurancy:  0.9135396853089333 | Validation Accurancy:  0.8859907388687134\n",
      "Epoch:  2982 | Train Accurancy:  0.9135491102933884 | Validation Accurancy:  0.8860111758112907\n",
      "Epoch:  2983 | Train Accurancy:  0.9135584533214569 | Validation Accurancy:  0.8860314637422562\n",
      "Epoch:  2984 | Train Accurancy:  0.9135678485035896 | Validation Accurancy:  0.886051818728447\n",
      "Epoch:  2985 | Train Accurancy:  0.9135772138834 | Validation Accurancy:  0.8860721215605736\n",
      "Epoch:  2986 | Train Accurancy:  0.9135865345597267 | Validation Accurancy:  0.8860910162329674\n",
      "Epoch:  2987 | Train Accurancy:  0.9135959148406982 | Validation Accurancy:  0.8861116021871567\n",
      "Epoch:  2988 | Train Accurancy:  0.9136052429676056 | Validation Accurancy:  0.8861322402954102\n",
      "Epoch:  2989 | Train Accurancy:  0.9136146232485771 | Validation Accurancy:  0.8861527889966965\n",
      "Epoch:  2990 | Train Accurancy:  0.9136239513754845 | Validation Accurancy:  0.886173240840435\n",
      "Epoch:  2991 | Train Accurancy:  0.9136331975460052 | Validation Accurancy:  0.88619364798069\n",
      "Epoch:  2992 | Train Accurancy:  0.9136425331234932 | Validation Accurancy:  0.8862137943506241\n",
      "Epoch:  2993 | Train Accurancy:  0.913651816546917 | Validation Accurancy:  0.8862341120839119\n",
      "Epoch:  2994 | Train Accurancy:  0.9136611521244049 | Validation Accurancy:  0.8862544000148773\n",
      "Epoch:  2995 | Train Accurancy:  0.9136703982949257 | Validation Accurancy:  0.8862745985388756\n",
      "Epoch:  2996 | Train Accurancy:  0.91367968916893 | Validation Accurancy:  0.886294849216938\n",
      "Epoch:  2997 | Train Accurancy:  0.9136889651417732 | Validation Accurancy:  0.8863149061799049\n",
      "Epoch:  2998 | Train Accurancy:  0.9136982336640358 | Validation Accurancy:  0.8863352239131927\n",
      "Epoch:  2999 | Train Accurancy:  0.9137074276804924 | Validation Accurancy:  0.8863553702831268\n",
      "Epoch:  3000 | Train Accurancy:  0.9137167185544968 | Validation Accurancy:  0.8863753080368042\n",
      "Epoch:  3001 | Train Accurancy:  0.9137259721755981 | Validation Accurancy:  0.8863955289125443\n",
      "Epoch:  3002 | Train Accurancy:  0.9137352183461189 | Validation Accurancy:  0.8864156380295753\n",
      "Epoch:  3003 | Train Accurancy:  0.9137444123625755 | Validation Accurancy:  0.886435754597187\n",
      "Epoch:  3004 | Train Accurancy:  0.9137536808848381 | Validation Accurancy:  0.8864558041095734\n",
      "Epoch:  3005 | Train Accurancy:  0.9137629047036171 | Validation Accurancy:  0.8864758759737015\n",
      "Epoch:  3006 | Train Accurancy:  0.9137720689177513 | Validation Accurancy:  0.8864960670471191\n",
      "Epoch:  3007 | Train Accurancy:  0.9137812778353691 | Validation Accurancy:  0.8865160271525383\n",
      "Epoch:  3008 | Train Accurancy:  0.9137904644012451 | Validation Accurancy:  0.8865345790982246\n",
      "Epoch:  3009 | Train Accurancy:  0.9137996137142181 | Validation Accurancy:  0.8865550681948662\n",
      "Epoch:  3010 | Train Accurancy:  0.9138088226318359 | Validation Accurancy:  0.8865753337740898\n",
      "Epoch:  3011 | Train Accurancy:  0.913817971944809 | Validation Accurancy:  0.886595644056797\n",
      "Epoch:  3012 | Train Accurancy:  0.9138271361589432 | Validation Accurancy:  0.8866158574819565\n",
      "Epoch:  3013 | Train Accurancy:  0.9138362854719162 | Validation Accurancy:  0.8866358995437622\n",
      "Epoch:  3014 | Train Accurancy:  0.9138454720377922 | Validation Accurancy:  0.8866559192538261\n",
      "Epoch:  3015 | Train Accurancy:  0.9138545617461205 | Validation Accurancy:  0.8866760283708572\n",
      "Epoch:  3016 | Train Accurancy:  0.9138636961579323 | Validation Accurancy:  0.8866960480809212\n",
      "Epoch:  3017 | Train Accurancy:  0.9138728529214859 | Validation Accurancy:  0.8867159336805344\n",
      "Epoch:  3018 | Train Accurancy:  0.913881927728653 | Validation Accurancy:  0.8867358341813087\n",
      "Epoch:  3019 | Train Accurancy:  0.9138910993933678 | Validation Accurancy:  0.8867558613419533\n",
      "Epoch:  3020 | Train Accurancy:  0.913900151848793 | Validation Accurancy:  0.8867758139967918\n",
      "Epoch:  3021 | Train Accurancy:  0.9139092713594437 | Validation Accurancy:  0.8867957293987274\n",
      "Epoch:  3022 | Train Accurancy:  0.9139183312654495 | Validation Accurancy:  0.8868154659867287\n",
      "Epoch:  3023 | Train Accurancy:  0.9139274433255196 | Validation Accurancy:  0.8868355602025986\n",
      "Epoch:  3024 | Train Accurancy:  0.9139365330338478 | Validation Accurancy:  0.8868553414940834\n",
      "Epoch:  3025 | Train Accurancy:  0.9139455929398537 | Validation Accurancy:  0.8868751898407936\n",
      "Epoch:  3026 | Train Accurancy:  0.9139546677470207 | Validation Accurancy:  0.8868950083851814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3027 | Train Accurancy:  0.9139636531472206 | Validation Accurancy:  0.88691496104002\n",
      "Epoch:  3028 | Train Accurancy:  0.9139727279543877 | Validation Accurancy:  0.88693468272686\n",
      "Epoch:  3029 | Train Accurancy:  0.9139817580580711 | Validation Accurancy:  0.8869545236229897\n",
      "Epoch:  3030 | Train Accurancy:  0.9139907732605934 | Validation Accurancy:  0.886974386870861\n",
      "Epoch:  3031 | Train Accurancy:  0.9139997884631157 | Validation Accurancy:  0.8869941234588623\n",
      "Epoch:  3032 | Train Accurancy:  0.9140088483691216 | Validation Accurancy:  0.8870138600468636\n",
      "Epoch:  3033 | Train Accurancy:  0.9140178337693214 | Validation Accurancy:  0.8870336189866066\n",
      "Epoch:  3034 | Train Accurancy:  0.9140268564224243 | Validation Accurancy:  0.8870533406734467\n",
      "Epoch:  3035 | Train Accurancy:  0.9140358790755272 | Validation Accurancy:  0.8870731666684151\n",
      "Epoch:  3036 | Train Accurancy:  0.9140447899699211 | Validation Accurancy:  0.8870929777622223\n",
      "Epoch:  3037 | Train Accurancy:  0.9140538200736046 | Validation Accurancy:  0.8871127218008041\n",
      "Epoch:  3038 | Train Accurancy:  0.9140627458691597 | Validation Accurancy:  0.8871323764324188\n",
      "Epoch:  3039 | Train Accurancy:  0.9140717312693596 | Validation Accurancy:  0.8871520012617111\n",
      "Epoch:  3040 | Train Accurancy:  0.9140806570649147 | Validation Accurancy:  0.8871717602014542\n",
      "Epoch:  3041 | Train Accurancy:  0.9140896275639534 | Validation Accurancy:  0.8871914893388748\n",
      "Epoch:  3042 | Train Accurancy:  0.9140986129641533 | Validation Accurancy:  0.8872112035751343\n",
      "Epoch:  3043 | Train Accurancy:  0.9141075164079666 | Validation Accurancy:  0.8872308284044266\n",
      "Epoch:  3044 | Train Accurancy:  0.9141164496541023 | Validation Accurancy:  0.8872503787279129\n",
      "Epoch:  3045 | Train Accurancy:  0.9141253903508186 | Validation Accurancy:  0.8872700780630112\n",
      "Epoch:  3046 | Train Accurancy:  0.914134256541729 | Validation Accurancy:  0.8872897401452065\n",
      "Epoch:  3047 | Train Accurancy:  0.9141432046890259 | Validation Accurancy:  0.8873093202710152\n",
      "Epoch:  3048 | Train Accurancy:  0.9141521006822586 | Validation Accurancy:  0.8873288780450821\n",
      "Epoch:  3049 | Train Accurancy:  0.9141610041260719 | Validation Accurancy:  0.887348547577858\n",
      "Epoch:  3050 | Train Accurancy:  0.9141699075698853 | Validation Accurancy:  0.8873680979013443\n",
      "Epoch:  3051 | Train Accurancy:  0.914178803563118 | Validation Accurancy:  0.88738764077425\n",
      "Epoch:  3052 | Train Accurancy:  0.9141876325011253 | Validation Accurancy:  0.8874072209000587\n",
      "Epoch:  3053 | Train Accurancy:  0.9141965359449387 | Validation Accurancy:  0.8874267786741257\n",
      "Epoch:  3054 | Train Accurancy:  0.9142053797841072 | Validation Accurancy:  0.8874463215470314\n",
      "Epoch:  3055 | Train Accurancy:  0.9142142236232758 | Validation Accurancy:  0.8874659016728401\n",
      "Epoch:  3056 | Train Accurancy:  0.9142230823636055 | Validation Accurancy:  0.8874853402376175\n",
      "Epoch:  3057 | Train Accurancy:  0.9142319336533546 | Validation Accurancy:  0.8875049203634262\n",
      "Epoch:  3058 | Train Accurancy:  0.9142407104372978 | Validation Accurancy:  0.887524351477623\n",
      "Epoch:  3059 | Train Accurancy:  0.9142495170235634 | Validation Accurancy:  0.8875438868999481\n",
      "Epoch:  3060 | Train Accurancy:  0.9142583683133125 | Validation Accurancy:  0.8875633478164673\n",
      "Epoch:  3061 | Train Accurancy:  0.9142671972513199 | Validation Accurancy:  0.8875828683376312\n",
      "Epoch:  3062 | Train Accurancy:  0.9142760187387466 | Validation Accurancy:  0.887602262198925\n",
      "Epoch:  3063 | Train Accurancy:  0.9142848029732704 | Validation Accurancy:  0.8876217156648636\n",
      "Epoch:  3064 | Train Accurancy:  0.9142935648560524 | Validation Accurancy:  0.8876412957906723\n",
      "Epoch:  3065 | Train Accurancy:  0.9143023565411568 | Validation Accurancy:  0.8876605853438377\n",
      "Epoch:  3066 | Train Accurancy:  0.9143111780285835 | Validation Accurancy:  0.8876799792051315\n",
      "Epoch:  3067 | Train Accurancy:  0.9143199622631073 | Validation Accurancy:  0.8876993954181671\n",
      "Epoch:  3068 | Train Accurancy:  0.9143286794424057 | Validation Accurancy:  0.8877188637852669\n",
      "Epoch:  3069 | Train Accurancy:  0.9143374189734459 | Validation Accurancy:  0.8877381607890129\n",
      "Epoch:  3070 | Train Accurancy:  0.9143461659550667 | Validation Accurancy:  0.8877575397491455\n",
      "Epoch:  3071 | Train Accurancy:  0.9143549427390099 | Validation Accurancy:  0.8877769410610199\n",
      "Epoch:  3072 | Train Accurancy:  0.9143636971712112 | Validation Accurancy:  0.8877962157130241\n",
      "Epoch:  3073 | Train Accurancy:  0.9143723547458649 | Validation Accurancy:  0.8878156244754791\n",
      "Epoch:  3074 | Train Accurancy:  0.9143811464309692 | Validation Accurancy:  0.8878349810838699\n",
      "Epoch:  3075 | Train Accurancy:  0.9143898487091064 | Validation Accurancy:  0.8878542855381966\n",
      "Epoch:  3076 | Train Accurancy:  0.9143985733389854 | Validation Accurancy:  0.887873612344265\n",
      "Epoch:  3077 | Train Accurancy:  0.9144072830677032 | Validation Accurancy:  0.8878928646445274\n",
      "Epoch:  3078 | Train Accurancy:  0.9144159778952599 | Validation Accurancy:  0.8879121765494347\n",
      "Epoch:  3079 | Train Accurancy:  0.9144246354699135 | Validation Accurancy:  0.8879314139485359\n",
      "Epoch:  3080 | Train Accurancy:  0.9144333153963089 | Validation Accurancy:  0.8879506886005402\n",
      "Epoch:  3081 | Train Accurancy:  0.9144420102238655 | Validation Accurancy:  0.8879698738455772\n",
      "Epoch:  3082 | Train Accurancy:  0.9144506528973579 | Validation Accurancy:  0.8879891112446785\n",
      "Epoch:  3083 | Train Accurancy:  0.9144592806696892 | Validation Accurancy:  0.8880084902048111\n",
      "Epoch:  3084 | Train Accurancy:  0.9144679382443428 | Validation Accurancy:  0.8880275934934616\n",
      "Epoch:  3085 | Train Accurancy:  0.9144766181707382 | Validation Accurancy:  0.8880468308925629\n",
      "Epoch:  3086 | Train Accurancy:  0.9144852459430695 | Validation Accurancy:  0.8880660757422447\n",
      "Epoch:  3087 | Train Accurancy:  0.9144938811659813 | Validation Accurancy:  0.8880851939320564\n",
      "Epoch:  3088 | Train Accurancy:  0.9145024865865707 | Validation Accurancy:  0.8881043121218681\n",
      "Epoch:  3089 | Train Accurancy:  0.914511114358902 | Validation Accurancy:  0.8881235271692276\n",
      "Epoch:  3090 | Train Accurancy:  0.9145197346806526 | Validation Accurancy:  0.8881426081061363\n",
      "Epoch:  3091 | Train Accurancy:  0.9145283177495003 | Validation Accurancy:  0.8881617784500122\n",
      "Epoch:  3092 | Train Accurancy:  0.9145369753241539 | Validation Accurancy:  0.8881808742880821\n",
      "Epoch:  3093 | Train Accurancy:  0.9145455211400986 | Validation Accurancy:  0.8881999105215073\n",
      "Epoch:  3094 | Train Accurancy:  0.9145541414618492 | Validation Accurancy:  0.8882191330194473\n",
      "Epoch:  3095 | Train Accurancy:  0.9145627394318581 | Validation Accurancy:  0.8882381990551949\n",
      "Epoch:  3096 | Train Accurancy:  0.9145712926983833 | Validation Accurancy:  0.8882572278380394\n",
      "Epoch:  3097 | Train Accurancy:  0.9145798161625862 | Validation Accurancy:  0.8882764279842377\n",
      "Epoch:  3098 | Train Accurancy:  0.9145883247256279 | Validation Accurancy:  0.8882955238223076\n",
      "Epoch:  3099 | Train Accurancy:  0.9145969375967979 | Validation Accurancy:  0.8883146047592163\n",
      "Epoch:  3100 | Train Accurancy:  0.9146054834127426 | Validation Accurancy:  0.888333685696125\n",
      "Epoch:  3101 | Train Accurancy:  0.9146140366792679 | Validation Accurancy:  0.8883526995778084\n",
      "Epoch:  3102 | Train Accurancy:  0.9146225601434708 | Validation Accurancy:  0.8883717507123947\n",
      "Epoch:  3103 | Train Accurancy:  0.914631076157093 | Validation Accurancy:  0.8883906900882721\n",
      "Epoch:  3104 | Train Accurancy:  0.9146396368741989 | Validation Accurancy:  0.888409748673439\n",
      "Epoch:  3105 | Train Accurancy:  0.9146481305360794 | Validation Accurancy:  0.8884288221597672\n",
      "Epoch:  3106 | Train Accurancy:  0.9146566018462181 | Validation Accurancy:  0.8884478434920311\n",
      "Epoch:  3107 | Train Accurancy:  0.9146651327610016 | Validation Accurancy:  0.8884667828679085\n",
      "Epoch:  3108 | Train Accurancy:  0.9146735593676567 | Validation Accurancy:  0.8884857967495918\n",
      "Epoch:  3109 | Train Accurancy:  0.9146820828318596 | Validation Accurancy:  0.8885047063231468\n",
      "Epoch:  3110 | Train Accurancy:  0.9146905243396759 | Validation Accurancy:  0.8885236084461212\n",
      "Epoch:  3111 | Train Accurancy:  0.9146990403532982 | Validation Accurancy:  0.8885425701737404\n",
      "Epoch:  3112 | Train Accurancy:  0.9147074893116951 | Validation Accurancy:  0.888561561703682\n",
      "Epoch:  3113 | Train Accurancy:  0.9147160053253174 | Validation Accurancy:  0.8885805159807205\n",
      "Epoch:  3114 | Train Accurancy:  0.9147244393825531 | Validation Accurancy:  0.8885994255542755\n",
      "Epoch:  3115 | Train Accurancy:  0.9147328361868858 | Validation Accurancy:  0.8886183053255081\n",
      "Epoch:  3116 | Train Accurancy:  0.9147413149476051 | Validation Accurancy:  0.8886372298002243\n",
      "Epoch:  3117 | Train Accurancy:  0.9147497862577438 | Validation Accurancy:  0.8886561244726181\n",
      "Epoch:  3118 | Train Accurancy:  0.9147582054138184 | Validation Accurancy:  0.8886750042438507\n",
      "Epoch:  3119 | Train Accurancy:  0.9147666171193123 | Validation Accurancy:  0.8886938765645027\n",
      "Epoch:  3120 | Train Accurancy:  0.9147749915719032 | Validation Accurancy:  0.8887127935886383\n",
      "Epoch:  3121 | Train Accurancy:  0.9147834554314613 | Validation Accurancy:  0.8887315168976784\n",
      "Epoch:  3122 | Train Accurancy:  0.9147918447852135 | Validation Accurancy:  0.8887503370642662\n",
      "Epoch:  3123 | Train Accurancy:  0.9148002043366432 | Validation Accurancy:  0.8887691721320152\n",
      "Epoch:  3124 | Train Accurancy:  0.9148085787892342 | Validation Accurancy:  0.8887880221009254\n",
      "Epoch:  3125 | Train Accurancy:  0.9148169830441475 | Validation Accurancy:  0.8888068571686745\n",
      "Epoch:  3126 | Train Accurancy:  0.9148253574967384 | Validation Accurancy:  0.8888256102800369\n",
      "Epoch:  3127 | Train Accurancy:  0.9148337468504906 | Validation Accurancy:  0.8888444229960442\n",
      "Epoch:  3128 | Train Accurancy:  0.9148421362042427 | Validation Accurancy:  0.8888632506132126\n",
      "Epoch:  3129 | Train Accurancy:  0.9148504361510277 | Validation Accurancy:  0.888882003724575\n",
      "Epoch:  3130 | Train Accurancy:  0.914858765900135 | Validation Accurancy:  0.888896994292736\n",
      "Epoch:  3131 | Train Accurancy:  0.9148670732975006 | Validation Accurancy:  0.8889167830348015\n",
      "Epoch:  3132 | Train Accurancy:  0.9148754328489304 | Validation Accurancy:  0.8889326229691505\n",
      "Epoch:  3133 | Train Accurancy:  0.9148837774991989 | Validation Accurancy:  0.8889529705047607\n",
      "Epoch:  3134 | Train Accurancy:  0.9148921519517899 | Validation Accurancy:  0.8889691159129143\n",
      "Epoch:  3135 | Train Accurancy:  0.9149004966020584 | Validation Accurancy:  0.8889896869659424\n",
      "Epoch:  3136 | Train Accurancy:  0.914908766746521 | Validation Accurancy:  0.8890060037374496\n",
      "Epoch:  3137 | Train Accurancy:  0.9149170592427254 | Validation Accurancy:  0.8890266939997673\n",
      "Epoch:  3138 | Train Accurancy:  0.9149252995848656 | Validation Accurancy:  0.8890430778264999\n",
      "Epoch:  3139 | Train Accurancy:  0.9149336069822311 | Validation Accurancy:  0.8890599682927132\n",
      "Epoch:  3140 | Train Accurancy:  0.9149418845772743 | Validation Accurancy:  0.8890813142061234\n",
      "Epoch:  3141 | Train Accurancy:  0.9149501547217369 | Validation Accurancy:  0.8890979439020157\n",
      "Epoch:  3142 | Train Accurancy:  0.9149584919214249 | Validation Accurancy:  0.889118917286396\n",
      "Epoch:  3143 | Train Accurancy:  0.9149667173624039 | Validation Accurancy:  0.88913544267416\n",
      "Epoch:  3144 | Train Accurancy:  0.9149749726057053 | Validation Accurancy:  0.8891524821519852\n",
      "Epoch:  3145 | Train Accurancy:  0.9149832651019096 | Validation Accurancy:  0.8891738578677177\n",
      "Epoch:  3146 | Train Accurancy:  0.9149914458394051 | Validation Accurancy:  0.8891905471682549\n",
      "Epoch:  3147 | Train Accurancy:  0.9149996936321259 | Validation Accurancy:  0.8892078325152397\n",
      "Epoch:  3148 | Train Accurancy:  0.9150079414248466 | Validation Accurancy:  0.8892291784286499\n",
      "Epoch:  3149 | Train Accurancy:  0.915016196668148 | Validation Accurancy:  0.889245867729187\n",
      "Epoch:  3150 | Train Accurancy:  0.915024422109127 | Validation Accurancy:  0.889263205230236\n",
      "Epoch:  3151 | Train Accurancy:  0.9150326624512672 | Validation Accurancy:  0.8892844691872597\n",
      "Epoch:  3152 | Train Accurancy:  0.9150407984852791 | Validation Accurancy:  0.8893012553453445\n",
      "Epoch:  3153 | Train Accurancy:  0.9150490313768387 | Validation Accurancy:  0.8893185928463936\n",
      "Epoch:  3154 | Train Accurancy:  0.9150571748614311 | Validation Accurancy:  0.8893398120999336\n",
      "Epoch:  3155 | Train Accurancy:  0.9150654152035713 | Validation Accurancy:  0.8893565982580185\n",
      "Epoch:  3156 | Train Accurancy:  0.9150735959410667 | Validation Accurancy:  0.889373816549778\n",
      "Epoch:  3157 | Train Accurancy:  0.9150817394256592 | Validation Accurancy:  0.8893951624631882\n",
      "Epoch:  3158 | Train Accurancy:  0.915089949965477 | Validation Accurancy:  0.8894117921590805\n",
      "Epoch:  3159 | Train Accurancy:  0.9150980859994888 | Validation Accurancy:  0.8894290402531624\n",
      "Epoch:  3160 | Train Accurancy:  0.9151062667369843 | Validation Accurancy:  0.8894503563642502\n",
      "Epoch:  3161 | Train Accurancy:  0.9151144176721573 | Validation Accurancy:  0.8894670754671097\n",
      "Epoch:  3162 | Train Accurancy:  0.9151225760579109 | Validation Accurancy:  0.8894843012094498\n",
      "Epoch:  3163 | Train Accurancy:  0.915130726993084 | Validation Accurancy:  0.8895053863525391\n",
      "Epoch:  3164 | Train Accurancy:  0.9151388257741928 | Validation Accurancy:  0.8895221129059792\n",
      "Epoch:  3165 | Train Accurancy:  0.9151469618082047 | Validation Accurancy:  0.8895392939448357\n",
      "Epoch:  3166 | Train Accurancy:  0.9151550903916359 | Validation Accurancy:  0.8895604386925697\n",
      "Epoch:  3167 | Train Accurancy:  0.9151631891727448 | Validation Accurancy:  0.8895770832896233\n",
      "Epoch:  3168 | Train Accurancy:  0.9151713028550148 | Validation Accurancy:  0.8895942866802216\n",
      "Epoch:  3169 | Train Accurancy:  0.9151794090867043 | Validation Accurancy:  0.8896153718233109\n",
      "Epoch:  3170 | Train Accurancy:  0.9151874706149101 | Validation Accurancy:  0.8896320909261703\n",
      "Epoch:  3171 | Train Accurancy:  0.9151956140995026 | Validation Accurancy:  0.8896491676568985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3172 | Train Accurancy:  0.9152037128806114 | Validation Accurancy:  0.8896702975034714\n",
      "Epoch:  3173 | Train Accurancy:  0.9152117669582367 | Validation Accurancy:  0.8896868526935577\n",
      "Epoch:  3174 | Train Accurancy:  0.9152198284864426 | Validation Accurancy:  0.8897039517760277\n",
      "Epoch:  3175 | Train Accurancy:  0.9152278751134872 | Validation Accurancy:  0.8897213935852051\n",
      "Epoch:  3176 | Train Accurancy:  0.9152359217405319 | Validation Accurancy:  0.8897426873445511\n",
      "Epoch:  3177 | Train Accurancy:  0.9152440130710602 | Validation Accurancy:  0.8897581398487091\n",
      "Epoch:  3178 | Train Accurancy:  0.9152520522475243 | Validation Accurancy:  0.8897757083177567\n",
      "Epoch:  3179 | Train Accurancy:  0.9152601063251495 | Validation Accurancy:  0.8897971138358116\n",
      "Epoch:  3180 | Train Accurancy:  0.9152681306004524 | Validation Accurancy:  0.8898139744997025\n",
      "Epoch:  3181 | Train Accurancy:  0.9152761176228523 | Validation Accurancy:  0.8898311480879784\n",
      "Epoch:  3182 | Train Accurancy:  0.9152842238545418 | Validation Accurancy:  0.8898473456501961\n",
      "Epoch:  3183 | Train Accurancy:  0.9152922108769417 | Validation Accurancy:  0.8898690566420555\n",
      "Epoch:  3184 | Train Accurancy:  0.9153002351522446 | Validation Accurancy:  0.8898860439658165\n",
      "Epoch:  3185 | Train Accurancy:  0.9153081700205803 | Validation Accurancy:  0.8899034932255745\n",
      "Epoch:  3186 | Train Accurancy:  0.9153162091970444 | Validation Accurancy:  0.8899197205901146\n",
      "Epoch:  3187 | Train Accurancy:  0.9153241738677025 | Validation Accurancy:  0.8899414539337158\n",
      "Epoch:  3188 | Train Accurancy:  0.9153321757912636 | Validation Accurancy:  0.8899585157632828\n",
      "Epoch:  3189 | Train Accurancy:  0.9153401702642441 | Validation Accurancy:  0.8899759873747826\n",
      "Epoch:  3190 | Train Accurancy:  0.9153481423854828 | Validation Accurancy:  0.8899922147393227\n",
      "Epoch:  3191 | Train Accurancy:  0.9153561219573021 | Validation Accurancy:  0.890010379254818\n",
      "Epoch:  3192 | Train Accurancy:  0.915364034473896 | Validation Accurancy:  0.8900319710373878\n",
      "Epoch:  3193 | Train Accurancy:  0.9153720363974571 | Validation Accurancy:  0.890047699213028\n",
      "Epoch:  3194 | Train Accurancy:  0.9153799787163734 | Validation Accurancy:  0.8900655061006546\n",
      "Epoch:  3195 | Train Accurancy:  0.9153879135847092 | Validation Accurancy:  0.8900832682847977\n",
      "Epoch:  3196 | Train Accurancy:  0.9153958410024643 | Validation Accurancy:  0.8901011273264885\n",
      "Epoch:  3197 | Train Accurancy:  0.9154038056731224 | Validation Accurancy:  0.8901213183999062\n",
      "Epoch:  3198 | Train Accurancy:  0.9154116958379745 | Validation Accurancy:  0.8901386484503746\n",
      "Epoch:  3199 | Train Accurancy:  0.9154196530580521 | Validation Accurancy:  0.8901560828089714\n",
      "Epoch:  3200 | Train Accurancy:  0.9154275879263878 | Validation Accurancy:  0.8901738077402115\n",
      "Epoch:  3201 | Train Accurancy:  0.9154354631900787 | Validation Accurancy:  0.8901902064681053\n",
      "Epoch:  3202 | Train Accurancy:  0.9154433757066727 | Validation Accurancy:  0.8902119249105453\n",
      "Epoch:  3203 | Train Accurancy:  0.9154512509703636 | Validation Accurancy:  0.8902290612459183\n",
      "Epoch:  3204 | Train Accurancy:  0.915459118783474 | Validation Accurancy:  0.8902463540434837\n",
      "Epoch:  3205 | Train Accurancy:  0.9154670611023903 | Validation Accurancy:  0.8902626559138298\n",
      "Epoch:  3206 | Train Accurancy:  0.9154749065637589 | Validation Accurancy:  0.8902806788682938\n",
      "Epoch:  3207 | Train Accurancy:  0.9154827818274498 | Validation Accurancy:  0.8903021514415741\n",
      "Epoch:  3208 | Train Accurancy:  0.9154906645417213 | Validation Accurancy:  0.8903178051114082\n",
      "Epoch:  3209 | Train Accurancy:  0.9154985025525093 | Validation Accurancy:  0.8903354629874229\n",
      "Epoch:  3210 | Train Accurancy:  0.9155063852667809 | Validation Accurancy:  0.89035315066576\n",
      "Epoch:  3211 | Train Accurancy:  0.9155142232775688 | Validation Accurancy:  0.8903708904981613\n",
      "Epoch:  3212 | Train Accurancy:  0.915522076189518 | Validation Accurancy:  0.8903874307870865\n",
      "Epoch:  3213 | Train Accurancy:  0.9155299142003059 | Validation Accurancy:  0.8904090598225594\n",
      "Epoch:  3214 | Train Accurancy:  0.9155377671122551 | Validation Accurancy:  0.8904262036085129\n",
      "Epoch:  3215 | Train Accurancy:  0.9155456051230431 | Validation Accurancy:  0.8904434144496918\n",
      "Epoch:  3216 | Train Accurancy:  0.9155534207820892 | Validation Accurancy:  0.8904596418142319\n",
      "Epoch:  3217 | Train Accurancy:  0.9155612140893936 | Validation Accurancy:  0.8904775753617287\n",
      "Epoch:  3218 | Train Accurancy:  0.9155690222978592 | Validation Accurancy:  0.8904955238103867\n",
      "Epoch:  3219 | Train Accurancy:  0.9155768677592278 | Validation Accurancy:  0.8905168026685715\n",
      "Epoch:  3220 | Train Accurancy:  0.9155846387147903 | Validation Accurancy:  0.8905323818325996\n",
      "Epoch:  3221 | Train Accurancy:  0.9155923873186111 | Validation Accurancy:  0.8905498012900352\n",
      "Epoch:  3222 | Train Accurancy:  0.9156001880764961 | Validation Accurancy:  0.8905674964189529\n",
      "Epoch:  3223 | Train Accurancy:  0.9156079739332199 | Validation Accurancy:  0.8905851319432259\n",
      "Epoch:  3224 | Train Accurancy:  0.9156157672405243 | Validation Accurancy:  0.8906015902757645\n",
      "Epoch:  3225 | Train Accurancy:  0.9156235158443451 | Validation Accurancy:  0.8906231373548508\n",
      "Epoch:  3226 | Train Accurancy:  0.9156312420964241 | Validation Accurancy:  0.89064010232687\n",
      "Epoch:  3227 | Train Accurancy:  0.9156390503048897 | Validation Accurancy:  0.8906572312116623\n",
      "Epoch:  3228 | Train Accurancy:  0.9156467989087105 | Validation Accurancy:  0.8906733319163322\n",
      "Epoch:  3229 | Train Accurancy:  0.9156545475125313 | Validation Accurancy:  0.8906911909580231\n",
      "Epoch:  3230 | Train Accurancy:  0.9156622812151909 | Validation Accurancy:  0.8907089382410049\n",
      "Epoch:  3231 | Train Accurancy:  0.9156699702143669 | Validation Accurancy:  0.890726737678051\n",
      "Epoch:  3232 | Train Accurancy:  0.9156777113676071 | Validation Accurancy:  0.8907467350363731\n",
      "Epoch:  3233 | Train Accurancy:  0.9156854450702667 | Validation Accurancy:  0.8907637596130371\n",
      "Epoch:  3234 | Train Accurancy:  0.9156931713223457 | Validation Accurancy:  0.8907810375094414\n",
      "Epoch:  3235 | Train Accurancy:  0.9157008826732635 | Validation Accurancy:  0.8907984346151352\n",
      "Epoch:  3236 | Train Accurancy:  0.9157086312770844 | Validation Accurancy:  0.8908146694302559\n",
      "Epoch:  3237 | Train Accurancy:  0.915716290473938 | Validation Accurancy:  0.8908325135707855\n",
      "Epoch:  3238 | Train Accurancy:  0.9157239496707916 | Validation Accurancy:  0.8908503353595734\n",
      "Epoch:  3239 | Train Accurancy:  0.9157316759228706 | Validation Accurancy:  0.890871487557888\n",
      "Epoch:  3240 | Train Accurancy:  0.9157393500208855 | Validation Accurancy:  0.890887051820755\n",
      "Epoch:  3241 | Train Accurancy:  0.9157470613718033 | Validation Accurancy:  0.890904426574707\n",
      "Epoch:  3242 | Train Accurancy:  0.9157547205686569 | Validation Accurancy:  0.890921875834465\n",
      "Epoch:  3243 | Train Accurancy:  0.9157623574137688 | Validation Accurancy:  0.8909393176436424\n",
      "Epoch:  3244 | Train Accurancy:  0.9157700315117836 | Validation Accurancy:  0.8909554556012154\n",
      "Epoch:  3245 | Train Accurancy:  0.9157776534557343 | Validation Accurancy:  0.8909734562039375\n",
      "Epoch:  3246 | Train Accurancy:  0.9157853052020073 | Validation Accurancy:  0.8909912183880806\n",
      "Epoch:  3247 | Train Accurancy:  0.9157930091023445 | Validation Accurancy:  0.8910124078392982\n",
      "Epoch:  3248 | Train Accurancy:  0.9158006086945534 | Validation Accurancy:  0.8910277262330055\n",
      "Epoch:  3249 | Train Accurancy:  0.9158082008361816 | Validation Accurancy:  0.8910451233386993\n",
      "Epoch:  3250 | Train Accurancy:  0.9158158749341965 | Validation Accurancy:  0.8910624608397484\n",
      "Epoch:  3251 | Train Accurancy:  0.9158234819769859 | Validation Accurancy:  0.8910799250006676\n",
      "Epoch:  3252 | Train Accurancy:  0.9158310741186142 | Validation Accurancy:  0.8910972252488136\n",
      "Epoch:  3253 | Train Accurancy:  0.9158387333154678 | Validation Accurancy:  0.8911134749650955\n",
      "Epoch:  3254 | Train Accurancy:  0.9158463105559349 | Validation Accurancy:  0.8911313638091087\n",
      "Epoch:  3255 | Train Accurancy:  0.915853887796402 | Validation Accurancy:  0.8911490887403488\n",
      "Epoch:  3256 | Train Accurancy:  0.9158615171909332 | Validation Accurancy:  0.8911701366305351\n",
      "Epoch:  3257 | Train Accurancy:  0.9158691018819809 | Validation Accurancy:  0.8911855667829514\n",
      "Epoch:  3258 | Train Accurancy:  0.9158766344189644 | Validation Accurancy:  0.8912027180194855\n",
      "Epoch:  3259 | Train Accurancy:  0.9158842340111732 | Validation Accurancy:  0.8912200778722763\n",
      "Epoch:  3260 | Train Accurancy:  0.9158918187022209 | Validation Accurancy:  0.8912373930215836\n",
      "Epoch:  3261 | Train Accurancy:  0.9158993661403656 | Validation Accurancy:  0.8912547677755356\n",
      "Epoch:  3262 | Train Accurancy:  0.9159069955348969 | Validation Accurancy:  0.8912709578871727\n",
      "Epoch:  3263 | Train Accurancy:  0.9159145057201385 | Validation Accurancy:  0.891288734972477\n",
      "Epoch:  3264 | Train Accurancy:  0.915922075510025 | Validation Accurancy:  0.8913063779473305\n",
      "Epoch:  3265 | Train Accurancy:  0.9159296005964279 | Validation Accurancy:  0.8913239985704422\n",
      "Epoch:  3266 | Train Accurancy:  0.9159371331334114 | Validation Accurancy:  0.8913435563445091\n",
      "Epoch:  3267 | Train Accurancy:  0.9159446507692337 | Validation Accurancy:  0.8913604840636253\n",
      "Epoch:  3268 | Train Accurancy:  0.9159522131085396 | Validation Accurancy:  0.8913774266839027\n",
      "Epoch:  3269 | Train Accurancy:  0.9159597083926201 | Validation Accurancy:  0.8913945630192757\n",
      "Epoch:  3270 | Train Accurancy:  0.9159672036767006 | Validation Accurancy:  0.8914117440581322\n",
      "Epoch:  3271 | Train Accurancy:  0.9159747064113617 | Validation Accurancy:  0.8914278447628021\n",
      "Epoch:  3272 | Train Accurancy:  0.9159822314977646 | Validation Accurancy:  0.8914453759789467\n",
      "Epoch:  3273 | Train Accurancy:  0.9159897342324257 | Validation Accurancy:  0.8914629444479942\n",
      "Epoch:  3274 | Train Accurancy:  0.9159972369670868 | Validation Accurancy:  0.891480453312397\n",
      "Epoch:  3275 | Train Accurancy:  0.9160047397017479 | Validation Accurancy:  0.8914966136217117\n",
      "Epoch:  3276 | Train Accurancy:  0.9160121902823448 | Validation Accurancy:  0.8915144726634026\n",
      "Epoch:  3277 | Train Accurancy:  0.9160196706652641 | Validation Accurancy:  0.8915320113301277\n",
      "Epoch:  3278 | Train Accurancy:  0.9160271733999252 | Validation Accurancy:  0.8915495052933693\n",
      "Epoch:  3279 | Train Accurancy:  0.9160345494747162 | Validation Accurancy:  0.8915690556168556\n",
      "Epoch:  3280 | Train Accurancy:  0.9160420596599579 | Validation Accurancy:  0.8915858268737793\n",
      "Epoch:  3281 | Train Accurancy:  0.9160495176911354 | Validation Accurancy:  0.8916026800870895\n",
      "Epoch:  3282 | Train Accurancy:  0.9160569608211517 | Validation Accurancy:  0.8916198238730431\n",
      "Epoch:  3283 | Train Accurancy:  0.9160644114017487 | Validation Accurancy:  0.891636848449707\n",
      "Epoch:  3284 | Train Accurancy:  0.9160718843340874 | Validation Accurancy:  0.8916540890932083\n",
      "Epoch:  3285 | Train Accurancy:  0.9160792157053947 | Validation Accurancy:  0.891669973731041\n",
      "Epoch:  3286 | Train Accurancy:  0.9160866811871529 | Validation Accurancy:  0.891687422990799\n",
      "Epoch:  3287 | Train Accurancy:  0.9160940945148468 | Validation Accurancy:  0.8917048424482346\n",
      "Epoch:  3288 | Train Accurancy:  0.9161015376448631 | Validation Accurancy:  0.8917222246527672\n",
      "Epoch:  3289 | Train Accurancy:  0.9161089360713959 | Validation Accurancy:  0.891739509999752\n",
      "Epoch:  3290 | Train Accurancy:  0.9161163717508316 | Validation Accurancy:  0.8917555660009384\n",
      "Epoch:  3291 | Train Accurancy:  0.9161237478256226 | Validation Accurancy:  0.8917731866240501\n",
      "Epoch:  3292 | Train Accurancy:  0.9161311611533165 | Validation Accurancy:  0.8917906731367111\n",
      "Epoch:  3293 | Train Accurancy:  0.9161385223269463 | Validation Accurancy:  0.8918080106377602\n",
      "Epoch:  3294 | Train Accurancy:  0.9161458909511566 | Validation Accurancy:  0.8918241113424301\n",
      "Epoch:  3295 | Train Accurancy:  0.9161533117294312 | Validation Accurancy:  0.8918417543172836\n",
      "Epoch:  3296 | Train Accurancy:  0.9161606729030609 | Validation Accurancy:  0.891859270632267\n",
      "Epoch:  3297 | Train Accurancy:  0.9161680489778519 | Validation Accurancy:  0.8918798640370369\n",
      "Epoch:  3298 | Train Accurancy:  0.916175402700901 | Validation Accurancy:  0.8918949738144875\n",
      "Epoch:  3299 | Train Accurancy:  0.9161827340722084 | Validation Accurancy:  0.8919119313359261\n",
      "Epoch:  3300 | Train Accurancy:  0.9161901250481606 | Validation Accurancy:  0.891928918659687\n",
      "Epoch:  3301 | Train Accurancy:  0.9161974638700485 | Validation Accurancy:  0.8919459208846092\n",
      "Epoch:  3302 | Train Accurancy:  0.9162047877907753 | Validation Accurancy:  0.8919629752635956\n",
      "Epoch:  3303 | Train Accurancy:  0.9162121266126633 | Validation Accurancy:  0.8919799998402596\n",
      "Epoch:  3304 | Train Accurancy:  0.9162194728851318 | Validation Accurancy:  0.8919970467686653\n",
      "Epoch:  3305 | Train Accurancy:  0.9162267968058586 | Validation Accurancy:  0.8920128121972084\n",
      "Epoch:  3306 | Train Accurancy:  0.916234128177166 | Validation Accurancy:  0.89203030616045\n",
      "Epoch:  3307 | Train Accurancy:  0.9162414148449898 | Validation Accurancy:  0.8920475542545319\n",
      "Epoch:  3308 | Train Accurancy:  0.9162487536668777 | Validation Accurancy:  0.8920647874474525\n",
      "Epoch:  3309 | Train Accurancy:  0.9162560328841209 | Validation Accurancy:  0.8920818716287613\n",
      "Epoch:  3310 | Train Accurancy:  0.9162633344531059 | Validation Accurancy:  0.8920978978276253\n",
      "Epoch:  3311 | Train Accurancy:  0.9162706136703491 | Validation Accurancy:  0.8921152055263519\n",
      "Epoch:  3312 | Train Accurancy:  0.9162779226899147 | Validation Accurancy:  0.8921326100826263\n",
      "Epoch:  3313 | Train Accurancy:  0.9162851944565773 | Validation Accurancy:  0.8921497985720634\n",
      "Epoch:  3314 | Train Accurancy:  0.9162924960255623 | Validation Accurancy:  0.8921669498085976\n",
      "Epoch:  3315 | Train Accurancy:  0.9162996858358383 | Validation Accurancy:  0.8921827897429466\n",
      "Epoch:  3316 | Train Accurancy:  0.9163070023059845 | Validation Accurancy:  0.8922002092003822\n",
      "Epoch:  3317 | Train Accurancy:  0.9163143187761307 | Validation Accurancy:  0.8922174498438835\n",
      "Epoch:  3318 | Train Accurancy:  0.9163215309381485 | Validation Accurancy:  0.8922345787286758\n",
      "Epoch:  3319 | Train Accurancy:  0.9163287580013275 | Validation Accurancy:  0.8922518044710159\n",
      "Epoch:  3320 | Train Accurancy:  0.9163360297679901 | Validation Accurancy:  0.8922675624489784\n",
      "Epoch:  3321 | Train Accurancy:  0.9163432642817497 | Validation Accurancy:  0.8922849893569946\n",
      "Epoch:  3322 | Train Accurancy:  0.9163504913449287 | Validation Accurancy:  0.8923022001981735\n",
      "Epoch:  3323 | Train Accurancy:  0.9163577631115913 | Validation Accurancy:  0.8923193290829659\n",
      "Epoch:  3324 | Train Accurancy:  0.9163649827241898 | Validation Accurancy:  0.8923363387584686\n",
      "Epoch:  3325 | Train Accurancy:  0.9163722023367882 | Validation Accurancy:  0.8923534005880356\n",
      "Epoch:  3326 | Train Accurancy:  0.9163794368505478 | Validation Accurancy:  0.8923691436648369\n",
      "Epoch:  3327 | Train Accurancy:  0.9163866192102432 | Validation Accurancy:  0.8923864439129829\n",
      "Epoch:  3328 | Train Accurancy:  0.9163938015699387 | Validation Accurancy:  0.89240363240242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3329 | Train Accurancy:  0.9164009988307953 | Validation Accurancy:  0.8924206048250198\n",
      "Epoch:  3330 | Train Accurancy:  0.9164082333445549 | Validation Accurancy:  0.892437607049942\n",
      "Epoch:  3331 | Train Accurancy:  0.9164154455065727 | Validation Accurancy:  0.8924534246325493\n",
      "Epoch:  3332 | Train Accurancy:  0.9164225533604622 | Validation Accurancy:  0.8924707099795341\n",
      "Epoch:  3333 | Train Accurancy:  0.9164297431707382 | Validation Accurancy:  0.8924877718091011\n",
      "Epoch:  3334 | Train Accurancy:  0.9164370000362396 | Validation Accurancy:  0.8925048336386681\n",
      "Epoch:  3335 | Train Accurancy:  0.9164441302418709 | Validation Accurancy:  0.8925217837095261\n",
      "Epoch:  3336 | Train Accurancy:  0.9164512529969215 | Validation Accurancy:  0.8925387859344482\n",
      "Epoch:  3337 | Train Accurancy:  0.9164584204554558 | Validation Accurancy:  0.8925543650984764\n",
      "Epoch:  3338 | Train Accurancy:  0.9164655655622482 | Validation Accurancy:  0.8925715610384941\n",
      "Epoch:  3339 | Train Accurancy:  0.9164728000760078 | Validation Accurancy:  0.892588660120964\n",
      "Epoch:  3340 | Train Accurancy:  0.9164798632264137 | Validation Accurancy:  0.8926056250929832\n",
      "Epoch:  3341 | Train Accurancy:  0.9164869710803032 | Validation Accurancy:  0.8926225826144218\n",
      "Epoch:  3342 | Train Accurancy:  0.9164941310882568 | Validation Accurancy:  0.8926394134759903\n",
      "Epoch:  3343 | Train Accurancy:  0.9165012910962105 | Validation Accurancy:  0.8926562145352364\n",
      "Epoch:  3344 | Train Accurancy:  0.9165084511041641 | Validation Accurancy:  0.8926717936992645\n",
      "Epoch:  3345 | Train Accurancy:  0.9165154844522476 | Validation Accurancy:  0.892688974738121\n",
      "Epoch:  3346 | Train Accurancy:  0.9165226072072983 | Validation Accurancy:  0.8927058503031731\n",
      "Epoch:  3347 | Train Accurancy:  0.9165297225117683 | Validation Accurancy:  0.8927228152751923\n",
      "Epoch:  3348 | Train Accurancy:  0.9165367856621742 | Validation Accurancy:  0.8927396759390831\n",
      "Epoch:  3349 | Train Accurancy:  0.9165439084172249 | Validation Accurancy:  0.8927564844489098\n",
      "Epoch:  3350 | Train Accurancy:  0.9165510311722755 | Validation Accurancy:  0.8927732408046722\n",
      "Epoch:  3351 | Train Accurancy:  0.9165581464767456 | Validation Accurancy:  0.8927887305617332\n",
      "Epoch:  3352 | Train Accurancy:  0.9165651947259903 | Validation Accurancy:  0.8928058221936226\n",
      "Epoch:  3353 | Train Accurancy:  0.9165722876787186 | Validation Accurancy:  0.8928228095173836\n",
      "Epoch:  3354 | Train Accurancy:  0.9165793433785439 | Validation Accurancy:  0.8928396999835968\n",
      "Epoch:  3355 | Train Accurancy:  0.9165864065289497 | Validation Accurancy:  0.8928563594818115\n",
      "Epoch:  3356 | Train Accurancy:  0.9165934845805168 | Validation Accurancy:  0.8928731381893158\n",
      "Epoch:  3357 | Train Accurancy:  0.9166004955768585 | Validation Accurancy:  0.8928898274898529\n",
      "Epoch:  3358 | Train Accurancy:  0.9166075736284256 | Validation Accurancy:  0.8929064348340034\n",
      "Epoch:  3359 | Train Accurancy:  0.9166145995259285 | Validation Accurancy:  0.8929219394922256\n",
      "Epoch:  3360 | Train Accurancy:  0.9166216477751732 | Validation Accurancy:  0.892938882112503\n",
      "Epoch:  3361 | Train Accurancy:  0.9166286960244179 | Validation Accurancy:  0.892955869436264\n",
      "Epoch:  3362 | Train Accurancy:  0.9166357144713402 | Validation Accurancy:  0.8929725661873817\n",
      "Epoch:  3363 | Train Accurancy:  0.9166427776217461 | Validation Accurancy:  0.8929892778396606\n",
      "Epoch:  3364 | Train Accurancy:  0.9166497439146042 | Validation Accurancy:  0.8930060565471649\n",
      "Epoch:  3365 | Train Accurancy:  0.9166568294167519 | Validation Accurancy:  0.8930226415395737\n",
      "Epoch:  3366 | Train Accurancy:  0.9166638478636742 | Validation Accurancy:  0.893039233982563\n",
      "Epoch:  3367 | Train Accurancy:  0.9166708067059517 | Validation Accurancy:  0.8930546417832375\n",
      "Epoch:  3368 | Train Accurancy:  0.9166778400540352 | Validation Accurancy:  0.8930715620517731\n",
      "Epoch:  3369 | Train Accurancy:  0.9166848137974739 | Validation Accurancy:  0.893088273704052\n",
      "Epoch:  3370 | Train Accurancy:  0.916691780090332 | Validation Accurancy:  0.8931051194667816\n",
      "Epoch:  3371 | Train Accurancy:  0.9166988059878349 | Validation Accurancy:  0.8931217044591904\n",
      "Epoch:  3372 | Train Accurancy:  0.9167057275772095 | Validation Accurancy:  0.8931382745504379\n",
      "Epoch:  3373 | Train Accurancy:  0.9167127907276154 | Validation Accurancy:  0.8931548669934273\n",
      "Epoch:  3374 | Train Accurancy:  0.9167197197675705 | Validation Accurancy:  0.8931713849306107\n",
      "Epoch:  3375 | Train Accurancy:  0.9167266935110092 | Validation Accurancy:  0.8931878581643105\n",
      "Epoch:  3376 | Train Accurancy:  0.9167336523532867 | Validation Accurancy:  0.8932044729590416\n",
      "Epoch:  3377 | Train Accurancy:  0.9167406111955643 | Validation Accurancy:  0.8932198211550713\n",
      "Epoch:  3378 | Train Accurancy:  0.916747584939003 | Validation Accurancy:  0.8932365253567696\n",
      "Epoch:  3379 | Train Accurancy:  0.9167545288801193 | Validation Accurancy:  0.8932533413171768\n",
      "Epoch:  3380 | Train Accurancy:  0.9167614877223969 | Validation Accurancy:  0.8932699784636497\n",
      "Epoch:  3381 | Train Accurancy:  0.916768379509449 | Validation Accurancy:  0.8932864665985107\n",
      "Epoch:  3382 | Train Accurancy:  0.9167753159999847 | Validation Accurancy:  0.8933029398322105\n",
      "Epoch:  3383 | Train Accurancy:  0.9167822450399399 | Validation Accurancy:  0.8933194205164909\n",
      "Epoch:  3384 | Train Accurancy:  0.9167892187833786 | Validation Accurancy:  0.8933359161019325\n",
      "Epoch:  3385 | Train Accurancy:  0.9167960956692696 | Validation Accurancy:  0.8933523818850517\n",
      "Epoch:  3386 | Train Accurancy:  0.9168029874563217 | Validation Accurancy:  0.8933686763048172\n",
      "Epoch:  3387 | Train Accurancy:  0.9168099388480186 | Validation Accurancy:  0.8933852016925812\n",
      "Epoch:  3388 | Train Accurancy:  0.916816808283329 | Validation Accurancy:  0.8934016227722168\n",
      "Epoch:  3389 | Train Accurancy:  0.9168237298727036 | Validation Accurancy:  0.8934179916977882\n",
      "Epoch:  3390 | Train Accurancy:  0.9168305844068527 | Validation Accurancy:  0.8934332057833672\n",
      "Epoch:  3391 | Train Accurancy:  0.9168375208973885 | Validation Accurancy:  0.8934498578310013\n",
      "Epoch:  3392 | Train Accurancy:  0.9168443828821182 | Validation Accurancy:  0.8934664949774742\n",
      "Epoch:  3393 | Train Accurancy:  0.9168512597680092 | Validation Accurancy:  0.8934830501675606\n",
      "Epoch:  3394 | Train Accurancy:  0.9168581590056419 | Validation Accurancy:  0.8935017809271812\n",
      "Epoch:  3395 | Train Accurancy:  0.9168649613857269 | Validation Accurancy:  0.8935174867510796\n",
      "Epoch:  3396 | Train Accurancy:  0.9168718531727791 | Validation Accurancy:  0.893533430993557\n",
      "Epoch:  3397 | Train Accurancy:  0.9168787077069283 | Validation Accurancy:  0.8935495316982269\n",
      "Epoch:  3398 | Train Accurancy:  0.9168855473399162 | Validation Accurancy:  0.8935655727982521\n",
      "Epoch:  3399 | Train Accurancy:  0.9168924242258072 | Validation Accurancy:  0.8935840353369713\n",
      "Epoch:  3400 | Train Accurancy:  0.9168993160128593 | Validation Accurancy:  0.8935995399951935\n",
      "Epoch:  3401 | Train Accurancy:  0.9169061556458473 | Validation Accurancy:  0.89361522346735\n",
      "Epoch:  3402 | Train Accurancy:  0.9169129431247711 | Validation Accurancy:  0.893631212413311\n",
      "Epoch:  3403 | Train Accurancy:  0.9169197753071785 | Validation Accurancy:  0.8936493769288063\n",
      "Epoch:  3404 | Train Accurancy:  0.9169266074895859 | Validation Accurancy:  0.8936648294329643\n",
      "Epoch:  3405 | Train Accurancy:  0.9169334396719933 | Validation Accurancy:  0.8936805576086044\n",
      "Epoch:  3406 | Train Accurancy:  0.91694026440382 | Validation Accurancy:  0.8936962857842445\n",
      "Epoch:  3407 | Train Accurancy:  0.9169470518827438 | Validation Accurancy:  0.8937144055962563\n",
      "Epoch:  3408 | Train Accurancy:  0.9169538468122482 | Validation Accurancy:  0.8937298059463501\n",
      "Epoch:  3409 | Train Accurancy:  0.9169606938958168 | Validation Accurancy:  0.8937455266714096\n",
      "Epoch:  3410 | Train Accurancy:  0.9169674888253212 | Validation Accurancy:  0.8937612846493721\n",
      "Epoch:  3411 | Train Accurancy:  0.9169742539525032 | Validation Accurancy:  0.8937794715166092\n",
      "Epoch:  3412 | Train Accurancy:  0.9169810488820076 | Validation Accurancy:  0.8937947675585747\n",
      "Epoch:  3413 | Train Accurancy:  0.916987843811512 | Validation Accurancy:  0.8938103094696999\n",
      "Epoch:  3414 | Train Accurancy:  0.9169945940375328 | Validation Accurancy:  0.8938261196017265\n",
      "Epoch:  3415 | Train Accurancy:  0.9170013815164566 | Validation Accurancy:  0.8938442692160606\n",
      "Epoch:  3416 | Train Accurancy:  0.9170081838965416 | Validation Accurancy:  0.8938595205545425\n",
      "Epoch:  3417 | Train Accurancy:  0.9170148894190788 | Validation Accurancy:  0.8938750326633453\n",
      "Epoch:  3418 | Train Accurancy:  0.9170216470956802 | Validation Accurancy:  0.8938908129930496\n",
      "Epoch:  3419 | Train Accurancy:  0.9170284569263458 | Validation Accurancy:  0.8939088359475136\n",
      "Epoch:  3420 | Train Accurancy:  0.9170351773500443 | Validation Accurancy:  0.8939241543412209\n",
      "Epoch:  3421 | Train Accurancy:  0.9170419350266457 | Validation Accurancy:  0.893939770758152\n",
      "Epoch:  3422 | Train Accurancy:  0.9170486703515053 | Validation Accurancy:  0.8939554318785667\n",
      "Epoch:  3423 | Train Accurancy:  0.9170554056763649 | Validation Accurancy:  0.8939734399318695\n",
      "Epoch:  3424 | Train Accurancy:  0.9170621335506439 | Validation Accurancy:  0.8939886838197708\n",
      "Epoch:  3425 | Train Accurancy:  0.9170688763260841 | Validation Accurancy:  0.8940041586756706\n",
      "Epoch:  3426 | Train Accurancy:  0.9170755594968796 | Validation Accurancy:  0.8940199390053749\n",
      "Epoch:  3427 | Train Accurancy:  0.9170823022723198 | Validation Accurancy:  0.8940378203988075\n",
      "Epoch:  3428 | Train Accurancy:  0.9170890226960182 | Validation Accurancy:  0.8940530940890312\n",
      "Epoch:  3429 | Train Accurancy:  0.9170957431197166 | Validation Accurancy:  0.8940686285495758\n",
      "Epoch:  3430 | Train Accurancy:  0.9171024113893509 | Validation Accurancy:  0.8940842598676682\n",
      "Epoch:  3431 | Train Accurancy:  0.9171091616153717 | Validation Accurancy:  0.8941021040081978\n",
      "Epoch:  3432 | Train Accurancy:  0.9171158075332642 | Validation Accurancy:  0.8941173627972603\n",
      "Epoch:  3433 | Train Accurancy:  0.9171225726604462 | Validation Accurancy:  0.8941328078508377\n",
      "Epoch:  3434 | Train Accurancy:  0.9171292334794998 | Validation Accurancy:  0.8941484689712524\n",
      "Epoch:  3435 | Train Accurancy:  0.9171358719468117 | Validation Accurancy:  0.8941662535071373\n",
      "Epoch:  3436 | Train Accurancy:  0.9171425625681877 | Validation Accurancy:  0.8941814228892326\n",
      "Epoch:  3437 | Train Accurancy:  0.9171492010354996 | Validation Accurancy:  0.8941968977451324\n",
      "Epoch:  3438 | Train Accurancy:  0.9171558693051338 | Validation Accurancy:  0.8942125141620636\n",
      "Epoch:  3439 | Train Accurancy:  0.9171625301241875 | Validation Accurancy:  0.8942281305789948\n",
      "Epoch:  3440 | Train Accurancy:  0.9171692058444023 | Validation Accurancy:  0.8942460864782333\n",
      "Epoch:  3441 | Train Accurancy:  0.9171758964657784 | Validation Accurancy:  0.8942613452672958\n",
      "Epoch:  3442 | Train Accurancy:  0.9171825498342514 | Validation Accurancy:  0.8942767381668091\n",
      "Epoch:  3443 | Train Accurancy:  0.9171891584992409 | Validation Accurancy:  0.8942922428250313\n",
      "Epoch:  3444 | Train Accurancy:  0.9171958118677139 | Validation Accurancy:  0.8943079560995102\n",
      "Epoch:  3445 | Train Accurancy:  0.9172024726867676 | Validation Accurancy:  0.8943257704377174\n",
      "Epoch:  3446 | Train Accurancy:  0.9172090515494347 | Validation Accurancy:  0.8943409621715546\n",
      "Epoch:  3447 | Train Accurancy:  0.9172157049179077 | Validation Accurancy:  0.8943564221262932\n",
      "Epoch:  3448 | Train Accurancy:  0.9172222837805748 | Validation Accurancy:  0.8943720236420631\n",
      "Epoch:  3449 | Train Accurancy:  0.9172289296984673 | Validation Accurancy:  0.8943875953555107\n",
      "Epoch:  3450 | Train Accurancy:  0.9172355234622955 | Validation Accurancy:  0.8944054767489433\n",
      "Epoch:  3451 | Train Accurancy:  0.9172421544790268 | Validation Accurancy:  0.8944205567240715\n",
      "Epoch:  3452 | Train Accurancy:  0.9172486960887909 | Validation Accurancy:  0.8944359123706818\n",
      "Epoch:  3453 | Train Accurancy:  0.9172553047537804 | Validation Accurancy:  0.8944515213370323\n",
      "Epoch:  3454 | Train Accurancy:  0.9172618761658669 | Validation Accurancy:  0.8944671079516411\n",
      "Epoch:  3455 | Train Accurancy:  0.9172685071825981 | Validation Accurancy:  0.8944848999381065\n",
      "Epoch:  3456 | Train Accurancy:  0.9172751232981682 | Validation Accurancy:  0.8945000171661377\n",
      "Epoch:  3457 | Train Accurancy:  0.9172816649079323 | Validation Accurancy:  0.894515298306942\n",
      "Epoch:  3458 | Train Accurancy:  0.9172882586717606 | Validation Accurancy:  0.8945307731628418\n",
      "Epoch:  3459 | Train Accurancy:  0.9172948226332664 | Validation Accurancy:  0.8945463001728058\n",
      "Epoch:  3460 | Train Accurancy:  0.9173014014959335 | Validation Accurancy:  0.89456407725811\n",
      "Epoch:  3461 | Train Accurancy:  0.9173079431056976 | Validation Accurancy:  0.8945792466402054\n",
      "Epoch:  3462 | Train Accurancy:  0.9173145368695259 | Validation Accurancy:  0.8945945128798485\n",
      "Epoch:  3463 | Train Accurancy:  0.9173210710287094 | Validation Accurancy:  0.8946099057793617\n",
      "Epoch:  3464 | Train Accurancy:  0.9173276200890541 | Validation Accurancy:  0.8946254625916481\n",
      "Epoch:  3465 | Train Accurancy:  0.9173341765999794 | Validation Accurancy:  0.8946410715579987\n",
      "Epoch:  3466 | Train Accurancy:  0.9173407629132271 | Validation Accurancy:  0.8946589529514313\n",
      "Epoch:  3467 | Train Accurancy:  0.9173472598195076 | Validation Accurancy:  0.8946739807724953\n",
      "Epoch:  3468 | Train Accurancy:  0.9173538163304329 | Validation Accurancy:  0.8946891948580742\n",
      "Epoch:  3469 | Train Accurancy:  0.9173603281378746 | Validation Accurancy:  0.894704669713974\n",
      "Epoch:  3470 | Train Accurancy:  0.9173667803406715 | Validation Accurancy:  0.8947200924158096\n",
      "Epoch:  3471 | Train Accurancy:  0.917373351752758 | Validation Accurancy:  0.8947356790304184\n",
      "Epoch:  3472 | Train Accurancy:  0.9173798188567162 | Validation Accurancy:  0.8947533592581749\n",
      "Epoch:  3473 | Train Accurancy:  0.9173863455653191 | Validation Accurancy:  0.894768513739109\n",
      "Epoch:  3474 | Train Accurancy:  0.9173927679657936 | Validation Accurancy:  0.8947837203741074\n",
      "Epoch:  3475 | Train Accurancy:  0.9173993691802025 | Validation Accurancy:  0.8947990164160728\n",
      "Epoch:  3476 | Train Accurancy:  0.9174058437347412 | Validation Accurancy:  0.894814521074295\n",
      "Epoch:  3477 | Train Accurancy:  0.9174123182892799 | Validation Accurancy:  0.8948301151394844\n",
      "Epoch:  3478 | Train Accurancy:  0.9174188077449799 | Validation Accurancy:  0.8948456570506096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3479 | Train Accurancy:  0.917425274848938 | Validation Accurancy:  0.8948633372783661\n",
      "Epoch:  3480 | Train Accurancy:  0.9174317792057991 | Validation Accurancy:  0.8948782756924629\n",
      "Epoch:  3481 | Train Accurancy:  0.917438268661499 | Validation Accurancy:  0.8948935270309448\n",
      "Epoch:  3482 | Train Accurancy:  0.9174447059631348 | Validation Accurancy:  0.8949089124798775\n",
      "Epoch:  3483 | Train Accurancy:  0.9174511954188347 | Validation Accurancy:  0.8949242979288101\n",
      "Epoch:  3484 | Train Accurancy:  0.9174576178193092 | Validation Accurancy:  0.8949397429823875\n",
      "Epoch:  3485 | Train Accurancy:  0.9174640402197838 | Validation Accurancy:  0.8949552848935127\n",
      "Epoch:  3486 | Train Accurancy:  0.9174705296754837 | Validation Accurancy:  0.894972912967205\n",
      "Epoch:  3487 | Train Accurancy:  0.9174769371747971 | Validation Accurancy:  0.8949878886342049\n",
      "Epoch:  3488 | Train Accurancy:  0.9174834713339806 | Validation Accurancy:  0.8950031474232674\n",
      "Epoch:  3489 | Train Accurancy:  0.9174898341298103 | Validation Accurancy:  0.8950183764100075\n",
      "Epoch:  3490 | Train Accurancy:  0.9174962714314461 | Validation Accurancy:  0.8950337320566177\n",
      "Epoch:  3491 | Train Accurancy:  0.9175027459859848 | Validation Accurancy:  0.8950491473078728\n",
      "Epoch:  3492 | Train Accurancy:  0.9175091534852982 | Validation Accurancy:  0.8950646296143532\n",
      "Epoch:  3493 | Train Accurancy:  0.9175155684351921 | Validation Accurancy:  0.8950822278857231\n",
      "Epoch:  3494 | Train Accurancy:  0.9175219610333443 | Validation Accurancy:  0.895097129046917\n",
      "Epoch:  3495 | Train Accurancy:  0.9175283834338188 | Validation Accurancy:  0.8951122090220451\n",
      "Epoch:  3496 | Train Accurancy:  0.917534776031971 | Validation Accurancy:  0.8951274529099464\n",
      "Epoch:  3497 | Train Accurancy:  0.9175412133336067 | Validation Accurancy:  0.8951427936553955\n",
      "Epoch:  3498 | Train Accurancy:  0.9175475686788559 | Validation Accurancy:  0.8951582089066505\n",
      "Epoch:  3499 | Train Accurancy:  0.9175540059804916 | Validation Accurancy:  0.895173579454422\n",
      "Epoch:  3500 | Train Accurancy:  0.9175603538751602 | Validation Accurancy:  0.89518903195858\n",
      "Epoch:  3501 | Train Accurancy:  0.9175667688250542 | Validation Accurancy:  0.8952045142650604\n",
      "Epoch:  3502 | Train Accurancy:  0.9175731390714645 | Validation Accurancy:  0.8952220380306244\n",
      "Epoch:  3503 | Train Accurancy:  0.9175794869661331 | Validation Accurancy:  0.895236924290657\n",
      "Epoch:  3504 | Train Accurancy:  0.9175859317183495 | Validation Accurancy:  0.8952519819140434\n",
      "Epoch:  3505 | Train Accurancy:  0.9175922498106956 | Validation Accurancy:  0.8952671438455582\n",
      "Epoch:  3506 | Train Accurancy:  0.9175986349582672 | Validation Accurancy:  0.8952825143933296\n",
      "Epoch:  3507 | Train Accurancy:  0.9176049456000328 | Validation Accurancy:  0.8952976763248444\n",
      "Epoch:  3508 | Train Accurancy:  0.9176113083958626 | Validation Accurancy:  0.8953131288290024\n",
      "Epoch:  3509 | Train Accurancy:  0.9176176860928535 | Validation Accurancy:  0.8953285589814186\n",
      "Epoch:  3510 | Train Accurancy:  0.9176240339875221 | Validation Accurancy:  0.8953439295291901\n",
      "Epoch:  3511 | Train Accurancy:  0.9176303595304489 | Validation Accurancy:  0.8953593224287033\n",
      "Epoch:  3512 | Train Accurancy:  0.9176367148756981 | Validation Accurancy:  0.8953767642378807\n",
      "Epoch:  3513 | Train Accurancy:  0.9176430255174637 | Validation Accurancy:  0.8953916057944298\n",
      "Epoch:  3514 | Train Accurancy:  0.9176493361592293 | Validation Accurancy:  0.8954066559672356\n",
      "Epoch:  3515 | Train Accurancy:  0.9176557064056396 | Validation Accurancy:  0.8954217657446861\n",
      "Epoch:  3516 | Train Accurancy:  0.917662002146244 | Validation Accurancy:  0.8954370468854904\n",
      "Epoch:  3517 | Train Accurancy:  0.9176682978868484 | Validation Accurancy:  0.895452231168747\n",
      "Epoch:  3518 | Train Accurancy:  0.917674608528614 | Validation Accurancy:  0.8954675495624542\n",
      "Epoch:  3519 | Train Accurancy:  0.9176809340715408 | Validation Accurancy:  0.8954828977584839\n",
      "Epoch:  3520 | Train Accurancy:  0.9176872596144676 | Validation Accurancy:  0.8954982236027718\n",
      "Epoch:  3521 | Train Accurancy:  0.9176935404539108 | Validation Accurancy:  0.895513541996479\n",
      "Epoch:  3522 | Train Accurancy:  0.9176998287439346 | Validation Accurancy:  0.8955289199948311\n",
      "Epoch:  3523 | Train Accurancy:  0.9177061393857002 | Validation Accurancy:  0.8955442532896996\n",
      "Epoch:  3524 | Train Accurancy:  0.9177124053239822 | Validation Accurancy:  0.8955615982413292\n",
      "Epoch:  3525 | Train Accurancy:  0.917718693614006 | Validation Accurancy:  0.8955763801932335\n",
      "Epoch:  3526 | Train Accurancy:  0.9177249521017075 | Validation Accurancy:  0.8955914080142975\n",
      "Epoch:  3527 | Train Accurancy:  0.9177312105894089 | Validation Accurancy:  0.8956063017249107\n",
      "Epoch:  3528 | Train Accurancy:  0.9177375286817551 | Validation Accurancy:  0.8956214040517807\n",
      "Epoch:  3529 | Train Accurancy:  0.9177437499165535 | Validation Accurancy:  0.895636573433876\n",
      "Epoch:  3530 | Train Accurancy:  0.9177500680088997 | Validation Accurancy:  0.8956518992781639\n",
      "Epoch:  3531 | Train Accurancy:  0.9177563115954399 | Validation Accurancy:  0.8956671431660652\n",
      "Epoch:  3532 | Train Accurancy:  0.9177625551819801 | Validation Accurancy:  0.8956823423504829\n",
      "Epoch:  3533 | Train Accurancy:  0.917768806219101 | Validation Accurancy:  0.8956974893808365\n",
      "Epoch:  3534 | Train Accurancy:  0.917775072157383 | Validation Accurancy:  0.8957128524780273\n",
      "Epoch:  3535 | Train Accurancy:  0.917781226336956 | Validation Accurancy:  0.8957282081246376\n",
      "Epoch:  3536 | Train Accurancy:  0.9177874773740768 | Validation Accurancy:  0.8957434669137001\n",
      "Epoch:  3537 | Train Accurancy:  0.9177937656641006 | Validation Accurancy:  0.8957587108016014\n",
      "Epoch:  3538 | Train Accurancy:  0.9177999496459961 | Validation Accurancy:  0.8957738503813744\n",
      "Epoch:  3539 | Train Accurancy:  0.9178061485290527 | Validation Accurancy:  0.895789124071598\n",
      "Epoch:  3540 | Train Accurancy:  0.9178123623132706 | Validation Accurancy:  0.8958063796162605\n",
      "Epoch:  3541 | Train Accurancy:  0.9178186431527138 | Validation Accurancy:  0.8958210274577141\n",
      "Epoch:  3542 | Train Accurancy:  0.917824812233448 | Validation Accurancy:  0.8958359137177467\n",
      "Epoch:  3543 | Train Accurancy:  0.9178310409188271 | Validation Accurancy:  0.895850881934166\n",
      "Epoch:  3544 | Train Accurancy:  0.9178371876478195 | Validation Accurancy:  0.8958659246563911\n",
      "Epoch:  3545 | Train Accurancy:  0.9178434312343597 | Validation Accurancy:  0.8958809226751328\n",
      "Epoch:  3546 | Train Accurancy:  0.9178496748209 | Validation Accurancy:  0.8958960324525833\n",
      "Epoch:  3547 | Train Accurancy:  0.9178558215498924 | Validation Accurancy:  0.895911194384098\n",
      "Epoch:  3548 | Train Accurancy:  0.9178619831800461 | Validation Accurancy:  0.8959263637661934\n",
      "Epoch:  3549 | Train Accurancy:  0.9178681597113609 | Validation Accurancy:  0.895941473543644\n",
      "Epoch:  3550 | Train Accurancy:  0.9178743585944176 | Validation Accurancy:  0.8959566205739975\n",
      "Epoch:  3551 | Train Accurancy:  0.9178805649280548 | Validation Accurancy:  0.8959717005491257\n",
      "Epoch:  3552 | Train Accurancy:  0.9178866967558861 | Validation Accurancy:  0.895986869931221\n",
      "Epoch:  3553 | Train Accurancy:  0.9178928956389427 | Validation Accurancy:  0.8960020840167999\n",
      "Epoch:  3554 | Train Accurancy:  0.9178990125656128 | Validation Accurancy:  0.8960170969367027\n",
      "Epoch:  3555 | Train Accurancy:  0.9179052039980888 | Validation Accurancy:  0.896032378077507\n",
      "Epoch:  3556 | Train Accurancy:  0.9179113730788231 | Validation Accurancy:  0.8960473909974098\n",
      "Epoch:  3557 | Train Accurancy:  0.9179175272583961 | Validation Accurancy:  0.8960623741149902\n",
      "Epoch:  3558 | Train Accurancy:  0.917923666536808 | Validation Accurancy:  0.8960774168372154\n",
      "Epoch:  3559 | Train Accurancy:  0.9179297834634781 | Validation Accurancy:  0.8960924595594406\n",
      "Epoch:  3560 | Train Accurancy:  0.9179359152913094 | Validation Accurancy:  0.8961075693368912\n",
      "Epoch:  3561 | Train Accurancy:  0.9179420247673988 | Validation Accurancy:  0.8961226791143417\n",
      "Epoch:  3562 | Train Accurancy:  0.9179481491446495 | Validation Accurancy:  0.8961377963423729\n",
      "Epoch:  3563 | Train Accurancy:  0.9179542288184166 | Validation Accurancy:  0.8961528316140175\n",
      "Epoch:  3564 | Train Accurancy:  0.9179604053497314 | Validation Accurancy:  0.8961679562926292\n",
      "Epoch:  3565 | Train Accurancy:  0.9179664924740791 | Validation Accurancy:  0.8961829990148544\n",
      "Epoch:  3566 | Train Accurancy:  0.9179726168513298 | Validation Accurancy:  0.8961980268359184\n",
      "Epoch:  3567 | Train Accurancy:  0.9179787114262581 | Validation Accurancy:  0.896213136613369\n",
      "Epoch:  3568 | Train Accurancy:  0.9179848060011864 | Validation Accurancy:  0.8962281942367554\n",
      "Epoch:  3569 | Train Accurancy:  0.91799096763134 | Validation Accurancy:  0.8962432146072388\n",
      "Epoch:  3570 | Train Accurancy:  0.9179969802498817 | Validation Accurancy:  0.8962582796812057\n",
      "Epoch:  3571 | Train Accurancy:  0.91800307482481 | Validation Accurancy:  0.8962732329964638\n",
      "Epoch:  3572 | Train Accurancy:  0.9180091619491577 | Validation Accurancy:  0.8962883278727531\n",
      "Epoch:  3573 | Train Accurancy:  0.9180152490735054 | Validation Accurancy:  0.8963033184409142\n",
      "Epoch:  3574 | Train Accurancy:  0.9180213212966919 | Validation Accurancy:  0.8963183835148811\n",
      "Epoch:  3575 | Train Accurancy:  0.9180274084210396 | Validation Accurancy:  0.896333321928978\n",
      "Epoch:  3576 | Train Accurancy:  0.9180334806442261 | Validation Accurancy:  0.8963484764099121\n",
      "Epoch:  3577 | Train Accurancy:  0.9180395379662514 | Validation Accurancy:  0.8963633552193642\n",
      "Epoch:  3578 | Train Accurancy:  0.9180455431342125 | Validation Accurancy:  0.8963783830404282\n",
      "Epoch:  3579 | Train Accurancy:  0.9180516302585602 | Validation Accurancy:  0.8963933736085892\n",
      "Epoch:  3580 | Train Accurancy:  0.9180576875805855 | Validation Accurancy:  0.8964083194732666\n",
      "Epoch:  3581 | Train Accurancy:  0.9180637300014496 | Validation Accurancy:  0.896423302590847\n",
      "Epoch:  3582 | Train Accurancy:  0.9180697724223137 | Validation Accurancy:  0.8964382335543633\n",
      "Epoch:  3583 | Train Accurancy:  0.9180758073925972 | Validation Accurancy:  0.8964531347155571\n",
      "Epoch:  3584 | Train Accurancy:  0.9180818647146225 | Validation Accurancy:  0.8964680805802345\n",
      "Epoch:  3585 | Train Accurancy:  0.9180878698825836 | Validation Accurancy:  0.8964830413460732\n",
      "Epoch:  3586 | Train Accurancy:  0.9180939197540283 | Validation Accurancy:  0.896498017013073\n",
      "Epoch:  3587 | Train Accurancy:  0.9180999025702477 | Validation Accurancy:  0.8965128809213638\n",
      "Epoch:  3588 | Train Accurancy:  0.9181059747934341 | Validation Accurancy:  0.8965278416872025\n",
      "Epoch:  3589 | Train Accurancy:  0.9181119725108147 | Validation Accurancy:  0.8965427801012993\n",
      "Epoch:  3590 | Train Accurancy:  0.9181179776787758 | Validation Accurancy:  0.8965577036142349\n",
      "Epoch:  3591 | Train Accurancy:  0.9181239977478981 | Validation Accurancy:  0.896572507917881\n",
      "Epoch:  3592 | Train Accurancy:  0.9181299731135368 | Validation Accurancy:  0.8965874761343002\n",
      "Epoch:  3593 | Train Accurancy:  0.9181359931826591 | Validation Accurancy:  0.8966023102402687\n",
      "Epoch:  3594 | Train Accurancy:  0.9181419834494591 | Validation Accurancy:  0.8966173231601715\n",
      "Epoch:  3595 | Train Accurancy:  0.9181479141116142 | Validation Accurancy:  0.8966320529580116\n",
      "Epoch:  3596 | Train Accurancy:  0.9181539490818977 | Validation Accurancy:  0.8966470062732697\n",
      "Epoch:  3597 | Train Accurancy:  0.9181599169969559 | Validation Accurancy:  0.8966618031263351\n",
      "Epoch:  3598 | Train Accurancy:  0.918165884912014 | Validation Accurancy:  0.896676629781723\n",
      "Epoch:  3599 | Train Accurancy:  0.9181718975305557 | Validation Accurancy:  0.8966915234923363\n",
      "Epoch:  3600 | Train Accurancy:  0.918177880346775 | Validation Accurancy:  0.8967063948512077\n",
      "Epoch:  3601 | Train Accurancy:  0.918183796107769 | Validation Accurancy:  0.8967211470007896\n",
      "Epoch:  3602 | Train Accurancy:  0.9181898161768913 | Validation Accurancy:  0.8967360034584999\n",
      "Epoch:  3603 | Train Accurancy:  0.9181957766413689 | Validation Accurancy:  0.8967508748173714\n",
      "Epoch:  3604 | Train Accurancy:  0.918201707303524 | Validation Accurancy:  0.8967657387256622\n",
      "Epoch:  3605 | Train Accurancy:  0.9182076677680016 | Validation Accurancy:  0.8967804238200188\n",
      "Epoch:  3606 | Train Accurancy:  0.9182136431336403 | Validation Accurancy:  0.8967952579259872\n",
      "Epoch:  3607 | Train Accurancy:  0.9182195663452148 | Validation Accurancy:  0.8968100547790527\n",
      "Epoch:  3608 | Train Accurancy:  0.9182255119085312 | Validation Accurancy:  0.8968248292803764\n",
      "Epoch:  3609 | Train Accurancy:  0.9182314351201057 | Validation Accurancy:  0.8968396186828613\n",
      "Epoch:  3610 | Train Accurancy:  0.9182373508810997 | Validation Accurancy:  0.896854430437088\n",
      "Epoch:  3611 | Train Accurancy:  0.9182433113455772 | Validation Accurancy:  0.8968691751360893\n",
      "Epoch:  3612 | Train Accurancy:  0.9182492569088936 | Validation Accurancy:  0.8968838602304459\n",
      "Epoch:  3613 | Train Accurancy:  0.9182551577687263 | Validation Accurancy:  0.896898664534092\n",
      "Epoch:  3614 | Train Accurancy:  0.9182610660791397 | Validation Accurancy:  0.8969133868813515\n",
      "Epoch:  3615 | Train Accurancy:  0.9182669818401337 | Validation Accurancy:  0.8969281166791916\n",
      "Epoch:  3616 | Train Accurancy:  0.91827292740345 | Validation Accurancy:  0.8969428092241287\n",
      "Epoch:  3617 | Train Accurancy:  0.9182787910103798 | Validation Accurancy:  0.8969576209783554\n",
      "Epoch:  3618 | Train Accurancy:  0.9182847216725349 | Validation Accurancy:  0.8969723731279373\n",
      "Epoch:  3619 | Train Accurancy:  0.9182905852794647 | Validation Accurancy:  0.8969870656728745\n",
      "Epoch:  3620 | Train Accurancy:  0.9182964786887169 | Validation Accurancy:  0.8970017433166504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3621 | Train Accurancy:  0.918302409350872 | Validation Accurancy:  0.8970164954662323\n",
      "Epoch:  3622 | Train Accurancy:  0.91830825060606 | Validation Accurancy:  0.8970311656594276\n",
      "Epoch:  3623 | Train Accurancy:  0.9183141365647316 | Validation Accurancy:  0.8970458880066872\n",
      "Epoch:  3624 | Train Accurancy:  0.9183200374245644 | Validation Accurancy:  0.8970605060458183\n",
      "Epoch:  3625 | Train Accurancy:  0.9183259010314941 | Validation Accurancy:  0.8970751836895943\n",
      "Epoch:  3626 | Train Accurancy:  0.9183317348361015 | Validation Accurancy:  0.8970898613333702\n",
      "Epoch:  3627 | Train Accurancy:  0.9183376207947731 | Validation Accurancy:  0.897104486823082\n",
      "Epoch:  3628 | Train Accurancy:  0.9183435216546059 | Validation Accurancy:  0.8971191868185997\n",
      "Epoch:  3629 | Train Accurancy:  0.918349377810955 | Validation Accurancy:  0.8971337750554085\n",
      "Epoch:  3630 | Train Accurancy:  0.9183552116155624 | Validation Accurancy:  0.897148460149765\n",
      "Epoch:  3631 | Train Accurancy:  0.918361060321331 | Validation Accurancy:  0.8971631228923798\n",
      "Epoch:  3632 | Train Accurancy:  0.9183669239282608 | Validation Accurancy:  0.8971777707338333\n",
      "Epoch:  3633 | Train Accurancy:  0.918372742831707 | Validation Accurancy:  0.8971922770142555\n",
      "Epoch:  3634 | Train Accurancy:  0.9183785915374756 | Validation Accurancy:  0.8972068876028061\n",
      "Epoch:  3635 | Train Accurancy:  0.918384425342083 | Validation Accurancy:  0.8972215875983238\n",
      "Epoch:  3636 | Train Accurancy:  0.9183902963995934 | Validation Accurancy:  0.8972361460328102\n",
      "Epoch:  3637 | Train Accurancy:  0.9183960631489754 | Validation Accurancy:  0.8972506821155548\n",
      "Epoch:  3638 | Train Accurancy:  0.918401874601841 | Validation Accurancy:  0.8972653448581696\n",
      "Epoch:  3639 | Train Accurancy:  0.918407753109932 | Validation Accurancy:  0.8972798734903336\n",
      "Epoch:  3640 | Train Accurancy:  0.9184135720133781 | Validation Accurancy:  0.8972945064306259\n",
      "Epoch:  3641 | Train Accurancy:  0.918419361114502 | Validation Accurancy:  0.8973090574145317\n",
      "Epoch:  3642 | Train Accurancy:  0.9184251874685287 | Validation Accurancy:  0.8973236232995987\n",
      "Epoch:  3643 | Train Accurancy:  0.918430931866169 | Validation Accurancy:  0.8973381742835045\n",
      "Epoch:  3644 | Train Accurancy:  0.9184367582201958 | Validation Accurancy:  0.8973526731133461\n",
      "Epoch:  3645 | Train Accurancy:  0.9184426069259644 | Validation Accurancy:  0.8973672240972519\n",
      "Epoch:  3646 | Train Accurancy:  0.9184483587741852 | Validation Accurancy:  0.8973817676305771\n",
      "Epoch:  3647 | Train Accurancy:  0.918454185128212 | Validation Accurancy:  0.8973963484168053\n",
      "Epoch:  3648 | Train Accurancy:  0.9184599444270134 | Validation Accurancy:  0.8974107801914215\n",
      "Epoch:  3649 | Train Accurancy:  0.9184657335281372 | Validation Accurancy:  0.8974253907799721\n",
      "Epoch:  3650 | Train Accurancy:  0.9184715300798416 | Validation Accurancy:  0.8974398747086525\n",
      "Epoch:  3651 | Train Accurancy:  0.918477289378643 | Validation Accurancy:  0.8974544182419777\n",
      "Epoch:  3652 | Train Accurancy:  0.9184831157326698 | Validation Accurancy:  0.8974689692258835\n",
      "Epoch:  3653 | Train Accurancy:  0.9184888675808907 | Validation Accurancy:  0.8974833562970161\n",
      "Epoch:  3654 | Train Accurancy:  0.9184945970773697 | Validation Accurancy:  0.8974978625774384\n",
      "Epoch:  3655 | Train Accurancy:  0.9185004010796547 | Validation Accurancy:  0.8975123092532158\n",
      "Epoch:  3656 | Train Accurancy:  0.9185061231255531 | Validation Accurancy:  0.8975267931818962\n",
      "Epoch:  3657 | Train Accurancy:  0.9185118973255157 | Validation Accurancy:  0.8975412100553513\n",
      "Epoch:  3658 | Train Accurancy:  0.918517641723156 | Validation Accurancy:  0.8975557461380959\n",
      "Epoch:  3659 | Train Accurancy:  0.9185234159231186 | Validation Accurancy:  0.8975701853632927\n",
      "Epoch:  3660 | Train Accurancy:  0.9185291454195976 | Validation Accurancy:  0.8975845947861671\n",
      "Epoch:  3661 | Train Accurancy:  0.9185348823666573 | Validation Accurancy:  0.8975990936160088\n",
      "Epoch:  3662 | Train Accurancy:  0.9185406267642975 | Validation Accurancy:  0.897613450884819\n",
      "Epoch:  3663 | Train Accurancy:  0.9185463264584541 | Validation Accurancy:  0.8976279199123383\n",
      "Epoch:  3664 | Train Accurancy:  0.9185520708560944 | Validation Accurancy:  0.8976423740386963\n",
      "Epoch:  3665 | Train Accurancy:  0.9185577556490898 | Validation Accurancy:  0.8976568505167961\n",
      "Epoch:  3666 | Train Accurancy:  0.9185634776949883 | Validation Accurancy:  0.8976711258292198\n",
      "Epoch:  3667 | Train Accurancy:  0.9185691997408867 | Validation Accurancy:  0.8976855427026749\n",
      "Epoch:  3668 | Train Accurancy:  0.9185748845338821 | Validation Accurancy:  0.8976999372243881\n",
      "Epoch:  3669 | Train Accurancy:  0.9185806289315224 | Validation Accurancy:  0.897714339196682\n",
      "Epoch:  3670 | Train Accurancy:  0.9185863435268402 | Validation Accurancy:  0.897728756070137\n",
      "Epoch:  3671 | Train Accurancy:  0.9185920283198357 | Validation Accurancy:  0.8977431058883667\n",
      "Epoch:  3672 | Train Accurancy:  0.9185977354645729 | Validation Accurancy:  0.8977574184536934\n",
      "Epoch:  3673 | Train Accurancy:  0.9186034575104713 | Validation Accurancy:  0.8977719247341156\n",
      "Epoch:  3674 | Train Accurancy:  0.9186091348528862 | Validation Accurancy:  0.8977862372994423\n",
      "Epoch:  3675 | Train Accurancy:  0.9186148121953011 | Validation Accurancy:  0.89780043810606\n",
      "Epoch:  3676 | Train Accurancy:  0.9186204969882965 | Validation Accurancy:  0.8978149518370628\n",
      "Epoch:  3677 | Train Accurancy:  0.9186261668801308 | Validation Accurancy:  0.8978292942047119\n",
      "Epoch:  3678 | Train Accurancy:  0.918631874024868 | Validation Accurancy:  0.897843524813652\n",
      "Epoch:  3679 | Train Accurancy:  0.9186375364661217 | Validation Accurancy:  0.8978578895330429\n",
      "Epoch:  3680 | Train Accurancy:  0.9186431914567947 | Validation Accurancy:  0.8978722244501114\n",
      "Epoch:  3681 | Train Accurancy:  0.9186488762497902 | Validation Accurancy:  0.8978865370154381\n",
      "Epoch:  3682 | Train Accurancy:  0.9186544939875603 | Validation Accurancy:  0.8979008719325066\n",
      "Epoch:  3683 | Train Accurancy:  0.9186601936817169 | Validation Accurancy:  0.8979151695966721\n",
      "Epoch:  3684 | Train Accurancy:  0.9186658784747124 | Validation Accurancy:  0.8979294151067734\n",
      "Epoch:  3685 | Train Accurancy:  0.9186714738607407 | Validation Accurancy:  0.8979436606168747\n",
      "Epoch:  3686 | Train Accurancy:  0.9186771661043167 | Validation Accurancy:  0.8979580402374268\n",
      "Epoch:  3687 | Train Accurancy:  0.9186827763915062 | Validation Accurancy:  0.8979722708463669\n",
      "Epoch:  3688 | Train Accurancy:  0.9186884239315987 | Validation Accurancy:  0.8979865461587906\n",
      "Epoch:  3689 | Train Accurancy:  0.9186940714716911 | Validation Accurancy:  0.8980008438229561\n",
      "Epoch:  3690 | Train Accurancy:  0.9186997190117836 | Validation Accurancy:  0.8980150669813156\n",
      "Epoch:  3691 | Train Accurancy:  0.9187053218483925 | Validation Accurancy:  0.8980293124914169\n",
      "Epoch:  3692 | Train Accurancy:  0.918710932135582 | Validation Accurancy:  0.8980436101555824\n",
      "Epoch:  3693 | Train Accurancy:  0.9187165647745132 | Validation Accurancy:  0.8980576917529106\n",
      "Epoch:  3694 | Train Accurancy:  0.9187221452593803 | Validation Accurancy:  0.8980720266699791\n",
      "Epoch:  3695 | Train Accurancy:  0.918727844953537 | Validation Accurancy:  0.8980863466858864\n",
      "Epoch:  3696 | Train Accurancy:  0.9187333658337593 | Validation Accurancy:  0.8981004431843758\n",
      "Epoch:  3697 | Train Accurancy:  0.91873899102211 | Validation Accurancy:  0.8981145769357681\n",
      "Epoch:  3698 | Train Accurancy:  0.9187446162104607 | Validation Accurancy:  0.8981288745999336\n",
      "Epoch:  3699 | Train Accurancy:  0.9187502041459084 | Validation Accurancy:  0.8981431424617767\n",
      "Epoch:  3700 | Train Accurancy:  0.9187558814883232 | Validation Accurancy:  0.8981572240591049\n",
      "Epoch:  3701 | Train Accurancy:  0.9187613874673843 | Validation Accurancy:  0.8981714621186256\n",
      "Epoch:  3702 | Train Accurancy:  0.918766975402832 | Validation Accurancy:  0.8981856480240822\n",
      "Epoch:  3703 | Train Accurancy:  0.9187726005911827 | Validation Accurancy:  0.8981998264789581\n",
      "Epoch:  3704 | Train Accurancy:  0.9187781438231468 | Validation Accurancy:  0.8982116729021072\n",
      "Epoch:  3705 | Train Accurancy:  0.9187837913632393 | Validation Accurancy:  0.8982264995574951\n",
      "Epoch:  3706 | Train Accurancy:  0.9187893569469452 | Validation Accurancy:  0.8982388600707054\n",
      "Epoch:  3707 | Train Accurancy:  0.9187948778271675 | Validation Accurancy:  0.898253969848156\n",
      "Epoch:  3708 | Train Accurancy:  0.9188004359602928 | Validation Accurancy:  0.8982688337564468\n",
      "Epoch:  3709 | Train Accurancy:  0.9188059940934181 | Validation Accurancy:  0.8982812836766243\n",
      "Epoch:  3710 | Train Accurancy:  0.9188116043806076 | Validation Accurancy:  0.8982963263988495\n",
      "Epoch:  3711 | Train Accurancy:  0.9188171625137329 | Validation Accurancy:  0.8983087837696075\n",
      "Epoch:  3712 | Train Accurancy:  0.9188226833939552 | Validation Accurancy:  0.8983241617679596\n",
      "Epoch:  3713 | Train Accurancy:  0.9188282787799835 | Validation Accurancy:  0.8983367681503296\n",
      "Epoch:  3714 | Train Accurancy:  0.9188338592648506 | Validation Accurancy:  0.89835225045681\n",
      "Epoch:  3715 | Train Accurancy:  0.9188393205404282 | Validation Accurancy:  0.898364745080471\n",
      "Epoch:  3716 | Train Accurancy:  0.9188448861241341 | Validation Accurancy:  0.8983802124857903\n",
      "Epoch:  3717 | Train Accurancy:  0.9188504070043564 | Validation Accurancy:  0.898392915725708\n",
      "Epoch:  3718 | Train Accurancy:  0.9188559427857399 | Validation Accurancy:  0.8984082713723183\n",
      "Epoch:  3719 | Train Accurancy:  0.9188615083694458 | Validation Accurancy:  0.898420974612236\n",
      "Epoch:  3720 | Train Accurancy:  0.9188670292496681 | Validation Accurancy:  0.8984363600611687\n",
      "Epoch:  3721 | Train Accurancy:  0.9188725501298904 | Validation Accurancy:  0.8984489813446999\n",
      "Epoch:  3722 | Train Accurancy:  0.9188780337572098 | Validation Accurancy:  0.8984644338488579\n",
      "Epoch:  3723 | Train Accurancy:  0.9188835546374321 | Validation Accurancy:  0.8984771072864532\n",
      "Epoch:  3724 | Train Accurancy:  0.9188890680670738 | Validation Accurancy:  0.8984924107789993\n",
      "Epoch:  3725 | Train Accurancy:  0.9188946187496185 | Validation Accurancy:  0.8985050767660141\n",
      "Epoch:  3726 | Train Accurancy:  0.9189001247286797 | Validation Accurancy:  0.8985204771161079\n",
      "Epoch:  3727 | Train Accurancy:  0.9189055785536766 | Validation Accurancy:  0.8985331952571869\n",
      "Epoch:  3728 | Train Accurancy:  0.9189111068844795 | Validation Accurancy:  0.8985485062003136\n",
      "Epoch:  3729 | Train Accurancy:  0.91891660541296 | Validation Accurancy:  0.8985611721873283\n",
      "Epoch:  3730 | Train Accurancy:  0.9189221411943436 | Validation Accurancy:  0.898576520383358\n",
      "Epoch:  3731 | Train Accurancy:  0.9189275577664375 | Validation Accurancy:  0.8985890671610832\n",
      "Epoch:  3732 | Train Accurancy:  0.9189330488443375 | Validation Accurancy:  0.8986044451594353\n",
      "Epoch:  3733 | Train Accurancy:  0.9189385175704956 | Validation Accurancy:  0.8986170962452888\n",
      "Epoch:  3734 | Train Accurancy:  0.9189439937472343 | Validation Accurancy:  0.8986323028802872\n",
      "Epoch:  3735 | Train Accurancy:  0.9189495071768761 | Validation Accurancy:  0.8986449092626572\n",
      "Epoch:  3736 | Train Accurancy:  0.918954961001873 | Validation Accurancy:  0.8986602649092674\n",
      "Epoch:  3737 | Train Accurancy:  0.9189604371786118 | Validation Accurancy:  0.8986729308962822\n",
      "Epoch:  3738 | Train Accurancy:  0.9189658313989639 | Validation Accurancy:  0.8986880853772163\n",
      "Epoch:  3739 | Train Accurancy:  0.9189713448286057 | Validation Accurancy:  0.8987007662653923\n",
      "Epoch:  3740 | Train Accurancy:  0.9189767837524414 | Validation Accurancy:  0.8987160176038742\n",
      "Epoch:  3741 | Train Accurancy:  0.9189822524785995 | Validation Accurancy:  0.8987285643815994\n",
      "Epoch:  3742 | Train Accurancy:  0.9189877137541771 | Validation Accurancy:  0.8987438455224037\n",
      "Epoch:  3743 | Train Accurancy:  0.9189931377768517 | Validation Accurancy:  0.8987564370036125\n",
      "Epoch:  3744 | Train Accurancy:  0.9189985617995262 | Validation Accurancy:  0.8987716436386108\n",
      "Epoch:  3745 | Train Accurancy:  0.9190040305256844 | Validation Accurancy:  0.8987841084599495\n",
      "Epoch:  3746 | Train Accurancy:  0.9190095141530037 | Validation Accurancy:  0.898799441754818\n",
      "Epoch:  3747 | Train Accurancy:  0.9190149232745171 | Validation Accurancy:  0.8988120555877686\n",
      "Epoch:  3748 | Train Accurancy:  0.9190203323960304 | Validation Accurancy:  0.8988272473216057\n",
      "Epoch:  3749 | Train Accurancy:  0.9190257787704468 | Validation Accurancy:  0.8988397642970085\n",
      "Epoch:  3750 | Train Accurancy:  0.919031172990799 | Validation Accurancy:  0.8988549709320068\n",
      "Epoch:  3751 | Train Accurancy:  0.9190366193652153 | Validation Accurancy:  0.8988674208521843\n",
      "Epoch:  3752 | Train Accurancy:  0.9190420135855675 | Validation Accurancy:  0.8988820984959602\n",
      "Epoch:  3753 | Train Accurancy:  0.9190474450588226 | Validation Accurancy:  0.8988965898752213\n",
      "Epoch:  3754 | Train Accurancy:  0.9190528318285942 | Validation Accurancy:  0.8989091664552689\n",
      "Epoch:  3755 | Train Accurancy:  0.919058196246624 | Validation Accurancy:  0.8989237248897552\n",
      "Epoch:  3756 | Train Accurancy:  0.919063612818718 | Validation Accurancy:  0.8989380821585655\n",
      "Epoch:  3757 | Train Accurancy:  0.9190690144896507 | Validation Accurancy:  0.8989522755146027\n",
      "Epoch:  3758 | Train Accurancy:  0.9190744161605835 | Validation Accurancy:  0.8989663869142532\n",
      "Epoch:  3759 | Train Accurancy:  0.9190798103809357 | Validation Accurancy:  0.8989805281162262\n",
      "Epoch:  3760 | Train Accurancy:  0.9190852269530296 | Validation Accurancy:  0.8989944085478783\n",
      "Epoch:  3761 | Train Accurancy:  0.9190906062722206 | Validation Accurancy:  0.8990083783864975\n",
      "Epoch:  3762 | Train Accurancy:  0.919095940887928 | Validation Accurancy:  0.8990221694111824\n",
      "Epoch:  3763 | Train Accurancy:  0.9191013649106026 | Validation Accurancy:  0.8990360572934151\n",
      "Epoch:  3764 | Train Accurancy:  0.9191067442297935 | Validation Accurancy:  0.8990498632192612\n",
      "Epoch:  3765 | Train Accurancy:  0.9191120490431786 | Validation Accurancy:  0.8990638107061386\n",
      "Epoch:  3766 | Train Accurancy:  0.9191174507141113 | Validation Accurancy:  0.8990776091814041\n",
      "Epoch:  3767 | Train Accurancy:  0.9191228076815605 | Validation Accurancy:  0.8990914300084114\n",
      "Epoch:  3768 | Train Accurancy:  0.9191281422972679 | Validation Accurancy:  0.8991051539778709\n",
      "Epoch:  3769 | Train Accurancy:  0.9191335216164589 | Validation Accurancy:  0.8991189077496529\n",
      "Epoch:  3770 | Train Accurancy:  0.9191388785839081 | Validation Accurancy:  0.899132676422596\n",
      "Epoch:  3771 | Train Accurancy:  0.9191442355513573 | Validation Accurancy:  0.8991463854908943\n",
      "Epoch:  3772 | Train Accurancy:  0.9191495552659035 | Validation Accurancy:  0.8991602510213852\n",
      "Epoch:  3773 | Train Accurancy:  0.9191548675298691 | Validation Accurancy:  0.8991739898920059\n",
      "Epoch:  3774 | Train Accurancy:  0.9191602393984795 | Validation Accurancy:  0.8991860076785088\n",
      "Epoch:  3775 | Train Accurancy:  0.9191655814647675 | Validation Accurancy:  0.8992002084851265\n",
      "Epoch:  3776 | Train Accurancy:  0.9191709458827972 | Validation Accurancy:  0.8992143198847771\n",
      "Epoch:  3777 | Train Accurancy:  0.9191762134432793 | Validation Accurancy:  0.8992282301187515\n",
      "Epoch:  3778 | Train Accurancy:  0.9191815406084061 | Validation Accurancy:  0.8992421999573708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3779 | Train Accurancy:  0.9191868826746941 | Validation Accurancy:  0.8992559760808945\n",
      "Epoch:  3780 | Train Accurancy:  0.9191922396421432 | Validation Accurancy:  0.8992698937654495\n",
      "Epoch:  3781 | Train Accurancy:  0.91919756680727 | Validation Accurancy:  0.8992836326360703\n",
      "Epoch:  3782 | Train Accurancy:  0.9192028269171715 | Validation Accurancy:  0.8992972448468208\n",
      "Epoch:  3783 | Train Accurancy:  0.9192081317305565 | Validation Accurancy:  0.8993110433220863\n",
      "Epoch:  3784 | Train Accurancy:  0.9192134812474251 | Validation Accurancy:  0.8993247747421265\n",
      "Epoch:  3785 | Train Accurancy:  0.9192187786102295 | Validation Accurancy:  0.8993385210633278\n",
      "Epoch:  3786 | Train Accurancy:  0.9192240536212921 | Validation Accurancy:  0.8993522375822067\n",
      "Epoch:  3787 | Train Accurancy:  0.9192293733358383 | Validation Accurancy:  0.8993657827377319\n",
      "Epoch:  3788 | Train Accurancy:  0.9192346781492233 | Validation Accurancy:  0.8993795737624168\n",
      "Epoch:  3789 | Train Accurancy:  0.9192399233579636 | Validation Accurancy:  0.8993932753801346\n",
      "Epoch:  3790 | Train Accurancy:  0.919245220720768 | Validation Accurancy:  0.8994068875908852\n",
      "Epoch:  3791 | Train Accurancy:  0.9192505180835724 | Validation Accurancy:  0.8994205370545387\n",
      "Epoch:  3792 | Train Accurancy:  0.9192557856440544 | Validation Accurancy:  0.8994325250387192\n",
      "Epoch:  3793 | Train Accurancy:  0.9192611053586006 | Validation Accurancy:  0.8994466736912727\n",
      "Epoch:  3794 | Train Accurancy:  0.9192663356661797 | Validation Accurancy:  0.8994606211781502\n",
      "Epoch:  3795 | Train Accurancy:  0.9192716181278229 | Validation Accurancy:  0.8994743451476097\n",
      "Epoch:  3796 | Train Accurancy:  0.9192769229412079 | Validation Accurancy:  0.899488277733326\n",
      "Epoch:  3797 | Train Accurancy:  0.9192821756005287 | Validation Accurancy:  0.8995020091533661\n",
      "Epoch:  3798 | Train Accurancy:  0.919287420809269 | Validation Accurancy:  0.8995156660676003\n",
      "Epoch:  3799 | Train Accurancy:  0.919292651116848 | Validation Accurancy:  0.8995294123888016\n",
      "Epoch:  3800 | Train Accurancy:  0.9192979261279106 | Validation Accurancy:  0.8995430544018745\n",
      "Epoch:  3801 | Train Accurancy:  0.9193031564354897 | Validation Accurancy:  0.8995565623044968\n",
      "Epoch:  3802 | Train Accurancy:  0.9193084090948105 | Validation Accurancy:  0.8995702490210533\n",
      "Epoch:  3803 | Train Accurancy:  0.9193137064576149 | Validation Accurancy:  0.8995838239789009\n",
      "Epoch:  3804 | Train Accurancy:  0.9193189144134521 | Validation Accurancy:  0.8995973840355873\n",
      "Epoch:  3805 | Train Accurancy:  0.9193241968750954 | Validation Accurancy:  0.8996093347668648\n",
      "Epoch:  3806 | Train Accurancy:  0.9193293750286102 | Validation Accurancy:  0.8996233195066452\n",
      "Epoch:  3807 | Train Accurancy:  0.9193346053361893 | Validation Accurancy:  0.8996372148394585\n",
      "Epoch:  3808 | Train Accurancy:  0.9193397909402847 | Validation Accurancy:  0.899651013314724\n",
      "Epoch:  3809 | Train Accurancy:  0.9193450883030891 | Validation Accurancy:  0.8996647596359253\n",
      "Epoch:  3810 | Train Accurancy:  0.9193502515554428 | Validation Accurancy:  0.8996783941984177\n",
      "Epoch:  3811 | Train Accurancy:  0.9193554893136024 | Validation Accurancy:  0.8996920734643936\n",
      "Epoch:  3812 | Train Accurancy:  0.9193607196211815 | Validation Accurancy:  0.8997056111693382\n",
      "Epoch:  3813 | Train Accurancy:  0.9193658828735352 | Validation Accurancy:  0.899719201028347\n",
      "Epoch:  3814 | Train Accurancy:  0.919371135532856 | Validation Accurancy:  0.8997326865792274\n",
      "Epoch:  3815 | Train Accurancy:  0.9193763360381126 | Validation Accurancy:  0.8997461348772049\n",
      "Epoch:  3816 | Train Accurancy:  0.9193815663456917 | Validation Accurancy:  0.8997581452131271\n",
      "Epoch:  3817 | Train Accurancy:  0.9193867519497871 | Validation Accurancy:  0.8997720703482628\n",
      "Epoch:  3818 | Train Accurancy:  0.9193919748067856 | Validation Accurancy:  0.8997858464717865\n",
      "Epoch:  3819 | Train Accurancy:  0.9193971082568169 | Validation Accurancy:  0.899799719452858\n",
      "Epoch:  3820 | Train Accurancy:  0.9194022938609123 | Validation Accurancy:  0.899813286960125\n",
      "Epoch:  3821 | Train Accurancy:  0.9194074720144272 | Validation Accurancy:  0.899826817214489\n",
      "Epoch:  3822 | Train Accurancy:  0.919412687420845 | Validation Accurancy:  0.8998404815793037\n",
      "Epoch:  3823 | Train Accurancy:  0.9194178730249405 | Validation Accurancy:  0.8998540118336678\n",
      "Epoch:  3824 | Train Accurancy:  0.9194230362772942 | Validation Accurancy:  0.8998675420880318\n",
      "Epoch:  3825 | Train Accurancy:  0.919428214430809 | Validation Accurancy:  0.8998793736100197\n",
      "Epoch:  3826 | Train Accurancy:  0.9194333478808403 | Validation Accurancy:  0.8998932763934135\n",
      "Epoch:  3827 | Train Accurancy:  0.9194385334849358 | Validation Accurancy:  0.899907112121582\n",
      "Epoch:  3828 | Train Accurancy:  0.9194437265396118 | Validation Accurancy:  0.8999207764863968\n",
      "Epoch:  3829 | Train Accurancy:  0.9194488599896431 | Validation Accurancy:  0.8999344110488892\n",
      "Epoch:  3830 | Train Accurancy:  0.9194540306925774 | Validation Accurancy:  0.899947889149189\n",
      "Epoch:  3831 | Train Accurancy:  0.9194591715931892 | Validation Accurancy:  0.8999613747000694\n",
      "Epoch:  3832 | Train Accurancy:  0.9194643422961235 | Validation Accurancy:  0.8999733403325081\n",
      "Epoch:  3833 | Train Accurancy:  0.919469453394413 | Validation Accurancy:  0.8999871835112572\n",
      "Epoch:  3834 | Train Accurancy:  0.9194746389985085 | Validation Accurancy:  0.9000010266900063\n",
      "Epoch:  3835 | Train Accurancy:  0.9194797426462173 | Validation Accurancy:  0.9000146761536598\n",
      "Epoch:  3836 | Train Accurancy:  0.9194848462939262 | Validation Accurancy:  0.9000281766057014\n",
      "Epoch:  3837 | Train Accurancy:  0.9194900467991829 | Validation Accurancy:  0.9000417217612267\n",
      "Epoch:  3838 | Train Accurancy:  0.9194951802492142 | Validation Accurancy:  0.9000552147626877\n",
      "Epoch:  3839 | Train Accurancy:  0.9195002764463425 | Validation Accurancy:  0.9000686854124069\n",
      "Epoch:  3840 | Train Accurancy:  0.9195054396986961 | Validation Accurancy:  0.9000804796814919\n",
      "Epoch:  3841 | Train Accurancy:  0.9195105284452438 | Validation Accurancy:  0.9000943750143051\n",
      "Epoch:  3842 | Train Accurancy:  0.9195156469941139 | Validation Accurancy:  0.9001079648733139\n",
      "Epoch:  3843 | Train Accurancy:  0.9195207729935646 | Validation Accurancy:  0.9001216888427734\n",
      "Epoch:  3844 | Train Accurancy:  0.9195258766412735 | Validation Accurancy:  0.9001351594924927\n",
      "Epoch:  3845 | Train Accurancy:  0.9195310696959496 | Validation Accurancy:  0.9001486748456955\n",
      "Epoch:  3846 | Train Accurancy:  0.9195360764861107 | Validation Accurancy:  0.9001620933413506\n",
      "Epoch:  3847 | Train Accurancy:  0.9195412173867226 | Validation Accurancy:  0.9001738503575325\n",
      "Epoch:  3848 | Train Accurancy:  0.9195462912321091 | Validation Accurancy:  0.9001877009868622\n",
      "Epoch:  3849 | Train Accurancy:  0.9195514395833015 | Validation Accurancy:  0.9002012759447098\n",
      "Epoch:  3850 | Train Accurancy:  0.9195565059781075 | Validation Accurancy:  0.9002148881554604\n",
      "Epoch:  3851 | Train Accurancy:  0.9195615872740746 | Validation Accurancy:  0.900228425860405\n",
      "Epoch:  3852 | Train Accurancy:  0.9195667132735252 | Validation Accurancy:  0.9002417847514153\n",
      "Epoch:  3853 | Train Accurancy:  0.9195717424154282 | Validation Accurancy:  0.900253601372242\n",
      "Epoch:  3854 | Train Accurancy:  0.919576846063137 | Validation Accurancy:  0.9002674296498299\n",
      "Epoch:  3855 | Train Accurancy:  0.91958187520504 | Validation Accurancy:  0.900281049311161\n",
      "Epoch:  3856 | Train Accurancy:  0.9195869714021683 | Validation Accurancy:  0.9002946391701698\n",
      "Epoch:  3857 | Train Accurancy:  0.9195920452475548 | Validation Accurancy:  0.9003081321716309\n",
      "Epoch:  3858 | Train Accurancy:  0.9195971488952637 | Validation Accurancy:  0.9003214985132217\n",
      "Epoch:  3859 | Train Accurancy:  0.9196022301912308 | Validation Accurancy:  0.9003332480788231\n",
      "Epoch:  3860 | Train Accurancy:  0.9196072593331337 | Validation Accurancy:  0.900347076356411\n",
      "Epoch:  3861 | Train Accurancy:  0.9196123331785202 | Validation Accurancy:  0.9003606960177422\n",
      "Epoch:  3862 | Train Accurancy:  0.9196173399686813 | Validation Accurancy:  0.9003742039203644\n",
      "Epoch:  3863 | Train Accurancy:  0.9196224212646484 | Validation Accurancy:  0.9003876745700836\n",
      "Epoch:  3864 | Train Accurancy:  0.9196274653077126 | Validation Accurancy:  0.9004010111093521\n",
      "Epoch:  3865 | Train Accurancy:  0.9196325689554214 | Validation Accurancy:  0.9004127606749535\n",
      "Epoch:  3866 | Train Accurancy:  0.9196375459432602 | Validation Accurancy:  0.9004264995455742\n",
      "Epoch:  3867 | Train Accurancy:  0.9196426197886467 | Validation Accurancy:  0.9004401341080666\n",
      "Epoch:  3868 | Train Accurancy:  0.9196476191282272 | Validation Accurancy:  0.9004535749554634\n",
      "Epoch:  3869 | Train Accurancy:  0.9196527078747749 | Validation Accurancy:  0.900467038154602\n",
      "Epoch:  3870 | Train Accurancy:  0.9196577295660973 | Validation Accurancy:  0.900480255484581\n",
      "Epoch:  3871 | Train Accurancy:  0.919662743806839 | Validation Accurancy:  0.9004920497536659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3872 | Train Accurancy:  0.9196677878499031 | Validation Accurancy:  0.9005056843161583\n",
      "Epoch:  3873 | Train Accurancy:  0.9196728095412254 | Validation Accurancy:  0.9005193263292313\n",
      "Epoch:  3874 | Train Accurancy:  0.9196778163313866 | Validation Accurancy:  0.9005327373743057\n",
      "Epoch:  3875 | Train Accurancy:  0.9196828678250313 | Validation Accurancy:  0.9005461037158966\n",
      "Epoch:  3876 | Train Accurancy:  0.9196878969669342 | Validation Accurancy:  0.9005578830838203\n",
      "Epoch:  3877 | Train Accurancy:  0.9196928665041924 | Validation Accurancy:  0.9005714729428291\n",
      "Epoch:  3878 | Train Accurancy:  0.9196978509426117 | Validation Accurancy:  0.9005850926041603\n",
      "Epoch:  3879 | Train Accurancy:  0.9197028651833534 | Validation Accurancy:  0.9005986154079437\n",
      "Epoch:  3880 | Train Accurancy:  0.919707864522934 | Validation Accurancy:  0.9006118103861809\n",
      "Epoch:  3881 | Train Accurancy:  0.9197129234671593 | Validation Accurancy:  0.900625191628933\n",
      "Epoch:  3882 | Train Accurancy:  0.9197178930044174 | Validation Accurancy:  0.9006367772817612\n",
      "Epoch:  3883 | Train Accurancy:  0.9197229072451591 | Validation Accurancy:  0.9006505236029625\n",
      "Epoch:  3884 | Train Accurancy:  0.9197278544306755 | Validation Accurancy:  0.9006640911102295\n",
      "Epoch:  3885 | Train Accurancy:  0.9197328090667725 | Validation Accurancy:  0.9006773456931114\n",
      "Epoch:  3886 | Train Accurancy:  0.9197378158569336 | Validation Accurancy:  0.9006906598806381\n",
      "Epoch:  3887 | Train Accurancy:  0.9197428151965141 | Validation Accurancy:  0.9007023423910141\n",
      "Epoch:  3888 | Train Accurancy:  0.9197478070855141 | Validation Accurancy:  0.9007159397006035\n",
      "Epoch:  3889 | Train Accurancy:  0.919752798974514 | Validation Accurancy:  0.9007294327020645\n",
      "Epoch:  3890 | Train Accurancy:  0.9197577461600304 | Validation Accurancy:  0.9007429108023643\n",
      "Epoch:  3891 | Train Accurancy:  0.9197626635432243 | Validation Accurancy:  0.9007562175393105\n",
      "Epoch:  3892 | Train Accurancy:  0.9197676405310631 | Validation Accurancy:  0.9007678404450417\n",
      "Epoch:  3893 | Train Accurancy:  0.9197726473212242 | Validation Accurancy:  0.9007814973592758\n",
      "Epoch:  3894 | Train Accurancy:  0.9197776168584824 | Validation Accurancy:  0.9007949605584145\n",
      "Epoch:  3895 | Train Accurancy:  0.9197825863957405 | Validation Accurancy:  0.9008081927895546\n",
      "Epoch:  3896 | Train Accurancy:  0.9197875186800957 | Validation Accurancy:  0.9008199945092201\n",
      "Epoch:  3897 | Train Accurancy:  0.9197924584150314 | Validation Accurancy:  0.9008336439728737\n",
      "Epoch:  3898 | Train Accurancy:  0.9197974428534508 | Validation Accurancy:  0.9008470475673676\n",
      "Epoch:  3899 | Train Accurancy:  0.919802337884903 | Validation Accurancy:  0.900860458612442\n",
      "Epoch:  3900 | Train Accurancy:  0.9198073074221611 | Validation Accurancy:  0.900873675942421\n",
      "Epoch:  3901 | Train Accurancy:  0.9198122844099998 | Validation Accurancy:  0.9008852690458298\n",
      "Epoch:  3902 | Train Accurancy:  0.919817179441452 | Validation Accurancy:  0.9008988365530968\n",
      "Epoch:  3903 | Train Accurancy:  0.9198221266269684 | Validation Accurancy:  0.900912307202816\n",
      "Epoch:  3904 | Train Accurancy:  0.9198270291090012 | Validation Accurancy:  0.9009256437420845\n",
      "Epoch:  3905 | Train Accurancy:  0.9198319464921951 | Validation Accurancy:  0.9009372889995575\n",
      "Epoch:  3906 | Train Accurancy:  0.9198368638753891 | Validation Accurancy:  0.9009508565068245\n",
      "Epoch:  3907 | Train Accurancy:  0.9198418110609055 | Validation Accurancy:  0.9009643122553825\n",
      "Epoch:  3908 | Train Accurancy:  0.9198467507958412 | Validation Accurancy:  0.9009775817394257\n",
      "Epoch:  3909 | Train Accurancy:  0.9198516383767128 | Validation Accurancy:  0.9009892046451569\n",
      "Epoch:  3910 | Train Accurancy:  0.9198565632104874 | Validation Accurancy:  0.9010028392076492\n",
      "Epoch:  3911 | Train Accurancy:  0.9198614582419395 | Validation Accurancy:  0.9010162577033043\n",
      "Epoch:  3912 | Train Accurancy:  0.9198663458228111 | Validation Accurancy:  0.9010295420885086\n",
      "Epoch:  3913 | Train Accurancy:  0.9198712483048439 | Validation Accurancy:  0.9010427072644234\n",
      "Epoch:  3914 | Train Accurancy:  0.9198761805891991 | Validation Accurancy:  0.901054210960865\n",
      "Epoch:  3915 | Train Accurancy:  0.9198810830712318 | Validation Accurancy:  0.9010676443576813\n",
      "Epoch:  3916 | Train Accurancy:  0.9198859855532646 | Validation Accurancy:  0.9010811597108841\n",
      "Epoch:  3917 | Train Accurancy:  0.9198908507823944 | Validation Accurancy:  0.9010943621397018\n",
      "Epoch:  3918 | Train Accurancy:  0.919895775616169 | Validation Accurancy:  0.9011060446500778\n",
      "Epoch:  3919 | Train Accurancy:  0.9199006259441376 | Validation Accurancy:  0.9011194482445717\n",
      "Epoch:  3920 | Train Accurancy:  0.9199055209755898 | Validation Accurancy:  0.9011328294873238\n",
      "Epoch:  3921 | Train Accurancy:  0.9199104011058807 | Validation Accurancy:  0.9011460989713669\n",
      "Epoch:  3922 | Train Accurancy:  0.9199152514338493 | Validation Accurancy:  0.9011576175689697\n",
      "Epoch:  3923 | Train Accurancy:  0.9199201539158821 | Validation Accurancy:  0.9011712074279785\n",
      "Epoch:  3924 | Train Accurancy:  0.9199250712990761 | Validation Accurancy:  0.9011844098567963\n",
      "Epoch:  3925 | Train Accurancy:  0.9199298769235611 | Validation Accurancy:  0.9011977836489677\n",
      "Epoch:  3926 | Train Accurancy:  0.9199347868561745 | Validation Accurancy:  0.9012093842029572\n",
      "Epoch:  3927 | Train Accurancy:  0.9199396222829819 | Validation Accurancy:  0.9012228101491928\n",
      "Epoch:  3928 | Train Accurancy:  0.919944517314434 | Validation Accurancy:  0.901236042380333\n",
      "Epoch:  3929 | Train Accurancy:  0.9199493229389191 | Validation Accurancy:  0.9012492373585701\n",
      "Epoch:  3930 | Train Accurancy:  0.9199542254209518 | Validation Accurancy:  0.9012608304619789\n",
      "Epoch:  3931 | Train Accurancy:  0.9199590384960175 | Validation Accurancy:  0.9012743085622787\n",
      "Epoch:  3932 | Train Accurancy:  0.9199639037251472 | Validation Accurancy:  0.9012876003980637\n",
      "Epoch:  3933 | Train Accurancy:  0.919968768954277 | Validation Accurancy:  0.901300810277462\n",
      "Epoch:  3934 | Train Accurancy:  0.919973574578762 | Validation Accurancy:  0.9013122841715813\n",
      "Epoch:  3935 | Train Accurancy:  0.919978454709053 | Validation Accurancy:  0.9013257473707199\n",
      "Epoch:  3936 | Train Accurancy:  0.9199832379817963 | Validation Accurancy:  0.9013390243053436\n",
      "Epoch:  3937 | Train Accurancy:  0.9199880436062813 | Validation Accurancy:  0.901350662112236\n",
      "Epoch:  3938 | Train Accurancy:  0.9199929237365723 | Validation Accurancy:  0.9013641625642776\n",
      "Epoch:  3939 | Train Accurancy:  0.9199977889657021 | Validation Accurancy:  0.901377372443676\n",
      "Epoch:  3940 | Train Accurancy:  0.9200025796890259 | Validation Accurancy:  0.9013905897736549\n",
      "Epoch:  3941 | Train Accurancy:  0.9200074374675751 | Validation Accurancy:  0.9014021381735802\n",
      "Epoch:  3942 | Train Accurancy:  0.9200122132897377 | Validation Accurancy:  0.9014155492186546\n",
      "Epoch:  3943 | Train Accurancy:  0.9200170338153839 | Validation Accurancy:  0.9014287441968918\n",
      "Epoch:  3944 | Train Accurancy:  0.9200218841433525 | Validation Accurancy:  0.901440367102623\n",
      "Epoch:  3945 | Train Accurancy:  0.9200266674160957 | Validation Accurancy:  0.901453822851181\n",
      "Epoch:  3946 | Train Accurancy:  0.9200314730405807 | Validation Accurancy:  0.9014671295881271\n",
      "Epoch:  3947 | Train Accurancy:  0.9200363233685493 | Validation Accurancy:  0.9014803394675255\n",
      "Epoch:  3948 | Train Accurancy:  0.9200411289930344 | Validation Accurancy:  0.9014918133616447\n",
      "Epoch:  3949 | Train Accurancy:  0.9200458824634552 | Validation Accurancy:  0.9015051424503326\n",
      "Epoch:  3950 | Train Accurancy:  0.920050635933876 | Validation Accurancy:  0.901518277823925\n",
      "Epoch:  3951 | Train Accurancy:  0.9200554564595222 | Validation Accurancy:  0.9015299752354622\n",
      "Epoch:  3952 | Train Accurancy:  0.9200602471828461 | Validation Accurancy:  0.9015433341264725\n",
      "Epoch:  3953 | Train Accurancy:  0.9200650230050087 | Validation Accurancy:  0.9015565440058708\n",
      "Epoch:  3954 | Train Accurancy:  0.9200698360800743 | Validation Accurancy:  0.9015695676207542\n",
      "Epoch:  3955 | Train Accurancy:  0.9200746193528175 | Validation Accurancy:  0.9015810787677765\n",
      "Epoch:  3956 | Train Accurancy:  0.9200794249773026 | Validation Accurancy:  0.9015944749116898\n",
      "Epoch:  3957 | Train Accurancy:  0.9200841933488846 | Validation Accurancy:  0.9016076028347015\n",
      "Epoch:  3958 | Train Accurancy:  0.9200889393687248 | Validation Accurancy:  0.9016191586852074\n",
      "Epoch:  3959 | Train Accurancy:  0.9200936853885651 | Validation Accurancy:  0.901632621884346\n",
      "Epoch:  3960 | Train Accurancy:  0.9200984537601471 | Validation Accurancy:  0.9016457349061966\n",
      "Epoch:  3961 | Train Accurancy:  0.9201032966375351 | Validation Accurancy:  0.9016573876142502\n",
      "Epoch:  3962 | Train Accurancy:  0.9201080724596977 | Validation Accurancy:  0.9016707465052605\n",
      "Epoch:  3963 | Train Accurancy:  0.920112781226635 | Validation Accurancy:  0.9016839265823364\n",
      "Epoch:  3964 | Train Accurancy:  0.920117549598217 | Validation Accurancy:  0.9016968533396721\n",
      "Epoch:  3965 | Train Accurancy:  0.9201222583651543 | Validation Accurancy:  0.901708334684372\n",
      "Epoch:  3966 | Train Accurancy:  0.9201270267367363 | Validation Accurancy:  0.901721641421318\n",
      "Epoch:  3967 | Train Accurancy:  0.9201317727565765 | Validation Accurancy:  0.9017347246408463\n",
      "Epoch:  3968 | Train Accurancy:  0.9201365783810616 | Validation Accurancy:  0.9017462432384491\n",
      "Epoch:  3969 | Train Accurancy:  0.9201412722468376 | Validation Accurancy:  0.9017596319317818\n",
      "Epoch:  3970 | Train Accurancy:  0.9201460555195808 | Validation Accurancy:  0.9017727747559547\n",
      "Epoch:  3971 | Train Accurancy:  0.9201508387923241 | Validation Accurancy:  0.9017842710018158\n",
      "Epoch:  3972 | Train Accurancy:  0.9201555252075195 | Validation Accurancy:  0.9017976149916649\n",
      "Epoch:  3973 | Train Accurancy:  0.9201601892709732 | Validation Accurancy:  0.9018107876181602\n",
      "Epoch:  3974 | Train Accurancy:  0.920164979994297 | Validation Accurancy:  0.9018222168087959\n",
      "Epoch:  3975 | Train Accurancy:  0.9201697036623955 | Validation Accurancy:  0.901835486292839\n",
      "Epoch:  3976 | Train Accurancy:  0.9201743751764297 | Validation Accurancy:  0.901848591864109\n",
      "Epoch:  3977 | Train Accurancy:  0.9201791062951088 | Validation Accurancy:  0.9018600657582283\n",
      "Epoch:  3978 | Train Accurancy:  0.9201838299632072 | Validation Accurancy:  0.9018735513091087\n",
      "Epoch:  3979 | Train Accurancy:  0.9201885685324669 | Validation Accurancy:  0.9018865674734116\n",
      "Epoch:  3980 | Train Accurancy:  0.9201932400465012 | Validation Accurancy:  0.9018979892134666\n",
      "Epoch:  3981 | Train Accurancy:  0.9201979413628578 | Validation Accurancy:  0.9019112288951874\n",
      "Epoch:  3982 | Train Accurancy:  0.9202026873826981 | Validation Accurancy:  0.9019244089722633\n",
      "Epoch:  3983 | Train Accurancy:  0.9202074110507965 | Validation Accurancy:  0.9019358903169632\n",
      "Epoch:  3984 | Train Accurancy:  0.9202121049165726 | Validation Accurancy:  0.9019491299986839\n",
      "Epoch:  3985 | Train Accurancy:  0.9202168211340904 | Validation Accurancy:  0.9019622653722763\n",
      "Epoch:  3986 | Train Accurancy:  0.9202215224504471 | Validation Accurancy:  0.9019736275076866\n",
      "Epoch:  3987 | Train Accurancy:  0.9202261865139008 | Validation Accurancy:  0.9019869118928909\n",
      "Epoch:  3988 | Train Accurancy:  0.9202309101819992 | Validation Accurancy:  0.9019999578595161\n",
      "Epoch:  3989 | Train Accurancy:  0.9202355593442917 | Validation Accurancy:  0.9020113795995712\n",
      "Epoch:  3990 | Train Accurancy:  0.9202402457594872 | Validation Accurancy:  0.9020246490836143\n",
      "Epoch:  3991 | Train Accurancy:  0.9202449545264244 | Validation Accurancy:  0.9020376279950142\n",
      "Epoch:  3992 | Train Accurancy:  0.9202496334910393 | Validation Accurancy:  0.9020491018891335\n",
      "Epoch:  3993 | Train Accurancy:  0.9202542677521706 | Validation Accurancy:  0.902062214910984\n",
      "Epoch:  3994 | Train Accurancy:  0.920258954167366 | Validation Accurancy:  0.9020754173398018\n",
      "Epoch:  3995 | Train Accurancy:  0.9202636331319809 | Validation Accurancy:  0.9020868316292763\n",
      "Epoch:  3996 | Train Accurancy:  0.920268326997757 | Validation Accurancy:  0.9021000117063522\n",
      "Epoch:  3997 | Train Accurancy:  0.9202729910612106 | Validation Accurancy:  0.9021129384636879\n",
      "Epoch:  3998 | Train Accurancy:  0.9202776774764061 | Validation Accurancy:  0.9021244123578072\n",
      "Epoch:  3999 | Train Accurancy:  0.9202823117375374 | Validation Accurancy:  0.9021376296877861\n",
      "Epoch:  4000 | Train Accurancy:  0.9202869758009911 | Validation Accurancy:  0.9021506309509277\n",
      "Epoch:  4001 | Train Accurancy:  0.9202916100621223 | Validation Accurancy:  0.9021619334816933\n",
      "Epoch:  4002 | Train Accurancy:  0.9202962890267372 | Validation Accurancy:  0.9021751582622528\n",
      "Epoch:  4003 | Train Accurancy:  0.9203009158372879 | Validation Accurancy:  0.9021881446242332\n",
      "Epoch:  4004 | Train Accurancy:  0.9203056022524834 | Validation Accurancy:  0.9021995589137077\n",
      "Epoch:  4005 | Train Accurancy:  0.9203102216124535 | Validation Accurancy:  0.9022126272320747\n",
      "Epoch:  4006 | Train Accurancy:  0.9203149005770683 | Validation Accurancy:  0.9022255688905716\n",
      "Epoch:  4007 | Train Accurancy:  0.9203195199370384 | Validation Accurancy:  0.9022369012236595\n",
      "Epoch:  4008 | Train Accurancy:  0.9203241169452667 | Validation Accurancy:  0.9022501558065414\n",
      "Epoch:  4009 | Train Accurancy:  0.9203287437558174 | Validation Accurancy:  0.902261532843113\n",
      "Epoch:  4010 | Train Accurancy:  0.9203333780169487 | Validation Accurancy:  0.9022748246788979\n",
      "Epoch:  4011 | Train Accurancy:  0.9203380569815636 | Validation Accurancy:  0.9022877290844917\n",
      "Epoch:  4012 | Train Accurancy:  0.9203426316380501 | Validation Accurancy:  0.902299202978611\n",
      "Epoch:  4013 | Train Accurancy:  0.9203472808003426 | Validation Accurancy:  0.9023124203085899\n",
      "Epoch:  4014 | Train Accurancy:  0.9203518629074097 | Validation Accurancy:  0.9023252576589584\n",
      "Epoch:  4015 | Train Accurancy:  0.9203565046191216 | Validation Accurancy:  0.9023367539048195\n",
      "Epoch:  4016 | Train Accurancy:  0.920361116528511 | Validation Accurancy:  0.9023498147726059\n",
      "Epoch:  4017 | Train Accurancy:  0.9203656911849976 | Validation Accurancy:  0.9023627564311028\n",
      "Epoch:  4018 | Train Accurancy:  0.9203703626990318 | Validation Accurancy:  0.9023740366101265\n",
      "Epoch:  4019 | Train Accurancy:  0.9203749224543571 | Validation Accurancy:  0.9023871049284935\n",
      "Epoch:  4020 | Train Accurancy:  0.9203795343637466 | Validation Accurancy:  0.9023984968662262\n",
      "Epoch:  4021 | Train Accurancy:  0.9203841760754585 | Validation Accurancy:  0.9024116843938828\n",
      "Epoch:  4022 | Train Accurancy:  0.9203887730836868 | Validation Accurancy:  0.9024245887994766\n",
      "Epoch:  4023 | Train Accurancy:  0.9203933253884315 | Validation Accurancy:  0.9024360254406929\n",
      "Epoch:  4024 | Train Accurancy:  0.9203979223966599 | Validation Accurancy:  0.9024491459131241\n",
      "Epoch:  4025 | Train Accurancy:  0.9204025715589523 | Validation Accurancy:  0.902460590004921\n",
      "Epoch:  4026 | Train Accurancy:  0.9204070940613747 | Validation Accurancy:  0.9024737030267715\n",
      "Epoch:  4027 | Train Accurancy:  0.9204117357730865 | Validation Accurancy:  0.9024866819381714\n",
      "Epoch:  4028 | Train Accurancy:  0.9204163253307343 | Validation Accurancy:  0.9024979844689369\n",
      "Epoch:  4029 | Train Accurancy:  0.9204208850860596 | Validation Accurancy:  0.9025110751390457\n",
      "Epoch:  4030 | Train Accurancy:  0.9204254299402237 | Validation Accurancy:  0.9025225564837456\n",
      "Epoch:  4031 | Train Accurancy:  0.9204300194978714 | Validation Accurancy:  0.9025355726480484\n",
      "Epoch:  4032 | Train Accurancy:  0.9204346090555191 | Validation Accurancy:  0.9025484696030617\n",
      "Epoch:  4033 | Train Accurancy:  0.9204391986131668 | Validation Accurancy:  0.9025598615407944\n",
      "Epoch:  4034 | Train Accurancy:  0.9204437583684921 | Validation Accurancy:  0.9025729522109032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4035 | Train Accurancy:  0.9204483330249786 | Validation Accurancy:  0.9025857374072075\n",
      "Epoch:  4036 | Train Accurancy:  0.920452855527401 | Validation Accurancy:  0.90259700268507\n",
      "Epoch:  4037 | Train Accurancy:  0.9204574376344681 | Validation Accurancy:  0.9026099815964699\n",
      "Epoch:  4038 | Train Accurancy:  0.9204619452357292 | Validation Accurancy:  0.9026213884353638\n",
      "Epoch:  4039 | Train Accurancy:  0.9204665347933769 | Validation Accurancy:  0.902634471654892\n",
      "Epoch:  4040 | Train Accurancy:  0.9204710945487022 | Validation Accurancy:  0.9026472717523575\n",
      "Epoch:  4041 | Train Accurancy:  0.920475646853447 | Validation Accurancy:  0.9026585891842842\n",
      "Epoch:  4042 | Train Accurancy:  0.9204801693558693 | Validation Accurancy:  0.9026715457439423\n",
      "Epoch:  4043 | Train Accurancy:  0.9204847067594528 | Validation Accurancy:  0.902682900428772\n",
      "Epoch:  4044 | Train Accurancy:  0.9204892590641975 | Validation Accurancy:  0.9026959910988808\n",
      "Epoch:  4045 | Train Accurancy:  0.9204938188195229 | Validation Accurancy:  0.9027074500918388\n",
      "Epoch:  4046 | Train Accurancy:  0.920498289167881 | Validation Accurancy:  0.902720533311367\n",
      "Epoch:  4047 | Train Accurancy:  0.9205028712749481 | Validation Accurancy:  0.9027333706617355\n",
      "Epoch:  4048 | Train Accurancy:  0.920507401227951 | Validation Accurancy:  0.9027446806430817\n",
      "Epoch:  4049 | Train Accurancy:  0.9205119162797928 | Validation Accurancy:  0.9027575999498367\n",
      "Epoch:  4050 | Train Accurancy:  0.9205164983868599 | Validation Accurancy:  0.9027690440416336\n",
      "Epoch:  4051 | Train Accurancy:  0.9205209538340569 | Validation Accurancy:  0.9027819484472275\n",
      "Epoch:  4052 | Train Accurancy:  0.9205255135893822 | Validation Accurancy:  0.9027948155999184\n",
      "Epoch:  4053 | Train Accurancy:  0.9205300435423851 | Validation Accurancy:  0.9028060808777809\n",
      "Epoch:  4054 | Train Accurancy:  0.920534536242485 | Validation Accurancy:  0.902819000184536\n",
      "Epoch:  4055 | Train Accurancy:  0.9205390214920044 | Validation Accurancy:  0.9028303921222687\n",
      "Epoch:  4056 | Train Accurancy:  0.9205435737967491 | Validation Accurancy:  0.9028433859348297\n",
      "Epoch:  4057 | Train Accurancy:  0.9205480962991714 | Validation Accurancy:  0.9028547927737236\n",
      "Epoch:  4058 | Train Accurancy:  0.9205525442957878 | Validation Accurancy:  0.9028677046298981\n",
      "Epoch:  4059 | Train Accurancy:  0.9205571115016937 | Validation Accurancy:  0.902880497276783\n",
      "Epoch:  4060 | Train Accurancy:  0.9205615445971489 | Validation Accurancy:  0.9028917998075485\n",
      "Epoch:  4061 | Train Accurancy:  0.9205660298466682 | Validation Accurancy:  0.9029046595096588\n",
      "Epoch:  4062 | Train Accurancy:  0.9205705374479294 | Validation Accurancy:  0.9029159843921661\n",
      "Epoch:  4063 | Train Accurancy:  0.9205750152468681 | Validation Accurancy:  0.902929000556469\n",
      "Epoch:  4064 | Train Accurancy:  0.9205795526504517 | Validation Accurancy:  0.9029403403401375\n",
      "Epoch:  4065 | Train Accurancy:  0.9205840080976486 | Validation Accurancy:  0.9029533043503761\n",
      "Epoch:  4066 | Train Accurancy:  0.9205885007977486 | Validation Accurancy:  0.9029646441340446\n",
      "Epoch:  4067 | Train Accurancy:  0.9205929562449455 | Validation Accurancy:  0.9029776155948639\n",
      "Epoch:  4068 | Train Accurancy:  0.9205974489450455 | Validation Accurancy:  0.9029903933405876\n",
      "Epoch:  4069 | Train Accurancy:  0.9206019341945648 | Validation Accurancy:  0.9030015021562576\n",
      "Epoch:  4070 | Train Accurancy:  0.920606404542923 | Validation Accurancy:  0.9030144512653351\n",
      "Epoch:  4071 | Train Accurancy:  0.9206108972430229 | Validation Accurancy:  0.9030258134007454\n",
      "Epoch:  4072 | Train Accurancy:  0.9206153526902199 | Validation Accurancy:  0.9030387103557587\n",
      "Epoch:  4073 | Train Accurancy:  0.9206198304891586 | Validation Accurancy:  0.9030500575900078\n",
      "Epoch:  4074 | Train Accurancy:  0.9206243082880974 | Validation Accurancy:  0.9030629247426987\n",
      "Epoch:  4075 | Train Accurancy:  0.9206287711858749 | Validation Accurancy:  0.9030743315815926\n",
      "Epoch:  4076 | Train Accurancy:  0.9206331744790077 | Validation Accurancy:  0.903087206184864\n",
      "Epoch:  4077 | Train Accurancy:  0.9206376299262047 | Validation Accurancy:  0.9030999019742012\n",
      "Epoch:  4078 | Train Accurancy:  0.920642115175724 | Validation Accurancy:  0.9031110927462578\n",
      "Epoch:  4079 | Train Accurancy:  0.9206465631723404 | Validation Accurancy:  0.9031238257884979\n",
      "Epoch:  4080 | Train Accurancy:  0.920651026070118 | Validation Accurancy:  0.9031352177262306\n",
      "Epoch:  4081 | Train Accurancy:  0.9206554144620895 | Validation Accurancy:  0.9031480923295021\n",
      "Epoch:  4082 | Train Accurancy:  0.9206598922610283 | Validation Accurancy:  0.9031593054533005\n",
      "Epoch:  4083 | Train Accurancy:  0.9206643477082253 | Validation Accurancy:  0.9031722247600555\n",
      "Epoch:  4084 | Train Accurancy:  0.920668788254261 | Validation Accurancy:  0.9031835421919823\n",
      "Epoch:  4085 | Train Accurancy:  0.9206731766462326 | Validation Accurancy:  0.9031964093446732\n",
      "Epoch:  4086 | Train Accurancy:  0.9206776469945908 | Validation Accurancy:  0.9032077044248581\n",
      "Epoch:  4087 | Train Accurancy:  0.9206820949912071 | Validation Accurancy:  0.9032205864787102\n",
      "Epoch:  4088 | Train Accurancy:  0.9206864386796951 | Validation Accurancy:  0.9032319635152817\n",
      "Epoch:  4089 | Train Accurancy:  0.9206909239292145 | Validation Accurancy:  0.9032447189092636\n",
      "Epoch:  4090 | Train Accurancy:  0.9206953719258308 | Validation Accurancy:  0.9032573997974396\n",
      "Epoch:  4091 | Train Accurancy:  0.9206997826695442 | Validation Accurancy:  0.9032685533165932\n",
      "Epoch:  4092 | Train Accurancy:  0.920704148709774 | Validation Accurancy:  0.9032813161611557\n",
      "Epoch:  4093 | Train Accurancy:  0.9207085594534874 | Validation Accurancy:  0.9032924994826317\n",
      "Epoch:  4094 | Train Accurancy:  0.9207129925489426 | Validation Accurancy:  0.9033053740859032\n",
      "Epoch:  4095 | Train Accurancy:  0.9207174554467201 | Validation Accurancy:  0.9033165499567986\n",
      "Epoch:  4096 | Train Accurancy:  0.9207218065857887 | Validation Accurancy:  0.9033294394612312\n",
      "Epoch:  4097 | Train Accurancy:  0.9207262545824051 | Validation Accurancy:  0.9033405408263206\n",
      "Epoch:  4098 | Train Accurancy:  0.9207306280732155 | Validation Accurancy:  0.9033534675836563\n",
      "Epoch:  4099 | Train Accurancy:  0.9207349866628647 | Validation Accurancy:  0.9033647328615189\n",
      "Epoch:  4100 | Train Accurancy:  0.9207394421100616 | Validation Accurancy:  0.9033776074647903\n",
      "Epoch:  4101 | Train Accurancy:  0.9207438454031944 | Validation Accurancy:  0.9033887013792992\n",
      "Epoch:  4102 | Train Accurancy:  0.920748196542263 | Validation Accurancy:  0.90340156853199\n",
      "Epoch:  4103 | Train Accurancy:  0.9207526445388794 | Validation Accurancy:  0.9034128040075302\n",
      "Epoch:  4104 | Train Accurancy:  0.9207570031285286 | Validation Accurancy:  0.9034256860613823\n",
      "Epoch:  4105 | Train Accurancy:  0.920761376619339 | Validation Accurancy:  0.9034368023276329\n",
      "Epoch:  4106 | Train Accurancy:  0.9207657650113106 | Validation Accurancy:  0.9034496545791626\n",
      "Epoch:  4107 | Train Accurancy:  0.9207701236009598 | Validation Accurancy:  0.9034609124064445\n",
      "Epoch:  4108 | Train Accurancy:  0.920774556696415 | Validation Accurancy:  0.9034736528992653\n",
      "Epoch:  4109 | Train Accurancy:  0.920778863132 | Validation Accurancy:  0.903484933078289\n",
      "Epoch:  4110 | Train Accurancy:  0.9207832738757133 | Validation Accurancy:  0.9034977182745934\n",
      "Epoch:  4111 | Train Accurancy:  0.920787625014782 | Validation Accurancy:  0.9035089239478111\n",
      "Epoch:  4112 | Train Accurancy:  0.9207920134067535 | Validation Accurancy:  0.9035217240452766\n",
      "Epoch:  4113 | Train Accurancy:  0.9207964017987251 | Validation Accurancy:  0.9035328701138496\n",
      "Epoch:  4114 | Train Accurancy:  0.9208007082343102 | Validation Accurancy:  0.9035456627607346\n",
      "Epoch:  4115 | Train Accurancy:  0.9208050817251205 | Validation Accurancy:  0.9035568982362747\n",
      "Epoch:  4116 | Train Accurancy:  0.9208094924688339 | Validation Accurancy:  0.9035695046186447\n",
      "Epoch:  4117 | Train Accurancy:  0.9208138212561607 | Validation Accurancy:  0.9035807624459267\n",
      "Epoch:  4118 | Train Accurancy:  0.9208181798458099 | Validation Accurancy:  0.9035935401916504\n",
      "Epoch:  4119 | Train Accurancy:  0.9208225309848785 | Validation Accurancy:  0.9036047831177711\n",
      "Epoch:  4120 | Train Accurancy:  0.9208268821239471 | Validation Accurancy:  0.9036173969507217\n",
      "Epoch:  4121 | Train Accurancy:  0.9208311960101128 | Validation Accurancy:  0.9036286026239395\n",
      "Epoch:  4122 | Train Accurancy:  0.9208355247974396 | Validation Accurancy:  0.9036412686109543\n",
      "Epoch:  4123 | Train Accurancy:  0.9208399131894112 | Validation Accurancy:  0.9036524742841721\n",
      "Epoch:  4124 | Train Accurancy:  0.9208442643284798 | Validation Accurancy:  0.9036651328206062\n",
      "Epoch:  4125 | Train Accurancy:  0.9208485633134842 | Validation Accurancy:  0.9036763608455658\n",
      "Epoch:  4126 | Train Accurancy:  0.9208529144525528 | Validation Accurancy:  0.9036889597773552\n",
      "Epoch:  4127 | Train Accurancy:  0.9208572283387184 | Validation Accurancy:  0.903700165450573\n",
      "Epoch:  4128 | Train Accurancy:  0.9208615198731422 | Validation Accurancy:  0.9037128612399101\n",
      "Epoch:  4129 | Train Accurancy:  0.9208659082651138 | Validation Accurancy:  0.9037240371108055\n",
      "Epoch:  4130 | Train Accurancy:  0.9208702519536018 | Validation Accurancy:  0.9037367179989815\n",
      "Epoch:  4131 | Train Accurancy:  0.9208745136857033 | Validation Accurancy:  0.9037478193640709\n",
      "Epoch:  4132 | Train Accurancy:  0.9208788350224495 | Validation Accurancy:  0.9037604033946991\n",
      "Epoch:  4133 | Train Accurancy:  0.9208831787109375 | Validation Accurancy:  0.9037715941667557\n",
      "Epoch:  4134 | Train Accurancy:  0.9208874702453613 | Validation Accurancy:  0.9037843272089958\n",
      "Epoch:  4135 | Train Accurancy:  0.9208917915821075 | Validation Accurancy:  0.9037953987717628\n",
      "Epoch:  4136 | Train Accurancy:  0.9208960980176926 | Validation Accurancy:  0.9038080945611\n",
      "Epoch:  4137 | Train Accurancy:  0.9209004491567612 | Validation Accurancy:  0.9038191810250282\n",
      "Epoch:  4138 | Train Accurancy:  0.920904740691185 | Validation Accurancy:  0.9038317501544952\n",
      "Epoch:  4139 | Train Accurancy:  0.9209089800715446 | Validation Accurancy:  0.9038428142666817\n",
      "Epoch:  4140 | Train Accurancy:  0.9209132865071297 | Validation Accurancy:  0.9038555696606636\n",
      "Epoch:  4141 | Train Accurancy:  0.9209176078438759 | Validation Accurancy:  0.9038666188716888\n",
      "Epoch:  4142 | Train Accurancy:  0.9209218993782997 | Validation Accurancy:  0.9038791805505753\n",
      "Epoch:  4143 | Train Accurancy:  0.9209261760115623 | Validation Accurancy:  0.9038901999592781\n",
      "Epoch:  4144 | Train Accurancy:  0.920930527150631 | Validation Accurancy:  0.9039015844464302\n",
      "Epoch:  4145 | Train Accurancy:  0.9209347814321518 | Validation Accurancy:  0.903914324939251\n",
      "Epoch:  4146 | Train Accurancy:  0.920939065515995 | Validation Accurancy:  0.9039255455136299\n",
      "Epoch:  4147 | Train Accurancy:  0.9209433495998383 | Validation Accurancy:  0.9039381816983223\n",
      "Epoch:  4148 | Train Accurancy:  0.9209476336836815 | Validation Accurancy:  0.9039492756128311\n",
      "Epoch:  4149 | Train Accurancy:  0.9209518581628799 | Validation Accurancy:  0.9039619415998459\n",
      "Epoch:  4150 | Train Accurancy:  0.9209561347961426 | Validation Accurancy:  0.9039729312062263\n",
      "Epoch:  4151 | Train Accurancy:  0.9209604561328888 | Validation Accurancy:  0.9039857313036919\n",
      "Epoch:  4152 | Train Accurancy:  0.920964702963829 | Validation Accurancy:  0.9039966985583305\n",
      "Epoch:  4153 | Train Accurancy:  0.9209689721465111 | Validation Accurancy:  0.9040093645453453\n",
      "Epoch:  4154 | Train Accurancy:  0.9209732487797737 | Validation Accurancy:  0.9040202423930168\n",
      "Epoch:  4155 | Train Accurancy:  0.9209775477647781 | Validation Accurancy:  0.9040315300226212\n",
      "Epoch:  4156 | Train Accurancy:  0.920981764793396 | Validation Accurancy:  0.9040442481637001\n",
      "Epoch:  4157 | Train Accurancy:  0.9209860265254974 | Validation Accurancy:  0.9040553942322731\n",
      "Epoch:  4158 | Train Accurancy:  0.9209902510046959 | Validation Accurancy:  0.9040679857134819\n",
      "Epoch:  4159 | Train Accurancy:  0.9209945425391197 | Validation Accurancy:  0.9040790721774101\n",
      "Epoch:  4160 | Train Accurancy:  0.9209987968206406 | Validation Accurancy:  0.9040915742516518\n",
      "Epoch:  4161 | Train Accurancy:  0.9210030362010002 | Validation Accurancy:  0.9041027128696442\n",
      "Epoch:  4162 | Train Accurancy:  0.9210072606801987 | Validation Accurancy:  0.9041152149438858\n",
      "Epoch:  4163 | Train Accurancy:  0.9210115149617195 | Validation Accurancy:  0.904126301407814\n",
      "Epoch:  4164 | Train Accurancy:  0.9210157692432404 | Validation Accurancy:  0.90413748472929\n",
      "Epoch:  4165 | Train Accurancy:  0.9210200607776642 | Validation Accurancy:  0.9041501730680466\n",
      "Epoch:  4166 | Train Accurancy:  0.9210242405533791 | Validation Accurancy:  0.9041612073779106\n",
      "Epoch:  4167 | Train Accurancy:  0.9210284650325775 | Validation Accurancy:  0.9041738212108612\n",
      "Epoch:  4168 | Train Accurancy:  0.9210326969623566 | Validation Accurancy:  0.9041848182678223\n",
      "Epoch:  4169 | Train Accurancy:  0.9210369661450386 | Validation Accurancy:  0.9041973799467087\n",
      "Epoch:  4170 | Train Accurancy:  0.9210412427783012 | Validation Accurancy:  0.904208354651928\n",
      "Epoch:  4171 | Train Accurancy:  0.9210454076528549 | Validation Accurancy:  0.9042195901274681\n",
      "Epoch:  4172 | Train Accurancy:  0.9210496470332146 | Validation Accurancy:  0.9042322188615799\n",
      "Epoch:  4173 | Train Accurancy:  0.92105383425951 | Validation Accurancy:  0.9042432680726051\n",
      "Epoch:  4174 | Train Accurancy:  0.9210580736398697 | Validation Accurancy:  0.9042558670043945\n",
      "Epoch:  4175 | Train Accurancy:  0.9210622534155846 | Validation Accurancy:  0.9042668640613556\n",
      "Epoch:  4176 | Train Accurancy:  0.9210665225982666 | Validation Accurancy:  0.9042793959379196\n",
      "Epoch:  4177 | Train Accurancy:  0.9210707172751427 | Validation Accurancy:  0.9042903706431389\n",
      "Epoch:  4178 | Train Accurancy:  0.9210749492049217 | Validation Accurancy:  0.9043014422059059\n",
      "Epoch:  4179 | Train Accurancy:  0.9210791364312172 | Validation Accurancy:  0.9043141454458237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4180 | Train Accurancy:  0.921083353459835 | Validation Accurancy:  0.9043252170085907\n",
      "Epoch:  4181 | Train Accurancy:  0.9210875555872917 | Validation Accurancy:  0.9043378010392189\n",
      "Epoch:  4182 | Train Accurancy:  0.9210917800664902 | Validation Accurancy:  0.904348611831665\n",
      "Epoch:  4183 | Train Accurancy:  0.9210959672927856 | Validation Accurancy:  0.9043612480163574\n",
      "Epoch:  4184 | Train Accurancy:  0.9211001247167587 | Validation Accurancy:  0.9043720662593842\n",
      "Epoch:  4185 | Train Accurancy:  0.9211043044924736 | Validation Accurancy:  0.9043833464384079\n",
      "Epoch:  4186 | Train Accurancy:  0.9211085364222527 | Validation Accurancy:  0.9043958485126495\n",
      "Epoch:  4187 | Train Accurancy:  0.9211127012968063 | Validation Accurancy:  0.9044068902730942\n",
      "Epoch:  4188 | Train Accurancy:  0.92111686617136 | Validation Accurancy:  0.9044193923473358\n",
      "Epoch:  4189 | Train Accurancy:  0.9211210757493973 | Validation Accurancy:  0.9044302850961685\n",
      "Epoch:  4190 | Train Accurancy:  0.921125240623951 | Validation Accurancy:  0.9044414758682251\n",
      "Epoch:  4191 | Train Accurancy:  0.9211294278502464 | Validation Accurancy:  0.9044540375471115\n",
      "Epoch:  4192 | Train Accurancy:  0.9211335852742195 | Validation Accurancy:  0.9044650048017502\n",
      "Epoch:  4193 | Train Accurancy:  0.9211377799510956 | Validation Accurancy:  0.9044775664806366\n",
      "Epoch:  4194 | Train Accurancy:  0.9211419150233269 | Validation Accurancy:  0.9044883400201797\n",
      "Epoch:  4195 | Train Accurancy:  0.9211461395025253 | Validation Accurancy:  0.9044995978474617\n",
      "Epoch:  4196 | Train Accurancy:  0.9211502596735954 | Validation Accurancy:  0.9045120924711227\n",
      "Epoch:  4197 | Train Accurancy:  0.9211544245481491 | Validation Accurancy:  0.9045231491327286\n",
      "Epoch:  4198 | Train Accurancy:  0.9211586490273476 | Validation Accurancy:  0.9045356214046478\n",
      "Epoch:  4199 | Train Accurancy:  0.92116279900074 | Validation Accurancy:  0.9045464769005775\n",
      "Epoch:  4200 | Train Accurancy:  0.9211669415235519 | Validation Accurancy:  0.904557503759861\n",
      "Epoch:  4201 | Train Accurancy:  0.9211711063981056 | Validation Accurancy:  0.904570147395134\n",
      "Epoch:  4202 | Train Accurancy:  0.9211752265691757 | Validation Accurancy:  0.9045810252428055\n",
      "Epoch:  4203 | Train Accurancy:  0.9211793392896652 | Validation Accurancy:  0.9045935124158859\n",
      "Epoch:  4204 | Train Accurancy:  0.9211835339665413 | Validation Accurancy:  0.904604434967041\n",
      "Epoch:  4205 | Train Accurancy:  0.9211877286434174 | Validation Accurancy:  0.9046155288815498\n",
      "Epoch:  4206 | Train Accurancy:  0.9211918264627457 | Validation Accurancy:  0.9046281352639198\n",
      "Epoch:  4207 | Train Accurancy:  0.9211959838867188 | Validation Accurancy:  0.9046390131115913\n",
      "Epoch:  4208 | Train Accurancy:  0.9212001413106918 | Validation Accurancy:  0.9046514183282852\n",
      "Epoch:  4209 | Train Accurancy:  0.9212042316794395 | Validation Accurancy:  0.9046621844172478\n",
      "Epoch:  4210 | Train Accurancy:  0.921208418905735 | Validation Accurancy:  0.904673270881176\n",
      "Epoch:  4211 | Train Accurancy:  0.9212125167250633 | Validation Accurancy:  0.90468580275774\n",
      "Epoch:  4212 | Train Accurancy:  0.9212166368961334 | Validation Accurancy:  0.9046967178583145\n",
      "Epoch:  4213 | Train Accurancy:  0.9212207794189453 | Validation Accurancy:  0.9047077745199203\n",
      "Epoch:  4214 | Train Accurancy:  0.921224907040596 | Validation Accurancy:  0.9047203883528709\n",
      "Epoch:  4215 | Train Accurancy:  0.9212290346622467 | Validation Accurancy:  0.9047312065958977\n",
      "Epoch:  4216 | Train Accurancy:  0.9212331473827362 | Validation Accurancy:  0.9047437161207199\n",
      "Epoch:  4217 | Train Accurancy:  0.9212372452020645 | Validation Accurancy:  0.904754564166069\n",
      "Epoch:  4218 | Train Accurancy:  0.9212414100766182 | Validation Accurancy:  0.9047655537724495\n",
      "Epoch:  4219 | Train Accurancy:  0.9212454706430435 | Validation Accurancy:  0.904777929186821\n",
      "Epoch:  4220 | Train Accurancy:  0.9212496131658554 | Validation Accurancy:  0.9047888740897179\n",
      "Epoch:  4221 | Train Accurancy:  0.9212537184357643 | Validation Accurancy:  0.9047999158501625\n",
      "Epoch:  4222 | Train Accurancy:  0.9212578535079956 | Validation Accurancy:  0.9048125371336937\n",
      "Epoch:  4223 | Train Accurancy:  0.9212619066238403 | Validation Accurancy:  0.904823400080204\n",
      "Epoch:  4224 | Train Accurancy:  0.9212660640478134 | Validation Accurancy:  0.9048357233405113\n",
      "Epoch:  4225 | Train Accurancy:  0.9212701469659805 | Validation Accurancy:  0.9048465266823769\n",
      "Epoch:  4226 | Train Accurancy:  0.92127425968647 | Validation Accurancy:  0.9048576056957245\n",
      "Epoch:  4227 | Train Accurancy:  0.921278327703476 | Validation Accurancy:  0.9048700109124184\n",
      "Epoch:  4228 | Train Accurancy:  0.9212824255228043 | Validation Accurancy:  0.9048808068037033\n",
      "Epoch:  4229 | Train Accurancy:  0.921286515891552 | Validation Accurancy:  0.9048920050263405\n",
      "Epoch:  4230 | Train Accurancy:  0.9212906137108803 | Validation Accurancy:  0.9049044325947762\n",
      "Epoch:  4231 | Train Accurancy:  0.9212947115302086 | Validation Accurancy:  0.9049153178930283\n",
      "Epoch:  4232 | Train Accurancy:  0.9212988168001175 | Validation Accurancy:  0.904926247894764\n",
      "Epoch:  4233 | Train Accurancy:  0.9213028997182846 | Validation Accurancy:  0.904938742518425\n",
      "Epoch:  4234 | Train Accurancy:  0.9213069528341293 | Validation Accurancy:  0.9049495235085487\n",
      "Epoch:  4235 | Train Accurancy:  0.9213110357522964 | Validation Accurancy:  0.9049619436264038\n",
      "Epoch:  4236 | Train Accurancy:  0.9213151261210442 | Validation Accurancy:  0.9049727842211723\n",
      "Epoch:  4237 | Train Accurancy:  0.9213191419839859 | Validation Accurancy:  0.9049837067723274\n",
      "Epoch:  4238 | Train Accurancy:  0.9213232919573784 | Validation Accurancy:  0.90499597042799\n",
      "Epoch:  4239 | Train Accurancy:  0.9213273152709007 | Validation Accurancy:  0.9050068631768227\n",
      "Epoch:  4240 | Train Accurancy:  0.9213314279913902 | Validation Accurancy:  0.9050178602337837\n",
      "Epoch:  4241 | Train Accurancy:  0.9213354736566544 | Validation Accurancy:  0.9050301983952522\n",
      "Epoch:  4242 | Train Accurancy:  0.9213395342230797 | Validation Accurancy:  0.9050410613417625\n",
      "Epoch:  4243 | Train Accurancy:  0.9213436171412468 | Validation Accurancy:  0.9050521180033684\n",
      "Epoch:  4244 | Train Accurancy:  0.9213476255536079 | Validation Accurancy:  0.9050644561648369\n",
      "Epoch:  4245 | Train Accurancy:  0.9213517382740974 | Validation Accurancy:  0.9050752893090248\n",
      "Epoch:  4246 | Train Accurancy:  0.921355739235878 | Validation Accurancy:  0.9050863161683083\n",
      "Epoch:  4247 | Train Accurancy:  0.9213598072528839 | Validation Accurancy:  0.9050986245274544\n",
      "Epoch:  4248 | Train Accurancy:  0.9213638976216316 | Validation Accurancy:  0.9051095172762871\n",
      "Epoch:  4249 | Train Accurancy:  0.9213679283857346 | Validation Accurancy:  0.9051204174757004\n",
      "Epoch:  4250 | Train Accurancy:  0.9213719889521599 | Validation Accurancy:  0.9051327705383301\n",
      "Epoch:  4251 | Train Accurancy:  0.9213760122656822 | Validation Accurancy:  0.9051436930894852\n",
      "Epoch:  4252 | Train Accurancy:  0.9213800355792046 | Validation Accurancy:  0.9051546677947044\n",
      "Epoch:  4253 | Train Accurancy:  0.9213840737938881 | Validation Accurancy:  0.9051668718457222\n",
      "Epoch:  4254 | Train Accurancy:  0.9213881269097328 | Validation Accurancy:  0.9051776826381683\n",
      "Epoch:  4255 | Train Accurancy:  0.9213921800255775 | Validation Accurancy:  0.905188649892807\n",
      "Epoch:  4256 | Train Accurancy:  0.9213961809873581 | Validation Accurancy:  0.9052010700106621\n",
      "Epoch:  4257 | Train Accurancy:  0.9214001968502998 | Validation Accurancy:  0.9052118062973022\n",
      "Epoch:  4258 | Train Accurancy:  0.9214042499661446 | Validation Accurancy:  0.9052228257060051\n",
      "Epoch:  4259 | Train Accurancy:  0.9214083254337311 | Validation Accurancy:  0.9052350670099258\n",
      "Epoch:  4260 | Train Accurancy:  0.921412318944931 | Validation Accurancy:  0.9052457958459854\n",
      "Epoch:  4261 | Train Accurancy:  0.9214162826538086 | Validation Accurancy:  0.9052566438913345\n",
      "Epoch:  4262 | Train Accurancy:  0.9214203655719757 | Validation Accurancy:  0.9052690640091896\n",
      "Epoch:  4263 | Train Accurancy:  0.9214243590831757 | Validation Accurancy:  0.9052797853946686\n",
      "Epoch:  4264 | Train Accurancy:  0.9214283674955368 | Validation Accurancy:  0.9052907451987267\n",
      "Epoch:  4265 | Train Accurancy:  0.9214323908090591 | Validation Accurancy:  0.9053029790520668\n",
      "Epoch:  4266 | Train Accurancy:  0.9214363768696785 | Validation Accurancy:  0.9053137749433517\n",
      "Epoch:  4267 | Train Accurancy:  0.9214403629302979 | Validation Accurancy:  0.9053247198462486\n",
      "Epoch:  4268 | Train Accurancy:  0.921444371342659 | Validation Accurancy:  0.9053369835019112\n",
      "Epoch:  4269 | Train Accurancy:  0.9214483946561813 | Validation Accurancy:  0.9053477421402931\n",
      "Epoch:  4270 | Train Accurancy:  0.9214524179697037 | Validation Accurancy:  0.9053586050868034\n",
      "Epoch:  4271 | Train Accurancy:  0.9214563816785812 | Validation Accurancy:  0.9053707420825958\n",
      "Epoch:  4272 | Train Accurancy:  0.921460434794426 | Validation Accurancy:  0.9053814709186554\n",
      "Epoch:  4273 | Train Accurancy:  0.9214644283056259 | Validation Accurancy:  0.9053925275802612\n",
      "Epoch:  4274 | Train Accurancy:  0.9214683845639229 | Validation Accurancy:  0.9054047390818596\n",
      "Epoch:  4275 | Train Accurancy:  0.9214724153280258 | Validation Accurancy:  0.9054154008626938\n",
      "Epoch:  4276 | Train Accurancy:  0.9214763641357422 | Validation Accurancy:  0.9054261744022369\n",
      "Epoch:  4277 | Train Accurancy:  0.9214803352952003 | Validation Accurancy:  0.9054385125637054\n",
      "Epoch:  4278 | Train Accurancy:  0.9214843735098839 | Validation Accurancy:  0.905449315905571\n",
      "Epoch:  4279 | Train Accurancy:  0.9214883595705032 | Validation Accurancy:  0.9054602384567261\n",
      "Epoch:  4280 | Train Accurancy:  0.9214923083782196 | Validation Accurancy:  0.9054723680019379\n",
      "Epoch:  4281 | Train Accurancy:  0.9214963167905807 | Validation Accurancy:  0.9054830297827721\n",
      "Epoch:  4282 | Train Accurancy:  0.9215002730488777 | Validation Accurancy:  0.9054938033223152\n",
      "Epoch:  4283 | Train Accurancy:  0.9215042516589165 | Validation Accurancy:  0.9055049270391464\n",
      "Epoch:  4284 | Train Accurancy:  0.9215082377195358 | Validation Accurancy:  0.9055170789361\n",
      "Epoch:  4285 | Train Accurancy:  0.9215122014284134 | Validation Accurancy:  0.9055279046297073\n",
      "Epoch:  4286 | Train Accurancy:  0.9215161353349686 | Validation Accurancy:  0.9055386856198311\n",
      "Epoch:  4287 | Train Accurancy:  0.9215200617909431 | Validation Accurancy:  0.9055509641766548\n",
      "Epoch:  4288 | Train Accurancy:  0.9215240627527237 | Validation Accurancy:  0.9055616706609726\n",
      "Epoch:  4289 | Train Accurancy:  0.9215280339121819 | Validation Accurancy:  0.9055725559592247\n",
      "Epoch:  4290 | Train Accurancy:  0.9215319827198982 | Validation Accurancy:  0.9055846631526947\n",
      "Epoch:  4291 | Train Accurancy:  0.9215359389781952 | Validation Accurancy:  0.9055953174829483\n",
      "Epoch:  4292 | Train Accurancy:  0.9215399399399757 | Validation Accurancy:  0.9056062176823616\n",
      "Epoch:  4293 | Train Accurancy:  0.9215438738465309 | Validation Accurancy:  0.9056171402335167\n",
      "Epoch:  4294 | Train Accurancy:  0.9215478077530861 | Validation Accurancy:  0.9056293219327927\n",
      "Epoch:  4295 | Train Accurancy:  0.9215517416596413 | Validation Accurancy:  0.9056401029229164\n",
      "Epoch:  4296 | Train Accurancy:  0.9215557351708412 | Validation Accurancy:  0.9056509286165237\n",
      "Epoch:  4297 | Train Accurancy:  0.9215596914291382 | Validation Accurancy:  0.905662976205349\n",
      "Epoch:  4298 | Train Accurancy:  0.9215636253356934 | Validation Accurancy:  0.9056736752390862\n",
      "Epoch:  4299 | Train Accurancy:  0.9215675666928291 | Validation Accurancy:  0.9056845381855965\n",
      "Epoch:  4300 | Train Accurancy:  0.9215714856982231 | Validation Accurancy:  0.9056953936815262\n",
      "Epoch:  4301 | Train Accurancy:  0.9215754345059395 | Validation Accurancy:  0.9057076200842857\n",
      "Epoch:  4302 | Train Accurancy:  0.9215793162584305 | Validation Accurancy:  0.9057182222604752\n",
      "Epoch:  4303 | Train Accurancy:  0.9215832203626633 | Validation Accurancy:  0.9057289883494377\n",
      "Epoch:  4304 | Train Accurancy:  0.9215872064232826 | Validation Accurancy:  0.9057400524616241\n",
      "Epoch:  4305 | Train Accurancy:  0.9215911328792572 | Validation Accurancy:  0.9057522788643837\n",
      "Epoch:  4306 | Train Accurancy:  0.9215950518846512 | Validation Accurancy:  0.9057629778981209\n",
      "Epoch:  4307 | Train Accurancy:  0.9215989783406258 | Validation Accurancy:  0.9057736918330193\n",
      "Epoch:  4308 | Train Accurancy:  0.9216029271483421 | Validation Accurancy:  0.9057857617735863\n",
      "Epoch:  4309 | Train Accurancy:  0.9216068312525749 | Validation Accurancy:  0.9057964384555817\n",
      "Epoch:  4310 | Train Accurancy:  0.9216107279062271 | Validation Accurancy:  0.9058072343468666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4311 | Train Accurancy:  0.9216146394610405 | Validation Accurancy:  0.9058181196451187\n",
      "Epoch:  4312 | Train Accurancy:  0.9216185584664345 | Validation Accurancy:  0.9058302268385887\n",
      "Epoch:  4313 | Train Accurancy:  0.9216224774718285 | Validation Accurancy:  0.9058408662676811\n",
      "Epoch:  4314 | Train Accurancy:  0.9216263592243195 | Validation Accurancy:  0.9058516398072243\n",
      "Epoch:  4315 | Train Accurancy:  0.9216302931308746 | Validation Accurancy:  0.9058625772595406\n",
      "Epoch:  4316 | Train Accurancy:  0.9216341897845268 | Validation Accurancy:  0.9058747291564941\n",
      "Epoch:  4317 | Train Accurancy:  0.9216381311416626 | Validation Accurancy:  0.9058852344751358\n",
      "Epoch:  4318 | Train Accurancy:  0.9216419979929924 | Validation Accurancy:  0.9058960527181625\n",
      "Epoch:  4319 | Train Accurancy:  0.921645849943161 | Validation Accurancy:  0.9059082046151161\n",
      "Epoch:  4320 | Train Accurancy:  0.9216497987508774 | Validation Accurancy:  0.905918799340725\n",
      "Epoch:  4321 | Train Accurancy:  0.9216536954045296 | Validation Accurancy:  0.9059294685721397\n",
      "Epoch:  4322 | Train Accurancy:  0.9216575995087624 | Validation Accurancy:  0.9059403017163277\n",
      "Epoch:  4323 | Train Accurancy:  0.9216615036129951 | Validation Accurancy:  0.9059524089097977\n",
      "Epoch:  4324 | Train Accurancy:  0.921665333211422 | Validation Accurancy:  0.9059630408883095\n",
      "Epoch:  4325 | Train Accurancy:  0.9216692298650742 | Validation Accurancy:  0.9059737101197243\n",
      "Epoch:  4326 | Train Accurancy:  0.9216731563210487 | Validation Accurancy:  0.9059845507144928\n",
      "Epoch:  4327 | Train Accurancy:  0.9216770157217979 | Validation Accurancy:  0.9059966579079628\n",
      "Epoch:  4328 | Train Accurancy:  0.9216808974742889 | Validation Accurancy:  0.9060072004795074\n",
      "Epoch:  4329 | Train Accurancy:  0.9216847866773605 | Validation Accurancy:  0.906017929315567\n",
      "Epoch:  4330 | Train Accurancy:  0.9216886386275291 | Validation Accurancy:  0.9060286730527878\n",
      "Epoch:  4331 | Train Accurancy:  0.9216925352811813 | Validation Accurancy:  0.9060407802462578\n",
      "Epoch:  4332 | Train Accurancy:  0.9216963425278664 | Validation Accurancy:  0.9060513749718666\n",
      "Epoch:  4333 | Train Accurancy:  0.9217002391815186 | Validation Accurancy:  0.9060621410608292\n",
      "Epoch:  4334 | Train Accurancy:  0.9217041432857513 | Validation Accurancy:  0.9060730189085007\n",
      "Epoch:  4335 | Train Accurancy:  0.9217080175876617 | Validation Accurancy:  0.9060851186513901\n",
      "Epoch:  4336 | Train Accurancy:  0.9217118322849274 | Validation Accurancy:  0.9060956388711929\n",
      "Epoch:  4337 | Train Accurancy:  0.921715721487999 | Validation Accurancy:  0.9061063081026077\n",
      "Epoch:  4338 | Train Accurancy:  0.9217195883393288 | Validation Accurancy:  0.9061172232031822\n",
      "Epoch:  4339 | Train Accurancy:  0.921723410487175 | Validation Accurancy:  0.9061290770769119\n",
      "Epoch:  4340 | Train Accurancy:  0.9217272624373436 | Validation Accurancy:  0.9061397165060043\n",
      "Epoch:  4341 | Train Accurancy:  0.9217311590909958 | Validation Accurancy:  0.9061503484845161\n",
      "Epoch:  4342 | Train Accurancy:  0.9217349961400032 | Validation Accurancy:  0.9061611518263817\n",
      "Epoch:  4343 | Train Accurancy:  0.9217388331890106 | Validation Accurancy:  0.9061720818281174\n",
      "Epoch:  4344 | Train Accurancy:  0.9217427149415016 | Validation Accurancy:  0.9061840921640396\n",
      "Epoch:  4345 | Train Accurancy:  0.9217465221881866 | Validation Accurancy:  0.9061947241425514\n",
      "Epoch:  4346 | Train Accurancy:  0.9217503592371941 | Validation Accurancy:  0.9062053114175797\n",
      "Epoch:  4347 | Train Accurancy:  0.9217542335391045 | Validation Accurancy:  0.9062160775065422\n",
      "Epoch:  4348 | Train Accurancy:  0.9217580631375313 | Validation Accurancy:  0.9062281548976898\n",
      "Epoch:  4349 | Train Accurancy:  0.9217618778347969 | Validation Accurancy:  0.9062387123703957\n",
      "Epoch:  4350 | Train Accurancy:  0.9217657297849655 | Validation Accurancy:  0.9062493592500687\n",
      "Epoch:  4351 | Train Accurancy:  0.9217695668339729 | Validation Accurancy:  0.9062600433826447\n",
      "Epoch:  4352 | Train Accurancy:  0.9217733815312386 | Validation Accurancy:  0.9062709137797356\n",
      "Epoch:  4353 | Train Accurancy:  0.9217771738767624 | Validation Accurancy:  0.906282901763916\n",
      "Epoch:  4354 | Train Accurancy:  0.9217810109257698 | Validation Accurancy:  0.906293474137783\n",
      "Epoch:  4355 | Train Accurancy:  0.9217848405241966 | Validation Accurancy:  0.9063040986657143\n",
      "Epoch:  4356 | Train Accurancy:  0.9217886477708817 | Validation Accurancy:  0.9063148349523544\n",
      "Epoch:  4357 | Train Accurancy:  0.9217924922704697 | Validation Accurancy:  0.9063267856836319\n",
      "Epoch:  4358 | Train Accurancy:  0.9217963218688965 | Validation Accurancy:  0.9063372686505318\n",
      "Epoch:  4359 | Train Accurancy:  0.9218001589179039 | Validation Accurancy:  0.9063479453325272\n",
      "Epoch:  4360 | Train Accurancy:  0.9218039661645889 | Validation Accurancy:  0.9063586816191673\n",
      "Epoch:  4361 | Train Accurancy:  0.9218077510595322 | Validation Accurancy:  0.9063694104552269\n",
      "Epoch:  4362 | Train Accurancy:  0.9218115583062172 | Validation Accurancy:  0.9063813462853432\n",
      "Epoch:  4363 | Train Accurancy:  0.9218153655529022 | Validation Accurancy:  0.9063920080661774\n",
      "Epoch:  4364 | Train Accurancy:  0.9218191802501678 | Validation Accurancy:  0.9064025059342384\n",
      "Epoch:  4365 | Train Accurancy:  0.9218229576945305 | Validation Accurancy:  0.9064132794737816\n",
      "Epoch:  4366 | Train Accurancy:  0.9218267947435379 | Validation Accurancy:  0.9064251556992531\n",
      "Epoch:  4367 | Train Accurancy:  0.9218306094408035 | Validation Accurancy:  0.9064355716109276\n",
      "Epoch:  4368 | Train Accurancy:  0.9218343868851662 | Validation Accurancy:  0.9064462333917618\n",
      "Epoch:  4369 | Train Accurancy:  0.9218381196260452 | Validation Accurancy:  0.9064568802714348\n",
      "Epoch:  4370 | Train Accurancy:  0.9218419641256332 | Validation Accurancy:  0.9064676761627197\n",
      "Epoch:  4371 | Train Accurancy:  0.9218457862734795 | Validation Accurancy:  0.906479649245739\n",
      "Epoch:  4372 | Train Accurancy:  0.9218495339155197 | Validation Accurancy:  0.9064900428056717\n",
      "Epoch:  4373 | Train Accurancy:  0.9218533113598824 | Validation Accurancy:  0.9065007492899895\n",
      "Epoch:  4374 | Train Accurancy:  0.9218571484088898 | Validation Accurancy:  0.9065114334225655\n",
      "Epoch:  4375 | Train Accurancy:  0.9218609035015106 | Validation Accurancy:  0.9065220579504967\n",
      "Epoch:  4376 | Train Accurancy:  0.9218646958470345 | Validation Accurancy:  0.9065340384840965\n",
      "Epoch:  4377 | Train Accurancy:  0.9218684956431389 | Validation Accurancy:  0.906544528901577\n",
      "Epoch:  4378 | Train Accurancy:  0.9218722209334373 | Validation Accurancy:  0.9065550863742828\n",
      "Epoch:  4379 | Train Accurancy:  0.9218760505318642 | Validation Accurancy:  0.9065657556056976\n",
      "Epoch:  4380 | Train Accurancy:  0.921879768371582 | Validation Accurancy:  0.9065763875842094\n",
      "Epoch:  4381 | Train Accurancy:  0.9218836054205894 | Validation Accurancy:  0.9065883606672287\n",
      "Epoch:  4382 | Train Accurancy:  0.9218873158097267 | Validation Accurancy:  0.9065988883376122\n",
      "Epoch:  4383 | Train Accurancy:  0.9218910932540894 | Validation Accurancy:  0.9066093415021896\n",
      "Epoch:  4384 | Train Accurancy:  0.921894833445549 | Validation Accurancy:  0.9066199958324432\n",
      "Epoch:  4385 | Train Accurancy:  0.9218986555933952 | Validation Accurancy:  0.906630665063858\n",
      "Epoch:  4386 | Train Accurancy:  0.9219024181365967 | Validation Accurancy:  0.9066414013504982\n",
      "Epoch:  4387 | Train Accurancy:  0.921906128525734 | Validation Accurancy:  0.9066533222794533\n",
      "Epoch:  4388 | Train Accurancy:  0.9219099506735802 | Validation Accurancy:  0.9066637754440308\n",
      "Epoch:  4389 | Train Accurancy:  0.9219136610627174 | Validation Accurancy:  0.906674288213253\n",
      "Epoch:  4390 | Train Accurancy:  0.9219174459576607 | Validation Accurancy:  0.9066849276423454\n",
      "Epoch:  4391 | Train Accurancy:  0.9219211488962173 | Validation Accurancy:  0.906695619225502\n",
      "Epoch:  4392 | Train Accurancy:  0.9219249486923218 | Validation Accurancy:  0.9067063704133034\n",
      "Epoch:  4393 | Train Accurancy:  0.9219286888837814 | Validation Accurancy:  0.9067183807492256\n",
      "Epoch:  4394 | Train Accurancy:  0.9219324365258217 | Validation Accurancy:  0.9067286998033524\n",
      "Epoch:  4395 | Train Accurancy:  0.9219361394643784 | Validation Accurancy:  0.9067392647266388\n",
      "Epoch:  4396 | Train Accurancy:  0.9219399318099022 | Validation Accurancy:  0.9067498445510864\n",
      "Epoch:  4397 | Train Accurancy:  0.9219436421990395 | Validation Accurancy:  0.90676049888134\n",
      "Epoch:  4398 | Train Accurancy:  0.9219474047422409 | Validation Accurancy:  0.9067723304033279\n",
      "Epoch:  4399 | Train Accurancy:  0.9219511523842812 | Validation Accurancy:  0.9067827016115189\n",
      "Epoch:  4400 | Train Accurancy:  0.9219548627734184 | Validation Accurancy:  0.9067932218313217\n",
      "Epoch:  4401 | Train Accurancy:  0.9219585806131363 | Validation Accurancy:  0.9068039208650589\n",
      "Epoch:  4402 | Train Accurancy:  0.9219623506069183 | Validation Accurancy:  0.9068145304918289\n",
      "Epoch:  4403 | Train Accurancy:  0.9219660386443138 | Validation Accurancy:  0.9068251773715019\n",
      "Epoch:  4404 | Train Accurancy:  0.9219698086380959 | Validation Accurancy:  0.9068369641900063\n",
      "Epoch:  4405 | Train Accurancy:  0.9219734817743301 | Validation Accurancy:  0.9068473353981972\n",
      "Epoch:  4406 | Train Accurancy:  0.9219772294163704 | Validation Accurancy:  0.9068578332662582\n",
      "Epoch:  4407 | Train Accurancy:  0.9219809472560883 | Validation Accurancy:  0.9068683832883835\n",
      "Epoch:  4408 | Train Accurancy:  0.9219846576452255 | Validation Accurancy:  0.9068790152668953\n",
      "Epoch:  4409 | Train Accurancy:  0.9219884127378464 | Validation Accurancy:  0.9068896397948265\n",
      "Epoch:  4410 | Train Accurancy:  0.9219920784235001 | Validation Accurancy:  0.9069014713168144\n",
      "Epoch:  4411 | Train Accurancy:  0.9219958558678627 | Validation Accurancy:  0.9069118648767471\n",
      "Epoch:  4412 | Train Accurancy:  0.9219995513558388 | Validation Accurancy:  0.906922310590744\n",
      "Epoch:  4413 | Train Accurancy:  0.9220032468438148 | Validation Accurancy:  0.9069328755140305\n",
      "Epoch:  4414 | Train Accurancy:  0.9220069870352745 | Validation Accurancy:  0.9069435223937035\n",
      "Epoch:  4415 | Train Accurancy:  0.9220106303691864 | Validation Accurancy:  0.9069541320204735\n",
      "Epoch:  4416 | Train Accurancy:  0.9220143929123878 | Validation Accurancy:  0.9069648236036301\n",
      "Epoch:  4417 | Train Accurancy:  0.9220180362462997 | Validation Accurancy:  0.9069765731692314\n",
      "Epoch:  4418 | Train Accurancy:  0.9220217540860176 | Validation Accurancy:  0.9069869294762611\n",
      "Epoch:  4419 | Train Accurancy:  0.9220254793763161 | Validation Accurancy:  0.9069974198937416\n",
      "Epoch:  4420 | Train Accurancy:  0.9220291525125504 | Validation Accurancy:  0.9070079177618027\n",
      "Epoch:  4421 | Train Accurancy:  0.922032818198204 | Validation Accurancy:  0.9070185199379921\n",
      "Epoch:  4422 | Train Accurancy:  0.9220365136861801 | Validation Accurancy:  0.907029040157795\n",
      "Epoch:  4423 | Train Accurancy:  0.9220402166247368 | Validation Accurancy:  0.9070397838950157\n",
      "Epoch:  4424 | Train Accurancy:  0.9220439121127129 | Validation Accurancy:  0.9070515409111977\n",
      "Epoch:  4425 | Train Accurancy:  0.9220476076006889 | Validation Accurancy:  0.9070618525147438\n",
      "Epoch:  4426 | Train Accurancy:  0.9220512956380844 | Validation Accurancy:  0.9070722684264183\n",
      "Epoch:  4427 | Train Accurancy:  0.9220549911260605 | Validation Accurancy:  0.9070826917886734\n",
      "Epoch:  4428 | Train Accurancy:  0.9220586121082306 | Validation Accurancy:  0.9070933386683464\n",
      "Epoch:  4429 | Train Accurancy:  0.9220623001456261 | Validation Accurancy:  0.907103918492794\n",
      "Epoch:  4430 | Train Accurancy:  0.9220660254359245 | Validation Accurancy:  0.9071145355701447\n",
      "Epoch:  4431 | Train Accurancy:  0.9220696836709976 | Validation Accurancy:  0.9071261584758759\n",
      "Epoch:  4432 | Train Accurancy:  0.9220733195543289 | Validation Accurancy:  0.9071365222334862\n",
      "Epoch:  4433 | Train Accurancy:  0.9220770597457886 | Validation Accurancy:  0.9071469381451607\n",
      "Epoch:  4434 | Train Accurancy:  0.9220806658267975 | Validation Accurancy:  0.9071575030684471\n",
      "Epoch:  4435 | Train Accurancy:  0.9220843464136124 | Validation Accurancy:  0.9071679934859276\n",
      "Epoch:  4436 | Train Accurancy:  0.9220880270004272 | Validation Accurancy:  0.9071785137057304\n",
      "Epoch:  4437 | Train Accurancy:  0.9220916777849197 | Validation Accurancy:  0.9071890786290169\n",
      "Epoch:  4438 | Train Accurancy:  0.9220953658223152 | Validation Accurancy:  0.9072008430957794\n",
      "Epoch:  4439 | Train Accurancy:  0.9220989793539047 | Validation Accurancy:  0.9072111546993256\n",
      "Epoch:  4440 | Train Accurancy:  0.9221026599407196 | Validation Accurancy:  0.9072215110063553\n",
      "Epoch:  4441 | Train Accurancy:  0.9221063181757927 | Validation Accurancy:  0.9072319492697716\n",
      "Epoch:  4442 | Train Accurancy:  0.922109954059124 | Validation Accurancy:  0.9072425588965416\n",
      "Epoch:  4443 | Train Accurancy:  0.9221136495471001 | Validation Accurancy:  0.9072530344128609\n",
      "Epoch:  4444 | Train Accurancy:  0.9221172705292702 | Validation Accurancy:  0.9072635546326637\n",
      "Epoch:  4445 | Train Accurancy:  0.9221209138631821 | Validation Accurancy:  0.907274104654789\n",
      "Epoch:  4446 | Train Accurancy:  0.9221245869994164 | Validation Accurancy:  0.9072858765721321\n",
      "Epoch:  4447 | Train Accurancy:  0.9221281856298447 | Validation Accurancy:  0.9072961285710335\n",
      "Epoch:  4448 | Train Accurancy:  0.922131858766079 | Validation Accurancy:  0.9073064774274826\n",
      "Epoch:  4449 | Train Accurancy:  0.9221354573965073 | Validation Accurancy:  0.9073168411850929\n",
      "Epoch:  4450 | Train Accurancy:  0.9221391305327415 | Validation Accurancy:  0.9073273837566376\n",
      "Epoch:  4451 | Train Accurancy:  0.9221427589654922 | Validation Accurancy:  0.907337985932827\n",
      "Epoch:  4452 | Train Accurancy:  0.9221464172005653 | Validation Accurancy:  0.9073484912514687\n",
      "Epoch:  4453 | Train Accurancy:  0.9221500530838966 | Validation Accurancy:  0.9073589965701103\n",
      "Epoch:  4454 | Train Accurancy:  0.9221536964178085 | Validation Accurancy:  0.9073694497346878\n",
      "Epoch:  4455 | Train Accurancy:  0.9221572801470757 | Validation Accurancy:  0.9073812291026115\n",
      "Epoch:  4456 | Train Accurancy:  0.9221609309315681 | Validation Accurancy:  0.9073914512991905\n",
      "Epoch:  4457 | Train Accurancy:  0.9221645966172218 | Validation Accurancy:  0.907401829957962\n",
      "Epoch:  4458 | Train Accurancy:  0.9221681877970695 | Validation Accurancy:  0.9074121564626694\n",
      "Epoch:  4459 | Train Accurancy:  0.9221717938780785 | Validation Accurancy:  0.9074226468801498\n",
      "Epoch:  4460 | Train Accurancy:  0.9221754148602486 | Validation Accurancy:  0.9074330553412437\n",
      "Epoch:  4461 | Train Accurancy:  0.9221790730953217 | Validation Accurancy:  0.9074435010552406\n",
      "Epoch:  4462 | Train Accurancy:  0.9221826642751694 | Validation Accurancy:  0.9074541330337524\n",
      "Epoch:  4463 | Train Accurancy:  0.9221862405538559 | Validation Accurancy:  0.9074645861983299\n",
      "Epoch:  4464 | Train Accurancy:  0.9221898540854454 | Validation Accurancy:  0.9074763208627701\n",
      "Epoch:  4465 | Train Accurancy:  0.9221935048699379 | Validation Accurancy:  0.907486580312252\n",
      "Epoch:  4466 | Train Accurancy:  0.9221970736980438 | Validation Accurancy:  0.9074967801570892\n",
      "Epoch:  4467 | Train Accurancy:  0.9222006425261497 | Validation Accurancy:  0.9075071662664413\n",
      "Epoch:  4468 | Train Accurancy:  0.9222042933106422 | Validation Accurancy:  0.9075175896286964\n",
      "Epoch:  4469 | Train Accurancy:  0.9222079291939735 | Validation Accurancy:  0.9075280055403709\n",
      "Epoch:  4470 | Train Accurancy:  0.9222115352749825 | Validation Accurancy:  0.907538428902626\n",
      "Epoch:  4471 | Train Accurancy:  0.9222151562571526 | Validation Accurancy:  0.9075489044189453\n",
      "Epoch:  4472 | Train Accurancy:  0.9222187101840973 | Validation Accurancy:  0.9075593501329422\n",
      "Epoch:  4473 | Train Accurancy:  0.9222223311662674 | Validation Accurancy:  0.9075698852539062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4474 | Train Accurancy:  0.9222258850932121 | Validation Accurancy:  0.9075803831219673\n",
      "Epoch:  4475 | Train Accurancy:  0.9222295209765434 | Validation Accurancy:  0.9075919613242149\n",
      "Epoch:  4476 | Train Accurancy:  0.922233060002327 | Validation Accurancy:  0.9076021984219551\n",
      "Epoch:  4477 | Train Accurancy:  0.9222366809844971 | Validation Accurancy:  0.9076125398278236\n",
      "Epoch:  4478 | Train Accurancy:  0.9222402349114418 | Validation Accurancy:  0.9076228812336922\n",
      "Epoch:  4479 | Train Accurancy:  0.9222438484430313 | Validation Accurancy:  0.9076331034302711\n",
      "Epoch:  4480 | Train Accurancy:  0.922247476875782 | Validation Accurancy:  0.9076435267925262\n",
      "Epoch:  4481 | Train Accurancy:  0.9222510382533073 | Validation Accurancy:  0.9076541140675545\n",
      "Epoch:  4482 | Train Accurancy:  0.9222545996308327 | Validation Accurancy:  0.9076644256711006\n",
      "Epoch:  4483 | Train Accurancy:  0.9222581833600998 | Validation Accurancy:  0.9076748713850975\n",
      "Epoch:  4484 | Train Accurancy:  0.9222617521882057 | Validation Accurancy:  0.9076853096485138\n",
      "Epoch:  4485 | Train Accurancy:  0.9222653061151505 | Validation Accurancy:  0.9076957330107689\n",
      "Epoch:  4486 | Train Accurancy:  0.9222688749432564 | Validation Accurancy:  0.9077073261141777\n",
      "Epoch:  4487 | Train Accurancy:  0.9222724661231041 | Validation Accurancy:  0.9077175036072731\n",
      "Epoch:  4488 | Train Accurancy:  0.9222760424017906 | Validation Accurancy:  0.9077276363968849\n",
      "Epoch:  4489 | Train Accurancy:  0.9222795963287354 | Validation Accurancy:  0.9077378809452057\n",
      "Epoch:  4490 | Train Accurancy:  0.9222831502556801 | Validation Accurancy:  0.907748319208622\n",
      "Epoch:  4491 | Train Accurancy:  0.9222867116332054 | Validation Accurancy:  0.9077586457133293\n",
      "Epoch:  4492 | Train Accurancy:  0.9222903251647949 | Validation Accurancy:  0.9077689871191978\n",
      "Epoch:  4493 | Train Accurancy:  0.9222938716411591 | Validation Accurancy:  0.9077794104814529\n",
      "Epoch:  4494 | Train Accurancy:  0.9222973585128784 | Validation Accurancy:  0.9077898487448692\n",
      "Epoch:  4495 | Train Accurancy:  0.9223009720444679 | Validation Accurancy:  0.9078002348542213\n",
      "Epoch:  4496 | Train Accurancy:  0.9223044887185097 | Validation Accurancy:  0.9078106358647346\n",
      "Epoch:  4497 | Train Accurancy:  0.9223081022500992 | Validation Accurancy:  0.9078210145235062\n",
      "Epoch:  4498 | Train Accurancy:  0.9223116338253021 | Validation Accurancy:  0.9078314751386642\n",
      "Epoch:  4499 | Train Accurancy:  0.9223151430487633 | Validation Accurancy:  0.9078419432044029\n",
      "Epoch:  4500 | Train Accurancy:  0.9223186671733856 | Validation Accurancy:  0.907852329313755\n",
      "Epoch:  4501 | Train Accurancy:  0.922322228550911 | Validation Accurancy:  0.9078626930713654\n",
      "Epoch:  4502 | Train Accurancy:  0.9223258048295975 | Validation Accurancy:  0.9078730493783951\n",
      "Epoch:  4503 | Train Accurancy:  0.9223293140530586 | Validation Accurancy:  0.9078833907842636\n",
      "Epoch:  4504 | Train Accurancy:  0.9223328977823257 | Validation Accurancy:  0.9078940227627754\n",
      "Epoch:  4505 | Train Accurancy:  0.9223364517092705 | Validation Accurancy:  0.9079043865203857\n",
      "Epoch:  4506 | Train Accurancy:  0.9223399460315704 | Validation Accurancy:  0.9079146683216095\n",
      "Epoch:  4507 | Train Accurancy:  0.922343485057354 | Validation Accurancy:  0.9079251065850258\n",
      "Epoch:  4508 | Train Accurancy:  0.9223470538854599 | Validation Accurancy:  0.9079365506768227\n",
      "Epoch:  4509 | Train Accurancy:  0.9223505407571793 | Validation Accurancy:  0.9079466015100479\n",
      "Epoch:  4510 | Train Accurancy:  0.9223540723323822 | Validation Accurancy:  0.9079568088054657\n",
      "Epoch:  4511 | Train Accurancy:  0.9223575815558434 | Validation Accurancy:  0.9079670086503029\n",
      "Epoch:  4512 | Train Accurancy:  0.9223611205816269 | Validation Accurancy:  0.9079772606492043\n",
      "Epoch:  4513 | Train Accurancy:  0.9223646223545074 | Validation Accurancy:  0.9079875871539116\n",
      "Epoch:  4514 | Train Accurancy:  0.9223681390285492 | Validation Accurancy:  0.9079979285597801\n",
      "Epoch:  4515 | Train Accurancy:  0.9223716706037521 | Validation Accurancy:  0.9080082550644875\n",
      "Epoch:  4516 | Train Accurancy:  0.9223752319812775 | Validation Accurancy:  0.9080185443162918\n",
      "Epoch:  4517 | Train Accurancy:  0.9223787412047386 | Validation Accurancy:  0.9080289080739021\n",
      "Epoch:  4518 | Train Accurancy:  0.9223822429776192 | Validation Accurancy:  0.9080392122268677\n",
      "Epoch:  4519 | Train Accurancy:  0.9223857298493385 | Validation Accurancy:  0.9080495089292526\n",
      "Epoch:  4520 | Train Accurancy:  0.9223892614245415 | Validation Accurancy:  0.9080598428845406\n",
      "Epoch:  4521 | Train Accurancy:  0.9223926961421967 | Validation Accurancy:  0.9080701768398285\n",
      "Epoch:  4522 | Train Accurancy:  0.9223962649703026 | Validation Accurancy:  0.9080805778503418\n",
      "Epoch:  4523 | Train Accurancy:  0.9223997518420219 | Validation Accurancy:  0.9080908596515656\n",
      "Epoch:  4524 | Train Accurancy:  0.9224032610654831 | Validation Accurancy:  0.9081011787056923\n",
      "Epoch:  4525 | Train Accurancy:  0.9224068149924278 | Validation Accurancy:  0.9081115797162056\n",
      "Epoch:  4526 | Train Accurancy:  0.9224102646112442 | Validation Accurancy:  0.9081219360232353\n",
      "Epoch:  4527 | Train Accurancy:  0.9224137514829636 | Validation Accurancy:  0.9081322327256203\n",
      "Epoch:  4528 | Train Accurancy:  0.9224172681570053 | Validation Accurancy:  0.9081424698233604\n",
      "Epoch:  4529 | Train Accurancy:  0.9224207475781441 | Validation Accurancy:  0.9081528931856155\n",
      "Epoch:  4530 | Train Accurancy:  0.9224242344498634 | Validation Accurancy:  0.9081632420420647\n",
      "Epoch:  4531 | Train Accurancy:  0.9224277585744858 | Validation Accurancy:  0.9081735536456108\n",
      "Epoch:  4532 | Train Accurancy:  0.9224312826991081 | Validation Accurancy:  0.9081838056445122\n",
      "Epoch:  4533 | Train Accurancy:  0.9224347621202469 | Validation Accurancy:  0.9081939831376076\n",
      "Epoch:  4534 | Train Accurancy:  0.9224381819367409 | Validation Accurancy:  0.9082043915987015\n",
      "Epoch:  4535 | Train Accurancy:  0.922441728413105 | Validation Accurancy:  0.9082146361470222\n",
      "Epoch:  4536 | Train Accurancy:  0.9224451780319214 | Validation Accurancy:  0.9082248955965042\n",
      "Epoch:  4537 | Train Accurancy:  0.9224486574530602 | Validation Accurancy:  0.9082352221012115\n",
      "Epoch:  4538 | Train Accurancy:  0.9224521145224571 | Validation Accurancy:  0.9082454442977905\n",
      "Epoch:  4539 | Train Accurancy:  0.9224556386470795 | Validation Accurancy:  0.9082558900117874\n",
      "Epoch:  4540 | Train Accurancy:  0.9224591106176376 | Validation Accurancy:  0.9082660749554634\n",
      "Epoch:  4541 | Train Accurancy:  0.9224625527858734 | Validation Accurancy:  0.9082763493061066\n",
      "Epoch:  4542 | Train Accurancy:  0.9224660322070122 | Validation Accurancy:  0.9082865938544273\n",
      "Epoch:  4543 | Train Accurancy:  0.9224694967269897 | Validation Accurancy:  0.9082968980073929\n",
      "Epoch:  4544 | Train Accurancy:  0.9224729686975479 | Validation Accurancy:  0.9083071947097778\n",
      "Epoch:  4545 | Train Accurancy:  0.9224764928221703 | Validation Accurancy:  0.9083174467086792\n",
      "Epoch:  4546 | Train Accurancy:  0.9224799126386642 | Validation Accurancy:  0.9083276838064194\n",
      "Epoch:  4547 | Train Accurancy:  0.9224833548069 | Validation Accurancy:  0.908337913453579\n",
      "Epoch:  4548 | Train Accurancy:  0.922486811876297 | Validation Accurancy:  0.9083481803536415\n",
      "Epoch:  4549 | Train Accurancy:  0.9224902540445328 | Validation Accurancy:  0.9083583578467369\n",
      "Epoch:  4550 | Train Accurancy:  0.9224937111139297 | Validation Accurancy:  0.9083686321973801\n",
      "Epoch:  4551 | Train Accurancy:  0.9224971756339073 | Validation Accurancy:  0.9083787724375725\n",
      "Epoch:  4552 | Train Accurancy:  0.9225005805492401 | Validation Accurancy:  0.9083891063928604\n",
      "Epoch:  4553 | Train Accurancy:  0.9225040823221207 | Validation Accurancy:  0.9083993956446648\n",
      "Epoch:  4554 | Train Accurancy:  0.9225076213479042 | Validation Accurancy:  0.9084096997976303\n",
      "Epoch:  4555 | Train Accurancy:  0.9225110113620758 | Validation Accurancy:  0.9084198772907257\n",
      "Epoch:  4556 | Train Accurancy:  0.9225144162774086 | Validation Accurancy:  0.9084299057722092\n",
      "Epoch:  4557 | Train Accurancy:  0.9225178733468056 | Validation Accurancy:  0.9084402993321419\n",
      "Epoch:  4558 | Train Accurancy:  0.9225213155150414 | Validation Accurancy:  0.9084503948688507\n",
      "Epoch:  4559 | Train Accurancy:  0.9225247651338577 | Validation Accurancy:  0.9084606170654297\n",
      "Epoch:  4560 | Train Accurancy:  0.9225282222032547 | Validation Accurancy:  0.9084708988666534\n",
      "Epoch:  4561 | Train Accurancy:  0.9225316718220711 | Validation Accurancy:  0.908481054008007\n",
      "Epoch:  4562 | Train Accurancy:  0.9225350618362427 | Validation Accurancy:  0.9084912911057472\n",
      "Epoch:  4563 | Train Accurancy:  0.9225384891033173 | Validation Accurancy:  0.9085014909505844\n",
      "Epoch:  4564 | Train Accurancy:  0.9225419610738754 | Validation Accurancy:  0.908511720597744\n",
      "Epoch:  4565 | Train Accurancy:  0.9225453957915306 | Validation Accurancy:  0.9085218757390976\n",
      "Epoch:  4566 | Train Accurancy:  0.9225487932562828 | Validation Accurancy:  0.9085320234298706\n",
      "Epoch:  4567 | Train Accurancy:  0.922552227973938 | Validation Accurancy:  0.9085421785712242\n",
      "Epoch:  4568 | Train Accurancy:  0.9225557148456573 | Validation Accurancy:  0.9085522964596748\n",
      "Epoch:  4569 | Train Accurancy:  0.9225590974092484 | Validation Accurancy:  0.9085625931620598\n",
      "Epoch:  4570 | Train Accurancy:  0.9225624948740005 | Validation Accurancy:  0.908572718501091\n",
      "Epoch:  4571 | Train Accurancy:  0.9225659221410751 | Validation Accurancy:  0.9085828959941864\n",
      "Epoch:  4572 | Train Accurancy:  0.9225693419575691 | Validation Accurancy:  0.90859305113554\n",
      "Epoch:  4573 | Train Accurancy:  0.9225727543234825 | Validation Accurancy:  0.908603347837925\n",
      "Epoch:  4574 | Train Accurancy:  0.9225761890411377 | Validation Accurancy:  0.908613421022892\n",
      "Epoch:  4575 | Train Accurancy:  0.9225796237587929 | Validation Accurancy:  0.908623531460762\n",
      "Epoch:  4576 | Train Accurancy:  0.9225829467177391 | Validation Accurancy:  0.908633641898632\n",
      "Epoch:  4577 | Train Accurancy:  0.9225864261388779 | Validation Accurancy:  0.9086437374353409\n",
      "Epoch:  4578 | Train Accurancy:  0.9225898310542107 | Validation Accurancy:  0.9086540564894676\n",
      "Epoch:  4579 | Train Accurancy:  0.9225932508707047 | Validation Accurancy:  0.9086641296744347\n",
      "Epoch:  4580 | Train Accurancy:  0.9225966557860374 | Validation Accurancy:  0.9086742550134659\n",
      "Epoch:  4581 | Train Accurancy:  0.922600045800209 | Validation Accurancy:  0.9086844548583031\n",
      "Epoch:  4582 | Train Accurancy:  0.9226034209132195 | Validation Accurancy:  0.9086946621537209\n",
      "Epoch:  4583 | Train Accurancy:  0.9226068556308746 | Validation Accurancy:  0.9087046459317207\n",
      "Epoch:  4584 | Train Accurancy:  0.9226102083921432 | Validation Accurancy:  0.9087148979306221\n",
      "Epoch:  4585 | Train Accurancy:  0.9226136580109596 | Validation Accurancy:  0.9087248742580414\n",
      "Epoch:  4586 | Train Accurancy:  0.9226170629262924 | Validation Accurancy:  0.9087350890040398\n",
      "Epoch:  4587 | Train Accurancy:  0.9226204603910446 | Validation Accurancy:  0.9087451621890068\n",
      "Epoch:  4588 | Train Accurancy:  0.922623835504055 | Validation Accurancy:  0.9087552130222321\n",
      "Epoch:  4589 | Train Accurancy:  0.9226272255182266 | Validation Accurancy:  0.9087653607130051\n",
      "Epoch:  4590 | Train Accurancy:  0.9226305857300758 | Validation Accurancy:  0.9087755158543587\n",
      "Epoch:  4591 | Train Accurancy:  0.9226340129971504 | Validation Accurancy:  0.9087856560945511\n",
      "Epoch:  4592 | Train Accurancy:  0.9226374179124832 | Validation Accurancy:  0.9087957218289375\n",
      "Epoch:  4593 | Train Accurancy:  0.9226407632231712 | Validation Accurancy:  0.9088057950139046\n",
      "Epoch:  4594 | Train Accurancy:  0.922644168138504 | Validation Accurancy:  0.908816009759903\n",
      "Epoch:  4595 | Train Accurancy:  0.922647550702095 | Validation Accurancy:  0.9088259786367416\n",
      "Epoch:  4596 | Train Accurancy:  0.9226509481668472 | Validation Accurancy:  0.9088360145688057\n",
      "Epoch:  4597 | Train Accurancy:  0.9226542934775352 | Validation Accurancy:  0.9088461697101593\n",
      "Epoch:  4598 | Train Accurancy:  0.9226576462388039 | Validation Accurancy:  0.9088562056422234\n",
      "Epoch:  4599 | Train Accurancy:  0.922661080956459 | Validation Accurancy:  0.908866360783577\n",
      "Epoch:  4600 | Train Accurancy:  0.9226644337177277 | Validation Accurancy:  0.9088763520121574\n",
      "Epoch:  4601 | Train Accurancy:  0.9226677715778351 | Validation Accurancy:  0.9088864251971245\n",
      "Epoch:  4602 | Train Accurancy:  0.9226711541414261 | Validation Accurancy:  0.9088965207338333\n",
      "Epoch:  4603 | Train Accurancy:  0.9226744994521141 | Validation Accurancy:  0.9089066311717033\n",
      "Epoch:  4604 | Train Accurancy:  0.9226778894662857 | Validation Accurancy:  0.9089166298508644\n",
      "Epoch:  4605 | Train Accurancy:  0.9226812496781349 | Validation Accurancy:  0.9089266583323479\n",
      "Epoch:  4606 | Train Accurancy:  0.9226846247911453 | Validation Accurancy:  0.9089368134737015\n",
      "Epoch:  4607 | Train Accurancy:  0.9226879626512527 | Validation Accurancy:  0.9089468494057655\n",
      "Epoch:  4608 | Train Accurancy:  0.9226913452148438 | Validation Accurancy:  0.9089568480849266\n",
      "Epoch:  4609 | Train Accurancy:  0.9226947128772736 | Validation Accurancy:  0.9089668840169907\n",
      "Epoch:  4610 | Train Accurancy:  0.922698050737381 | Validation Accurancy:  0.9089768603444099\n",
      "Epoch:  4611 | Train Accurancy:  0.9227014258503914 | Validation Accurancy:  0.9089870601892471\n",
      "Epoch:  4612 | Train Accurancy:  0.9227047264575958 | Validation Accurancy:  0.908996969461441\n",
      "Epoch:  4613 | Train Accurancy:  0.9227081015706062 | Validation Accurancy:  0.9090069457888603\n",
      "Epoch:  4614 | Train Accurancy:  0.9227114170789719 | Validation Accurancy:  0.9090169668197632\n",
      "Epoch:  4615 | Train Accurancy:  0.9227148145437241 | Validation Accurancy:  0.9090270474553108\n",
      "Epoch:  4616 | Train Accurancy:  0.9227181151509285 | Validation Accurancy:  0.9090371429920197\n",
      "Epoch:  4617 | Train Accurancy:  0.9227214828133583 | Validation Accurancy:  0.9090471044182777\n",
      "Epoch:  4618 | Train Accurancy:  0.9227248132228851 | Validation Accurancy:  0.9090571179986\n",
      "Epoch:  4619 | Train Accurancy:  0.922728143632412 | Validation Accurancy:  0.9090670719742775\n",
      "Epoch:  4620 | Train Accurancy:  0.922731526196003 | Validation Accurancy:  0.9090770855545998\n",
      "Epoch:  4621 | Train Accurancy:  0.9227348566055298 | Validation Accurancy:  0.909087136387825\n",
      "Epoch:  4622 | Train Accurancy:  0.922738179564476 | Validation Accurancy:  0.9090971276164055\n",
      "Epoch:  4623 | Train Accurancy:  0.922741524875164 | Validation Accurancy:  0.9091071784496307\n",
      "Epoch:  4624 | Train Accurancy:  0.9227448403835297 | Validation Accurancy:  0.9091171398758888\n",
      "Epoch:  4625 | Train Accurancy:  0.9227481856942177 | Validation Accurancy:  0.9091270864009857\n",
      "Epoch:  4626 | Train Accurancy:  0.9227515012025833 | Validation Accurancy:  0.9091370850801468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4627 | Train Accurancy:  0.9227548390626907 | Validation Accurancy:  0.9091471806168556\n",
      "Epoch:  4628 | Train Accurancy:  0.9227581694722176 | Validation Accurancy:  0.9091573134064674\n",
      "Epoch:  4629 | Train Accurancy:  0.9227614924311638 | Validation Accurancy:  0.9091675579547882\n",
      "Epoch:  4630 | Train Accurancy:  0.92276481539011 | Validation Accurancy:  0.9091776087880135\n",
      "Epoch:  4631 | Train Accurancy:  0.9227681457996368 | Validation Accurancy:  0.9091877117753029\n",
      "Epoch:  4632 | Train Accurancy:  0.9227714091539383 | Validation Accurancy:  0.9091977551579475\n",
      "Epoch:  4633 | Train Accurancy:  0.9227747619152069 | Validation Accurancy:  0.909207709133625\n",
      "Epoch:  4634 | Train Accurancy:  0.9227780625224113 | Validation Accurancy:  0.9092178046703339\n",
      "Epoch:  4635 | Train Accurancy:  0.9227814003825188 | Validation Accurancy:  0.909227691590786\n",
      "Epoch:  4636 | Train Accurancy:  0.9227847084403038 | Validation Accurancy:  0.9092376381158829\n",
      "Epoch:  4637 | Train Accurancy:  0.9227880090475082 | Validation Accurancy:  0.9092476069927216\n",
      "Epoch:  4638 | Train Accurancy:  0.9227912947535515 | Validation Accurancy:  0.9092575684189796\n",
      "Epoch:  4639 | Train Accurancy:  0.9227946326136589 | Validation Accurancy:  0.9092675969004631\n",
      "Epoch:  4640 | Train Accurancy:  0.9227979704737663 | Validation Accurancy:  0.9092774763703346\n",
      "Epoch:  4641 | Train Accurancy:  0.9228012412786484 | Validation Accurancy:  0.9092874154448509\n",
      "Epoch:  4642 | Train Accurancy:  0.9228045642375946 | Validation Accurancy:  0.9092973321676254\n",
      "Epoch:  4643 | Train Accurancy:  0.9228078275918961 | Validation Accurancy:  0.9093072265386581\n",
      "Epoch:  4644 | Train Accurancy:  0.9228111654520035 | Validation Accurancy:  0.9093170687556267\n",
      "Epoch:  4645 | Train Accurancy:  0.9228144809603691 | Validation Accurancy:  0.9093270823359489\n",
      "Epoch:  4646 | Train Accurancy:  0.9228178188204765 | Validation Accurancy:  0.9093369245529175\n",
      "Epoch:  4647 | Train Accurancy:  0.9228210598230362 | Validation Accurancy:  0.9093469083309174\n",
      "Epoch:  4648 | Train Accurancy:  0.9228243604302406 | Validation Accurancy:  0.9093568846583366\n",
      "Epoch:  4649 | Train Accurancy:  0.9228276461362839 | Validation Accurancy:  0.9093668013811111\n",
      "Epoch:  4650 | Train Accurancy:  0.9228309541940689 | Validation Accurancy:  0.9093766510486603\n",
      "Epoch:  4651 | Train Accurancy:  0.9228341951966286 | Validation Accurancy:  0.9093865305185318\n",
      "Epoch:  4652 | Train Accurancy:  0.9228374511003494 | Validation Accurancy:  0.9093964248895645\n",
      "Epoch:  4653 | Train Accurancy:  0.9228407815098763 | Validation Accurancy:  0.9094064086675644\n",
      "Epoch:  4654 | Train Accurancy:  0.9228440746665001 | Validation Accurancy:  0.9094162359833717\n",
      "Epoch:  4655 | Train Accurancy:  0.9228473156690598 | Validation Accurancy:  0.9094259738922119\n",
      "Epoch:  4656 | Train Accurancy:  0.9228506162762642 | Validation Accurancy:  0.9094359055161476\n",
      "Epoch:  4657 | Train Accurancy:  0.9228538349270821 | Validation Accurancy:  0.9094458296895027\n",
      "Epoch:  4658 | Train Accurancy:  0.9228571504354477 | Validation Accurancy:  0.9094556495547295\n",
      "Epoch:  4659 | Train Accurancy:  0.9228604733943939 | Validation Accurancy:  0.9094655364751816\n",
      "Epoch:  4660 | Train Accurancy:  0.9228637292981148 | Validation Accurancy:  0.9094754159450531\n",
      "Epoch:  4661 | Train Accurancy:  0.9228670373558998 | Validation Accurancy:  0.9094854071736336\n",
      "Epoch:  4662 | Train Accurancy:  0.9228703081607819 | Validation Accurancy:  0.9094952344894409\n",
      "Epoch:  4663 | Train Accurancy:  0.9228735268115997 | Validation Accurancy:  0.909505121409893\n",
      "Epoch:  4664 | Train Accurancy:  0.9228768274188042 | Validation Accurancy:  0.9095149859786034\n",
      "Epoch:  4665 | Train Accurancy:  0.9228800758719444 | Validation Accurancy:  0.9095247760415077\n",
      "Epoch:  4666 | Train Accurancy:  0.9228833392262459 | Validation Accurancy:  0.9095345288515091\n",
      "Epoch:  4667 | Train Accurancy:  0.9228865951299667 | Validation Accurancy:  0.9095443785190582\n",
      "Epoch:  4668 | Train Accurancy:  0.9228898510336876 | Validation Accurancy:  0.9095542952418327\n",
      "Epoch:  4669 | Train Accurancy:  0.9228930845856667 | Validation Accurancy:  0.9095640629529953\n",
      "Epoch:  4670 | Train Accurancy:  0.9228963479399681 | Validation Accurancy:  0.9095739051699638\n",
      "Epoch:  4671 | Train Accurancy:  0.9228996708989143 | Validation Accurancy:  0.9095837622880936\n",
      "Epoch:  4672 | Train Accurancy:  0.9229029417037964 | Validation Accurancy:  0.9095935970544815\n",
      "Epoch:  4673 | Train Accurancy:  0.9229061454534531 | Validation Accurancy:  0.9096033945679665\n",
      "Epoch:  4674 | Train Accurancy:  0.9229093641042709 | Validation Accurancy:  0.9096133038401604\n",
      "Epoch:  4675 | Train Accurancy:  0.9229126498103142 | Validation Accurancy:  0.9096231013536453\n",
      "Epoch:  4676 | Train Accurancy:  0.922915905714035 | Validation Accurancy:  0.909632958471775\n",
      "Epoch:  4677 | Train Accurancy:  0.9229190871119499 | Validation Accurancy:  0.9096427261829376\n",
      "Epoch:  4678 | Train Accurancy:  0.922922395169735 | Validation Accurancy:  0.9096525385975838\n",
      "Epoch:  4679 | Train Accurancy:  0.9229256138205528 | Validation Accurancy:  0.9096623808145523\n",
      "Epoch:  4680 | Train Accurancy:  0.9229288995265961 | Validation Accurancy:  0.9096721857786179\n",
      "Epoch:  4681 | Train Accurancy:  0.9229321032762527 | Validation Accurancy:  0.9096818640828133\n",
      "Epoch:  4682 | Train Accurancy:  0.9229353442788124 | Validation Accurancy:  0.9096916392445564\n",
      "Epoch:  4683 | Train Accurancy:  0.9229385852813721 | Validation Accurancy:  0.9097016006708145\n",
      "Epoch:  4684 | Train Accurancy:  0.9229418337345123 | Validation Accurancy:  0.9097112342715263\n",
      "Epoch:  4685 | Train Accurancy:  0.9229450523853302 | Validation Accurancy:  0.9097210690379143\n",
      "Epoch:  4686 | Train Accurancy:  0.9229483157396317 | Validation Accurancy:  0.909730963408947\n",
      "Epoch:  4687 | Train Accurancy:  0.9229515045881271 | Validation Accurancy:  0.9097407683730125\n",
      "Epoch:  4688 | Train Accurancy:  0.922954760491848 | Validation Accurancy:  0.909750446677208\n",
      "Epoch:  4689 | Train Accurancy:  0.9229579642415047 | Validation Accurancy:  0.9097602665424347\n",
      "Epoch:  4690 | Train Accurancy:  0.9229611828923225 | Validation Accurancy:  0.9097700119018555\n",
      "Epoch:  4691 | Train Accurancy:  0.9229644313454628 | Validation Accurancy:  0.9097799360752106\n",
      "Epoch:  4692 | Train Accurancy:  0.9229676574468613 | Validation Accurancy:  0.9097895845770836\n",
      "Epoch:  4693 | Train Accurancy:  0.9229708537459373 | Validation Accurancy:  0.909799262881279\n",
      "Epoch:  4694 | Train Accurancy:  0.9229741171002388 | Validation Accurancy:  0.9098091423511505\n",
      "Epoch:  4695 | Train Accurancy:  0.9229773133993149 | Validation Accurancy:  0.9098188802599907\n",
      "Epoch:  4696 | Train Accurancy:  0.9229805618524551 | Validation Accurancy:  0.9098285734653473\n",
      "Epoch:  4697 | Train Accurancy:  0.9229837357997894 | Validation Accurancy:  0.9098384082317352\n",
      "Epoch:  4698 | Train Accurancy:  0.9229869768023491 | Validation Accurancy:  0.9098480492830276\n",
      "Epoch:  4699 | Train Accurancy:  0.9229901507496834 | Validation Accurancy:  0.909857802093029\n",
      "Epoch:  4700 | Train Accurancy:  0.922993429005146 | Validation Accurancy:  0.909867636859417\n",
      "Epoch:  4701 | Train Accurancy:  0.9229965955018997 | Validation Accurancy:  0.90987728536129\n",
      "Epoch:  4702 | Train Accurancy:  0.9229998290538788 | Validation Accurancy:  0.9098870307207108\n",
      "Epoch:  4703 | Train Accurancy:  0.9230030551552773 | Validation Accurancy:  0.9098968207836151\n",
      "Epoch:  4704 | Train Accurancy:  0.9230061993002892 | Validation Accurancy:  0.9099065214395523\n",
      "Epoch:  4705 | Train Accurancy:  0.9230094477534294 | Validation Accurancy:  0.9099162593483925\n",
      "Epoch:  4706 | Train Accurancy:  0.9230125993490219 | Validation Accurancy:  0.9099259749054909\n",
      "Epoch:  4707 | Train Accurancy:  0.923015832901001 | Validation Accurancy:  0.9099358096718788\n",
      "Epoch:  4708 | Train Accurancy:  0.9230190292000771 | Validation Accurancy:  0.9099454581737518\n",
      "Epoch:  4709 | Train Accurancy:  0.9230222031474113 | Validation Accurancy:  0.909955233335495\n",
      "Epoch:  4710 | Train Accurancy:  0.9230254217982292 | Validation Accurancy:  0.9099648296833038\n",
      "Epoch:  4711 | Train Accurancy:  0.9230286180973053 | Validation Accurancy:  0.9099745526909828\n",
      "Epoch:  4712 | Train Accurancy:  0.923031784594059 | Validation Accurancy:  0.9099842235445976\n",
      "Epoch:  4713 | Train Accurancy:  0.9230350106954575 | Validation Accurancy:  0.909993939101696\n",
      "Epoch:  4714 | Train Accurancy:  0.9230382218956947 | Validation Accurancy:  0.9100037068128586\n",
      "Epoch:  4715 | Train Accurancy:  0.9230414181947708 | Validation Accurancy:  0.910013347864151\n",
      "Epoch:  4716 | Train Accurancy:  0.9230445548892021 | Validation Accurancy:  0.9100230261683464\n",
      "Epoch:  4717 | Train Accurancy:  0.923047736287117 | Validation Accurancy:  0.9100328832864761\n",
      "Epoch:  4718 | Train Accurancy:  0.9230508804321289 | Validation Accurancy:  0.9100423976778984\n",
      "Epoch:  4719 | Train Accurancy:  0.9230541214346886 | Validation Accurancy:  0.9100520759820938\n",
      "Epoch:  4720 | Train Accurancy:  0.9230572655797005 | Validation Accurancy:  0.9100618585944176\n",
      "Epoch:  4721 | Train Accurancy:  0.9230604842305183 | Validation Accurancy:  0.9100714921951294\n",
      "Epoch:  4722 | Train Accurancy:  0.9230635687708855 | Validation Accurancy:  0.9100811257958412\n",
      "Epoch:  4723 | Train Accurancy:  0.9230667874217033 | Validation Accurancy:  0.910090871155262\n",
      "Epoch:  4724 | Train Accurancy:  0.9230699986219406 | Validation Accurancy:  0.910100482404232\n",
      "Epoch:  4725 | Train Accurancy:  0.9230731651186943 | Validation Accurancy:  0.9101101979613304\n",
      "Epoch:  4726 | Train Accurancy:  0.923076368868351 | Validation Accurancy:  0.9101198688149452\n",
      "Epoch:  4727 | Train Accurancy:  0.9230795428156853 | Validation Accurancy:  0.9101295694708824\n",
      "Epoch:  4728 | Train Accurancy:  0.923082709312439 | Validation Accurancy:  0.9101392775774002\n",
      "Epoch:  4729 | Train Accurancy:  0.9230858385562897 | Validation Accurancy:  0.9101488441228867\n",
      "Epoch:  4730 | Train Accurancy:  0.923088975250721 | Validation Accurancy:  0.9101585149765015\n",
      "Epoch:  4731 | Train Accurancy:  0.9230921417474747 | Validation Accurancy:  0.9101681336760521\n",
      "Epoch:  4732 | Train Accurancy:  0.9230953305959702 | Validation Accurancy:  0.9101777449250221\n",
      "Epoch:  4733 | Train Accurancy:  0.9230984672904015 | Validation Accurancy:  0.9101874530315399\n",
      "Epoch:  4734 | Train Accurancy:  0.9231016933917999 | Validation Accurancy:  0.9101970121264458\n",
      "Epoch:  4735 | Train Accurancy:  0.9231047704815865 | Validation Accurancy:  0.9102066457271576\n",
      "Epoch:  4736 | Train Accurancy:  0.9231079816818237 | Validation Accurancy:  0.9102163463830948\n",
      "Epoch:  4737 | Train Accurancy:  0.9231111258268356 | Validation Accurancy:  0.9102258309721947\n",
      "Epoch:  4738 | Train Accurancy:  0.9231142699718475 | Validation Accurancy:  0.9102355465292931\n",
      "Epoch:  4739 | Train Accurancy:  0.9231173992156982 | Validation Accurancy:  0.9102452248334885\n",
      "Epoch:  4740 | Train Accurancy:  0.923120528459549 | Validation Accurancy:  0.9102547839283943\n",
      "Epoch:  4741 | Train Accurancy:  0.9231237098574638 | Validation Accurancy:  0.9102644771337509\n",
      "Epoch:  4742 | Train Accurancy:  0.9231268391013145 | Validation Accurancy:  0.9102740436792374\n",
      "Epoch:  4743 | Train Accurancy:  0.9231300204992294 | Validation Accurancy:  0.9102836549282074\n",
      "Epoch:  4744 | Train Accurancy:  0.9231331571936607 | Validation Accurancy:  0.910293273627758\n",
      "Epoch:  4745 | Train Accurancy:  0.9231362491846085 | Validation Accurancy:  0.9103028327226639\n",
      "Epoch:  4746 | Train Accurancy:  0.9231394454836845 | Validation Accurancy:  0.9103124439716339\n",
      "Epoch:  4747 | Train Accurancy:  0.9231425747275352 | Validation Accurancy:  0.9103220924735069\n",
      "Epoch:  4748 | Train Accurancy:  0.9231457561254501 | Validation Accurancy:  0.9103316441178322\n",
      "Epoch:  4749 | Train Accurancy:  0.923148863017559 | Validation Accurancy:  0.910341314971447\n",
      "Epoch:  4750 | Train Accurancy:  0.9231519550085068 | Validation Accurancy:  0.9103508368134499\n",
      "Epoch:  4751 | Train Accurancy:  0.9231550917029381 | Validation Accurancy:  0.9103604555130005\n",
      "Epoch:  4752 | Train Accurancy:  0.9231582656502724 | Validation Accurancy:  0.9103700742125511\n",
      "Epoch:  4753 | Train Accurancy:  0.9231613352894783 | Validation Accurancy:  0.9103795513510704\n",
      "Epoch:  4754 | Train Accurancy:  0.9231645166873932 | Validation Accurancy:  0.9103890955448151\n",
      "Epoch:  4755 | Train Accurancy:  0.9231676235795021 | Validation Accurancy:  0.9103987365961075\n",
      "Epoch:  4756 | Train Accurancy:  0.9231707528233528 | Validation Accurancy:  0.9104083254933357\n",
      "Epoch:  4757 | Train Accurancy:  0.9231738820672035 | Validation Accurancy:  0.910417951643467\n",
      "Epoch:  4758 | Train Accurancy:  0.9231770485639572 | Validation Accurancy:  0.9104273989796638\n",
      "Epoch:  4759 | Train Accurancy:  0.9231801107525826 | Validation Accurancy:  0.9104370549321175\n",
      "Epoch:  4760 | Train Accurancy:  0.9231832474470139 | Validation Accurancy:  0.9104465246200562\n",
      "Epoch:  4761 | Train Accurancy:  0.9231863841414452 | Validation Accurancy:  0.9104561433196068\n",
      "Epoch:  4762 | Train Accurancy:  0.9231894835829735 | Validation Accurancy:  0.9104657396674156\n",
      "Epoch:  4763 | Train Accurancy:  0.9231926128268242 | Validation Accurancy:  0.9104751423001289\n",
      "Epoch:  4764 | Train Accurancy:  0.9231956675648689 | Validation Accurancy:  0.910484790802002\n",
      "Epoch:  4765 | Train Accurancy:  0.923198826611042 | Validation Accurancy:  0.9104943051934242\n",
      "Epoch:  4766 | Train Accurancy:  0.9232019260525703 | Validation Accurancy:  0.9105038270354271\n",
      "Epoch:  4767 | Train Accurancy:  0.9232050403952599 | Validation Accurancy:  0.9105134084820747\n",
      "Epoch:  4768 | Train Accurancy:  0.92320816218853 | Validation Accurancy:  0.9105229824781418\n",
      "Epoch:  4769 | Train Accurancy:  0.9232112616300583 | Validation Accurancy:  0.9105324596166611\n",
      "Epoch:  4770 | Train Accurancy:  0.9232143983244896 | Validation Accurancy:  0.9105420559644699\n",
      "Epoch:  4771 | Train Accurancy:  0.9232174903154373 | Validation Accurancy:  0.9105515629053116\n",
      "Epoch:  4772 | Train Accurancy:  0.9232205674052238 | Validation Accurancy:  0.9105611220002174\n",
      "Epoch:  4773 | Train Accurancy:  0.9232236817479134 | Validation Accurancy:  0.9105705693364143\n",
      "Epoch:  4774 | Train Accurancy:  0.9232268035411835 | Validation Accurancy:  0.910580150783062\n",
      "Epoch:  4775 | Train Accurancy:  0.92322988063097 | Validation Accurancy:  0.910589687526226\n",
      "Epoch:  4776 | Train Accurancy:  0.9232329875230789 | Validation Accurancy:  0.9105991572141647\n",
      "Epoch:  4777 | Train Accurancy:  0.9232360646128654 | Validation Accurancy:  0.9106086194515228\n",
      "Epoch:  4778 | Train Accurancy:  0.9232391491532326 | Validation Accurancy:  0.9106182232499123\n",
      "Epoch:  4779 | Train Accurancy:  0.9232422262430191 | Validation Accurancy:  0.9106276109814644\n",
      "Epoch:  4780 | Train Accurancy:  0.9232453107833862 | Validation Accurancy:  0.9106371775269508\n",
      "Epoch:  4781 | Train Accurancy:  0.9232484400272369 | Validation Accurancy:  0.9106466546654701\n",
      "Epoch:  4782 | Train Accurancy:  0.9232515469193459 | Validation Accurancy:  0.9106561318039894\n",
      "Epoch:  4783 | Train Accurancy:  0.9232546016573906 | Validation Accurancy:  0.9106656461954117\n",
      "Epoch:  4784 | Train Accurancy:  0.9232576563954353 | Validation Accurancy:  0.910675086081028\n",
      "Epoch:  4785 | Train Accurancy:  0.9232607260346413 | Validation Accurancy:  0.9106846302747726\n",
      "Epoch:  4786 | Train Accurancy:  0.9232638329267502 | Validation Accurancy:  0.910694032907486\n",
      "Epoch:  4787 | Train Accurancy:  0.9232669100165367 | Validation Accurancy:  0.9107035472989082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4788 | Train Accurancy:  0.923269972205162 | Validation Accurancy:  0.910712942481041\n",
      "Epoch:  4789 | Train Accurancy:  0.9232730939984322 | Validation Accurancy:  0.9107224643230438\n",
      "Epoch:  4790 | Train Accurancy:  0.9232761412858963 | Validation Accurancy:  0.9107319340109825\n",
      "Epoch:  4791 | Train Accurancy:  0.9232792183756828 | Validation Accurancy:  0.9107414036989212\n",
      "Epoch:  4792 | Train Accurancy:  0.9232822954654694 | Validation Accurancy:  0.9107509925961494\n",
      "Epoch:  4793 | Train Accurancy:  0.9232853800058365 | Validation Accurancy:  0.9107604548335075\n",
      "Epoch:  4794 | Train Accurancy:  0.9232884496450424 | Validation Accurancy:  0.9107698202133179\n",
      "Epoch:  4795 | Train Accurancy:  0.9232915118336678 | Validation Accurancy:  0.9107793495059013\n",
      "Epoch:  4796 | Train Accurancy:  0.9232945665717125 | Validation Accurancy:  0.9107888042926788\n",
      "Epoch:  4797 | Train Accurancy:  0.9232976734638214 | Validation Accurancy:  0.9107982441782951\n",
      "Epoch:  4798 | Train Accurancy:  0.9233007058501244 | Validation Accurancy:  0.9108077362179756\n",
      "Epoch:  4799 | Train Accurancy:  0.9233037680387497 | Validation Accurancy:  0.9108171388506889\n",
      "Epoch:  4800 | Train Accurancy:  0.9233068376779556 | Validation Accurancy:  0.9108264744281769\n",
      "Epoch:  4801 | Train Accurancy:  0.9233099147677422 | Validation Accurancy:  0.9108359664678574\n",
      "Epoch:  4802 | Train Accurancy:  0.9233129844069481 | Validation Accurancy:  0.9108453691005707\n",
      "Epoch:  4803 | Train Accurancy:  0.9233160242438316 | Validation Accurancy:  0.9108548164367676\n",
      "Epoch:  4804 | Train Accurancy:  0.9233190268278122 | Validation Accurancy:  0.9108642265200615\n",
      "Epoch:  4805 | Train Accurancy:  0.9233221188187599 | Validation Accurancy:  0.910873755812645\n",
      "Epoch:  4806 | Train Accurancy:  0.9233251810073853 | Validation Accurancy:  0.9108831360936165\n",
      "Epoch:  4807 | Train Accurancy:  0.9233282431960106 | Validation Accurancy:  0.910892553627491\n",
      "Epoch:  4808 | Train Accurancy:  0.9233312755823135 | Validation Accurancy:  0.9109020903706551\n",
      "Epoch:  4809 | Train Accurancy:  0.9233343303203583 | Validation Accurancy:  0.9109113216400146\n",
      "Epoch:  4810 | Train Accurancy:  0.9233373701572418 | Validation Accurancy:  0.9109208509325981\n",
      "Epoch:  4811 | Train Accurancy:  0.9233404025435448 | Validation Accurancy:  0.9109302014112473\n",
      "Epoch:  4812 | Train Accurancy:  0.9233434647321701 | Validation Accurancy:  0.910939559340477\n",
      "Epoch:  4813 | Train Accurancy:  0.9233464896678925 | Validation Accurancy:  0.9109490439295769\n",
      "Epoch:  4814 | Train Accurancy:  0.923349566757679 | Validation Accurancy:  0.9109583869576454\n",
      "Epoch:  4815 | Train Accurancy:  0.9233526438474655 | Validation Accurancy:  0.9109677150845528\n",
      "Epoch:  4816 | Train Accurancy:  0.9233555868268013 | Validation Accurancy:  0.9109771326184273\n",
      "Epoch:  4817 | Train Accurancy:  0.9233587086200714 | Validation Accurancy:  0.9109865352511406\n",
      "Epoch:  4818 | Train Accurancy:  0.9233617335557938 | Validation Accurancy:  0.9109959676861763\n",
      "Epoch:  4819 | Train Accurancy:  0.9233647137880325 | Validation Accurancy:  0.9110053479671478\n",
      "Epoch:  4820 | Train Accurancy:  0.9233677834272385 | Validation Accurancy:  0.9110147804021835\n",
      "Epoch:  4821 | Train Accurancy:  0.923370823264122 | Validation Accurancy:  0.9110241383314133\n",
      "Epoch:  4822 | Train Accurancy:  0.9233738258481026 | Validation Accurancy:  0.9110335186123848\n",
      "Epoch:  4823 | Train Accurancy:  0.9233768656849861 | Validation Accurancy:  0.9110428988933563\n",
      "Epoch:  4824 | Train Accurancy:  0.9233798757195473 | Validation Accurancy:  0.9110521003603935\n",
      "Epoch:  4825 | Train Accurancy:  0.9233829155564308 | Validation Accurancy:  0.911061629652977\n",
      "Epoch:  4826 | Train Accurancy:  0.923385925590992 | Validation Accurancy:  0.9110709652304649\n",
      "Epoch:  4827 | Train Accurancy:  0.9233889728784561 | Validation Accurancy:  0.9110802710056305\n",
      "Epoch:  4828 | Train Accurancy:  0.9233919754624367 | Validation Accurancy:  0.9110896736383438\n",
      "Epoch:  4829 | Train Accurancy:  0.9233950227499008 | Validation Accurancy:  0.9110990539193153\n",
      "Epoch:  4830 | Train Accurancy:  0.9233980104327202 | Validation Accurancy:  0.9111083969473839\n",
      "Epoch:  4831 | Train Accurancy:  0.9234010428190231 | Validation Accurancy:  0.9111177921295166\n",
      "Epoch:  4832 | Train Accurancy:  0.9234040677547455 | Validation Accurancy:  0.9111271277070045\n",
      "Epoch:  4833 | Train Accurancy:  0.9234070330858231 | Validation Accurancy:  0.9111364260315895\n",
      "Epoch:  4834 | Train Accurancy:  0.923410102725029 | Validation Accurancy:  0.9111457392573357\n",
      "Epoch:  4835 | Train Accurancy:  0.9234131202101707 | Validation Accurancy:  0.9111551344394684\n",
      "Epoch:  4836 | Train Accurancy:  0.9234161004424095 | Validation Accurancy:  0.9111643806099892\n",
      "Epoch:  4837 | Train Accurancy:  0.9234190955758095 | Validation Accurancy:  0.9111725091934204\n",
      "Epoch:  4838 | Train Accurancy:  0.9234221279621124 | Validation Accurancy:  0.9111821949481964\n",
      "Epoch:  4839 | Train Accurancy:  0.92342509329319 | Validation Accurancy:  0.911191776394844\n",
      "Epoch:  4840 | Train Accurancy:  0.9234281554818153 | Validation Accurancy:  0.9112014323472977\n",
      "Epoch:  4841 | Train Accurancy:  0.9234311729669571 | Validation Accurancy:  0.9112107753753662\n",
      "Epoch:  4842 | Train Accurancy:  0.9234341159462929 | Validation Accurancy:  0.9112188667058945\n",
      "Epoch:  4843 | Train Accurancy:  0.9234371557831764 | Validation Accurancy:  0.91122867166996\n",
      "Epoch:  4844 | Train Accurancy:  0.9234401285648346 | Validation Accurancy:  0.9112382233142853\n",
      "Epoch:  4845 | Train Accurancy:  0.9234431460499763 | Validation Accurancy:  0.9112477749586105\n",
      "Epoch:  4846 | Train Accurancy:  0.9234461337327957 | Validation Accurancy:  0.9112559407949448\n",
      "Epoch:  4847 | Train Accurancy:  0.9234491214156151 | Validation Accurancy:  0.9112656638026237\n",
      "Epoch:  4848 | Train Accurancy:  0.9234521239995956 | Validation Accurancy:  0.9112753495573997\n",
      "Epoch:  4849 | Train Accurancy:  0.923455111682415 | Validation Accurancy:  0.9112848564982414\n",
      "Epoch:  4850 | Train Accurancy:  0.9234580993652344 | Validation Accurancy:  0.9112929925322533\n",
      "Epoch:  4851 | Train Accurancy:  0.9234610721468925 | Validation Accurancy:  0.9113027676939964\n",
      "Epoch:  4852 | Train Accurancy:  0.9234640747308731 | Validation Accurancy:  0.9113125279545784\n",
      "Epoch:  4853 | Train Accurancy:  0.9234670326113701 | Validation Accurancy:  0.9113219231367111\n",
      "Epoch:  4854 | Train Accurancy:  0.9234700426459312 | Validation Accurancy:  0.9113301411271095\n",
      "Epoch:  4855 | Train Accurancy:  0.9234730303287506 | Validation Accurancy:  0.9113399088382721\n",
      "Epoch:  4856 | Train Accurancy:  0.9234760105609894 | Validation Accurancy:  0.9113495722413063\n",
      "Epoch:  4857 | Train Accurancy:  0.9234790056943893 | Validation Accurancy:  0.9113591089844704\n",
      "Epoch:  4858 | Train Accurancy:  0.9234819561243057 | Validation Accurancy:  0.911367192864418\n",
      "Epoch:  4859 | Train Accurancy:  0.9234849512577057 | Validation Accurancy:  0.9113769754767418\n",
      "Epoch:  4860 | Train Accurancy:  0.9234879240393639 | Validation Accurancy:  0.911386601626873\n",
      "Epoch:  4861 | Train Accurancy:  0.9234908670186996 | Validation Accurancy:  0.9113960936665535\n",
      "Epoch:  4862 | Train Accurancy:  0.9234938621520996 | Validation Accurancy:  0.9114042669534683\n",
      "Epoch:  4863 | Train Accurancy:  0.923496849834919 | Validation Accurancy:  0.9114140123128891\n",
      "Epoch:  4864 | Train Accurancy:  0.9234998300671577 | Validation Accurancy:  0.9114236384630203\n",
      "Epoch:  4865 | Train Accurancy:  0.9235027879476547 | Validation Accurancy:  0.9114330038428307\n",
      "Epoch:  4866 | Train Accurancy:  0.9235057607293129 | Validation Accurancy:  0.9114412292838097\n",
      "Epoch:  4867 | Train Accurancy:  0.9235087260603905 | Validation Accurancy:  0.911450944840908\n",
      "Epoch:  4868 | Train Accurancy:  0.923511728644371 | Validation Accurancy:  0.911460630595684\n",
      "Epoch:  4869 | Train Accurancy:  0.9235147014260292 | Validation Accurancy:  0.9114700928330421\n",
      "Epoch:  4870 | Train Accurancy:  0.9235176295042038 | Validation Accurancy:  0.9114782586693764\n",
      "Epoch:  4871 | Train Accurancy:  0.923520602285862 | Validation Accurancy:  0.9114888161420822\n",
      "Epoch:  4872 | Train Accurancy:  0.9235235452651978 | Validation Accurancy:  0.9114968031644821\n",
      "Epoch:  4873 | Train Accurancy:  0.9235265031456947 | Validation Accurancy:  0.9115073904395103\n",
      "Epoch:  4874 | Train Accurancy:  0.9235294759273529 | Validation Accurancy:  0.9115153849124908\n",
      "Epoch:  4875 | Train Accurancy:  0.9235323816537857 | Validation Accurancy:  0.9115259349346161\n",
      "Epoch:  4876 | Train Accurancy:  0.9235353469848633 | Validation Accurancy:  0.9115337431430817\n",
      "Epoch:  4877 | Train Accurancy:  0.9235383197665215 | Validation Accurancy:  0.9115443751215935\n",
      "Epoch:  4878 | Train Accurancy:  0.9235412627458572 | Validation Accurancy:  0.9115523025393486\n",
      "Epoch:  4879 | Train Accurancy:  0.9235442131757736 | Validation Accurancy:  0.9115626886487007\n",
      "Epoch:  4880 | Train Accurancy:  0.9235471934080124 | Validation Accurancy:  0.911570817232132\n",
      "Epoch:  4881 | Train Accurancy:  0.9235501661896706 | Validation Accurancy:  0.9115799516439438\n",
      "Epoch:  4882 | Train Accurancy:  0.9235530346632004 | Validation Accurancy:  0.9115890711545944\n",
      "Epoch:  4883 | Train Accurancy:  0.9235560148954391 | Validation Accurancy:  0.9115984216332436\n",
      "Epoch:  4884 | Train Accurancy:  0.9235589504241943 | Validation Accurancy:  0.9116087779402733\n",
      "Epoch:  4885 | Train Accurancy:  0.9235619008541107 | Validation Accurancy:  0.911616638302803\n",
      "Epoch:  4886 | Train Accurancy:  0.9235648289322853 | Validation Accurancy:  0.9116258323192596\n",
      "Epoch:  4887 | Train Accurancy:  0.9235677644610405 | Validation Accurancy:  0.9116350039839745\n",
      "Epoch:  4888 | Train Accurancy:  0.9235707595944405 | Validation Accurancy:  0.9116441234946251\n",
      "Epoch:  4889 | Train Accurancy:  0.9235736802220345 | Validation Accurancy:  0.9116533696651459\n",
      "Epoch:  4890 | Train Accurancy:  0.9235765635967255 | Validation Accurancy:  0.9116637408733368\n",
      "Epoch:  4891 | Train Accurancy:  0.9235794991254807 | Validation Accurancy:  0.9116726666688919\n",
      "Epoch:  4892 | Train Accurancy:  0.9235824644565582 | Validation Accurancy:  0.9116815030574799\n",
      "Epoch:  4893 | Train Accurancy:  0.923585407435894 | Validation Accurancy:  0.9116905257105827\n",
      "Epoch:  4894 | Train Accurancy:  0.9235883057117462 | Validation Accurancy:  0.9116995632648468\n",
      "Epoch:  4895 | Train Accurancy:  0.923591248691082 | Validation Accurancy:  0.9117086231708527\n",
      "Epoch:  4896 | Train Accurancy:  0.9235941916704178 | Validation Accurancy:  0.9117176979780197\n",
      "Epoch:  4897 | Train Accurancy:  0.9235971197485924 | Validation Accurancy:  0.9117268100380898\n",
      "Epoch:  4898 | Train Accurancy:  0.9236000329256058 | Validation Accurancy:  0.911735936999321\n",
      "Epoch:  4899 | Train Accurancy:  0.923602893948555 | Validation Accurancy:  0.911745086312294\n",
      "Epoch:  4900 | Train Accurancy:  0.9236059039831161 | Validation Accurancy:  0.9117541760206223\n",
      "Epoch:  4901 | Train Accurancy:  0.9236087873578072 | Validation Accurancy:  0.91176338493824\n",
      "Epoch:  4902 | Train Accurancy:  0.92361169308424 | Validation Accurancy:  0.9117725044488907\n",
      "Epoch:  4903 | Train Accurancy:  0.9236146509647369 | Validation Accurancy:  0.9117815271019936\n",
      "Epoch:  4904 | Train Accurancy:  0.9236175268888474 | Validation Accurancy:  0.9117906764149666\n",
      "Epoch:  4905 | Train Accurancy:  0.923620417714119 | Validation Accurancy:  0.9117999523878098\n",
      "Epoch:  4906 | Train Accurancy:  0.9236234128475189 | Validation Accurancy:  0.911808930337429\n",
      "Epoch:  4907 | Train Accurancy:  0.9236263185739517 | Validation Accurancy:  0.9118181243538857\n",
      "Epoch:  4908 | Train Accurancy:  0.9236291870474815 | Validation Accurancy:  0.9118272140622139\n",
      "Epoch:  4909 | Train Accurancy:  0.9236321002244949 | Validation Accurancy:  0.9118363335728645\n",
      "Epoch:  4910 | Train Accurancy:  0.9236349910497665 | Validation Accurancy:  0.9118453487753868\n",
      "Epoch:  4911 | Train Accurancy:  0.9236379489302635 | Validation Accurancy:  0.9118544980883598\n",
      "Epoch:  4912 | Train Accurancy:  0.9236408472061157 | Validation Accurancy:  0.9118636399507523\n",
      "Epoch:  4913 | Train Accurancy:  0.9236437603831291 | Validation Accurancy:  0.9118727520108223\n",
      "Epoch:  4914 | Train Accurancy:  0.9236466437578201 | Validation Accurancy:  0.9118817821145058\n",
      "Epoch:  4915 | Train Accurancy:  0.9236495494842529 | Validation Accurancy:  0.9118910506367683\n",
      "Epoch:  4916 | Train Accurancy:  0.9236524328589439 | Validation Accurancy:  0.9119000062346458\n",
      "Epoch:  4917 | Train Accurancy:  0.9236553683876991 | Validation Accurancy:  0.9119092151522636\n",
      "Epoch:  4918 | Train Accurancy:  0.9236582443118095 | Validation Accurancy:  0.9119182601571083\n",
      "Epoch:  4919 | Train Accurancy:  0.92366112023592 | Validation Accurancy:  0.91192726790905\n",
      "Epoch:  4920 | Train Accurancy:  0.9236640185117722 | Validation Accurancy:  0.9119365140795708\n",
      "Epoch:  4921 | Train Accurancy:  0.9236669465899467 | Validation Accurancy:  0.9119455069303513\n",
      "Epoch:  4922 | Train Accurancy:  0.9236698299646378 | Validation Accurancy:  0.9119546264410019\n",
      "Epoch:  4923 | Train Accurancy:  0.9236727505922318 | Validation Accurancy:  0.9119637086987495\n",
      "Epoch:  4924 | Train Accurancy:  0.9236755892634392 | Validation Accurancy:  0.9119727239012718\n",
      "Epoch:  4925 | Train Accurancy:  0.9236784875392914 | Validation Accurancy:  0.9119818434119225\n",
      "Epoch:  4926 | Train Accurancy:  0.9236813560128212 | Validation Accurancy:  0.9119908660650253\n",
      "Epoch:  4927 | Train Accurancy:  0.9236842691898346 | Validation Accurancy:  0.9120011553168297\n",
      "Epoch:  4928 | Train Accurancy:  0.9236871004104614 | Validation Accurancy:  0.912009984254837\n",
      "Epoch:  4929 | Train Accurancy:  0.923690028488636 | Validation Accurancy:  0.9120187535881996\n",
      "Epoch:  4930 | Train Accurancy:  0.9236929416656494 | Validation Accurancy:  0.9120276868343353\n",
      "Epoch:  4931 | Train Accurancy:  0.9236957877874374 | Validation Accurancy:  0.9120365157723427\n",
      "Epoch:  4932 | Train Accurancy:  0.9236986860632896 | Validation Accurancy:  0.9120455756783485\n",
      "Epoch:  4933 | Train Accurancy:  0.9237015470862389 | Validation Accurancy:  0.9120545610785484\n",
      "Epoch:  4934 | Train Accurancy:  0.9237044528126717 | Validation Accurancy:  0.9120635613799095\n",
      "Epoch:  4935 | Train Accurancy:  0.9237072542309761 | Validation Accurancy:  0.9120726585388184\n",
      "Epoch:  4936 | Train Accurancy:  0.9237102046608925 | Validation Accurancy:  0.9120816215872765\n",
      "Epoch:  4937 | Train Accurancy:  0.9237130731344223 | Validation Accurancy:  0.9120907038450241\n",
      "Epoch:  4938 | Train Accurancy:  0.9237159267067909 | Validation Accurancy:  0.9120997190475464\n",
      "Epoch:  4939 | Train Accurancy:  0.9237188100814819 | Validation Accurancy:  0.9121086597442627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4940 | Train Accurancy:  0.9237216636538506 | Validation Accurancy:  0.9121176674962044\n",
      "Epoch:  4941 | Train Accurancy:  0.9237245246767998 | Validation Accurancy:  0.9121266901493073\n",
      "Epoch:  4942 | Train Accurancy:  0.9237273707985878 | Validation Accurancy:  0.9121358022093773\n",
      "Epoch:  4943 | Train Accurancy:  0.9237302839756012 | Validation Accurancy:  0.9121447950601578\n",
      "Epoch:  4944 | Train Accurancy:  0.9237331077456474 | Validation Accurancy:  0.9121537283062935\n",
      "Epoch:  4945 | Train Accurancy:  0.9237359911203384 | Validation Accurancy:  0.9121628627181053\n",
      "Epoch:  4946 | Train Accurancy:  0.9237388223409653 | Validation Accurancy:  0.9121717885136604\n",
      "Epoch:  4947 | Train Accurancy:  0.9237417057156563 | Validation Accurancy:  0.9121809303760529\n",
      "Epoch:  4948 | Train Accurancy:  0.9237445890903473 | Validation Accurancy:  0.9121898859739304\n",
      "Epoch:  4949 | Train Accurancy:  0.9237474650144577 | Validation Accurancy:  0.9121989458799362\n",
      "Epoch:  4950 | Train Accurancy:  0.9237502664327621 | Validation Accurancy:  0.9122079461812973\n",
      "Epoch:  4951 | Train Accurancy:  0.9237531498074532 | Validation Accurancy:  0.912216916680336\n",
      "Epoch:  4952 | Train Accurancy:  0.9237559959292412 | Validation Accurancy:  0.9122259765863419\n",
      "Epoch:  4953 | Train Accurancy:  0.9237588793039322 | Validation Accurancy:  0.9122349247336388\n",
      "Epoch:  4954 | Train Accurancy:  0.9237616583704948 | Validation Accurancy:  0.9122438281774521\n",
      "Epoch:  4955 | Train Accurancy:  0.9237645342946053 | Validation Accurancy:  0.9122529029846191\n",
      "Epoch:  4956 | Train Accurancy:  0.9237673953175545 | Validation Accurancy:  0.9122618287801743\n",
      "Epoch:  4957 | Train Accurancy:  0.9237702116370201 | Validation Accurancy:  0.9122708514332771\n",
      "Epoch:  4958 | Train Accurancy:  0.9237730801105499 | Validation Accurancy:  0.9122798070311546\n",
      "Epoch:  4959 | Train Accurancy:  0.923775926232338 | Validation Accurancy:  0.9122888967394829\n",
      "Epoch:  4960 | Train Accurancy:  0.9237788021564484 | Validation Accurancy:  0.9122978001832962\n",
      "Epoch:  4961 | Train Accurancy:  0.9237816259264946 | Validation Accurancy:  0.9123067781329155\n",
      "Epoch:  4962 | Train Accurancy:  0.923784464597702 | Validation Accurancy:  0.912315659224987\n",
      "Epoch:  4963 | Train Accurancy:  0.9237872883677483 | Validation Accurancy:  0.9123247340321541\n",
      "Epoch:  4964 | Train Accurancy:  0.9237901270389557 | Validation Accurancy:  0.9123335927724838\n",
      "Epoch:  4965 | Train Accurancy:  0.9237929880619049 | Validation Accurancy:  0.9123427867889404\n",
      "Epoch:  4966 | Train Accurancy:  0.92379579693079 | Validation Accurancy:  0.9123516827821732\n",
      "Epoch:  4967 | Train Accurancy:  0.9237986728549004 | Validation Accurancy:  0.9123606160283089\n",
      "Epoch:  4968 | Train Accurancy:  0.9238014370203018 | Validation Accurancy:  0.91236961632967\n",
      "Epoch:  4969 | Train Accurancy:  0.9238043203949928 | Validation Accurancy:  0.912378579378128\n",
      "Epoch:  4970 | Train Accurancy:  0.9238071441650391 | Validation Accurancy:  0.9123874753713608\n",
      "Epoch:  4971 | Train Accurancy:  0.9238100051879883 | Validation Accurancy:  0.9123964235186577\n",
      "Epoch:  4972 | Train Accurancy:  0.9238128438591957 | Validation Accurancy:  0.9124053940176964\n",
      "Epoch:  4973 | Train Accurancy:  0.9238156378269196 | Validation Accurancy:  0.9124143570661545\n",
      "Epoch:  4974 | Train Accurancy:  0.9238184690475464 | Validation Accurancy:  0.9124231487512589\n",
      "Epoch:  4975 | Train Accurancy:  0.923821285367012 | Validation Accurancy:  0.9124322980642319\n",
      "Epoch:  4976 | Train Accurancy:  0.9238240867853165 | Validation Accurancy:  0.9124411717057228\n",
      "Epoch:  4977 | Train Accurancy:  0.9238269403576851 | Validation Accurancy:  0.9124500975012779\n",
      "Epoch:  4978 | Train Accurancy:  0.9238297268748283 | Validation Accurancy:  0.9124590381979942\n",
      "Epoch:  4979 | Train Accurancy:  0.9238325506448746 | Validation Accurancy:  0.9124679267406464\n",
      "Epoch:  4980 | Train Accurancy:  0.9238353446125984 | Validation Accurancy:  0.9124769121408463\n",
      "Epoch:  4981 | Train Accurancy:  0.9238381907343864 | Validation Accurancy:  0.9124858304858208\n",
      "Epoch:  4982 | Train Accurancy:  0.9238409996032715 | Validation Accurancy:  0.9124947786331177\n",
      "Epoch:  4983 | Train Accurancy:  0.9238437935709953 | Validation Accurancy:  0.9125036895275116\n",
      "Epoch:  4984 | Train Accurancy:  0.9238466173410416 | Validation Accurancy:  0.9125125557184219\n",
      "Epoch:  4985 | Train Accurancy:  0.9238494336605072 | Validation Accurancy:  0.9125214889645576\n",
      "Epoch:  4986 | Train Accurancy:  0.9238522872328758 | Validation Accurancy:  0.9125304147601128\n",
      "Epoch:  4987 | Train Accurancy:  0.9238550662994385 | Validation Accurancy:  0.9125392809510231\n",
      "Epoch:  4988 | Train Accurancy:  0.9238578826189041 | Validation Accurancy:  0.9125481024384499\n",
      "Epoch:  4989 | Train Accurancy:  0.9238606616854668 | Validation Accurancy:  0.9125570952892303\n",
      "Epoch:  4990 | Train Accurancy:  0.9238634780049324 | Validation Accurancy:  0.9125660732388496\n",
      "Epoch:  4991 | Train Accurancy:  0.9238662794232368 | Validation Accurancy:  0.9125749841332436\n",
      "Epoch:  4992 | Train Accurancy:  0.9238690882921219 | Validation Accurancy:  0.9125838950276375\n",
      "Epoch:  4993 | Train Accurancy:  0.9238718822598457 | Validation Accurancy:  0.912592701613903\n",
      "Epoch:  4994 | Train Accurancy:  0.9238746985793114 | Validation Accurancy:  0.9126017093658447\n",
      "Epoch:  4995 | Train Accurancy:  0.923877514898777 | Validation Accurancy:  0.9126105010509491\n",
      "Epoch:  4996 | Train Accurancy:  0.9238802567124367 | Validation Accurancy:  0.9126195013523102\n",
      "Epoch:  4997 | Train Accurancy:  0.9238830804824829 | Validation Accurancy:  0.9126282408833504\n",
      "Epoch:  4998 | Train Accurancy:  0.9238858669996262 | Validation Accurancy:  0.9126371368765831\n",
      "Epoch:  4999 | Train Accurancy:  0.9238886907696724 | Validation Accurancy:  0.9126460328698158\n",
      "Epoch:  5000 | Train Accurancy:  0.9238914623856544 | Validation Accurancy:  0.9126548618078232\n",
      "Epoch:  5001 | Train Accurancy:  0.9238942414522171 | Validation Accurancy:  0.9126637130975723\n",
      "Epoch:  5002 | Train Accurancy:  0.9238970652222633 | Validation Accurancy:  0.9126726537942886\n",
      "Epoch:  5003 | Train Accurancy:  0.923899844288826 | Validation Accurancy:  0.9126814529299736\n",
      "Epoch:  5004 | Train Accurancy:  0.9239026382565498 | Validation Accurancy:  0.9126903712749481\n",
      "Epoch:  5005 | Train Accurancy:  0.9239054098725319 | Validation Accurancy:  0.9126992747187614\n",
      "Epoch:  5006 | Train Accurancy:  0.9239081963896751 | Validation Accurancy:  0.91270811855793\n",
      "Epoch:  5007 | Train Accurancy:  0.923910990357399 | Validation Accurancy:  0.9127168953418732\n",
      "Epoch:  5008 | Train Accurancy:  0.923913761973381 | Validation Accurancy:  0.9127258211374283\n",
      "Epoch:  5009 | Train Accurancy:  0.9239165037870407 | Validation Accurancy:  0.9127347022294998\n",
      "Epoch:  5010 | Train Accurancy:  0.923919327557087 | Validation Accurancy:  0.91274344176054\n",
      "Epoch:  5011 | Train Accurancy:  0.923922099173069 | Validation Accurancy:  0.9127523452043533\n",
      "Epoch:  5012 | Train Accurancy:  0.9239248782396317 | Validation Accurancy:  0.9127612337470055\n",
      "Epoch:  5013 | Train Accurancy:  0.9239276349544525 | Validation Accurancy:  0.9127699658274651\n",
      "Epoch:  5014 | Train Accurancy:  0.9239304140210152 | Validation Accurancy:  0.9127788245677948\n",
      "Epoch:  5015 | Train Accurancy:  0.9239331781864166 | Validation Accurancy:  0.9127877801656723\n",
      "Epoch:  5016 | Train Accurancy:  0.9239359870553017 | Validation Accurancy:  0.9127965942025185\n",
      "Epoch:  5017 | Train Accurancy:  0.9239387437701225 | Validation Accurancy:  0.9128053262829781\n",
      "Epoch:  5018 | Train Accurancy:  0.9239415153861046 | Validation Accurancy:  0.9128141850233078\n",
      "Epoch:  5019 | Train Accurancy:  0.9239443019032478 | Validation Accurancy:  0.9128229841589928\n",
      "Epoch:  5020 | Train Accurancy:  0.9239470586180687 | Validation Accurancy:  0.9128318503499031\n",
      "Epoch:  5021 | Train Accurancy:  0.923949807882309 | Validation Accurancy:  0.9128406718373299\n",
      "Epoch:  5022 | Train Accurancy:  0.9239525943994522 | Validation Accurancy:  0.9128494933247566\n",
      "Epoch:  5023 | Train Accurancy:  0.9239553511142731 | Validation Accurancy:  0.9128584042191505\n",
      "Epoch:  5024 | Train Accurancy:  0.9239580854773521 | Validation Accurancy:  0.9128671586513519\n",
      "Epoch:  5025 | Train Accurancy:  0.9239608719944954 | Validation Accurancy:  0.9128759577870369\n",
      "Epoch:  5026 | Train Accurancy:  0.9239636212587357 | Validation Accurancy:  0.9128847122192383\n",
      "Epoch:  5027 | Train Accurancy:  0.9239664152264595 | Validation Accurancy:  0.9128933772444725\n",
      "Epoch:  5028 | Train Accurancy:  0.9239691346883774 | Validation Accurancy:  0.9129023104906082\n",
      "Epoch:  5029 | Train Accurancy:  0.9239719063043594 | Validation Accurancy:  0.912911094725132\n",
      "Epoch:  5030 | Train Accurancy:  0.9239746630191803 | Validation Accurancy:  0.9129197672009468\n",
      "Epoch:  5031 | Train Accurancy:  0.9239774122834206 | Validation Accurancy:  0.91292854398489\n",
      "Epoch:  5032 | Train Accurancy:  0.9239801913499832 | Validation Accurancy:  0.9129374250769615\n",
      "Epoch:  5033 | Train Accurancy:  0.9239829257130623 | Validation Accurancy:  0.9129462093114853\n",
      "Epoch:  5034 | Train Accurancy:  0.9239856973290443 | Validation Accurancy:  0.9129548966884613\n",
      "Epoch:  5035 | Train Accurancy:  0.9239884316921234 | Validation Accurancy:  0.9129638448357582\n",
      "Epoch:  5036 | Train Accurancy:  0.9239911660552025 | Validation Accurancy:  0.9129725992679596\n",
      "Epoch:  5037 | Train Accurancy:  0.9239939004182816 | Validation Accurancy:  0.9129813611507416\n",
      "Epoch:  5038 | Train Accurancy:  0.923996664583683 | Validation Accurancy:  0.9129901081323624\n",
      "Epoch:  5039 | Train Accurancy:  0.9239994063973427 | Validation Accurancy:  0.9129989296197891\n",
      "Epoch:  5040 | Train Accurancy:  0.9240021482110023 | Validation Accurancy:  0.9130077287554741\n",
      "Epoch:  5041 | Train Accurancy:  0.9240048602223396 | Validation Accurancy:  0.9130163937807083\n",
      "Epoch:  5042 | Train Accurancy:  0.9240076020359993 | Validation Accurancy:  0.9130252078175545\n",
      "Epoch:  5043 | Train Accurancy:  0.9240103662014008 | Validation Accurancy:  0.9130338653922081\n",
      "Epoch:  5044 | Train Accurancy:  0.9240131005644798 | Validation Accurancy:  0.9130427986383438\n",
      "Epoch:  5045 | Train Accurancy:  0.9240158498287201 | Validation Accurancy:  0.913051500916481\n",
      "Epoch:  5046 | Train Accurancy:  0.9240185543894768 | Validation Accurancy:  0.9130601659417152\n",
      "Epoch:  5047 | Train Accurancy:  0.9240213111042976 | Validation Accurancy:  0.9130690544843674\n",
      "Epoch:  5048 | Train Accurancy:  0.9240240603685379 | Validation Accurancy:  0.9130777195096016\n",
      "Epoch:  5049 | Train Accurancy:  0.9240267723798752 | Validation Accurancy:  0.9130864590406418\n",
      "Epoch:  5050 | Train Accurancy:  0.9240294918417931 | Validation Accurancy:  0.9130951687693596\n",
      "Epoch:  5051 | Train Accurancy:  0.9240322560071945 | Validation Accurancy:  0.9131040126085281\n",
      "Epoch:  5052 | Train Accurancy:  0.92403494566679 | Validation Accurancy:  0.913112685084343\n",
      "Epoch:  5053 | Train Accurancy:  0.9240376800298691 | Validation Accurancy:  0.9131214842200279\n",
      "Epoch:  5054 | Train Accurancy:  0.9240404143929482 | Validation Accurancy:  0.9131302908062935\n",
      "Epoch:  5055 | Train Accurancy:  0.924043171107769 | Validation Accurancy:  0.9131389334797859\n",
      "Epoch:  5056 | Train Accurancy:  0.9240458905696869 | Validation Accurancy:  0.9131477102637291\n",
      "Epoch:  5057 | Train Accurancy:  0.92404855042696 | Validation Accurancy:  0.9131564050912857\n",
      "Epoch:  5058 | Train Accurancy:  0.924051322042942 | Validation Accurancy:  0.9131650179624557\n",
      "Epoch:  5059 | Train Accurancy:  0.9240540564060211 | Validation Accurancy:  0.9131737798452377\n",
      "Epoch:  5060 | Train Accurancy:  0.9240567982196808 | Validation Accurancy:  0.9131825044751167\n",
      "Epoch:  5061 | Train Accurancy:  0.9240594655275345 | Validation Accurancy:  0.9131911993026733\n",
      "Epoch:  5062 | Train Accurancy:  0.9240622222423553 | Validation Accurancy:  0.9131999388337135\n",
      "Epoch:  5063 | Train Accurancy:  0.924064926803112 | Validation Accurancy:  0.9132087677717209\n",
      "Epoch:  5064 | Train Accurancy:  0.9240676239132881 | Validation Accurancy:  0.9132174327969551\n",
      "Epoch:  5065 | Train Accurancy:  0.9240703284740448 | Validation Accurancy:  0.9132261052727699\n",
      "Epoch:  5066 | Train Accurancy:  0.9240730255842209 | Validation Accurancy:  0.9132348522543907\n",
      "Epoch:  5067 | Train Accurancy:  0.9240757375955582 | Validation Accurancy:  0.9132435545325279\n",
      "Epoch:  5068 | Train Accurancy:  0.924078457057476 | Validation Accurancy:  0.9132522568106651\n",
      "Epoch:  5069 | Train Accurancy:  0.9240811541676521 | Validation Accurancy:  0.9132609739899635\n",
      "Epoch:  5070 | Train Accurancy:  0.9240839034318924 | Validation Accurancy:  0.913269653916359\n",
      "Epoch:  5071 | Train Accurancy:  0.9240865707397461 | Validation Accurancy:  0.9132783487439156\n",
      "Epoch:  5072 | Train Accurancy:  0.924089290201664 | Validation Accurancy:  0.913286991417408\n",
      "Epoch:  5073 | Train Accurancy:  0.9240919798612595 | Validation Accurancy:  0.9132956564426422\n",
      "Epoch:  5074 | Train Accurancy:  0.9240946769714355 | Validation Accurancy:  0.9133044183254242\n",
      "Epoch:  5075 | Train Accurancy:  0.9240974187850952 | Validation Accurancy:  0.9133130609989166\n",
      "Epoch:  5076 | Train Accurancy:  0.9241001084446907 | Validation Accurancy:  0.9133217260241508\n",
      "Epoch:  5077 | Train Accurancy:  0.9241027683019638 | Validation Accurancy:  0.9133304357528687\n",
      "Epoch:  5078 | Train Accurancy:  0.9241054803133011 | Validation Accurancy:  0.9133391678333282\n",
      "Epoch:  5079 | Train Accurancy:  0.9241081550717354 | Validation Accurancy:  0.9133478552103043\n",
      "Epoch:  5080 | Train Accurancy:  0.9241108596324921 | Validation Accurancy:  0.9133564308285713\n",
      "Epoch:  5081 | Train Accurancy:  0.9241136014461517 | Validation Accurancy:  0.9133652225136757\n",
      "Epoch:  5082 | Train Accurancy:  0.9241162538528442 | Validation Accurancy:  0.913373775780201\n",
      "Epoch:  5083 | Train Accurancy:  0.9241189807653427 | Validation Accurancy:  0.9133823812007904\n",
      "Epoch:  5084 | Train Accurancy:  0.9241216257214546 | Validation Accurancy:  0.9133911281824112\n",
      "Epoch:  5085 | Train Accurancy:  0.9241243451833725 | Validation Accurancy:  0.913399837911129\n",
      "Epoch:  5086 | Train Accurancy:  0.9241270273923874 | Validation Accurancy:  0.9134083986282349\n",
      "Epoch:  5087 | Train Accurancy:  0.9241296425461769 | Validation Accurancy:  0.9134169667959213\n",
      "Epoch:  5088 | Train Accurancy:  0.9241323694586754 | Validation Accurancy:  0.9134257063269615\n",
      "Epoch:  5089 | Train Accurancy:  0.9241350814700127 | Validation Accurancy:  0.913434274494648\n",
      "Epoch:  5090 | Train Accurancy:  0.9241377636790276 | Validation Accurancy:  0.9134429395198822\n",
      "Epoch:  5091 | Train Accurancy:  0.9241404458880424 | Validation Accurancy:  0.9134516790509224\n",
      "Epoch:  5092 | Train Accurancy:  0.924143098294735 | Validation Accurancy:  0.9134602919220924\n",
      "Epoch:  5093 | Train Accurancy:  0.9241457879543304 | Validation Accurancy:  0.9134689718484879\n",
      "Epoch:  5094 | Train Accurancy:  0.9241485074162483 | Validation Accurancy:  0.9134775623679161\n",
      "Epoch:  5095 | Train Accurancy:  0.9241511449217796 | Validation Accurancy:  0.913486160337925\n",
      "Epoch:  5096 | Train Accurancy:  0.9241537973284721 | Validation Accurancy:  0.9134948253631592\n",
      "Epoch:  5097 | Train Accurancy:  0.9241565391421318 | Validation Accurancy:  0.9135033413767815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5098 | Train Accurancy:  0.9241591915488243 | Validation Accurancy:  0.9135120287537575\n",
      "Epoch:  5099 | Train Accurancy:  0.9241618290543556 | Validation Accurancy:  0.9135204628109932\n",
      "Epoch:  5100 | Train Accurancy:  0.9241645261645317 | Validation Accurancy:  0.9135292544960976\n",
      "Epoch:  5101 | Train Accurancy:  0.9241671785712242 | Validation Accurancy:  0.9135377928614616\n",
      "Epoch:  5102 | Train Accurancy:  0.9241698905825615 | Validation Accurancy:  0.9135464057326317\n",
      "Epoch:  5103 | Train Accurancy:  0.9241725355386734 | Validation Accurancy:  0.9135549813508987\n",
      "Epoch:  5104 | Train Accurancy:  0.9241751879453659 | Validation Accurancy:  0.9135636761784554\n",
      "Epoch:  5105 | Train Accurancy:  0.9241778701543808 | Validation Accurancy:  0.9135722443461418\n",
      "Epoch:  5106 | Train Accurancy:  0.9241804555058479 | Validation Accurancy:  0.9135807827115059\n",
      "Epoch:  5107 | Train Accurancy:  0.9241831749677658 | Validation Accurancy:  0.9135894104838371\n",
      "Epoch:  5108 | Train Accurancy:  0.9241858348250389 | Validation Accurancy:  0.9135980606079102\n",
      "Epoch:  5109 | Train Accurancy:  0.9241884872317314 | Validation Accurancy:  0.9136066734790802\n",
      "Epoch:  5110 | Train Accurancy:  0.9241911694407463 | Validation Accurancy:  0.9136153534054756\n",
      "Epoch:  5111 | Train Accurancy:  0.924193762242794 | Validation Accurancy:  0.9136238247156143\n",
      "Epoch:  5112 | Train Accurancy:  0.9241964966058731 | Validation Accurancy:  0.9136325046420097\n",
      "Epoch:  5113 | Train Accurancy:  0.9241991117596626 | Validation Accurancy:  0.9136409312486649\n",
      "Epoch:  5114 | Train Accurancy:  0.9242017716169357 | Validation Accurancy:  0.9136496260762215\n",
      "Epoch:  5115 | Train Accurancy:  0.9242044314742088 | Validation Accurancy:  0.9136580899357796\n",
      "Epoch:  5116 | Train Accurancy:  0.924207054078579 | Validation Accurancy:  0.9136667773127556\n",
      "Epoch:  5117 | Train Accurancy:  0.9242097586393356 | Validation Accurancy:  0.9136753752827644\n",
      "Epoch:  5118 | Train Accurancy:  0.9242124035954475 | Validation Accurancy:  0.9136839434504509\n",
      "Epoch:  5119 | Train Accurancy:  0.9242150411009789 | Validation Accurancy:  0.9136923998594284\n",
      "Epoch:  5120 | Train Accurancy:  0.9242176711559296 | Validation Accurancy:  0.9137010648846626\n",
      "Epoch:  5121 | Train Accurancy:  0.9242203757166862 | Validation Accurancy:  0.9137096852064133\n",
      "Epoch:  5122 | Train Accurancy:  0.9242229759693146 | Validation Accurancy:  0.9137182012200356\n",
      "Epoch:  5123 | Train Accurancy:  0.9242256358265877 | Validation Accurancy:  0.9137267991900444\n",
      "Epoch:  5124 | Train Accurancy:  0.9242282584309578 | Validation Accurancy:  0.9137353077530861\n",
      "Epoch:  5125 | Train Accurancy:  0.9242309331893921 | Validation Accurancy:  0.9137439280748367\n",
      "Epoch:  5126 | Train Accurancy:  0.9242335557937622 | Validation Accurancy:  0.913752444088459\n",
      "Epoch:  5127 | Train Accurancy:  0.9242361932992935 | Validation Accurancy:  0.9137611538171768\n",
      "Epoch:  5128 | Train Accurancy:  0.9242388010025024 | Validation Accurancy:  0.9137696325778961\n",
      "Epoch:  5129 | Train Accurancy:  0.924241453409195 | Validation Accurancy:  0.9137780517339706\n",
      "Epoch:  5130 | Train Accurancy:  0.9242440685629845 | Validation Accurancy:  0.9137866050004959\n",
      "Epoch:  5131 | Train Accurancy:  0.924246720969677 | Validation Accurancy:  0.9137952029705048\n",
      "Epoch:  5132 | Train Accurancy:  0.9242493733763695 | Validation Accurancy:  0.913803867995739\n",
      "Epoch:  5133 | Train Accurancy:  0.9242519661784172 | Validation Accurancy:  0.9138122498989105\n",
      "Epoch:  5134 | Train Accurancy:  0.9242546409368515 | Validation Accurancy:  0.9138208702206612\n",
      "Epoch:  5135 | Train Accurancy:  0.9242572858929634 | Validation Accurancy:  0.9138293713331223\n",
      "Epoch:  5136 | Train Accurancy:  0.9242599159479141 | Validation Accurancy:  0.9138378202915192\n",
      "Epoch:  5137 | Train Accurancy:  0.9242625012993813 | Validation Accurancy:  0.9138464480638504\n",
      "Epoch:  5138 | Train Accurancy:  0.9242651462554932 | Validation Accurancy:  0.9138548821210861\n",
      "Epoch:  5139 | Train Accurancy:  0.9242677837610245 | Validation Accurancy:  0.9138634577393532\n",
      "Epoch:  5140 | Train Accurancy:  0.9242704063653946 | Validation Accurancy:  0.9138719663023949\n",
      "Epoch:  5141 | Train Accurancy:  0.9242730215191841 | Validation Accurancy:  0.9138805344700813\n",
      "Epoch:  5142 | Train Accurancy:  0.9242756217718124 | Validation Accurancy:  0.9138890504837036\n",
      "Epoch:  5143 | Train Accurancy:  0.9242782294750214 | Validation Accurancy:  0.9138975962996483\n",
      "Epoch:  5144 | Train Accurancy:  0.9242808446288109 | Validation Accurancy:  0.9139060154557228\n",
      "Epoch:  5145 | Train Accurancy:  0.9242834895849228 | Validation Accurancy:  0.9139145165681839\n",
      "Epoch:  5146 | Train Accurancy:  0.9242861345410347 | Validation Accurancy:  0.9139230325818062\n",
      "Epoch:  5147 | Train Accurancy:  0.9242887049913406 | Validation Accurancy:  0.9139316082000732\n",
      "Epoch:  5148 | Train Accurancy:  0.9242913573980331 | Validation Accurancy:  0.913940079510212\n",
      "Epoch:  5149 | Train Accurancy:  0.9242939278483391 | Validation Accurancy:  0.9139485731720924\n",
      "Epoch:  5150 | Train Accurancy:  0.9242965951561928 | Validation Accurancy:  0.9139570519328117\n",
      "Epoch:  5151 | Train Accurancy:  0.9242992103099823 | Validation Accurancy:  0.9139655083417892\n",
      "Epoch:  5152 | Train Accurancy:  0.9243018329143524 | Validation Accurancy:  0.9139740914106369\n",
      "Epoch:  5153 | Train Accurancy:  0.9243044033646584 | Validation Accurancy:  0.913982480764389\n",
      "Epoch:  5154 | Train Accurancy:  0.9243069961667061 | Validation Accurancy:  0.9139910265803337\n",
      "Epoch:  5155 | Train Accurancy:  0.9243096262216568 | Validation Accurancy:  0.9139995723962784\n",
      "Epoch:  5156 | Train Accurancy:  0.9243122488260269 | Validation Accurancy:  0.9140080288052559\n",
      "Epoch:  5157 | Train Accurancy:  0.9243148192763329 | Validation Accurancy:  0.914016455411911\n",
      "Epoch:  5158 | Train Accurancy:  0.9243174716830254 | Validation Accurancy:  0.9140249565243721\n",
      "Epoch:  5159 | Train Accurancy:  0.9243200197815895 | Validation Accurancy:  0.9140335023403168\n",
      "Epoch:  5160 | Train Accurancy:  0.9243226200342178 | Validation Accurancy:  0.9140419289469719\n",
      "Epoch:  5161 | Train Accurancy:  0.924325242638588 | Validation Accurancy:  0.9140504747629166\n",
      "Epoch:  5162 | Train Accurancy:  0.9243278205394745 | Validation Accurancy:  0.9140588194131851\n",
      "Epoch:  5163 | Train Accurancy:  0.9243304431438446 | Validation Accurancy:  0.9140672907233238\n",
      "Epoch:  5164 | Train Accurancy:  0.9243330210447311 | Validation Accurancy:  0.9140758141875267\n",
      "Epoch:  5165 | Train Accurancy:  0.9243356361985207 | Validation Accurancy:  0.9140842333436012\n",
      "Epoch:  5166 | Train Accurancy:  0.9243382215499878 | Validation Accurancy:  0.9140926524996758\n",
      "Epoch:  5167 | Train Accurancy:  0.9243408367037773 | Validation Accurancy:  0.9141011610627174\n",
      "Epoch:  5168 | Train Accurancy:  0.9243434220552444 | Validation Accurancy:  0.9141096323728561\n",
      "Epoch:  5169 | Train Accurancy:  0.9243460223078728 | Validation Accurancy:  0.9141180962324142\n",
      "Epoch:  5170 | Train Accurancy:  0.9243486002087593 | Validation Accurancy:  0.9141264706850052\n",
      "Epoch:  5171 | Train Accurancy:  0.9243512079119682 | Validation Accurancy:  0.9141349792480469\n",
      "Epoch:  5172 | Train Accurancy:  0.9243537709116936 | Validation Accurancy:  0.914143405854702\n",
      "Epoch:  5173 | Train Accurancy:  0.9243563488125801 | Validation Accurancy:  0.9141518920660019\n",
      "Epoch:  5174 | Train Accurancy:  0.9243589416146278 | Validation Accurancy:  0.914160281419754\n",
      "Epoch:  5175 | Train Accurancy:  0.9243615493178368 | Validation Accurancy:  0.9141686856746674\n",
      "Epoch:  5176 | Train Accurancy:  0.9243640825152397 | Validation Accurancy:  0.9141770452260971\n",
      "Epoch:  5177 | Train Accurancy:  0.924366682767868 | Validation Accurancy:  0.914185531437397\n",
      "Epoch:  5178 | Train Accurancy:  0.9243692979216576 | Validation Accurancy:  0.9141939356923103\n",
      "Epoch:  5179 | Train Accurancy:  0.9243718907237053 | Validation Accurancy:  0.9142023175954819\n",
      "Epoch:  5180 | Train Accurancy:  0.9243744239211082 | Validation Accurancy:  0.914210744202137\n",
      "Epoch:  5181 | Train Accurancy:  0.9243770316243172 | Validation Accurancy:  0.9142190963029861\n",
      "Epoch:  5182 | Train Accurancy:  0.9243795946240425 | Validation Accurancy:  0.9142275005578995\n",
      "Epoch:  5183 | Train Accurancy:  0.9243821799755096 | Validation Accurancy:  0.9142359495162964\n",
      "Epoch:  5184 | Train Accurancy:  0.924384780228138 | Validation Accurancy:  0.914244256913662\n",
      "Epoch:  5185 | Train Accurancy:  0.9243873059749603 | Validation Accurancy:  0.9142527356743813\n",
      "Epoch:  5186 | Train Accurancy:  0.9243899211287498 | Validation Accurancy:  0.9142610654234886\n",
      "Epoch:  5187 | Train Accurancy:  0.9243924245238304 | Validation Accurancy:  0.9142695367336273\n",
      "Epoch:  5188 | Train Accurancy:  0.9243950173258781 | Validation Accurancy:  0.9142778441309929\n",
      "Epoch:  5189 | Train Accurancy:  0.9243975579738617 | Validation Accurancy:  0.9142862856388092\n",
      "Epoch:  5190 | Train Accurancy:  0.9244002103805542 | Validation Accurancy:  0.9142947718501091\n",
      "Epoch:  5191 | Train Accurancy:  0.9244027361273766 | Validation Accurancy:  0.9143031090497971\n",
      "Epoch:  5192 | Train Accurancy:  0.9244052991271019 | Validation Accurancy:  0.9143115654587746\n",
      "Epoch:  5193 | Train Accurancy:  0.9244079068303108 | Validation Accurancy:  0.9143198430538177\n",
      "Epoch:  5194 | Train Accurancy:  0.9244104400277138 | Validation Accurancy:  0.91432835906744\n",
      "Epoch:  5195 | Train Accurancy:  0.9244129508733749 | Validation Accurancy:  0.9143367186188698\n",
      "Epoch:  5196 | Train Accurancy:  0.9244155138731003 | Validation Accurancy:  0.9143450781702995\n",
      "Epoch:  5197 | Train Accurancy:  0.9244181662797928 | Validation Accurancy:  0.914353497326374\n",
      "Epoch:  5198 | Train Accurancy:  0.924420639872551 | Validation Accurancy:  0.9143619015812874\n",
      "Epoch:  5199 | Train Accurancy:  0.9244232103228569 | Validation Accurancy:  0.9143702909350395\n",
      "Epoch:  5200 | Train Accurancy:  0.924425795674324 | Validation Accurancy:  0.9143786281347275\n",
      "Epoch:  5201 | Train Accurancy:  0.9244283810257912 | Validation Accurancy:  0.9143869802355766\n",
      "Epoch:  5202 | Train Accurancy:  0.9244308993220329 | Validation Accurancy:  0.9143954068422318\n",
      "Epoch:  5203 | Train Accurancy:  0.9244334846735001 | Validation Accurancy:  0.9144037067890167\n",
      "Epoch:  5204 | Train Accurancy:  0.9244359955191612 | Validation Accurancy:  0.9144120961427689\n",
      "Epoch:  5205 | Train Accurancy:  0.924438551068306 | Validation Accurancy:  0.9144204407930374\n",
      "Epoch:  5206 | Train Accurancy:  0.9244410768151283 | Validation Accurancy:  0.9144288450479507\n",
      "Epoch:  5207 | Train Accurancy:  0.9244436845183372 | Validation Accurancy:  0.9144372195005417\n",
      "Epoch:  5208 | Train Accurancy:  0.9244462102651596 | Validation Accurancy:  0.9144456088542938\n",
      "Epoch:  5209 | Train Accurancy:  0.9244487583637238 | Validation Accurancy:  0.9144539013504982\n",
      "Epoch:  5210 | Train Accurancy:  0.9244512990117073 | Validation Accurancy:  0.9144622087478638\n",
      "Epoch:  5211 | Train Accurancy:  0.9244538396596909 | Validation Accurancy:  0.9144705906510353\n",
      "Epoch:  5212 | Train Accurancy:  0.9244563952088356 | Validation Accurancy:  0.914478987455368\n",
      "Epoch:  5213 | Train Accurancy:  0.9244589805603027 | Validation Accurancy:  0.914487361907959\n",
      "Epoch:  5214 | Train Accurancy:  0.9244614541530609 | Validation Accurancy:  0.9144956395030022\n",
      "Epoch:  5215 | Train Accurancy:  0.9244640544056892 | Validation Accurancy:  0.9145040437579155\n",
      "Epoch:  5216 | Train Accurancy:  0.9244665578007698 | Validation Accurancy:  0.9145123213529587\n",
      "Epoch:  5217 | Train Accurancy:  0.924469105899334 | Validation Accurancy:  0.9145206063985825\n",
      "Epoch:  5218 | Train Accurancy:  0.9244716688990593 | Validation Accurancy:  0.914528951048851\n",
      "Epoch:  5219 | Train Accurancy:  0.9244741648435593 | Validation Accurancy:  0.9145372733473778\n",
      "Epoch:  5220 | Train Accurancy:  0.9244766533374786 | Validation Accurancy:  0.9145457297563553\n",
      "Epoch:  5221 | Train Accurancy:  0.9244791939854622 | Validation Accurancy:  0.9145539999008179\n",
      "Epoch:  5222 | Train Accurancy:  0.9244817569851875 | Validation Accurancy:  0.9145623743534088\n",
      "Epoch:  5223 | Train Accurancy:  0.9244842827320099 | Validation Accurancy:  0.9145707413554192\n",
      "Epoch:  5224 | Train Accurancy:  0.9244868382811546 | Validation Accurancy:  0.9145789444446564\n",
      "Epoch:  5225 | Train Accurancy:  0.9244893714785576 | Validation Accurancy:  0.9145872965455055\n",
      "Epoch:  5226 | Train Accurancy:  0.9244918525218964 | Validation Accurancy:  0.9145955666899681\n",
      "Epoch:  5227 | Train Accurancy:  0.9244943708181381 | Validation Accurancy:  0.9146039634943008\n",
      "Epoch:  5228 | Train Accurancy:  0.9244969561696053 | Validation Accurancy:  0.9146122261881828\n",
      "Epoch:  5229 | Train Accurancy:  0.924499437212944 | Validation Accurancy:  0.9146205335855484\n",
      "Epoch:  5230 | Train Accurancy:  0.9245020002126694 | Validation Accurancy:  0.9146288633346558\n",
      "Epoch:  5231 | Train Accurancy:  0.9245044440031052 | Validation Accurancy:  0.9146371781826019\n",
      "Epoch:  5232 | Train Accurancy:  0.9245070368051529 | Validation Accurancy:  0.9146455004811287\n",
      "Epoch:  5233 | Train Accurancy:  0.9245095327496529 | Validation Accurancy:  0.9146538004279137\n",
      "Epoch:  5234 | Train Accurancy:  0.9245120584964752 | Validation Accurancy:  0.9146620184183121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5235 | Train Accurancy:  0.9245145693421364 | Validation Accurancy:  0.9146703705191612\n",
      "Epoch:  5236 | Train Accurancy:  0.9245171248912811 | Validation Accurancy:  0.914678655564785\n",
      "Epoch:  5237 | Train Accurancy:  0.9245196506381035 | Validation Accurancy:  0.9146869033575058\n",
      "Epoch:  5238 | Train Accurancy:  0.9245221614837646 | Validation Accurancy:  0.9146952331066132\n",
      "Epoch:  5239 | Train Accurancy:  0.9245246276259422 | Validation Accurancy:  0.9147035405039787\n",
      "Epoch:  5240 | Train Accurancy:  0.9245271608233452 | Validation Accurancy:  0.9147118106484413\n",
      "Epoch:  5241 | Train Accurancy:  0.9245296865701675 | Validation Accurancy:  0.9147200360894203\n",
      "Epoch:  5242 | Train Accurancy:  0.9245322048664093 | Validation Accurancy:  0.9147282987833023\n",
      "Epoch:  5243 | Train Accurancy:  0.9245347008109093 | Validation Accurancy:  0.9147365763783455\n",
      "Epoch:  5244 | Train Accurancy:  0.9245372116565704 | Validation Accurancy:  0.9147448763251305\n",
      "Epoch:  5245 | Train Accurancy:  0.9245397225022316 | Validation Accurancy:  0.9147531613707542\n",
      "Epoch:  5246 | Train Accurancy:  0.9245422258973122 | Validation Accurancy:  0.9147615060210228\n",
      "Epoch:  5247 | Train Accurancy:  0.9245447441935539 | Validation Accurancy:  0.9147696793079376\n",
      "Epoch:  5248 | Train Accurancy:  0.9245472475886345 | Validation Accurancy:  0.9147779569029808\n",
      "Epoch:  5249 | Train Accurancy:  0.924549788236618 | Validation Accurancy:  0.914786271750927\n",
      "Epoch:  5250 | Train Accurancy:  0.9245522245764732 | Validation Accurancy:  0.9147944077849388\n",
      "Epoch:  5251 | Train Accurancy:  0.9245547726750374 | Validation Accurancy:  0.9148027151823044\n",
      "Epoch:  5252 | Train Accurancy:  0.9245572462677956 | Validation Accurancy:  0.9148109704256058\n",
      "Epoch:  5253 | Train Accurancy:  0.9245597496628761 | Validation Accurancy:  0.9148193076252937\n",
      "Epoch:  5254 | Train Accurancy:  0.9245622381567955 | Validation Accurancy:  0.9148275330662727\n",
      "Epoch:  5255 | Train Accurancy:  0.9245647862553596 | Validation Accurancy:  0.9148357436060905\n",
      "Epoch:  5256 | Train Accurancy:  0.9245672598481178 | Validation Accurancy:  0.9148440212011337\n",
      "Epoch:  5257 | Train Accurancy:  0.9245697408914566 | Validation Accurancy:  0.9148522913455963\n",
      "Epoch:  5258 | Train Accurancy:  0.9245722144842148 | Validation Accurancy:  0.9148605316877365\n",
      "Epoch:  5259 | Train Accurancy:  0.9245747029781342 | Validation Accurancy:  0.9148687645792961\n",
      "Epoch:  5260 | Train Accurancy:  0.9245772063732147 | Validation Accurancy:  0.9148769602179527\n",
      "Epoch:  5261 | Train Accurancy:  0.9245796874165535 | Validation Accurancy:  0.9148852080106735\n",
      "Epoch:  5262 | Train Accurancy:  0.9245821908116341 | Validation Accurancy:  0.9148933961987495\n",
      "Epoch:  5263 | Train Accurancy:  0.9245847091078758 | Validation Accurancy:  0.9149016439914703\n",
      "Epoch:  5264 | Train Accurancy:  0.9245871305465698 | Validation Accurancy:  0.9149099513888359\n",
      "Epoch:  5265 | Train Accurancy:  0.9245897009968758 | Validation Accurancy:  0.9149181023240089\n",
      "Epoch:  5266 | Train Accurancy:  0.9245921745896339 | Validation Accurancy:  0.9149263650178909\n",
      "Epoch:  5267 | Train Accurancy:  0.9245946779847145 | Validation Accurancy:  0.9149346873164177\n",
      "Epoch:  5268 | Train Accurancy:  0.9245971515774727 | Validation Accurancy:  0.9149428457021713\n",
      "Epoch:  5269 | Train Accurancy:  0.9245996177196503 | Validation Accurancy:  0.914950966835022\n",
      "Epoch:  5270 | Train Accurancy:  0.9246020764112473 | Validation Accurancy:  0.9149592220783234\n",
      "Epoch:  5271 | Train Accurancy:  0.924604557454586 | Validation Accurancy:  0.914967343211174\n",
      "Epoch:  5272 | Train Accurancy:  0.9246070608496666 | Validation Accurancy:  0.914975605905056\n",
      "Epoch:  5273 | Train Accurancy:  0.9246095642447472 | Validation Accurancy:  0.9149837642908096\n",
      "Epoch:  5274 | Train Accurancy:  0.9246120154857635 | Validation Accurancy:  0.9149920269846916\n",
      "Epoch:  5275 | Train Accurancy:  0.9246144816279411 | Validation Accurancy:  0.9150001704692841\n",
      "Epoch:  5276 | Train Accurancy:  0.9246169850230217 | Validation Accurancy:  0.9150084182620049\n",
      "Epoch:  5277 | Train Accurancy:  0.9246194437146187 | Validation Accurancy:  0.9150166884064674\n",
      "Epoch:  5278 | Train Accurancy:  0.924621932208538 | Validation Accurancy:  0.9150248244404793\n",
      "Epoch:  5279 | Train Accurancy:  0.9246243610978127 | Validation Accurancy:  0.9150329902768135\n",
      "Epoch:  5280 | Train Accurancy:  0.9246268793940544 | Validation Accurancy:  0.9150411859154701\n",
      "Epoch:  5281 | Train Accurancy:  0.9246293231844902 | Validation Accurancy:  0.9150495231151581\n",
      "Epoch:  5282 | Train Accurancy:  0.9246317818760872 | Validation Accurancy:  0.9150576293468475\n",
      "Epoch:  5283 | Train Accurancy:  0.924634262919426 | Validation Accurancy:  0.91506577283144\n",
      "Epoch:  5284 | Train Accurancy:  0.9246367514133453 | Validation Accurancy:  0.915073998272419\n",
      "Epoch:  5285 | Train Accurancy:  0.9246391952037811 | Validation Accurancy:  0.9150820896029472\n",
      "Epoch:  5286 | Train Accurancy:  0.9246416389942169 | Validation Accurancy:  0.9150903075933456\n",
      "Epoch:  5287 | Train Accurancy:  0.9246441423892975 | Validation Accurancy:  0.9150984808802605\n",
      "Epoch:  5288 | Train Accurancy:  0.9246466085314751 | Validation Accurancy:  0.9151066318154335\n",
      "Epoch:  5289 | Train Accurancy:  0.9246490746736526 | Validation Accurancy:  0.9151147827506065\n",
      "Epoch:  5290 | Train Accurancy:  0.9246515557169914 | Validation Accurancy:  0.915122963488102\n",
      "Epoch:  5291 | Train Accurancy:  0.9246539399027824 | Validation Accurancy:  0.9151311218738556\n",
      "Epoch:  5292 | Train Accurancy:  0.924656443297863 | Validation Accurancy:  0.9151393249630928\n",
      "Epoch:  5293 | Train Accurancy:  0.9246588870882988 | Validation Accurancy:  0.91514752805233\n",
      "Epoch:  5294 | Train Accurancy:  0.9246614053845406 | Validation Accurancy:  0.9151556938886642\n",
      "Epoch:  5295 | Train Accurancy:  0.9246638044714928 | Validation Accurancy:  0.9151638522744179\n",
      "Epoch:  5296 | Train Accurancy:  0.9246663004159927 | Validation Accurancy:  0.9151719883084297\n",
      "Epoch:  5297 | Train Accurancy:  0.9246687144041061 | Validation Accurancy:  0.9151800870895386\n",
      "Epoch:  5298 | Train Accurancy:  0.9246711730957031 | Validation Accurancy:  0.9151882752776146\n",
      "Epoch:  5299 | Train Accurancy:  0.9246736466884613 | Validation Accurancy:  0.9151964113116264\n",
      "Epoch:  5300 | Train Accurancy:  0.9246761128306389 | Validation Accurancy:  0.9152046665549278\n",
      "Epoch:  5301 | Train Accurancy:  0.9246785715222359 | Validation Accurancy:  0.9152127206325531\n",
      "Epoch:  5302 | Train Accurancy:  0.9246809929609299 | Validation Accurancy:  0.9152209013700485\n",
      "Epoch:  5303 | Train Accurancy:  0.9246834143996239 | Validation Accurancy:  0.9152289554476738\n",
      "Epoch:  5304 | Train Accurancy:  0.9246859028935432 | Validation Accurancy:  0.9152371138334274\n",
      "Epoch:  5305 | Train Accurancy:  0.9246883019804955 | Validation Accurancy:  0.9152452498674393\n",
      "Epoch:  5306 | Train Accurancy:  0.9246907457709312 | Validation Accurancy:  0.9152533784508705\n",
      "Epoch:  5307 | Train Accurancy:  0.9246932044625282 | Validation Accurancy:  0.915261521935463\n",
      "Epoch:  5308 | Train Accurancy:  0.9246956333518028 | Validation Accurancy:  0.9152697250247002\n",
      "Epoch:  5309 | Train Accurancy:  0.9246981367468834 | Validation Accurancy:  0.9152777940034866\n",
      "Epoch:  5310 | Train Accurancy:  0.9247004836797714 | Validation Accurancy:  0.9152859449386597\n",
      "Epoch:  5311 | Train Accurancy:  0.9247029796242714 | Validation Accurancy:  0.9152940735220909\n",
      "Epoch:  5312 | Train Accurancy:  0.9247053861618042 | Validation Accurancy:  0.9153021648526192\n",
      "Epoch:  5313 | Train Accurancy:  0.9247079193592072 | Validation Accurancy:  0.9153102710843086\n",
      "Epoch:  5314 | Train Accurancy:  0.9247102662920952 | Validation Accurancy:  0.9153184071183205\n",
      "Epoch:  5315 | Train Accurancy:  0.9247127547860146 | Validation Accurancy:  0.9153264537453651\n",
      "Epoch:  5316 | Train Accurancy:  0.9247151762247086 | Validation Accurancy:  0.915334515273571\n",
      "Epoch:  5317 | Train Accurancy:  0.924717627465725 | Validation Accurancy:  0.9153427705168724\n",
      "Epoch:  5318 | Train Accurancy:  0.9247200638055801 | Validation Accurancy:  0.9153507575392723\n",
      "Epoch:  5319 | Train Accurancy:  0.9247225150465965 | Validation Accurancy:  0.9153589233756065\n",
      "Epoch:  5320 | Train Accurancy:  0.9247249141335487 | Validation Accurancy:  0.915367029607296\n",
      "Epoch:  5321 | Train Accurancy:  0.9247273430228233 | Validation Accurancy:  0.9153750464320183\n",
      "Epoch:  5322 | Train Accurancy:  0.924729734659195 | Validation Accurancy:  0.9153831675648689\n",
      "Epoch:  5323 | Train Accurancy:  0.9247322380542755 | Validation Accurancy:  0.9153912514448166\n",
      "Epoch:  5324 | Train Accurancy:  0.9247346445918083 | Validation Accurancy:  0.9153993651270866\n",
      "Epoch:  5325 | Train Accurancy:  0.9247370734810829 | Validation Accurancy:  0.9154074341058731\n",
      "Epoch:  5326 | Train Accurancy:  0.9247394949197769 | Validation Accurancy:  0.9154155254364014\n",
      "Epoch:  5327 | Train Accurancy:  0.9247418865561485 | Validation Accurancy:  0.9154237359762192\n",
      "Epoch:  5328 | Train Accurancy:  0.9247443228960037 | Validation Accurancy:  0.9154317453503609\n",
      "Epoch:  5329 | Train Accurancy:  0.9247467368841171 | Validation Accurancy:  0.9154398143291473\n",
      "Epoch:  5330 | Train Accurancy:  0.9247491806745529 | Validation Accurancy:  0.9154479056596756\n",
      "Epoch:  5331 | Train Accurancy:  0.9247516393661499 | Validation Accurancy:  0.9154559820890427\n",
      "Epoch:  5332 | Train Accurancy:  0.9247540310025215 | Validation Accurancy:  0.9154640659689903\n",
      "Epoch:  5333 | Train Accurancy:  0.9247564822435379 | Validation Accurancy:  0.915472075343132\n",
      "Epoch:  5334 | Train Accurancy:  0.9247588217258453 | Validation Accurancy:  0.9154802486300468\n",
      "Epoch:  5335 | Train Accurancy:  0.9247612953186035 | Validation Accurancy:  0.915488213300705\n",
      "Epoch:  5336 | Train Accurancy:  0.9247636720538139 | Validation Accurancy:  0.915496326982975\n",
      "Epoch:  5337 | Train Accurancy:  0.9247660636901855 | Validation Accurancy:  0.9155044108629227\n",
      "Epoch:  5338 | Train Accurancy:  0.9247685521841049 | Validation Accurancy:  0.9155123680830002\n",
      "Epoch:  5339 | Train Accurancy:  0.9247709140181541 | Validation Accurancy:  0.9155205190181732\n",
      "Epoch:  5340 | Train Accurancy:  0.9247733131051064 | Validation Accurancy:  0.9155285134911537\n",
      "Epoch:  5341 | Train Accurancy:  0.9247757494449615 | Validation Accurancy:  0.9155365750193596\n",
      "Epoch:  5342 | Train Accurancy:  0.9247781932353973 | Validation Accurancy:  0.9155446514487267\n",
      "Epoch:  5343 | Train Accurancy:  0.9247806072235107 | Validation Accurancy:  0.9155527055263519\n",
      "Epoch:  5344 | Train Accurancy:  0.9247829914093018 | Validation Accurancy:  0.915560707449913\n",
      "Epoch:  5345 | Train Accurancy:  0.9247853830456734 | Validation Accurancy:  0.9155687540769577\n",
      "Epoch:  5346 | Train Accurancy:  0.924787774682045 | Validation Accurancy:  0.9155768975615501\n",
      "Epoch:  5347 | Train Accurancy:  0.9247901737689972 | Validation Accurancy:  0.9155848696827888\n",
      "Epoch:  5348 | Train Accurancy:  0.924792617559433 | Validation Accurancy:  0.9155929163098335\n",
      "Epoch:  5349 | Train Accurancy:  0.924794964492321 | Validation Accurancy:  0.915600948035717\n",
      "Epoch:  5350 | Train Accurancy:  0.9247973784804344 | Validation Accurancy:  0.9156090095639229\n",
      "Epoch:  5351 | Train Accurancy:  0.9247998148202896 | Validation Accurancy:  0.9156169444322586\n",
      "Epoch:  5352 | Train Accurancy:  0.9248021617531776 | Validation Accurancy:  0.9156249910593033\n",
      "Epoch:  5353 | Train Accurancy:  0.9248045906424522 | Validation Accurancy:  0.9156329929828644\n",
      "Epoch:  5354 | Train Accurancy:  0.9248069748282433 | Validation Accurancy:  0.9156410917639732\n",
      "Epoch:  5355 | Train Accurancy:  0.9248093888163567 | Validation Accurancy:  0.9156491011381149\n",
      "Epoch:  5356 | Train Accurancy:  0.9248117879033089 | Validation Accurancy:  0.9156570956110954\n",
      "Epoch:  5357 | Train Accurancy:  0.9248141869902611 | Validation Accurancy:  0.9156650975346565\n",
      "Epoch:  5358 | Train Accurancy:  0.9248166084289551 | Validation Accurancy:  0.9156731590628624\n",
      "Epoch:  5359 | Train Accurancy:  0.9248189553618431 | Validation Accurancy:  0.9156811386346817\n",
      "Epoch:  5360 | Train Accurancy:  0.9248213320970535 | Validation Accurancy:  0.9156892150640488\n",
      "Epoch:  5361 | Train Accurancy:  0.9248237833380699 | Validation Accurancy:  0.9156971350312233\n",
      "Epoch:  5362 | Train Accurancy:  0.9248261451721191 | Validation Accurancy:  0.9157051891088486\n",
      "Epoch:  5363 | Train Accurancy:  0.9248285368084908 | Validation Accurancy:  0.9157132357358932\n",
      "Epoch:  5364 | Train Accurancy:  0.9248309284448624 | Validation Accurancy:  0.9157212153077126\n",
      "Epoch:  5365 | Train Accurancy:  0.9248332977294922 | Validation Accurancy:  0.9157291874289513\n",
      "Epoch:  5366 | Train Accurancy:  0.9248357117176056 | Validation Accurancy:  0.915737196803093\n",
      "Epoch:  5367 | Train Accurancy:  0.9248380661010742 | Validation Accurancy:  0.9157451540231705\n",
      "Epoch:  5368 | Train Accurancy:  0.9248404279351234 | Validation Accurancy:  0.9157531335949898\n",
      "Epoch:  5369 | Train Accurancy:  0.9248428344726562 | Validation Accurancy:  0.9157610833644867\n",
      "Epoch:  5370 | Train Accurancy:  0.9248452037572861 | Validation Accurancy:  0.915769100189209\n",
      "Epoch:  5371 | Train Accurancy:  0.9248476177453995 | Validation Accurancy:  0.9157770797610283\n",
      "Epoch:  5372 | Train Accurancy:  0.9248499497771263 | Validation Accurancy:  0.9157851412892342\n",
      "Epoch:  5373 | Train Accurancy:  0.9248523488640785 | Validation Accurancy:  0.9157931506633759\n",
      "Epoch:  5374 | Train Accurancy:  0.9248547405004501 | Validation Accurancy:  0.9158011674880981\n",
      "Epoch:  5375 | Train Accurancy:  0.9248570576310158 | Validation Accurancy:  0.9158091023564339\n",
      "Epoch:  5376 | Train Accurancy:  0.9248595014214516 | Validation Accurancy:  0.9158171117305756\n",
      "Epoch:  5377 | Train Accurancy:  0.9248618558049202 | Validation Accurancy:  0.9158250540494919\n",
      "Epoch:  5378 | Train Accurancy:  0.9248642548918724 | Validation Accurancy:  0.9158331155776978\n",
      "Epoch:  5379 | Train Accurancy:  0.924866609275341 | Validation Accurancy:  0.9158410578966141\n",
      "Epoch:  5380 | Train Accurancy:  0.9248689785599709 | Validation Accurancy:  0.9158489480614662\n",
      "Epoch:  5381 | Train Accurancy:  0.924871414899826 | Validation Accurancy:  0.9158569350838661\n",
      "Epoch:  5382 | Train Accurancy:  0.9248737394809723 | Validation Accurancy:  0.9158648550510406\n",
      "Epoch:  5383 | Train Accurancy:  0.9248761087656021 | Validation Accurancy:  0.9158728420734406\n",
      "Epoch:  5384 | Train Accurancy:  0.9248784482479095 | Validation Accurancy:  0.9158807992935181\n",
      "Epoch:  5385 | Train Accurancy:  0.9248808473348618 | Validation Accurancy:  0.9158887192606926\n",
      "Epoch:  5386 | Train Accurancy:  0.9248832538723946 | Validation Accurancy:  0.915896587073803\n",
      "Epoch:  5387 | Train Accurancy:  0.9248856008052826 | Validation Accurancy:  0.9159046113491058\n",
      "Epoch:  5388 | Train Accurancy:  0.9248878955841064 | Validation Accurancy:  0.9159125536680222\n",
      "Epoch:  5389 | Train Accurancy:  0.9248902797698975 | Validation Accurancy:  0.9159204065799713\n",
      "Epoch:  5390 | Train Accurancy:  0.9248926416039467 | Validation Accurancy:  0.9159284308552742\n",
      "Epoch:  5391 | Train Accurancy:  0.9248950332403183 | Validation Accurancy:  0.9159364551305771\n",
      "Epoch:  5392 | Train Accurancy:  0.9248974174261093 | Validation Accurancy:  0.9159444347023964\n",
      "Epoch:  5393 | Train Accurancy:  0.9248997122049332 | Validation Accurancy:  0.9159523621201515\n",
      "Epoch:  5394 | Train Accurancy:  0.9249021336436272 | Validation Accurancy:  0.9159602299332619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5395 | Train Accurancy:  0.9249044805765152 | Validation Accurancy:  0.9159682020545006\n",
      "Epoch:  5396 | Train Accurancy:  0.924906812608242 | Validation Accurancy:  0.9159761220216751\n",
      "Epoch:  5397 | Train Accurancy:  0.9249091446399689 | Validation Accurancy:  0.9159841537475586\n",
      "Epoch:  5398 | Train Accurancy:  0.9249114841222763 | Validation Accurancy:  0.915991947054863\n",
      "Epoch:  5399 | Train Accurancy:  0.9249139055609703 | Validation Accurancy:  0.9159998893737793\n",
      "Epoch:  5400 | Train Accurancy:  0.9249162152409554 | Validation Accurancy:  0.9160078391432762\n",
      "Epoch:  5401 | Train Accurancy:  0.9249185845255852 | Validation Accurancy:  0.9160157218575478\n",
      "Epoch:  5402 | Train Accurancy:  0.9249209091067314 | Validation Accurancy:  0.9160236120223999\n",
      "Epoch:  5403 | Train Accurancy:  0.9249232485890388 | Validation Accurancy:  0.9160315245389938\n",
      "Epoch:  5404 | Train Accurancy:  0.9249255806207657 | Validation Accurancy:  0.9160394296050072\n",
      "Epoch:  5405 | Train Accurancy:  0.9249279648065567 | Validation Accurancy:  0.9160474091768265\n",
      "Epoch:  5406 | Train Accurancy:  0.9249303266406059 | Validation Accurancy:  0.9160553365945816\n",
      "Epoch:  5407 | Train Accurancy:  0.9249326512217522 | Validation Accurancy:  0.9160631373524666\n",
      "Epoch:  5408 | Train Accurancy:  0.924935020506382 | Validation Accurancy:  0.9160711467266083\n",
      "Epoch:  5409 | Train Accurancy:  0.9249373823404312 | Validation Accurancy:  0.9160789921879768\n",
      "Epoch:  5410 | Train Accurancy:  0.9249397441744804 | Validation Accurancy:  0.916086919605732\n",
      "Epoch:  5411 | Train Accurancy:  0.9249420240521431 | Validation Accurancy:  0.9160949066281319\n",
      "Epoch:  5412 | Train Accurancy:  0.9249443858861923 | Validation Accurancy:  0.9161027371883392\n",
      "Epoch:  5413 | Train Accurancy:  0.924946740269661 | Validation Accurancy:  0.9161107018589973\n",
      "Epoch:  5414 | Train Accurancy:  0.924949049949646 | Validation Accurancy:  0.9161185249686241\n",
      "Epoch:  5415 | Train Accurancy:  0.9249514192342758 | Validation Accurancy:  0.916126511991024\n",
      "Epoch:  5416 | Train Accurancy:  0.9249537661671638 | Validation Accurancy:  0.9161342829465866\n",
      "Epoch:  5417 | Train Accurancy:  0.9249560683965683 | Validation Accurancy:  0.9161421805620193\n",
      "Epoch:  5418 | Train Accurancy:  0.9249584004282951 | Validation Accurancy:  0.9161501377820969\n",
      "Epoch:  5419 | Train Accurancy:  0.9249607175588608 | Validation Accurancy:  0.9161579757928848\n",
      "Epoch:  5420 | Train Accurancy:  0.9249631017446518 | Validation Accurancy:  0.9161659255623817\n",
      "Epoch:  5421 | Train Accurancy:  0.9249654114246368 | Validation Accurancy:  0.9161737039685249\n",
      "Epoch:  5422 | Train Accurancy:  0.9249677583575249 | Validation Accurancy:  0.9161816462874413\n",
      "Epoch:  5423 | Train Accurancy:  0.9249700754880905 | Validation Accurancy:  0.9161895513534546\n",
      "Epoch:  5424 | Train Accurancy:  0.9249724075198174 | Validation Accurancy:  0.9161973744630814\n",
      "Epoch:  5425 | Train Accurancy:  0.9249747321009636 | Validation Accurancy:  0.9162052422761917\n",
      "Epoch:  5426 | Train Accurancy:  0.9249770492315292 | Validation Accurancy:  0.9162131026387215\n",
      "Epoch:  5427 | Train Accurancy:  0.9249794110655785 | Validation Accurancy:  0.91622094810009\n",
      "Epoch:  5428 | Train Accurancy:  0.9249817132949829 | Validation Accurancy:  0.916228860616684\n",
      "Epoch:  5429 | Train Accurancy:  0.9249840602278709 | Validation Accurancy:  0.9162367507815361\n",
      "Epoch:  5430 | Train Accurancy:  0.9249863848090172 | Validation Accurancy:  0.9162446036934853\n",
      "Epoch:  5431 | Train Accurancy:  0.9249887391924858 | Validation Accurancy:  0.9162523746490479\n",
      "Epoch:  5432 | Train Accurancy:  0.9249910414218903 | Validation Accurancy:  0.9162603467702866\n",
      "Epoch:  5433 | Train Accurancy:  0.9249933809041977 | Validation Accurancy:  0.9162681251764297\n",
      "Epoch:  5434 | Train Accurancy:  0.924995668232441 | Validation Accurancy:  0.9162760749459267\n",
      "Epoch:  5435 | Train Accurancy:  0.9249979928135872 | Validation Accurancy:  0.9162837713956833\n",
      "Epoch:  5436 | Train Accurancy:  0.925000324845314 | Validation Accurancy:  0.9162917584180832\n",
      "Epoch:  5437 | Train Accurancy:  0.9250026047229767 | Validation Accurancy:  0.9162995144724846\n",
      "Epoch:  5438 | Train Accurancy:  0.9250049367547035 | Validation Accurancy:  0.9163074046373367\n",
      "Epoch:  5439 | Train Accurancy:  0.925007276237011 | Validation Accurancy:  0.9163152202963829\n",
      "Epoch:  5440 | Train Accurancy:  0.9250095710158348 | Validation Accurancy:  0.9163229838013649\n",
      "Epoch:  5441 | Train Accurancy:  0.9250118583440781 | Validation Accurancy:  0.9163309037685394\n",
      "Epoch:  5442 | Train Accurancy:  0.9250142425298691 | Validation Accurancy:  0.9163387194275856\n",
      "Epoch:  5443 | Train Accurancy:  0.9250165224075317 | Validation Accurancy:  0.9163465425372124\n",
      "Epoch:  5444 | Train Accurancy:  0.9250188246369362 | Validation Accurancy:  0.9163543432950974\n",
      "Epoch:  5445 | Train Accurancy:  0.9250211417675018 | Validation Accurancy:  0.9163622558116913\n",
      "Epoch:  5446 | Train Accurancy:  0.9250235185027122 | Validation Accurancy:  0.9163700416684151\n",
      "Epoch:  5447 | Train Accurancy:  0.9250257685780525 | Validation Accurancy:  0.9163778275251389\n",
      "Epoch:  5448 | Train Accurancy:  0.9250280633568764 | Validation Accurancy:  0.916385717689991\n",
      "Epoch:  5449 | Train Accurancy:  0.9250303730368614 | Validation Accurancy:  0.9163936004042625\n",
      "Epoch:  5450 | Train Accurancy:  0.9250327125191689 | Validation Accurancy:  0.9164014309644699\n",
      "Epoch:  5451 | Train Accurancy:  0.9250349849462509 | Validation Accurancy:  0.9164091497659683\n",
      "Epoch:  5452 | Train Accurancy:  0.925037331879139 | Validation Accurancy:  0.9164170026779175\n",
      "Epoch:  5453 | Train Accurancy:  0.9250395968556404 | Validation Accurancy:  0.9164248406887054\n",
      "Epoch:  5454 | Train Accurancy:  0.925041913986206 | Validation Accurancy:  0.9164326414465904\n",
      "Epoch:  5455 | Train Accurancy:  0.9250442236661911 | Validation Accurancy:  0.9164403900504112\n",
      "Epoch:  5456 | Train Accurancy:  0.9250464886426926 | Validation Accurancy:  0.9164482206106186\n",
      "Epoch:  5457 | Train Accurancy:  0.9250488206744194 | Validation Accurancy:  0.9164559841156006\n",
      "Epoch:  5458 | Train Accurancy:  0.9250511303544044 | Validation Accurancy:  0.916463814675808\n",
      "Epoch:  5459 | Train Accurancy:  0.9250533804297447 | Validation Accurancy:  0.9164717346429825\n",
      "Epoch:  5460 | Train Accurancy:  0.925055705010891 | Validation Accurancy:  0.9164794012904167\n",
      "Epoch:  5461 | Train Accurancy:  0.9250580072402954 | Validation Accurancy:  0.9164871647953987\n",
      "Epoch:  5462 | Train Accurancy:  0.9250602722167969 | Validation Accurancy:  0.9164950475096703\n",
      "Epoch:  5463 | Train Accurancy:  0.9250626042485237 | Validation Accurancy:  0.9165028557181358\n",
      "Epoch:  5464 | Train Accurancy:  0.925064891576767 | Validation Accurancy:  0.916510596871376\n",
      "Epoch:  5465 | Train Accurancy:  0.9250671565532684 | Validation Accurancy:  0.9165182784199715\n",
      "Epoch:  5466 | Train Accurancy:  0.9250694513320923 | Validation Accurancy:  0.9165262058377266\n",
      "Epoch:  5467 | Train Accurancy:  0.9250717461109161 | Validation Accurancy:  0.9165339022874832\n",
      "Epoch:  5468 | Train Accurancy:  0.9250740483403206 | Validation Accurancy:  0.9165417179465294\n",
      "Epoch:  5469 | Train Accurancy:  0.9250763356685638 | Validation Accurancy:  0.9165494292974472\n",
      "Epoch:  5470 | Train Accurancy:  0.9250786453485489 | Validation Accurancy:  0.9165572449564934\n",
      "Epoch:  5471 | Train Accurancy:  0.9250809252262115 | Validation Accurancy:  0.9165650308132172\n",
      "Epoch:  5472 | Train Accurancy:  0.9250832051038742 | Validation Accurancy:  0.9165727719664574\n",
      "Epoch:  5473 | Train Accurancy:  0.9250854998826981 | Validation Accurancy:  0.9165805578231812\n",
      "Epoch:  5474 | Train Accurancy:  0.9250877648591995 | Validation Accurancy:  0.9165882840752602\n",
      "Epoch:  5475 | Train Accurancy:  0.9250900596380234 | Validation Accurancy:  0.9165960028767586\n",
      "Epoch:  5476 | Train Accurancy:  0.9250923320651054 | Validation Accurancy:  0.9166039079427719\n",
      "Epoch:  5477 | Train Accurancy:  0.9250946268439293 | Validation Accurancy:  0.9166116863489151\n",
      "Epoch:  5478 | Train Accurancy:  0.9250968992710114 | Validation Accurancy:  0.9166193529963493\n",
      "Epoch:  5479 | Train Accurancy:  0.9250992015004158 | Validation Accurancy:  0.9166270643472672\n",
      "Epoch:  5480 | Train Accurancy:  0.9251014441251755 | Validation Accurancy:  0.9166349694132805\n",
      "Epoch:  5481 | Train Accurancy:  0.9251037091016769 | Validation Accurancy:  0.9166426882147789\n",
      "Epoch:  5482 | Train Accurancy:  0.9251060262322426 | Validation Accurancy:  0.9166504144668579\n",
      "Epoch:  5483 | Train Accurancy:  0.925108291208744 | Validation Accurancy:  0.9166581407189369\n",
      "Epoch:  5484 | Train Accurancy:  0.9251105561852455 | Validation Accurancy:  0.9166659489274025\n",
      "Epoch:  5485 | Train Accurancy:  0.9251127988100052 | Validation Accurancy:  0.9166736602783203\n",
      "Epoch:  5486 | Train Accurancy:  0.9251151159405708 | Validation Accurancy:  0.9166814386844635\n",
      "Epoch:  5487 | Train Accurancy:  0.9251173958182335 | Validation Accurancy:  0.9166891947388649\n",
      "Epoch:  5488 | Train Accurancy:  0.9251196756958961 | Validation Accurancy:  0.9166969060897827\n",
      "Epoch:  5489 | Train Accurancy:  0.9251218810677528 | Validation Accurancy:  0.9167046695947647\n",
      "Epoch:  5490 | Train Accurancy:  0.9251242429018021 | Validation Accurancy:  0.9167123585939407\n",
      "Epoch:  5491 | Train Accurancy:  0.9251264706254005 | Validation Accurancy:  0.9167201668024063\n",
      "Epoch:  5492 | Train Accurancy:  0.9251287281513214 | Validation Accurancy:  0.9167279005050659\n",
      "Epoch:  5493 | Train Accurancy:  0.9251310303807259 | Validation Accurancy:  0.9167354851961136\n",
      "Epoch:  5494 | Train Accurancy:  0.9251332804560661 | Validation Accurancy:  0.9167432710528374\n",
      "Epoch:  5495 | Train Accurancy:  0.9251354932785034 | Validation Accurancy:  0.916751004755497\n",
      "Epoch:  5496 | Train Accurancy:  0.9251378104090691 | Validation Accurancy:  0.9167586639523506\n",
      "Epoch:  5497 | Train Accurancy:  0.9251400455832481 | Validation Accurancy:  0.9167663902044296\n",
      "Epoch:  5498 | Train Accurancy:  0.9251422882080078 | Validation Accurancy:  0.9167742878198624\n",
      "Epoch:  5499 | Train Accurancy:  0.9251445978879929 | Validation Accurancy:  0.9167819246649742\n",
      "Epoch:  5500 | Train Accurancy:  0.9251469001173973 | Validation Accurancy:  0.9167896807193756\n",
      "Epoch:  5501 | Train Accurancy:  0.9251491129398346 | Validation Accurancy:  0.9167973324656487\n",
      "Epoch:  5502 | Train Accurancy:  0.9251513481140137 | Validation Accurancy:  0.9168050736188889\n",
      "Epoch:  5503 | Train Accurancy:  0.9251536130905151 | Validation Accurancy:  0.9168127030134201\n",
      "Epoch:  5504 | Train Accurancy:  0.9251558482646942 | Validation Accurancy:  0.9168205112218857\n",
      "Epoch:  5505 | Train Accurancy:  0.9251581579446793 | Validation Accurancy:  0.9168282002210617\n",
      "Epoch:  5506 | Train Accurancy:  0.9251604229211807 | Validation Accurancy:  0.9168359041213989\n",
      "Epoch:  5507 | Train Accurancy:  0.9251626431941986 | Validation Accurancy:  0.9168436601758003\n",
      "Epoch:  5508 | Train Accurancy:  0.9251649081707001 | Validation Accurancy:  0.9168513268232346\n",
      "Epoch:  5509 | Train Accurancy:  0.9251671805977821 | Validation Accurancy:  0.91685900837183\n",
      "Epoch:  5510 | Train Accurancy:  0.9251693934202194 | Validation Accurancy:  0.9168666079640388\n",
      "Epoch:  5511 | Train Accurancy:  0.9251716583967209 | Validation Accurancy:  0.9168743938207626\n",
      "Epoch:  5512 | Train Accurancy:  0.9251739159226418 | Validation Accurancy:  0.9168819710612297\n",
      "Epoch:  5513 | Train Accurancy:  0.9251761361956596 | Validation Accurancy:  0.9168897122144699\n",
      "Epoch:  5514 | Train Accurancy:  0.9251784160733223 | Validation Accurancy:  0.9168973937630653\n",
      "Epoch:  5515 | Train Accurancy:  0.9251806512475014 | Validation Accurancy:  0.9169050678610802\n",
      "Epoch:  5516 | Train Accurancy:  0.9251829236745834 | Validation Accurancy:  0.916912667453289\n",
      "Epoch:  5517 | Train Accurancy:  0.9251851662993431 | Validation Accurancy:  0.916920468211174\n",
      "Epoch:  5518 | Train Accurancy:  0.9251873716711998 | Validation Accurancy:  0.9169282093644142\n",
      "Epoch:  5519 | Train Accurancy:  0.9251896217465401 | Validation Accurancy:  0.9169357568025589\n",
      "Epoch:  5520 | Train Accurancy:  0.9251918643712997 | Validation Accurancy:  0.9169435277581215\n",
      "Epoch:  5521 | Train Accurancy:  0.9251940995454788 | Validation Accurancy:  0.9169512093067169\n",
      "Epoch:  5522 | Train Accurancy:  0.9251963719725609 | Validation Accurancy:  0.9169588461518288\n",
      "Epoch:  5523 | Train Accurancy:  0.9251985996961594 | Validation Accurancy:  0.9169665575027466\n",
      "Epoch:  5524 | Train Accurancy:  0.9252008572220802 | Validation Accurancy:  0.9169741943478584\n",
      "Epoch:  5525 | Train Accurancy:  0.9252031147480011 | Validation Accurancy:  0.9169817864894867\n",
      "Epoch:  5526 | Train Accurancy:  0.9252053126692772 | Validation Accurancy:  0.9169895276427269\n",
      "Epoch:  5527 | Train Accurancy:  0.9252075478434563 | Validation Accurancy:  0.916997142136097\n",
      "Epoch:  5528 | Train Accurancy:  0.9252098277211189 | Validation Accurancy:  0.9170048236846924\n",
      "Epoch:  5529 | Train Accurancy:  0.9252120330929756 | Validation Accurancy:  0.917012557387352\n",
      "Epoch:  5530 | Train Accurancy:  0.9252142533659935 | Validation Accurancy:  0.9170201122760773\n",
      "Epoch:  5531 | Train Accurancy:  0.925216518342495 | Validation Accurancy:  0.9170277491211891\n",
      "Epoch:  5532 | Train Accurancy:  0.9252187237143517 | Validation Accurancy:  0.9170353934168816\n",
      "Epoch:  5533 | Train Accurancy:  0.9252209737896919 | Validation Accurancy:  0.9170430526137352\n",
      "Epoch:  5534 | Train Accurancy:  0.9252231791615486 | Validation Accurancy:  0.9170506969094276\n",
      "Epoch:  5535 | Train Accurancy:  0.9252254068851471 | Validation Accurancy:  0.9170584231615067\n",
      "Epoch:  5536 | Train Accurancy:  0.925227664411068 | Validation Accurancy:  0.9170660302042961\n",
      "Epoch:  5537 | Train Accurancy:  0.9252298846840858 | Validation Accurancy:  0.9170736223459244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5538 | Train Accurancy:  0.9252321422100067 | Validation Accurancy:  0.9170813411474228\n",
      "Epoch:  5539 | Train Accurancy:  0.9252343103289604 | Validation Accurancy:  0.9170889034867287\n",
      "Epoch:  5540 | Train Accurancy:  0.9252365753054619 | Validation Accurancy:  0.9170965850353241\n",
      "Epoch:  5541 | Train Accurancy:  0.9252388030290604 | Validation Accurancy:  0.9171042367815971\n",
      "Epoch:  5542 | Train Accurancy:  0.9252410754561424 | Validation Accurancy:  0.917111799120903\n",
      "Epoch:  5543 | Train Accurancy:  0.9252432137727737 | Validation Accurancy:  0.9171195328235626\n",
      "Epoch:  5544 | Train Accurancy:  0.9252454712986946 | Validation Accurancy:  0.9171271398663521\n",
      "Epoch:  5545 | Train Accurancy:  0.9252476766705513 | Validation Accurancy:  0.9171347171068192\n",
      "Epoch:  5546 | Train Accurancy:  0.9252498596906662 | Validation Accurancy:  0.9171423763036728\n",
      "Epoch:  5547 | Train Accurancy:  0.9252520948648453 | Validation Accurancy:  0.9171499460935593\n",
      "Epoch:  5548 | Train Accurancy:  0.9252543598413467 | Validation Accurancy:  0.9171575456857681\n",
      "Epoch:  5549 | Train Accurancy:  0.9252565279603004 | Validation Accurancy:  0.9171651974320412\n",
      "Epoch:  5550 | Train Accurancy:  0.9252587705850601 | Validation Accurancy:  0.9171727821230888\n",
      "Epoch:  5551 | Train Accurancy:  0.925260953605175 | Validation Accurancy:  0.9171804338693619\n",
      "Epoch:  5552 | Train Accurancy:  0.9252631664276123 | Validation Accurancy:  0.9171880558133125\n",
      "Epoch:  5553 | Train Accurancy:  0.925265446305275 | Validation Accurancy:  0.9171955958008766\n",
      "Epoch:  5554 | Train Accurancy:  0.9252676442265511 | Validation Accurancy:  0.9172032848000526\n",
      "Epoch:  5555 | Train Accurancy:  0.9252698570489883 | Validation Accurancy:  0.9172109290957451\n",
      "Epoch:  5556 | Train Accurancy:  0.9252720922231674 | Validation Accurancy:  0.9172184765338898\n",
      "Epoch:  5557 | Train Accurancy:  0.9252742454409599 | Validation Accurancy:  0.9172260537743568\n",
      "Epoch:  5558 | Train Accurancy:  0.9252764508128166 | Validation Accurancy:  0.9172337353229523\n",
      "Epoch:  5559 | Train Accurancy:  0.9252786710858345 | Validation Accurancy:  0.9172412902116776\n",
      "Epoch:  5560 | Train Accurancy:  0.925280898809433 | Validation Accurancy:  0.9172488078474998\n",
      "Epoch:  5561 | Train Accurancy:  0.9252830818295479 | Validation Accurancy:  0.9172563776373863\n",
      "Epoch:  5562 | Train Accurancy:  0.9252853319048882 | Validation Accurancy:  0.917263962328434\n",
      "Epoch:  5563 | Train Accurancy:  0.9252875000238419 | Validation Accurancy:  0.9172715991735458\n",
      "Epoch:  5564 | Train Accurancy:  0.9252897351980209 | Validation Accurancy:  0.9172792211174965\n",
      "Epoch:  5565 | Train Accurancy:  0.9252919107675552 | Validation Accurancy:  0.9172867834568024\n",
      "Epoch:  5566 | Train Accurancy:  0.9252941161394119 | Validation Accurancy:  0.9172943457961082\n",
      "Epoch:  5567 | Train Accurancy:  0.9252963066101074 | Validation Accurancy:  0.9173019751906395\n",
      "Epoch:  5568 | Train Accurancy:  0.9252985417842865 | Validation Accurancy:  0.9173095673322678\n",
      "Epoch:  5569 | Train Accurancy:  0.9253007248044014 | Validation Accurancy:  0.9173171147704124\n",
      "Epoch:  5570 | Train Accurancy:  0.9253029599785805 | Validation Accurancy:  0.9173246845602989\n",
      "Epoch:  5571 | Train Accurancy:  0.9253051280975342 | Validation Accurancy:  0.9173322394490242\n",
      "Epoch:  5572 | Train Accurancy:  0.9253073036670685 | Validation Accurancy:  0.9173398986458778\n",
      "Epoch:  5573 | Train Accurancy:  0.9253095388412476 | Validation Accurancy:  0.9173475056886673\n",
      "Epoch:  5574 | Train Accurancy:  0.9253117218613625 | Validation Accurancy:  0.917354941368103\n",
      "Epoch:  5575 | Train Accurancy:  0.9253139197826385 | Validation Accurancy:  0.9173625484108925\n",
      "Epoch:  5576 | Train Accurancy:  0.9253160953521729 | Validation Accurancy:  0.9173700883984566\n",
      "Epoch:  5577 | Train Accurancy:  0.9253182783722878 | Validation Accurancy:  0.9173777922987938\n",
      "Epoch:  5578 | Train Accurancy:  0.925320491194725 | Validation Accurancy:  0.9173852577805519\n",
      "Epoch:  5579 | Train Accurancy:  0.9253227189183235 | Validation Accurancy:  0.9173927381634712\n",
      "Epoch:  5580 | Train Accurancy:  0.925324834883213 | Validation Accurancy:  0.9174002707004547\n",
      "Epoch:  5581 | Train Accurancy:  0.9253270849585533 | Validation Accurancy:  0.9174078777432442\n",
      "Epoch:  5582 | Train Accurancy:  0.9253292456269264 | Validation Accurancy:  0.9174153506755829\n",
      "Epoch:  5583 | Train Accurancy:  0.9253314435482025 | Validation Accurancy:  0.9174229353666306\n",
      "Epoch:  5584 | Train Accurancy:  0.9253336265683174 | Validation Accurancy:  0.9174304530024529\n",
      "Epoch:  5585 | Train Accurancy:  0.9253358170390129 | Validation Accurancy:  0.9174380004405975\n",
      "Epoch:  5586 | Train Accurancy:  0.9253380447626114 | Validation Accurancy:  0.9174455255270004\n",
      "Epoch:  5587 | Train Accurancy:  0.9253402054309845 | Validation Accurancy:  0.9174530431628227\n",
      "Epoch:  5588 | Train Accurancy:  0.9253423735499382 | Validation Accurancy:  0.9174607023596764\n",
      "Epoch:  5589 | Train Accurancy:  0.9253445714712143 | Validation Accurancy:  0.9174682423472404\n",
      "Epoch:  5590 | Train Accurancy:  0.9253467246890068 | Validation Accurancy:  0.9174758419394493\n",
      "Epoch:  5591 | Train Accurancy:  0.9253489226102829 | Validation Accurancy:  0.917483314871788\n",
      "Epoch:  5592 | Train Accurancy:  0.9253511279821396 | Validation Accurancy:  0.9174909368157387\n",
      "Epoch:  5593 | Train Accurancy:  0.9253532886505127 | Validation Accurancy:  0.9174983277916908\n",
      "Epoch:  5594 | Train Accurancy:  0.9253554716706276 | Validation Accurancy:  0.9175058975815773\n",
      "Epoch:  5595 | Train Accurancy:  0.9253576248884201 | Validation Accurancy:  0.9175127744674683\n",
      "Epoch:  5596 | Train Accurancy:  0.925359807908535 | Validation Accurancy:  0.9175205081701279\n",
      "Epoch:  5597 | Train Accurancy:  0.9253620132803917 | Validation Accurancy:  0.9175280407071114\n",
      "Epoch:  5598 | Train Accurancy:  0.9253642037510872 | Validation Accurancy:  0.9175357073545456\n",
      "Epoch:  5599 | Train Accurancy:  0.9253663569688797 | Validation Accurancy:  0.9175433441996574\n",
      "Epoch:  5600 | Train Accurancy:  0.9253685101866722 | Validation Accurancy:  0.9175502508878708\n",
      "Epoch:  5601 | Train Accurancy:  0.9253707230091095 | Validation Accurancy:  0.9175580441951752\n",
      "Epoch:  5602 | Train Accurancy:  0.9253729060292244 | Validation Accurancy:  0.9175656363368034\n",
      "Epoch:  5603 | Train Accurancy:  0.9253750592470169 | Validation Accurancy:  0.9175732061266899\n",
      "Epoch:  5604 | Train Accurancy:  0.92537721991539 | Validation Accurancy:  0.9175808057188988\n",
      "Epoch:  5605 | Train Accurancy:  0.9253793805837631 | Validation Accurancy:  0.9175877645611763\n",
      "Epoch:  5606 | Train Accurancy:  0.9253815710544586 | Validation Accurancy:  0.9175953716039658\n",
      "Epoch:  5607 | Train Accurancy:  0.9253836944699287 | Validation Accurancy:  0.9176030829548836\n",
      "Epoch:  5608 | Train Accurancy:  0.9253858625888824 | Validation Accurancy:  0.9176108092069626\n",
      "Epoch:  5609 | Train Accurancy:  0.9253880903124809 | Validation Accurancy:  0.9176182597875595\n",
      "Epoch:  5610 | Train Accurancy:  0.9253902360796928 | Validation Accurancy:  0.917625330388546\n",
      "Epoch:  5611 | Train Accurancy:  0.925392396748066 | Validation Accurancy:  0.9176329299807549\n",
      "Epoch:  5612 | Train Accurancy:  0.9253945499658585 | Validation Accurancy:  0.9176407232880592\n",
      "Epoch:  5613 | Train Accurancy:  0.9253967106342316 | Validation Accurancy:  0.9176482111215591\n",
      "Epoch:  5614 | Train Accurancy:  0.9253988787531853 | Validation Accurancy:  0.9176557511091232\n",
      "Epoch:  5615 | Train Accurancy:  0.9254010394215584 | Validation Accurancy:  0.917662687599659\n",
      "Epoch:  5616 | Train Accurancy:  0.9254032149910927 | Validation Accurancy:  0.9176703467965126\n",
      "Epoch:  5617 | Train Accurancy:  0.9254054054617882 | Validation Accurancy:  0.9176780208945274\n",
      "Epoch:  5618 | Train Accurancy:  0.9254074990749359 | Validation Accurancy:  0.9176855906844139\n",
      "Epoch:  5619 | Train Accurancy:  0.925409696996212 | Validation Accurancy:  0.9176932498812675\n",
      "Epoch:  5620 | Train Accurancy:  0.9254118129611015 | Validation Accurancy:  0.9177000373601913\n",
      "Epoch:  5621 | Train Accurancy:  0.9254140481352806 | Validation Accurancy:  0.9177077785134315\n",
      "Epoch:  5622 | Train Accurancy:  0.9254161641001701 | Validation Accurancy:  0.9177152886986732\n",
      "Epoch:  5623 | Train Accurancy:  0.925418309867382 | Validation Accurancy:  0.9177229553461075\n",
      "Epoch:  5624 | Train Accurancy:  0.9254205003380775 | Validation Accurancy:  0.9177299216389656\n",
      "Epoch:  5625 | Train Accurancy:  0.9254226386547089 | Validation Accurancy:  0.917737565934658\n",
      "Epoch:  5626 | Train Accurancy:  0.9254247769713402 | Validation Accurancy:  0.9177451580762863\n",
      "Epoch:  5627 | Train Accurancy:  0.9254268854856491 | Validation Accurancy:  0.9177527949213982\n",
      "Epoch:  5628 | Train Accurancy:  0.925429068505764 | Validation Accurancy:  0.9177603349089622\n",
      "Epoch:  5629 | Train Accurancy:  0.9254312142729759 | Validation Accurancy:  0.917767234146595\n",
      "Epoch:  5630 | Train Accurancy:  0.9254333525896072 | Validation Accurancy:  0.9177748933434486\n",
      "Epoch:  5631 | Train Accurancy:  0.9254355430603027 | Validation Accurancy:  0.9177825674414635\n",
      "Epoch:  5632 | Train Accurancy:  0.9254376664757729 | Validation Accurancy:  0.9177901521325111\n",
      "Epoch:  5633 | Train Accurancy:  0.9254398122429848 | Validation Accurancy:  0.9177970215678215\n",
      "Epoch:  5634 | Train Accurancy:  0.9254419803619385 | Validation Accurancy:  0.9178047478199005\n",
      "Epoch:  5635 | Train Accurancy:  0.9254441037774086 | Validation Accurancy:  0.9178123623132706\n",
      "Epoch:  5636 | Train Accurancy:  0.9254462644457817 | Validation Accurancy:  0.9178199470043182\n",
      "Epoch:  5637 | Train Accurancy:  0.9254484251141548 | Validation Accurancy:  0.917827419936657\n",
      "Epoch:  5638 | Train Accurancy:  0.9254505634307861 | Validation Accurancy:  0.9178342893719673\n",
      "Epoch:  5639 | Train Accurancy:  0.9254526346921921 | Validation Accurancy:  0.9178419783711433\n",
      "Epoch:  5640 | Train Accurancy:  0.9254548102617264 | Validation Accurancy:  0.917849563062191\n",
      "Epoch:  5641 | Train Accurancy:  0.9254569560289383 | Validation Accurancy:  0.9178570136427879\n",
      "Epoch:  5642 | Train Accurancy:  0.9254591315984726 | Validation Accurancy:  0.9178639277815819\n",
      "Epoch:  5643 | Train Accurancy:  0.9254612550139427 | Validation Accurancy:  0.9178715795278549\n",
      "Epoch:  5644 | Train Accurancy:  0.9254633486270905 | Validation Accurancy:  0.917879194021225\n",
      "Epoch:  5645 | Train Accurancy:  0.9254655092954636 | Validation Accurancy:  0.9178866669535637\n",
      "Epoch:  5646 | Train Accurancy:  0.9254677072167397 | Validation Accurancy:  0.9178941771388054\n",
      "Epoch:  5647 | Train Accurancy:  0.9254697933793068 | Validation Accurancy:  0.9179010763764381\n",
      "Epoch:  5648 | Train Accurancy:  0.9254719316959381 | Validation Accurancy:  0.9179086610674858\n",
      "Epoch:  5649 | Train Accurancy:  0.925474040210247 | Validation Accurancy:  0.9179162681102753\n",
      "Epoch:  5650 | Train Accurancy:  0.9254762083292007 | Validation Accurancy:  0.9179238602519035\n",
      "Epoch:  5651 | Train Accurancy:  0.9254783466458321 | Validation Accurancy:  0.9179307296872139\n",
      "Epoch:  5652 | Train Accurancy:  0.9254804626107216 | Validation Accurancy:  0.9179383143782616\n",
      "Epoch:  5653 | Train Accurancy:  0.9254825562238693 | Validation Accurancy:  0.917945884168148\n",
      "Epoch:  5654 | Train Accurancy:  0.9254847094416618 | Validation Accurancy:  0.9179533645510674\n",
      "Epoch:  5655 | Train Accurancy:  0.9254868403077126 | Validation Accurancy:  0.9179603159427643\n",
      "Epoch:  5656 | Train Accurancy:  0.9254889637231827 | Validation Accurancy:  0.9179679527878761\n",
      "Epoch:  5657 | Train Accurancy:  0.925491102039814 | Validation Accurancy:  0.917975515127182\n",
      "Epoch:  5658 | Train Accurancy:  0.9254932403564453 | Validation Accurancy:  0.9179830327630043\n",
      "Epoch:  5659 | Train Accurancy:  0.925495333969593 | Validation Accurancy:  0.9179898723959923\n",
      "Epoch:  5660 | Train Accurancy:  0.9254974275827408 | Validation Accurancy:  0.9179976731538773\n",
      "Epoch:  5661 | Train Accurancy:  0.9254995808005333 | Validation Accurancy:  0.9180051237344742\n",
      "Epoch:  5662 | Train Accurancy:  0.9255017265677452 | Validation Accurancy:  0.9180126562714577\n",
      "Epoch:  5663 | Train Accurancy:  0.9255038499832153 | Validation Accurancy:  0.9180195331573486\n",
      "Epoch:  5664 | Train Accurancy:  0.9255060032010078 | Validation Accurancy:  0.9180270582437515\n",
      "Epoch:  5665 | Train Accurancy:  0.9255080670118332 | Validation Accurancy:  0.9180346876382828\n",
      "Epoch:  5666 | Train Accurancy:  0.9255102053284645 | Validation Accurancy:  0.918041542172432\n",
      "Epoch:  5667 | Train Accurancy:  0.9255123361945152 | Validation Accurancy:  0.9180492162704468\n",
      "Epoch:  5668 | Train Accurancy:  0.9255144372582436 | Validation Accurancy:  0.9180567488074303\n",
      "Epoch:  5669 | Train Accurancy:  0.9255165681242943 | Validation Accurancy:  0.9180643707513809\n",
      "Epoch:  5670 | Train Accurancy:  0.9255186319351196 | Validation Accurancy:  0.9180712401866913\n",
      "Epoch:  5671 | Train Accurancy:  0.9255207479000092 | Validation Accurancy:  0.9180788993835449\n",
      "Epoch:  5672 | Train Accurancy:  0.9255229011178017 | Validation Accurancy:  0.9180863425135612\n",
      "Epoch:  5673 | Train Accurancy:  0.9255250617861748 | Validation Accurancy:  0.9180939495563507\n",
      "Epoch:  5674 | Train Accurancy:  0.9255271628499031 | Validation Accurancy:  0.9181007444858551\n",
      "Epoch:  5675 | Train Accurancy:  0.9255292788147926 | Validation Accurancy:  0.9181083217263222\n",
      "Epoch:  5676 | Train Accurancy:  0.9255313575267792 | Validation Accurancy:  0.9181158542633057\n",
      "Epoch:  5677 | Train Accurancy:  0.9255334958434105 | Validation Accurancy:  0.9181232899427414\n",
      "Epoch:  5678 | Train Accurancy:  0.9255356267094612 | Validation Accurancy:  0.9181302264332771\n",
      "Epoch:  5679 | Train Accurancy:  0.9255376979708672 | Validation Accurancy:  0.9181377962231636\n",
      "Epoch:  5680 | Train Accurancy:  0.9255397766828537 | Validation Accurancy:  0.9181452766060829\n",
      "Epoch:  5681 | Train Accurancy:  0.9255418628454208 | Validation Accurancy:  0.9181528761982918\n",
      "Epoch:  5682 | Train Accurancy:  0.9255440458655357 | Validation Accurancy:  0.9181596338748932\n",
      "Epoch:  5683 | Train Accurancy:  0.9255460947751999 | Validation Accurancy:  0.9181672111153603\n",
      "Epoch:  5684 | Train Accurancy:  0.9255482777953148 | Validation Accurancy:  0.9181747660040855\n",
      "Epoch:  5685 | Train Accurancy:  0.9255503341555595 | Validation Accurancy:  0.9181815832853317\n",
      "Epoch:  5686 | Train Accurancy:  0.9255524352192879 | Validation Accurancy:  0.9181892052292824\n",
      "Epoch:  5687 | Train Accurancy:  0.9255545437335968 | Validation Accurancy:  0.9181967675685883\n",
      "Epoch:  5688 | Train Accurancy:  0.9255566149950027 | Validation Accurancy:  0.91820427775383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5689 | Train Accurancy:  0.9255587607622147 | Validation Accurancy:  0.9182110130786896\n",
      "Epoch:  5690 | Train Accurancy:  0.9255608320236206 | Validation Accurancy:  0.918218620121479\n",
      "Epoch:  5691 | Train Accurancy:  0.9255629405379295 | Validation Accurancy:  0.9182261452078819\n",
      "Epoch:  5692 | Train Accurancy:  0.9255650788545609 | Validation Accurancy:  0.9182330444455147\n",
      "Epoch:  5693 | Train Accurancy:  0.9255671575665474 | Validation Accurancy:  0.9182405918836594\n",
      "Epoch:  5694 | Train Accurancy:  0.9255692288279533 | Validation Accurancy:  0.9182482212781906\n",
      "Epoch:  5695 | Train Accurancy:  0.9255713224411011 | Validation Accurancy:  0.9182556495070457\n",
      "Epoch:  5696 | Train Accurancy:  0.9255734160542488 | Validation Accurancy:  0.918262355029583\n",
      "Epoch:  5697 | Train Accurancy:  0.9255754873156548 | Validation Accurancy:  0.918270044028759\n",
      "Epoch:  5698 | Train Accurancy:  0.9255776032805443 | Validation Accurancy:  0.9182774648070335\n",
      "Epoch:  5699 | Train Accurancy:  0.9255797639489174 | Validation Accurancy:  0.9182848408818245\n",
      "Epoch:  5700 | Train Accurancy:  0.9255817905068398 | Validation Accurancy:  0.9182917028665543\n",
      "Epoch:  5701 | Train Accurancy:  0.9255839288234711 | Validation Accurancy:  0.9182992503046989\n",
      "Epoch:  5702 | Train Accurancy:  0.9255859926342964 | Validation Accurancy:  0.9183068051934242\n",
      "Epoch:  5703 | Train Accurancy:  0.9255880787968636 | Validation Accurancy:  0.9183141440153122\n",
      "Epoch:  5704 | Train Accurancy:  0.9255901426076889 | Validation Accurancy:  0.918320968747139\n",
      "Epoch:  5705 | Train Accurancy:  0.9255922585725784 | Validation Accurancy:  0.9183285385370255\n",
      "Epoch:  5706 | Train Accurancy:  0.9255943447351456 | Validation Accurancy:  0.9183360412716866\n",
      "Epoch:  5707 | Train Accurancy:  0.9255964457988739 | Validation Accurancy:  0.9183429405093193\n",
      "Epoch:  5708 | Train Accurancy:  0.9255985021591187 | Validation Accurancy:  0.9183505102992058\n",
      "Epoch:  5709 | Train Accurancy:  0.925600603222847 | Validation Accurancy:  0.9183579310774803\n",
      "Epoch:  5710 | Train Accurancy:  0.9256026819348335 | Validation Accurancy:  0.9183653369545937\n",
      "Epoch:  5711 | Train Accurancy:  0.9256047531962395 | Validation Accurancy:  0.9183721765875816\n",
      "Epoch:  5712 | Train Accurancy:  0.9256068542599678 | Validation Accurancy:  0.9183797016739845\n",
      "Epoch:  5713 | Train Accurancy:  0.9256089404225349 | Validation Accurancy:  0.9183872565627098\n",
      "Epoch:  5714 | Train Accurancy:  0.9256110340356827 | Validation Accurancy:  0.9183940067887306\n",
      "Epoch:  5715 | Train Accurancy:  0.925613097846508 | Validation Accurancy:  0.9184014871716499\n",
      "Epoch:  5716 | Train Accurancy:  0.9256151765584946 | Validation Accurancy:  0.918408952653408\n",
      "Epoch:  5717 | Train Accurancy:  0.9256172478199005 | Validation Accurancy:  0.9184164255857468\n",
      "Epoch:  5718 | Train Accurancy:  0.9256193414330482 | Validation Accurancy:  0.9184232801198959\n",
      "Epoch:  5719 | Train Accurancy:  0.9256214201450348 | Validation Accurancy:  0.9184307381510735\n",
      "Epoch:  5720 | Train Accurancy:  0.9256235212087631 | Validation Accurancy:  0.9184381887316704\n",
      "Epoch:  5721 | Train Accurancy:  0.9256256073713303 | Validation Accurancy:  0.9184455573558807\n",
      "Epoch:  5722 | Train Accurancy:  0.9256276860833168 | Validation Accurancy:  0.9184523671865463\n",
      "Epoch:  5723 | Train Accurancy:  0.925629697740078 | Validation Accurancy:  0.9184599220752716\n",
      "Epoch:  5724 | Train Accurancy:  0.9256317839026451 | Validation Accurancy:  0.9184673354029655\n",
      "Epoch:  5725 | Train Accurancy:  0.9256338849663734 | Validation Accurancy:  0.9184741601347923\n",
      "Epoch:  5726 | Train Accurancy:  0.925635926425457 | Validation Accurancy:  0.9184816628694534\n",
      "Epoch:  5727 | Train Accurancy:  0.925637997686863 | Validation Accurancy:  0.9184891805052757\n",
      "Epoch:  5728 | Train Accurancy:  0.9256400838494301 | Validation Accurancy:  0.9184965044260025\n",
      "Epoch:  5729 | Train Accurancy:  0.9256421700119972 | Validation Accurancy:  0.9185033068060875\n",
      "Epoch:  5730 | Train Accurancy:  0.9256442114710808 | Validation Accurancy:  0.9185109287500381\n",
      "Epoch:  5731 | Train Accurancy:  0.9256462901830673 | Validation Accurancy:  0.9185182601213455\n",
      "Epoch:  5732 | Train Accurancy:  0.9256483614444733 | Validation Accurancy:  0.9185249879956245\n",
      "Epoch:  5733 | Train Accurancy:  0.9256504476070404 | Validation Accurancy:  0.9185325726866722\n",
      "Epoch:  5734 | Train Accurancy:  0.9256525114178658 | Validation Accurancy:  0.9185400977730751\n",
      "Epoch:  5735 | Train Accurancy:  0.9256545454263687 | Validation Accurancy:  0.9185474142432213\n",
      "Epoch:  5736 | Train Accurancy:  0.9256566092371941 | Validation Accurancy:  0.9185541793704033\n",
      "Epoch:  5737 | Train Accurancy:  0.9256587326526642 | Validation Accurancy:  0.9185616970062256\n",
      "Epoch:  5738 | Train Accurancy:  0.9256607368588448 | Validation Accurancy:  0.9185690358281136\n",
      "Epoch:  5739 | Train Accurancy:  0.9256628006696701 | Validation Accurancy:  0.918575830757618\n",
      "Epoch:  5740 | Train Accurancy:  0.925664909183979 | Validation Accurancy:  0.9185833632946014\n",
      "Epoch:  5741 | Train Accurancy:  0.925666943192482 | Validation Accurancy:  0.918590746819973\n",
      "Epoch:  5742 | Train Accurancy:  0.9256689548492432 | Validation Accurancy:  0.918598122894764\n",
      "Epoch:  5743 | Train Accurancy:  0.9256710782647133 | Validation Accurancy:  0.918604888021946\n",
      "Epoch:  5744 | Train Accurancy:  0.925673134624958 | Validation Accurancy:  0.9186122864484787\n",
      "Epoch:  5745 | Train Accurancy:  0.9256751835346222 | Validation Accurancy:  0.918619766831398\n",
      "Epoch:  5746 | Train Accurancy:  0.9256772324442863 | Validation Accurancy:  0.9186265766620636\n",
      "Epoch:  5747 | Train Accurancy:  0.9256793186068535 | Validation Accurancy:  0.9186341464519501\n",
      "Epoch:  5748 | Train Accurancy:  0.9256813526153564 | Validation Accurancy:  0.9186415374279022\n",
      "Epoch:  5749 | Train Accurancy:  0.92568339407444 | Validation Accurancy:  0.918648324906826\n",
      "Epoch:  5750 | Train Accurancy:  0.9256854802370071 | Validation Accurancy:  0.9186557531356812\n",
      "Epoch:  5751 | Train Accurancy:  0.9256875142455101 | Validation Accurancy:  0.9186631590127945\n",
      "Epoch:  5752 | Train Accurancy:  0.9256895557045937 | Validation Accurancy:  0.918670542538166\n",
      "Epoch:  5753 | Train Accurancy:  0.925691619515419 | Validation Accurancy:  0.9186771810054779\n",
      "Epoch:  5754 | Train Accurancy:  0.9256936684250832 | Validation Accurancy:  0.918684609234333\n",
      "Epoch:  5755 | Train Accurancy:  0.9256957024335861 | Validation Accurancy:  0.9186921119689941\n",
      "Epoch:  5756 | Train Accurancy:  0.9256977587938309 | Validation Accurancy:  0.9186988547444344\n",
      "Epoch:  5757 | Train Accurancy:  0.9256998226046562 | Validation Accurancy:  0.9187063649296761\n",
      "Epoch:  5758 | Train Accurancy:  0.9257018566131592 | Validation Accurancy:  0.9187138006091118\n",
      "Epoch:  5759 | Train Accurancy:  0.9257039129734039 | Validation Accurancy:  0.918721079826355\n",
      "Epoch:  5760 | Train Accurancy:  0.9257059171795845 | Validation Accurancy:  0.9187278300523758\n",
      "Epoch:  5761 | Train Accurancy:  0.9257079809904099 | Validation Accurancy:  0.9187352433800697\n",
      "Epoch:  5762 | Train Accurancy:  0.9257100373506546 | Validation Accurancy:  0.9187425598502159\n",
      "Epoch:  5763 | Train Accurancy:  0.9257120862603188 | Validation Accurancy:  0.9187493249773979\n",
      "Epoch:  5764 | Train Accurancy:  0.9257141575217247 | Validation Accurancy:  0.9187567308545113\n",
      "Epoch:  5765 | Train Accurancy:  0.9257161393761635 | Validation Accurancy:  0.9187642261385918\n",
      "Epoch:  5766 | Train Accurancy:  0.9257181659340858 | Validation Accurancy:  0.9187709614634514\n",
      "Epoch:  5767 | Train Accurancy:  0.925720252096653 | Validation Accurancy:  0.9187784940004349\n",
      "Epoch:  5768 | Train Accurancy:  0.9257222563028336 | Validation Accurancy:  0.9187858924269676\n",
      "Epoch:  5769 | Train Accurancy:  0.9257243126630783 | Validation Accurancy:  0.9187932163476944\n",
      "Epoch:  5770 | Train Accurancy:  0.9257263392210007 | Validation Accurancy:  0.9187998399138451\n",
      "Epoch:  5771 | Train Accurancy:  0.9257284477353096 | Validation Accurancy:  0.9188073053956032\n",
      "Epoch:  5772 | Train Accurancy:  0.9257304295897484 | Validation Accurancy:  0.91881462931633\n",
      "Epoch:  5773 | Train Accurancy:  0.9257324412465096 | Validation Accurancy:  0.9188213720917702\n",
      "Epoch:  5774 | Train Accurancy:  0.9257345050573349 | Validation Accurancy:  0.9188288226723671\n",
      "Epoch:  5775 | Train Accurancy:  0.9257365241646767 | Validation Accurancy:  0.9188362285494804\n",
      "Epoch:  5776 | Train Accurancy:  0.9257386773824692 | Validation Accurancy:  0.9188428223133087\n",
      "Epoch:  5777 | Train Accurancy:  0.925740621984005 | Validation Accurancy:  0.9188502877950668\n",
      "Epoch:  5778 | Train Accurancy:  0.9257426410913467 | Validation Accurancy:  0.9188577756285667\n",
      "Epoch:  5779 | Train Accurancy:  0.9257446676492691 | Validation Accurancy:  0.9188650846481323\n",
      "Epoch:  5780 | Train Accurancy:  0.9257467240095139 | Validation Accurancy:  0.9188717678189278\n",
      "Epoch:  5781 | Train Accurancy:  0.9257487803697586 | Validation Accurancy:  0.9188791066408157\n",
      "Epoch:  5782 | Train Accurancy:  0.9257507547736168 | Validation Accurancy:  0.9188864231109619\n",
      "Epoch:  5783 | Train Accurancy:  0.925752803683281 | Validation Accurancy:  0.9188931062817574\n",
      "Epoch:  5784 | Train Accurancy:  0.9257548525929451 | Validation Accurancy:  0.9189005792140961\n",
      "Epoch:  5785 | Train Accurancy:  0.9257568418979645 | Validation Accurancy:  0.9189080148935318\n",
      "Epoch:  5786 | Train Accurancy:  0.9257588759064674 | Validation Accurancy:  0.9189145863056183\n",
      "Epoch:  5787 | Train Accurancy:  0.9257608950138092 | Validation Accurancy:  0.9189220815896988\n",
      "Epoch:  5788 | Train Accurancy:  0.9257629439234734 | Validation Accurancy:  0.9189294502139091\n",
      "Epoch:  5789 | Train Accurancy:  0.9257649853825569 | Validation Accurancy:  0.9189368113875389\n",
      "Epoch:  5790 | Train Accurancy:  0.9257670268416405 | Validation Accurancy:  0.9189433827996254\n",
      "Epoch:  5791 | Train Accurancy:  0.9257689639925957 | Validation Accurancy:  0.9189507812261581\n",
      "Epoch:  5792 | Train Accurancy:  0.9257710203528404 | Validation Accurancy:  0.9189581945538521\n",
      "Epoch:  5793 | Train Accurancy:  0.9257730692625046 | Validation Accurancy:  0.918964758515358\n",
      "Epoch:  5794 | Train Accurancy:  0.9257750660181046 | Validation Accurancy:  0.9189721718430519\n",
      "Epoch:  5795 | Train Accurancy:  0.9257770702242851 | Validation Accurancy:  0.9189794957637787\n",
      "Epoch:  5796 | Train Accurancy:  0.9257791116833687 | Validation Accurancy:  0.9189861938357353\n",
      "Epoch:  5797 | Train Accurancy:  0.9257811158895493 | Validation Accurancy:  0.9189935177564621\n",
      "Epoch:  5798 | Train Accurancy:  0.9257831275463104 | Validation Accurancy:  0.9190009161829948\n",
      "Epoch:  5799 | Train Accurancy:  0.925785206258297 | Validation Accurancy:  0.9190075621008873\n",
      "Epoch:  5800 | Train Accurancy:  0.925787165760994 | Validation Accurancy:  0.9190150648355484\n",
      "Epoch:  5801 | Train Accurancy:  0.9257891848683357 | Validation Accurancy:  0.919022373855114\n",
      "Epoch:  5802 | Train Accurancy:  0.9257911816239357 | Validation Accurancy:  0.9190296232700348\n",
      "Epoch:  5803 | Train Accurancy:  0.9257932230830193 | Validation Accurancy:  0.9190362319350243\n",
      "Epoch:  5804 | Train Accurancy:  0.9257952198386192 | Validation Accurancy:  0.919043742120266\n",
      "Epoch:  5805 | Train Accurancy:  0.9257972687482834 | Validation Accurancy:  0.9190509542822838\n",
      "Epoch:  5806 | Train Accurancy:  0.9257992580533028 | Validation Accurancy:  0.9190576449036598\n",
      "Epoch:  5807 | Train Accurancy:  0.9258012622594833 | Validation Accurancy:  0.9190650060772896\n",
      "Epoch:  5808 | Train Accurancy:  0.9258033409714699 | Validation Accurancy:  0.9190723076462746\n",
      "Epoch:  5809 | Train Accurancy:  0.9258053377270699 | Validation Accurancy:  0.919079102575779\n",
      "Epoch:  5810 | Train Accurancy:  0.9258073344826698 | Validation Accurancy:  0.9190864711999893\n",
      "Epoch:  5811 | Train Accurancy:  0.925809346139431 | Validation Accurancy:  0.9190937280654907\n",
      "Epoch:  5812 | Train Accurancy:  0.9258113205432892 | Validation Accurancy:  0.919100433588028\n",
      "Epoch:  5813 | Train Accurancy:  0.9258133322000504 | Validation Accurancy:  0.9191077649593353\n",
      "Epoch:  5814 | Train Accurancy:  0.9258153513073921 | Validation Accurancy:  0.9191151633858681\n",
      "Epoch:  5815 | Train Accurancy:  0.9258173480629921 | Validation Accurancy:  0.9191224053502083\n",
      "Epoch:  5816 | Train Accurancy:  0.9258193820714951 | Validation Accurancy:  0.9191289767622948\n",
      "Epoch:  5817 | Train Accurancy:  0.925821341574192 | Validation Accurancy:  0.919136255979538\n",
      "Epoch:  5818 | Train Accurancy:  0.9258233532309532 | Validation Accurancy:  0.9191435724496841\n",
      "Epoch:  5819 | Train Accurancy:  0.9258253797888756 | Validation Accurancy:  0.919150210916996\n",
      "Epoch:  5820 | Train Accurancy:  0.9258273541927338 | Validation Accurancy:  0.9191576018929482\n",
      "Epoch:  5821 | Train Accurancy:  0.925829328596592 | Validation Accurancy:  0.919164814054966\n",
      "Epoch:  5822 | Train Accurancy:  0.9258313402533531 | Validation Accurancy:  0.9191714823246002\n",
      "Epoch:  5823 | Train Accurancy:  0.9258333444595337 | Validation Accurancy:  0.9191788360476494\n",
      "Epoch:  5824 | Train Accurancy:  0.925835371017456 | Validation Accurancy:  0.9191861897706985\n",
      "Epoch:  5825 | Train Accurancy:  0.9258373454213142 | Validation Accurancy:  0.9191928058862686\n",
      "Epoch:  5826 | Train Accurancy:  0.9258393347263336 | Validation Accurancy:  0.9192001298069954\n",
      "Epoch:  5827 | Train Accurancy:  0.9258413538336754 | Validation Accurancy:  0.9192074537277222\n",
      "Epoch:  5828 | Train Accurancy:  0.9258433654904366 | Validation Accurancy:  0.9192140176892281\n",
      "Epoch:  5829 | Train Accurancy:  0.925845317542553 | Validation Accurancy:  0.9192214459180832\n",
      "Epoch:  5830 | Train Accurancy:  0.9258473441004753 | Validation Accurancy:  0.9192286878824234\n",
      "Epoch:  5831 | Train Accurancy:  0.9258493408560753 | Validation Accurancy:  0.9192354306578636\n",
      "Epoch:  5832 | Train Accurancy:  0.9258513003587723 | Validation Accurancy:  0.9192427024245262\n",
      "Epoch:  5833 | Train Accurancy:  0.9258532673120499 | Validation Accurancy:  0.9192499592900276\n",
      "Epoch:  5834 | Train Accurancy:  0.9258553013205528 | Validation Accurancy:  0.9192566350102425\n",
      "Epoch:  5835 | Train Accurancy:  0.925857275724411 | Validation Accurancy:  0.9192640036344528\n",
      "Epoch:  5836 | Train Accurancy:  0.9258592948317528 | Validation Accurancy:  0.9192711859941483\n",
      "Epoch:  5837 | Train Accurancy:  0.9258612617850304 | Validation Accurancy:  0.9192784577608109\n",
      "Epoch:  5838 | Train Accurancy:  0.9258632957935333 | Validation Accurancy:  0.9192849844694138\n",
      "Epoch:  5839 | Train Accurancy:  0.9258652478456497 | Validation Accurancy:  0.9192923605442047\n",
      "Epoch:  5840 | Train Accurancy:  0.9258672147989273 | Validation Accurancy:  0.9192996248602867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5841 | Train Accurancy:  0.9258692264556885 | Validation Accurancy:  0.9193062856793404\n",
      "Epoch:  5842 | Train Accurancy:  0.9258712157607079 | Validation Accurancy:  0.9193135499954224\n",
      "Epoch:  5843 | Train Accurancy:  0.925873190164566 | Validation Accurancy:  0.9193207249045372\n",
      "Epoch:  5844 | Train Accurancy:  0.9258751794695854 | Validation Accurancy:  0.9193273708224297\n",
      "Epoch:  5845 | Train Accurancy:  0.9258771762251854 | Validation Accurancy:  0.9193347170948982\n",
      "Epoch:  5846 | Train Accurancy:  0.9258791655302048 | Validation Accurancy:  0.9193420261144638\n",
      "Epoch:  5847 | Train Accurancy:  0.9258811101317406 | Validation Accurancy:  0.9193485602736473\n",
      "Epoch:  5848 | Train Accurancy:  0.9258830919861794 | Validation Accurancy:  0.9193559512495995\n",
      "Epoch:  5849 | Train Accurancy:  0.9258850738406181 | Validation Accurancy:  0.9193631485104561\n",
      "Epoch:  5850 | Train Accurancy:  0.9258871003985405 | Validation Accurancy:  0.9193698316812515\n",
      "Epoch:  5851 | Train Accurancy:  0.9258890450000763 | Validation Accurancy:  0.9193770065903664\n",
      "Epoch:  5852 | Train Accurancy:  0.9258910045027733 | Validation Accurancy:  0.9193843305110931\n",
      "Epoch:  5853 | Train Accurancy:  0.9258930012583733 | Validation Accurancy:  0.9193908795714378\n",
      "Epoch:  5854 | Train Accurancy:  0.925894983112812 | Validation Accurancy:  0.9193981811404228\n",
      "Epoch:  5855 | Train Accurancy:  0.9258969128131866 | Validation Accurancy:  0.9194054752588272\n",
      "Epoch:  5856 | Train Accurancy:  0.9258989468216896 | Validation Accurancy:  0.9194120988249779\n",
      "Epoch:  5857 | Train Accurancy:  0.9259009137749672 | Validation Accurancy:  0.9194193184375763\n",
      "Epoch:  5858 | Train Accurancy:  0.9259028658270836 | Validation Accurancy:  0.9194265380501747\n",
      "Epoch:  5859 | Train Accurancy:  0.9259048774838448 | Validation Accurancy:  0.9194332286715508\n",
      "Epoch:  5860 | Train Accurancy:  0.9259068071842194 | Validation Accurancy:  0.9194405004382133\n",
      "Epoch:  5861 | Train Accurancy:  0.9259087815880775 | Validation Accurancy:  0.919447660446167\n",
      "Epoch:  5862 | Train Accurancy:  0.9259107410907745 | Validation Accurancy:  0.9194543063640594\n",
      "Epoch:  5863 | Train Accurancy:  0.9259127303957939 | Validation Accurancy:  0.919461578130722\n",
      "Epoch:  5864 | Train Accurancy:  0.9259146824479103 | Validation Accurancy:  0.9194687455892563\n",
      "Epoch:  5865 | Train Accurancy:  0.9259166792035103 | Validation Accurancy:  0.9194754213094711\n",
      "Epoch:  5866 | Train Accurancy:  0.9259187057614326 | Validation Accurancy:  0.9194826632738113\n",
      "Epoch:  5867 | Train Accurancy:  0.9259206280112267 | Validation Accurancy:  0.9194898754358292\n",
      "Epoch:  5868 | Train Accurancy:  0.9259225353598595 | Validation Accurancy:  0.9194963946938515\n",
      "Epoch:  5869 | Train Accurancy:  0.92592453956604 | Validation Accurancy:  0.9195038080215454\n",
      "Epoch:  5870 | Train Accurancy:  0.92592653632164 | Validation Accurancy:  0.9195109233260155\n",
      "Epoch:  5871 | Train Accurancy:  0.925928495824337 | Validation Accurancy:  0.9195176288485527\n",
      "Epoch:  5872 | Train Accurancy:  0.9259304255247116 | Validation Accurancy:  0.9195248559117317\n",
      "Epoch:  5873 | Train Accurancy:  0.9259323999285698 | Validation Accurancy:  0.9195319637656212\n",
      "Epoch:  5874 | Train Accurancy:  0.9259343519806862 | Validation Accurancy:  0.9195385426282883\n",
      "Epoch:  5875 | Train Accurancy:  0.9259363114833832 | Validation Accurancy:  0.9195456951856613\n",
      "Epoch:  5876 | Train Accurancy:  0.9259382709860802 | Validation Accurancy:  0.9195530340075493\n",
      "Epoch:  5877 | Train Accurancy:  0.925940252840519 | Validation Accurancy:  0.9195595979690552\n",
      "Epoch:  5878 | Train Accurancy:  0.9259422197937965 | Validation Accurancy:  0.9195668324828148\n",
      "Epoch:  5879 | Train Accurancy:  0.9259441643953323 | Validation Accurancy:  0.9195740148425102\n",
      "Epoch:  5880 | Train Accurancy:  0.9259461015462875 | Validation Accurancy:  0.9195806458592415\n",
      "Epoch:  5881 | Train Accurancy:  0.9259481057524681 | Validation Accurancy:  0.9195878803730011\n",
      "Epoch:  5882 | Train Accurancy:  0.9259500727057457 | Validation Accurancy:  0.9195950701832771\n",
      "Epoch:  5883 | Train Accurancy:  0.9259520024061203 | Validation Accurancy:  0.9196020886301994\n",
      "Epoch:  5884 | Train Accurancy:  0.9259539544582367 | Validation Accurancy:  0.9196087121963501\n",
      "Epoch:  5885 | Train Accurancy:  0.9259559065103531 | Validation Accurancy:  0.9196158945560455\n",
      "Epoch:  5886 | Train Accurancy:  0.9259578436613083 | Validation Accurancy:  0.9196230620145798\n",
      "Epoch:  5887 | Train Accurancy:  0.9259598180651665 | Validation Accurancy:  0.9196296259760857\n",
      "Epoch:  5888 | Train Accurancy:  0.9259617701172829 | Validation Accurancy:  0.9196368455886841\n",
      "Epoch:  5889 | Train Accurancy:  0.9259637370705605 | Validation Accurancy:  0.9196440503001213\n",
      "Epoch:  5890 | Train Accurancy:  0.9259657487273216 | Validation Accurancy:  0.9196505919098854\n",
      "Epoch:  5891 | Train Accurancy:  0.9259676486253738 | Validation Accurancy:  0.9196577817201614\n",
      "Epoch:  5892 | Train Accurancy:  0.9259696155786514 | Validation Accurancy:  0.9196649938821793\n",
      "Epoch:  5893 | Train Accurancy:  0.925971508026123 | Validation Accurancy:  0.9196716099977493\n",
      "Epoch:  5894 | Train Accurancy:  0.9259734451770782 | Validation Accurancy:  0.9196788445115089\n",
      "Epoch:  5895 | Train Accurancy:  0.9259754121303558 | Validation Accurancy:  0.9196859374642372\n",
      "Epoch:  5896 | Train Accurancy:  0.9259773790836334 | Validation Accurancy:  0.9196924343705177\n",
      "Epoch:  5897 | Train Accurancy:  0.9259793385863304 | Validation Accurancy:  0.9196997359395027\n",
      "Epoch:  5898 | Train Accurancy:  0.9259812384843826 | Validation Accurancy:  0.9197068437933922\n",
      "Epoch:  5899 | Train Accurancy:  0.925983227789402 | Validation Accurancy:  0.9197133556008339\n",
      "Epoch:  5900 | Train Accurancy:  0.925985112786293 | Validation Accurancy:  0.9197205454111099\n",
      "Epoch:  5901 | Train Accurancy:  0.9259870871901512 | Validation Accurancy:  0.9197276681661606\n",
      "Epoch:  5902 | Train Accurancy:  0.9259890243411064 | Validation Accurancy:  0.9197342544794083\n",
      "Epoch:  5903 | Train Accurancy:  0.9259909689426422 | Validation Accurancy:  0.9197415560483932\n",
      "Epoch:  5904 | Train Accurancy:  0.9259928613901138 | Validation Accurancy:  0.9197486117482185\n",
      "Epoch:  5905 | Train Accurancy:  0.9259948506951332 | Validation Accurancy:  0.9197551235556602\n",
      "Epoch:  5906 | Train Accurancy:  0.9259968176484108 | Validation Accurancy:  0.9197623059153557\n",
      "Epoch:  5907 | Train Accurancy:  0.925998717546463 | Validation Accurancy:  0.9197695702314377\n",
      "Epoch:  5908 | Train Accurancy:  0.9260006919503212 | Validation Accurancy:  0.9197760745882988\n",
      "Epoch:  5909 | Train Accurancy:  0.9260026440024376 | Validation Accurancy:  0.9197832494974136\n",
      "Epoch:  5910 | Train Accurancy:  0.9260045289993286 | Validation Accurancy:  0.9197898730635643\n",
      "Epoch:  5911 | Train Accurancy:  0.9260065630078316 | Validation Accurancy:  0.9197970852255821\n",
      "Epoch:  5912 | Train Accurancy:  0.9260084256529808 | Validation Accurancy:  0.9198043048381805\n",
      "Epoch:  5913 | Train Accurancy:  0.9260103777050972 | Validation Accurancy:  0.9198107421398163\n",
      "Epoch:  5914 | Train Accurancy:  0.9260123074054718 | Validation Accurancy:  0.9198180064558983\n",
      "Epoch:  5915 | Train Accurancy:  0.9260142594575882 | Validation Accurancy:  0.9198251441121101\n",
      "Epoch:  5916 | Train Accurancy:  0.9260161593556404 | Validation Accurancy:  0.919831670820713\n",
      "Epoch:  5917 | Train Accurancy:  0.9260181039571762 | Validation Accurancy:  0.9198389053344727\n",
      "Epoch:  5918 | Train Accurancy:  0.926020011305809 | Validation Accurancy:  0.9198460131883621\n",
      "Epoch:  5919 | Train Accurancy:  0.9260219559073448 | Validation Accurancy:  0.9198525920510292\n",
      "Epoch:  5920 | Train Accurancy:  0.9260238856077194 | Validation Accurancy:  0.9198596626520157\n",
      "Epoch:  5921 | Train Accurancy:  0.9260258302092552 | Validation Accurancy:  0.9198667332530022\n",
      "Epoch:  5922 | Train Accurancy:  0.926027774810791 | Validation Accurancy:  0.9198732674121857\n",
      "Epoch:  5923 | Train Accurancy:  0.9260297194123268 | Validation Accurancy:  0.9198804572224617\n",
      "Epoch:  5924 | Train Accurancy:  0.9260315746068954 | Validation Accurancy:  0.919887587428093\n",
      "Epoch:  5925 | Train Accurancy:  0.92603350430727 | Validation Accurancy:  0.9198941737413406\n",
      "Epoch:  5926 | Train Accurancy:  0.9260354489088058 | Validation Accurancy:  0.9199012443423271\n",
      "Epoch:  5927 | Train Accurancy:  0.9260373413562775 | Validation Accurancy:  0.9199082851409912\n",
      "Epoch:  5928 | Train Accurancy:  0.9260392636060715 | Validation Accurancy:  0.9199148640036583\n",
      "Epoch:  5929 | Train Accurancy:  0.9260412156581879 | Validation Accurancy:  0.9199220687150955\n",
      "Epoch:  5930 | Train Accurancy:  0.9260431528091431 | Validation Accurancy:  0.9199291095137596\n",
      "Epoch:  5931 | Train Accurancy:  0.9260451048612595 | Validation Accurancy:  0.9199356064200401\n",
      "Epoch:  5932 | Train Accurancy:  0.9260469824075699 | Validation Accurancy:  0.9199427291750908\n",
      "Epoch:  5933 | Train Accurancy:  0.9260489270091057 | Validation Accurancy:  0.9199498817324638\n",
      "Epoch:  5934 | Train Accurancy:  0.9260508194565773 | Validation Accurancy:  0.9199563339352608\n",
      "Epoch:  5935 | Train Accurancy:  0.9260528013110161 | Validation Accurancy:  0.9199635535478592\n",
      "Epoch:  5936 | Train Accurancy:  0.9260546937584877 | Validation Accurancy:  0.9199700802564621\n",
      "Epoch:  5937 | Train Accurancy:  0.9260565936565399 | Validation Accurancy:  0.919977217912674\n",
      "Epoch:  5938 | Train Accurancy:  0.9260585233569145 | Validation Accurancy:  0.919984370470047\n",
      "Epoch:  5939 | Train Accurancy:  0.9260604158043861 | Validation Accurancy:  0.9199909344315529\n",
      "Epoch:  5940 | Train Accurancy:  0.9260623380541801 | Validation Accurancy:  0.9199980720877647\n",
      "Epoch:  5941 | Train Accurancy:  0.9260642677545547 | Validation Accurancy:  0.920005165040493\n",
      "Epoch:  5942 | Train Accurancy:  0.9260661974549294 | Validation Accurancy:  0.9200116470456123\n",
      "Epoch:  5943 | Train Accurancy:  0.9260680601000786 | Validation Accurancy:  0.9200187996029854\n",
      "Epoch:  5944 | Train Accurancy:  0.9260700419545174 | Validation Accurancy:  0.9200259074568748\n",
      "Epoch:  5945 | Train Accurancy:  0.9260719493031502 | Validation Accurancy:  0.9200323298573494\n",
      "Epoch:  5946 | Train Accurancy:  0.92607381939888 | Validation Accurancy:  0.9200395867228508\n",
      "Epoch:  5947 | Train Accurancy:  0.9260757490992546 | Validation Accurancy:  0.9200465381145477\n",
      "Epoch:  5948 | Train Accurancy:  0.9260776489973068 | Validation Accurancy:  0.9200529083609581\n",
      "Epoch:  5949 | Train Accurancy:  0.9260795935988426 | Validation Accurancy:  0.9200600907206535\n",
      "Epoch:  5950 | Train Accurancy:  0.926081471145153 | Validation Accurancy:  0.920067198574543\n",
      "Epoch:  5951 | Train Accurancy:  0.9260834231972694 | Validation Accurancy:  0.9200736805796623\n",
      "Epoch:  5952 | Train Accurancy:  0.9260853230953217 | Validation Accurancy:  0.9200807586312294\n",
      "Epoch:  5953 | Train Accurancy:  0.9260872602462769 | Validation Accurancy:  0.9200878143310547\n",
      "Epoch:  5954 | Train Accurancy:  0.9260891675949097 | Validation Accurancy:  0.9200943186879158\n",
      "Epoch:  5955 | Train Accurancy:  0.9260910451412201 | Validation Accurancy:  0.9201013892889023\n",
      "Epoch:  5956 | Train Accurancy:  0.9260929301381111 | Validation Accurancy:  0.9201079979538918\n",
      "Epoch:  5957 | Train Accurancy:  0.9260948523879051 | Validation Accurancy:  0.9201151207089424\n",
      "Epoch:  5958 | Train Accurancy:  0.9260967597365379 | Validation Accurancy:  0.9201221317052841\n",
      "Epoch:  5959 | Train Accurancy:  0.9260987043380737 | Validation Accurancy:  0.9201286658644676\n",
      "Epoch:  5960 | Train Accurancy:  0.9261005893349648 | Validation Accurancy:  0.9201358035206795\n",
      "Epoch:  5961 | Train Accurancy:  0.9261024296283722 | Validation Accurancy:  0.9201428443193436\n",
      "Epoch:  5962 | Train Accurancy:  0.926104374229908 | Validation Accurancy:  0.9201493114233017\n",
      "Epoch:  5963 | Train Accurancy:  0.9261062666773796 | Validation Accurancy:  0.9201564490795135\n",
      "Epoch:  5964 | Train Accurancy:  0.92610814422369 | Validation Accurancy:  0.9201634600758553\n",
      "Epoch:  5965 | Train Accurancy:  0.9261100590229034 | Validation Accurancy:  0.9201699569821358\n",
      "Epoch:  5966 | Train Accurancy:  0.9261119738221169 | Validation Accurancy:  0.9201770946383476\n",
      "Epoch:  5967 | Train Accurancy:  0.9261138439178467 | Validation Accurancy:  0.9201840534806252\n",
      "Epoch:  5968 | Train Accurancy:  0.9261157661676407 | Validation Accurancy:  0.9201905056834221\n",
      "Epoch:  5969 | Train Accurancy:  0.9261176139116287 | Validation Accurancy:  0.920197568833828\n",
      "Epoch:  5970 | Train Accurancy:  0.9261195659637451 | Validation Accurancy:  0.9202039912343025\n",
      "Epoch:  5971 | Train Accurancy:  0.926121398806572 | Validation Accurancy:  0.9202111586928368\n",
      "Epoch:  5972 | Train Accurancy:  0.9261232987046242 | Validation Accurancy:  0.9202181845903397\n",
      "Epoch:  5973 | Train Accurancy:  0.9261252656579018 | Validation Accurancy:  0.9202246218919754\n",
      "Epoch:  5974 | Train Accurancy:  0.9261271134018898 | Validation Accurancy:  0.9202316775918007\n",
      "Epoch:  5975 | Train Accurancy:  0.9261289983987808 | Validation Accurancy:  0.9202388301491737\n",
      "Epoch:  5976 | Train Accurancy:  0.9261308759450912 | Validation Accurancy:  0.9202452003955841\n",
      "Epoch:  5977 | Train Accurancy:  0.9261327609419823 | Validation Accurancy:  0.9202523231506348\n",
      "Epoch:  5978 | Train Accurancy:  0.9261347129940987 | Validation Accurancy:  0.9202593490481377\n",
      "Epoch:  5979 | Train Accurancy:  0.9261365905404091 | Validation Accurancy:  0.9202657714486122\n",
      "Epoch:  5980 | Train Accurancy:  0.9261384531855583 | Validation Accurancy:  0.9202728271484375\n",
      "Epoch:  5981 | Train Accurancy:  0.9261403530836105 | Validation Accurancy:  0.9202798679471016\n",
      "Epoch:  5982 | Train Accurancy:  0.9261422157287598 | Validation Accurancy:  0.9202863350510597\n",
      "Epoch:  5983 | Train Accurancy:  0.9261441379785538 | Validation Accurancy:  0.9202933982014656\n",
      "Epoch:  5984 | Train Accurancy:  0.9261460229754448 | Validation Accurancy:  0.9202998131513596\n",
      "Epoch:  5985 | Train Accurancy:  0.9261479005217552 | Validation Accurancy:  0.9203069359064102\n",
      "Epoch:  5986 | Train Accurancy:  0.9261497780680656 | Validation Accurancy:  0.9203139767050743\n",
      "Epoch:  5987 | Train Accurancy:  0.9261516779661179 | Validation Accurancy:  0.9203203395009041\n",
      "Epoch:  5988 | Train Accurancy:  0.9261535480618477 | Validation Accurancy:  0.9203275665640831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5989 | Train Accurancy:  0.9261554777622223 | Validation Accurancy:  0.920334480702877\n",
      "Epoch:  5990 | Train Accurancy:  0.9261573106050491 | Validation Accurancy:  0.920340970158577\n",
      "Epoch:  5991 | Train Accurancy:  0.9261592254042625 | Validation Accurancy:  0.9203480109572411\n",
      "Epoch:  5992 | Train Accurancy:  0.9261610731482506 | Validation Accurancy:  0.920354887843132\n",
      "Epoch:  5993 | Train Accurancy:  0.9261629730463028 | Validation Accurancy:  0.9203613772988319\n",
      "Epoch:  5994 | Train Accurancy:  0.9261648803949356 | Validation Accurancy:  0.920368418097496\n",
      "Epoch:  5995 | Train Accurancy:  0.9261667281389236 | Validation Accurancy:  0.9203748553991318\n",
      "Epoch:  5996 | Train Accurancy:  0.9261686280369759 | Validation Accurancy:  0.9203819781541824\n",
      "Epoch:  5997 | Train Accurancy:  0.9261705130338669 | Validation Accurancy:  0.9203889667987823\n",
      "Epoch:  5998 | Train Accurancy:  0.9261723831295967 | Validation Accurancy:  0.9203953593969345\n",
      "Epoch:  5999 | Train Accurancy:  0.9261742606759071 | Validation Accurancy:  0.9204024821519852\n",
      "Epoch:  6000 | Train Accurancy:  0.9261761382222176 | Validation Accurancy:  0.9204093962907791\n",
      "Epoch:  6001 | Train Accurancy:  0.9261779859662056 | Validation Accurancy:  0.920415922999382\n",
      "Epoch:  6002 | Train Accurancy:  0.9261798784136772 | Validation Accurancy:  0.9204228892922401\n",
      "Epoch:  6003 | Train Accurancy:  0.9261817634105682 | Validation Accurancy:  0.9204293712973595\n",
      "Epoch:  6004 | Train Accurancy:  0.9261836260557175 | Validation Accurancy:  0.9204364791512489\n",
      "Epoch:  6005 | Train Accurancy:  0.9261854961514473 | Validation Accurancy:  0.9204433932900429\n",
      "Epoch:  6006 | Train Accurancy:  0.9261873438954353 | Validation Accurancy:  0.9204498007893562\n",
      "Epoch:  6007 | Train Accurancy:  0.9261893033981323 | Validation Accurancy:  0.9204568192362785\n",
      "Epoch:  6008 | Train Accurancy:  0.9261911138892174 | Validation Accurancy:  0.9204638302326202\n",
      "Epoch:  6009 | Train Accurancy:  0.9261929839849472 | Validation Accurancy:  0.9204702377319336\n",
      "Epoch:  6010 | Train Accurancy:  0.9261948615312576 | Validation Accurancy:  0.9204772934317589\n",
      "Epoch:  6011 | Train Accurancy:  0.9261967316269875 | Validation Accurancy:  0.9204841330647469\n",
      "Epoch:  6012 | Train Accurancy:  0.9261986091732979 | Validation Accurancy:  0.9204905480146408\n",
      "Epoch:  6013 | Train Accurancy:  0.9262005090713501 | Validation Accurancy:  0.9204976558685303\n",
      "Epoch:  6014 | Train Accurancy:  0.9262023493647575 | Validation Accurancy:  0.9205040484666824\n",
      "Epoch:  6015 | Train Accurancy:  0.9262041747570038 | Validation Accurancy:  0.9205111190676689\n",
      "Epoch:  6016 | Train Accurancy:  0.9262060597538948 | Validation Accurancy:  0.9205180332064629\n",
      "Epoch:  6017 | Train Accurancy:  0.9262079373002052 | Validation Accurancy:  0.9205244854092598\n",
      "Epoch:  6018 | Train Accurancy:  0.9262097403407097 | Validation Accurancy:  0.9205315932631493\n",
      "Epoch:  6019 | Train Accurancy:  0.9262116253376007 | Validation Accurancy:  0.9205384105443954\n",
      "Epoch:  6020 | Train Accurancy:  0.9262135028839111 | Validation Accurancy:  0.9205448925495148\n",
      "Epoch:  6021 | Train Accurancy:  0.9262153878808022 | Validation Accurancy:  0.9205518215894699\n",
      "Epoch:  6022 | Train Accurancy:  0.9262172505259514 | Validation Accurancy:  0.9205583110451698\n",
      "Epoch:  6023 | Train Accurancy:  0.9262190759181976 | Validation Accurancy:  0.920565240085125\n",
      "Epoch:  6024 | Train Accurancy:  0.9262210056185722 | Validation Accurancy:  0.9205722957849503\n",
      "Epoch:  6025 | Train Accurancy:  0.9262228310108185 | Validation Accurancy:  0.9205787032842636\n",
      "Epoch:  6026 | Train Accurancy:  0.9262247085571289 | Validation Accurancy:  0.9205856770277023\n",
      "Epoch:  6027 | Train Accurancy:  0.9262265935540199 | Validation Accurancy:  0.9205925911664963\n",
      "Epoch:  6028 | Train Accurancy:  0.926228404045105 | Validation Accurancy:  0.9205989390611649\n",
      "Epoch:  6029 | Train Accurancy:  0.9262302368879318 | Validation Accurancy:  0.9206058979034424\n",
      "Epoch:  6030 | Train Accurancy:  0.926232136785984 | Validation Accurancy:  0.9206128567457199\n",
      "Epoch:  6031 | Train Accurancy:  0.9262339770793915 | Validation Accurancy:  0.9206192940473557\n",
      "Epoch:  6032 | Train Accurancy:  0.9262358769774437 | Validation Accurancy:  0.9206262081861496\n",
      "Epoch:  6033 | Train Accurancy:  0.9262376874685287 | Validation Accurancy:  0.9206325858831406\n",
      "Epoch:  6034 | Train Accurancy:  0.9262395277619362 | Validation Accurancy:  0.9206395968794823\n",
      "Epoch:  6035 | Train Accurancy:  0.9262414500117302 | Validation Accurancy:  0.9206465408205986\n",
      "Epoch:  6036 | Train Accurancy:  0.9262432083487511 | Validation Accurancy:  0.9206529334187508\n",
      "Epoch:  6037 | Train Accurancy:  0.9262451082468033 | Validation Accurancy:  0.9206599220633507\n",
      "Epoch:  6038 | Train Accurancy:  0.9262469783425331 | Validation Accurancy:  0.9206668883562088\n",
      "Epoch:  6039 | Train Accurancy:  0.9262488186359406 | Validation Accurancy:  0.9206731766462326\n",
      "Epoch:  6040 | Train Accurancy:  0.9262506738305092 | Validation Accurancy:  0.9206802025437355\n",
      "Epoch:  6041 | Train Accurancy:  0.9262525215744972 | Validation Accurancy:  0.9206865280866623\n",
      "Epoch:  6042 | Train Accurancy:  0.9262543171644211 | Validation Accurancy:  0.9206936359405518\n",
      "Epoch:  6043 | Train Accurancy:  0.9262561947107315 | Validation Accurancy:  0.9207005500793457\n",
      "Epoch:  6044 | Train Accurancy:  0.9262580648064613 | Validation Accurancy:  0.9207069054245949\n",
      "Epoch:  6045 | Train Accurancy:  0.92625992000103 | Validation Accurancy:  0.9207138046622276\n",
      "Epoch:  6046 | Train Accurancy:  0.9262617453932762 | Validation Accurancy:  0.9207207188010216\n",
      "Epoch:  6047 | Train Accurancy:  0.9262636378407478 | Validation Accurancy:  0.9207272231578827\n",
      "Epoch:  6048 | Train Accurancy:  0.9262654483318329 | Validation Accurancy:  0.9207341820001602\n",
      "Epoch:  6049 | Train Accurancy:  0.9262673109769821 | Validation Accurancy:  0.9207404479384422\n",
      "Epoch:  6050 | Train Accurancy:  0.9262691661715508 | Validation Accurancy:  0.9207475334405899\n",
      "Epoch:  6051 | Train Accurancy:  0.9262709692120552 | Validation Accurancy:  0.9207543656229973\n",
      "Epoch:  6052 | Train Accurancy:  0.9262727722525597 | Validation Accurancy:  0.9207607284188271\n",
      "Epoch:  6053 | Train Accurancy:  0.9262746423482895 | Validation Accurancy:  0.9207676723599434\n",
      "Epoch:  6054 | Train Accurancy:  0.9262765347957611 | Validation Accurancy:  0.9207747131586075\n",
      "Epoch:  6055 | Train Accurancy:  0.9262783452868462 | Validation Accurancy:  0.9207809418439865\n",
      "Epoch:  6056 | Train Accurancy:  0.9262801706790924 | Validation Accurancy:  0.920787937939167\n",
      "Epoch:  6057 | Train Accurancy:  0.9262820035219193 | Validation Accurancy:  0.9207941815257072\n",
      "Epoch:  6058 | Train Accurancy:  0.9262838214635849 | Validation Accurancy:  0.9208012595772743\n",
      "Epoch:  6059 | Train Accurancy:  0.9262857213616371 | Validation Accurancy:  0.9208081886172295\n",
      "Epoch:  6060 | Train Accurancy:  0.9262875467538834 | Validation Accurancy:  0.9208144471049309\n",
      "Epoch:  6061 | Train Accurancy:  0.9262893497943878 | Validation Accurancy:  0.9208214282989502\n",
      "Epoch:  6062 | Train Accurancy:  0.9262911900877953 | Validation Accurancy:  0.9208283424377441\n",
      "Epoch:  6063 | Train Accurancy:  0.9262930303812027 | Validation Accurancy:  0.9208346381783485\n",
      "Epoch:  6064 | Train Accurancy:  0.9262948781251907 | Validation Accurancy:  0.9208415821194649\n",
      "Epoch:  6065 | Train Accurancy:  0.9262967184185982 | Validation Accurancy:  0.920847974717617\n",
      "Epoch:  6066 | Train Accurancy:  0.9262985363602638 | Validation Accurancy:  0.9208549484610558\n",
      "Epoch:  6067 | Train Accurancy:  0.9263003915548325 | Validation Accurancy:  0.9208617359399796\n",
      "Epoch:  6068 | Train Accurancy:  0.9263022094964981 | Validation Accurancy:  0.9208680167794228\n",
      "Epoch:  6069 | Train Accurancy:  0.9263041093945503 | Validation Accurancy:  0.9208749905228615\n",
      "Epoch:  6070 | Train Accurancy:  0.9263059124350548 | Validation Accurancy:  0.9208819195628166\n",
      "Epoch:  6071 | Train Accurancy:  0.9263077452778816 | Validation Accurancy:  0.9208882004022598\n",
      "Epoch:  6072 | Train Accurancy:  0.9263095632195473 | Validation Accurancy:  0.920895166695118\n",
      "Epoch:  6073 | Train Accurancy:  0.9263113364577293 | Validation Accurancy:  0.9209015220403671\n",
      "Epoch:  6074 | Train Accurancy:  0.9263131767511368 | Validation Accurancy:  0.9209084212779999\n",
      "Epoch:  6075 | Train Accurancy:  0.926315002143383 | Validation Accurancy:  0.920915350317955\n",
      "Epoch:  6076 | Train Accurancy:  0.9263168573379517 | Validation Accurancy:  0.9209216758608818\n",
      "Epoch:  6077 | Train Accurancy:  0.9263186827301979 | Validation Accurancy:  0.9209286198019981\n",
      "Epoch:  6078 | Train Accurancy:  0.9263205081224442 | Validation Accurancy:  0.9209354743361473\n",
      "Epoch:  6079 | Train Accurancy:  0.9263223260641098 | Validation Accurancy:  0.920941635966301\n",
      "Epoch:  6080 | Train Accurancy:  0.9263241663575172 | Validation Accurancy:  0.9209486320614815\n",
      "Epoch:  6081 | Train Accurancy:  0.9263259992003441 | Validation Accurancy:  0.9209549576044083\n",
      "Epoch:  6082 | Train Accurancy:  0.9263278096914291 | Validation Accurancy:  0.92096196860075\n",
      "Epoch:  6083 | Train Accurancy:  0.9263296201825142 | Validation Accurancy:  0.9209687262773514\n",
      "Epoch:  6084 | Train Accurancy:  0.9263314679265022 | Validation Accurancy:  0.9209750667214394\n",
      "Epoch:  6085 | Train Accurancy:  0.9263332337141037 | Validation Accurancy:  0.9209819957613945\n",
      "Epoch:  6086 | Train Accurancy:  0.9263351336121559 | Validation Accurancy:  0.9209883064031601\n",
      "Epoch:  6087 | Train Accurancy:  0.9263369143009186 | Validation Accurancy:  0.9209952056407928\n",
      "Epoch:  6088 | Train Accurancy:  0.9263387471437454 | Validation Accurancy:  0.9210021644830704\n",
      "Epoch:  6089 | Train Accurancy:  0.9263406023383141 | Validation Accurancy:  0.9210083931684494\n",
      "Epoch:  6090 | Train Accurancy:  0.9263423308730125 | Validation Accurancy:  0.9210152924060822\n",
      "Epoch:  6091 | Train Accurancy:  0.926344208419323 | Validation Accurancy:  0.9210221096873283\n",
      "Epoch:  6092 | Train Accurancy:  0.9263460412621498 | Validation Accurancy:  0.9210284724831581\n",
      "Epoch:  6093 | Train Accurancy:  0.9263478368520737 | Validation Accurancy:  0.9210353344678879\n",
      "Epoch:  6094 | Train Accurancy:  0.9263496175408363 | Validation Accurancy:  0.9210416153073311\n",
      "Epoch:  6095 | Train Accurancy:  0.9263514429330826 | Validation Accurancy:  0.9210485145449638\n",
      "Epoch:  6096 | Train Accurancy:  0.9263533055782318 | Validation Accurancy:  0.921055443584919\n",
      "Epoch:  6097 | Train Accurancy:  0.9263550788164139 | Validation Accurancy:  0.9210616871714592\n",
      "Epoch:  6098 | Train Accurancy:  0.9263568967580795 | Validation Accurancy:  0.9210685715079308\n",
      "Epoch:  6099 | Train Accurancy:  0.9263587221503258 | Validation Accurancy:  0.9210749343037605\n",
      "Epoch:  6100 | Train Accurancy:  0.9263605177402496 | Validation Accurancy:  0.9210818260908127\n",
      "Epoch:  6101 | Train Accurancy:  0.9263623729348183 | Validation Accurancy:  0.921088695526123\n",
      "Epoch:  6102 | Train Accurancy:  0.9263641461730003 | Validation Accurancy:  0.9210949242115021\n",
      "Epoch:  6103 | Train Accurancy:  0.9263659566640854 | Validation Accurancy:  0.9211017787456512\n",
      "Epoch:  6104 | Train Accurancy:  0.9263677671551704 | Validation Accurancy:  0.9211080074310303\n",
      "Epoch:  6105 | Train Accurancy:  0.9263695701956749 | Validation Accurancy:  0.9211150482296944\n",
      "Epoch:  6106 | Train Accurancy:  0.9263713657855988 | Validation Accurancy:  0.9211219325661659\n",
      "Epoch:  6107 | Train Accurancy:  0.9263732209801674 | Validation Accurancy:  0.9211280792951584\n",
      "Epoch:  6108 | Train Accurancy:  0.9263750463724136 | Validation Accurancy:  0.9211349934339523\n",
      "Epoch:  6109 | Train Accurancy:  0.9263768419623375 | Validation Accurancy:  0.9211412593722343\n",
      "Epoch:  6110 | Train Accurancy:  0.9263786152005196 | Validation Accurancy:  0.9211480766534805\n",
      "Epoch:  6111 | Train Accurancy:  0.9263804778456688 | Validation Accurancy:  0.9211550429463387\n",
      "Epoch:  6112 | Train Accurancy:  0.9263822287321091 | Validation Accurancy:  0.9211613014340401\n",
      "Epoch:  6113 | Train Accurancy:  0.9263840541243553 | Validation Accurancy:  0.9211681708693504\n",
      "Epoch:  6114 | Train Accurancy:  0.9263858497142792 | Validation Accurancy:  0.9211748912930489\n",
      "Epoch:  6115 | Train Accurancy:  0.9263876006007195 | Validation Accurancy:  0.9211812019348145\n",
      "Epoch:  6116 | Train Accurancy:  0.9263894632458687 | Validation Accurancy:  0.9211880713701248\n",
      "Epoch:  6117 | Train Accurancy:  0.9263912662863731 | Validation Accurancy:  0.9211943969130516\n",
      "Epoch:  6118 | Train Accurancy:  0.926393061876297 | Validation Accurancy:  0.9212012588977814\n",
      "Epoch:  6119 | Train Accurancy:  0.9263948202133179 | Validation Accurancy:  0.9212080985307693\n",
      "Epoch:  6120 | Train Accurancy:  0.9263966530561447 | Validation Accurancy:  0.9212142154574394\n",
      "Epoch:  6121 | Train Accurancy:  0.9263984709978104 | Validation Accurancy:  0.9212211892008781\n",
      "Epoch:  6122 | Train Accurancy:  0.9264002367854118 | Validation Accurancy:  0.9212274700403214\n",
      "Epoch:  6123 | Train Accurancy:  0.9264020845293999 | Validation Accurancy:  0.9212343022227287\n",
      "Epoch:  6124 | Train Accurancy:  0.9264038130640984 | Validation Accurancy:  0.9212411269545555\n",
      "Epoch:  6125 | Train Accurancy:  0.9264056384563446 | Validation Accurancy:  0.921247310936451\n",
      "Epoch:  6126 | Train Accurancy:  0.9264073818922043 | Validation Accurancy:  0.9212541729211807\n",
      "Epoch:  6127 | Train Accurancy:  0.9264092370867729 | Validation Accurancy:  0.9212604835629463\n",
      "Epoch:  6128 | Train Accurancy:  0.9264110252261162 | Validation Accurancy:  0.9212673529982567\n",
      "Epoch:  6129 | Train Accurancy:  0.9264127537608147 | Validation Accurancy:  0.9212741404771805\n",
      "Epoch:  6130 | Train Accurancy:  0.9264145866036415 | Validation Accurancy:  0.9212803989648819\n",
      "Epoch:  6131 | Train Accurancy:  0.9264164492487907 | Validation Accurancy:  0.9212872684001923\n",
      "Epoch:  6132 | Train Accurancy:  0.926418200135231 | Validation Accurancy:  0.9212940186262131\n",
      "Epoch:  6133 | Train Accurancy:  0.9264199957251549 | Validation Accurancy:  0.9213001877069473\n",
      "Epoch:  6134 | Train Accurancy:  0.9264217764139175 | Validation Accurancy:  0.9213071018457413\n",
      "Epoch:  6135 | Train Accurancy:  0.9264235720038414 | Validation Accurancy:  0.9213131442666054\n",
      "Epoch:  6136 | Train Accurancy:  0.9264253154397011 | Validation Accurancy:  0.9213201701641083\n",
      "Epoch:  6137 | Train Accurancy:  0.9264272004365921 | Validation Accurancy:  0.9213268905878067\n",
      "Epoch:  6138 | Train Accurancy:  0.9264289513230324 | Validation Accurancy:  0.9213331714272499\n",
      "Epoch:  6139 | Train Accurancy:  0.9264307394623756 | Validation Accurancy:  0.9213400334119797\n",
      "Epoch:  6140 | Train Accurancy:  0.9264325201511383 | Validation Accurancy:  0.9213462695479393\n",
      "Epoch:  6141 | Train Accurancy:  0.9264343231916428 | Validation Accurancy:  0.9213531464338303\n",
      "Epoch:  6142 | Train Accurancy:  0.9264360889792442 | Validation Accurancy:  0.9213598743081093\n",
      "Epoch:  6143 | Train Accurancy:  0.9264378324151039 | Validation Accurancy:  0.9213660880923271\n",
      "Epoch:  6144 | Train Accurancy:  0.9264396727085114 | Validation Accurancy:  0.9213729351758957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6145 | Train Accurancy:  0.9264414235949516 | Validation Accurancy:  0.9213792458176613\n",
      "Epoch:  6146 | Train Accurancy:  0.9264432564377785 | Validation Accurancy:  0.9213861003518105\n",
      "Epoch:  6147 | Train Accurancy:  0.926444984972477 | Validation Accurancy:  0.9213927611708641\n",
      "Epoch:  6148 | Train Accurancy:  0.9264468103647232 | Validation Accurancy:  0.9213988929986954\n",
      "Epoch:  6149 | Train Accurancy:  0.9264486506581306 | Validation Accurancy:  0.9214056953787804\n",
      "Epoch:  6150 | Train Accurancy:  0.9264503940939903 | Validation Accurancy:  0.921412006020546\n",
      "Epoch:  6151 | Train Accurancy:  0.9264521598815918 | Validation Accurancy:  0.9214188605546951\n",
      "Epoch:  6152 | Train Accurancy:  0.9264539629220963 | Validation Accurancy:  0.9214256629347801\n",
      "Epoch:  6153 | Train Accurancy:  0.9264557510614395 | Validation Accurancy:  0.9214318916201591\n",
      "Epoch:  6154 | Train Accurancy:  0.926457516849041 | Validation Accurancy:  0.9214386269450188\n",
      "Epoch:  6155 | Train Accurancy:  0.9264592677354813 | Validation Accurancy:  0.9214448630809784\n",
      "Epoch:  6156 | Train Accurancy:  0.9264610856771469 | Validation Accurancy:  0.9214516803622246\n",
      "Epoch:  6157 | Train Accurancy:  0.926462821662426 | Validation Accurancy:  0.9214585274457932\n",
      "Epoch:  6158 | Train Accurancy:  0.9264646098017693 | Validation Accurancy:  0.9214646816253662\n",
      "Epoch:  6159 | Train Accurancy:  0.9264663979411125 | Validation Accurancy:  0.9214714244008064\n",
      "Epoch:  6160 | Train Accurancy:  0.9264681711792946 | Validation Accurancy:  0.921477697789669\n",
      "Epoch:  6161 | Train Accurancy:  0.9264699593186378 | Validation Accurancy:  0.9214844405651093\n",
      "Epoch:  6162 | Train Accurancy:  0.9264716804027557 | Validation Accurancy:  0.9214912727475166\n",
      "Epoch:  6163 | Train Accurancy:  0.9264735132455826 | Validation Accurancy:  0.9214973598718643\n",
      "Epoch:  6164 | Train Accurancy:  0.9264752864837646 | Validation Accurancy:  0.9215042442083359\n",
      "Epoch:  6165 | Train Accurancy:  0.9264770448207855 | Validation Accurancy:  0.9215104579925537\n",
      "Epoch:  6166 | Train Accurancy:  0.9264787808060646 | Validation Accurancy:  0.9215173274278641\n",
      "Epoch:  6167 | Train Accurancy:  0.9264806061983109 | Validation Accurancy:  0.9215240925550461\n",
      "Epoch:  6168 | Train Accurancy:  0.9264823645353317 | Validation Accurancy:  0.9215301349759102\n",
      "Epoch:  6169 | Train Accurancy:  0.9264841079711914 | Validation Accurancy:  0.9215369522571564\n",
      "Epoch:  6170 | Train Accurancy:  0.9264859035611153 | Validation Accurancy:  0.9215431213378906\n",
      "Epoch:  6171 | Train Accurancy:  0.926487646996975 | Validation Accurancy:  0.9215498641133308\n",
      "Epoch:  6172 | Train Accurancy:  0.9264894351363182 | Validation Accurancy:  0.9215565696358681\n",
      "Epoch:  6173 | Train Accurancy:  0.9264911711215973 | Validation Accurancy:  0.9215627536177635\n",
      "Epoch:  6174 | Train Accurancy:  0.9264929965138435 | Validation Accurancy:  0.9215695038437843\n",
      "Epoch:  6175 | Train Accurancy:  0.926494799554348 | Validation Accurancy:  0.9215757548809052\n",
      "Epoch:  6176 | Train Accurancy:  0.9264964833855629 | Validation Accurancy:  0.9215824902057648\n",
      "Epoch:  6177 | Train Accurancy:  0.9264982268214226 | Validation Accurancy:  0.9215887039899826\n",
      "Epoch:  6178 | Train Accurancy:  0.926499992609024 | Validation Accurancy:  0.9215955287218094\n",
      "Epoch:  6179 | Train Accurancy:  0.9265017509460449 | Validation Accurancy:  0.9216017574071884\n",
      "Epoch:  6180 | Train Accurancy:  0.9265035539865494 | Validation Accurancy:  0.9216084778308868\n",
      "Epoch:  6181 | Train Accurancy:  0.9265052899718285 | Validation Accurancy:  0.921615295112133\n",
      "Epoch:  6182 | Train Accurancy:  0.9265071079134941 | Validation Accurancy:  0.9216214790940285\n",
      "Epoch:  6183 | Train Accurancy:  0.9265088364481926 | Validation Accurancy:  0.9216282367706299\n",
      "Epoch:  6184 | Train Accurancy:  0.9265106171369553 | Validation Accurancy:  0.9216344505548477\n",
      "Epoch:  6185 | Train Accurancy:  0.9265123382210732 | Validation Accurancy:  0.9216412678360939\n",
      "Epoch:  6186 | Train Accurancy:  0.9265141114592552 | Validation Accurancy:  0.921647422015667\n",
      "Epoch:  6187 | Train Accurancy:  0.9265158399939537 | Validation Accurancy:  0.9216542094945908\n",
      "Epoch:  6188 | Train Accurancy:  0.9265176132321358 | Validation Accurancy:  0.9216604381799698\n",
      "Epoch:  6189 | Train Accurancy:  0.9265193715691566 | Validation Accurancy:  0.9216671958565712\n",
      "Epoch:  6190 | Train Accurancy:  0.9265211671590805 | Validation Accurancy:  0.9216734394431114\n",
      "Epoch:  6191 | Train Accurancy:  0.9265228882431984 | Validation Accurancy:  0.9216802939772606\n",
      "Epoch:  6192 | Train Accurancy:  0.9265246167778969 | Validation Accurancy:  0.9216864258050919\n",
      "Epoch:  6193 | Train Accurancy:  0.9265264421701431 | Validation Accurancy:  0.92169339209795\n",
      "Epoch:  6194 | Train Accurancy:  0.9265281930565834 | Validation Accurancy:  0.921700082719326\n",
      "Epoch:  6195 | Train Accurancy:  0.9265299141407013 | Validation Accurancy:  0.9217061325907707\n",
      "Epoch:  6196 | Train Accurancy:  0.9265316873788834 | Validation Accurancy:  0.9217129573225975\n",
      "Epoch:  6197 | Train Accurancy:  0.9265334904193878 | Validation Accurancy:  0.9217191562056541\n",
      "Epoch:  6198 | Train Accurancy:  0.9265352115035057 | Validation Accurancy:  0.9217258617281914\n",
      "Epoch:  6199 | Train Accurancy:  0.9265369698405266 | Validation Accurancy:  0.9217320904135704\n",
      "Epoch:  6200 | Train Accurancy:  0.9265386909246445 | Validation Accurancy:  0.9217388331890106\n",
      "Epoch:  6201 | Train Accurancy:  0.9265404269099236 | Validation Accurancy:  0.9217450469732285\n",
      "Epoch:  6202 | Train Accurancy:  0.926542192697525 | Validation Accurancy:  0.9217518493533134\n",
      "Epoch:  6203 | Train Accurancy:  0.9265439361333847 | Validation Accurancy:  0.9217580631375313\n",
      "Epoch:  6204 | Train Accurancy:  0.9265456944704056 | Validation Accurancy:  0.9217648059129715\n",
      "Epoch:  6205 | Train Accurancy:  0.9265474379062653 | Validation Accurancy:  0.9217709675431252\n",
      "Epoch:  6206 | Train Accurancy:  0.9265491813421249 | Validation Accurancy:  0.9217778220772743\n",
      "Epoch:  6207 | Train Accurancy:  0.9265509471297264 | Validation Accurancy:  0.9217844977974892\n",
      "Epoch:  6208 | Train Accurancy:  0.9265526682138443 | Validation Accurancy:  0.9217905849218369\n",
      "Epoch:  6209 | Train Accurancy:  0.9265544191002846 | Validation Accurancy:  0.9217972904443741\n",
      "Epoch:  6210 | Train Accurancy:  0.9265561476349831 | Validation Accurancy:  0.9218034446239471\n",
      "Epoch:  6211 | Train Accurancy:  0.9265579208731651 | Validation Accurancy:  0.9218102321028709\n",
      "Epoch:  6212 | Train Accurancy:  0.9265596494078636 | Validation Accurancy:  0.9218164160847664\n",
      "Epoch:  6213 | Train Accurancy:  0.9265614077448845 | Validation Accurancy:  0.9218232184648514\n",
      "Epoch:  6214 | Train Accurancy:  0.9265631437301636 | Validation Accurancy:  0.9218293502926826\n",
      "Epoch:  6215 | Train Accurancy:  0.9265648946166039 | Validation Accurancy:  0.9218360558152199\n",
      "Epoch:  6216 | Train Accurancy:  0.9265666007995605 | Validation Accurancy:  0.9218423217535019\n",
      "Epoch:  6217 | Train Accurancy:  0.9265683963894844 | Validation Accurancy:  0.9218491092324257\n",
      "Epoch:  6218 | Train Accurancy:  0.9265701249241829 | Validation Accurancy:  0.9218553081154823\n",
      "Epoch:  6219 | Train Accurancy:  0.9265718683600426 | Validation Accurancy:  0.9218620583415031\n",
      "Epoch:  6220 | Train Accurancy:  0.9265735968947411 | Validation Accurancy:  0.921868197619915\n",
      "Epoch:  6221 | Train Accurancy:  0.9265753105282784 | Validation Accurancy:  0.9218750819563866\n",
      "Epoch:  6222 | Train Accurancy:  0.926577053964138 | Validation Accurancy:  0.9218811318278313\n",
      "Epoch:  6223 | Train Accurancy:  0.9265787973999977 | Validation Accurancy:  0.9218879416584969\n",
      "Epoch:  6224 | Train Accurancy:  0.9265805259346962 | Validation Accurancy:  0.9218945652246475\n",
      "Epoch:  6225 | Train Accurancy:  0.9265822917222977 | Validation Accurancy:  0.9219006672501564\n",
      "Epoch:  6226 | Train Accurancy:  0.9265839830040932 | Validation Accurancy:  0.9219073802232742\n",
      "Epoch:  6227 | Train Accurancy:  0.9265857562422752 | Validation Accurancy:  0.9219135120511055\n",
      "Epoch:  6228 | Train Accurancy:  0.9265874773263931 | Validation Accurancy:  0.9219202697277069\n",
      "Epoch:  6229 | Train Accurancy:  0.9265892505645752 | Validation Accurancy:  0.9219264015555382\n",
      "Epoch:  6230 | Train Accurancy:  0.9265909492969513 | Validation Accurancy:  0.921933077275753\n",
      "Epoch:  6231 | Train Accurancy:  0.9265926778316498 | Validation Accurancy:  0.9219392910599709\n",
      "Epoch:  6232 | Train Accurancy:  0.9265944212675095 | Validation Accurancy:  0.9219459667801857\n",
      "Epoch:  6233 | Train Accurancy:  0.9265961796045303 | Validation Accurancy:  0.9219522178173065\n",
      "Epoch:  6234 | Train Accurancy:  0.9265979006886482 | Validation Accurancy:  0.9219589382410049\n",
      "Epoch:  6235 | Train Accurancy:  0.9265996292233467 | Validation Accurancy:  0.921965092420578\n",
      "Epoch:  6236 | Train Accurancy:  0.9266013577580452 | Validation Accurancy:  0.9219717979431152\n",
      "Epoch:  6237 | Train Accurancy:  0.9266030564904213 | Validation Accurancy:  0.9219784736633301\n",
      "Epoch:  6238 | Train Accurancy:  0.9266048148274422 | Validation Accurancy:  0.9219844788312912\n",
      "Epoch:  6239 | Train Accurancy:  0.9266065508127213 | Validation Accurancy:  0.921991154551506\n",
      "Epoch:  6240 | Train Accurancy:  0.9266082942485809 | Validation Accurancy:  0.9219972416758537\n",
      "Epoch:  6241 | Train Accurancy:  0.926609992980957 | Validation Accurancy:  0.9220040291547775\n",
      "Epoch:  6242 | Train Accurancy:  0.9266117364168167 | Validation Accurancy:  0.922010213136673\n",
      "Epoch:  6243 | Train Accurancy:  0.9266134649515152 | Validation Accurancy:  0.9220169261097908\n",
      "Epoch:  6244 | Train Accurancy:  0.9266152158379555 | Validation Accurancy:  0.9220229908823967\n",
      "Epoch:  6245 | Train Accurancy:  0.926616907119751 | Validation Accurancy:  0.9220297485589981\n",
      "Epoch:  6246 | Train Accurancy:  0.9266186431050301 | Validation Accurancy:  0.9220359027385712\n",
      "Epoch:  6247 | Train Accurancy:  0.9266203567385674 | Validation Accurancy:  0.9220424667000771\n",
      "Epoch:  6248 | Train Accurancy:  0.926622062921524 | Validation Accurancy:  0.9220486953854561\n",
      "Epoch:  6249 | Train Accurancy:  0.9266238287091255 | Validation Accurancy:  0.9220554530620575\n",
      "Epoch:  6250 | Train Accurancy:  0.9266255050897598 | Validation Accurancy:  0.9220615550875664\n",
      "Epoch:  6251 | Train Accurancy:  0.9266272485256195 | Validation Accurancy:  0.9220682755112648\n",
      "Epoch:  6252 | Train Accurancy:  0.926628977060318 | Validation Accurancy:  0.9220748916268349\n",
      "Epoch:  6253 | Train Accurancy:  0.9266306906938553 | Validation Accurancy:  0.9220810905098915\n",
      "Epoch:  6254 | Train Accurancy:  0.9266323745250702 | Validation Accurancy:  0.9220877140760422\n",
      "Epoch:  6255 | Train Accurancy:  0.9266341552138329 | Validation Accurancy:  0.9220938012003899\n",
      "Epoch:  6256 | Train Accurancy:  0.9266358315944672 | Validation Accurancy:  0.9221004173159599\n",
      "Epoch:  6257 | Train Accurancy:  0.9266375824809074 | Validation Accurancy:  0.9221066012978554\n",
      "Epoch:  6258 | Train Accurancy:  0.9266392663121223 | Validation Accurancy:  0.922113262116909\n",
      "Epoch:  6259 | Train Accurancy:  0.9266409873962402 | Validation Accurancy:  0.9221192970871925\n",
      "Epoch:  6260 | Train Accurancy:  0.9266427457332611 | Validation Accurancy:  0.9221260100603104\n",
      "Epoch:  6261 | Train Accurancy:  0.9266444444656372 | Validation Accurancy:  0.9221322536468506\n",
      "Epoch:  6262 | Train Accurancy:  0.9266461208462715 | Validation Accurancy:  0.9221389144659042\n",
      "Epoch:  6263 | Train Accurancy:  0.926647886633873 | Validation Accurancy:  0.9221449568867683\n",
      "Epoch:  6264 | Train Accurancy:  0.9266496077179909 | Validation Accurancy:  0.9221516475081444\n",
      "Epoch:  6265 | Train Accurancy:  0.9266513288021088 | Validation Accurancy:  0.9221577793359756\n",
      "Epoch:  6266 | Train Accurancy:  0.9266530051827431 | Validation Accurancy:  0.9221645072102547\n",
      "Epoch:  6267 | Train Accurancy:  0.9266547858715057 | Validation Accurancy:  0.9221707060933113\n",
      "Epoch:  6268 | Train Accurancy:  0.9266564026474953 | Validation Accurancy:  0.9221772849559784\n",
      "Epoch:  6269 | Train Accurancy:  0.926658146083355 | Validation Accurancy:  0.9221838638186455\n",
      "Epoch:  6270 | Train Accurancy:  0.9266599044203758 | Validation Accurancy:  0.9221898689866066\n",
      "Epoch:  6271 | Train Accurancy:  0.9266615957021713 | Validation Accurancy:  0.9221965000033379\n",
      "Epoch:  6272 | Train Accurancy:  0.9266633093357086 | Validation Accurancy:  0.9222025722265244\n",
      "Epoch:  6273 | Train Accurancy:  0.9266650006175041 | Validation Accurancy:  0.9222094193100929\n",
      "Epoch:  6274 | Train Accurancy:  0.926666721701622 | Validation Accurancy:  0.9222154468297958\n",
      "Epoch:  6275 | Train Accurancy:  0.9266683533787727 | Validation Accurancy:  0.9222220405936241\n",
      "Epoch:  6276 | Train Accurancy:  0.9266700893640518 | Validation Accurancy:  0.9222281649708748\n",
      "Epoch:  6277 | Train Accurancy:  0.9266718477010727 | Validation Accurancy:  0.9222347885370255\n",
      "Epoch:  6278 | Train Accurancy:  0.9266735687851906 | Validation Accurancy:  0.9222409054636955\n",
      "Epoch:  6279 | Train Accurancy:  0.9266752153635025 | Validation Accurancy:  0.9222475364804268\n",
      "Epoch:  6280 | Train Accurancy:  0.926676943898201 | Validation Accurancy:  0.9222536757588387\n",
      "Epoch:  6281 | Train Accurancy:  0.9266786500811577 | Validation Accurancy:  0.9222603812813759\n",
      "Epoch:  6282 | Train Accurancy:  0.9266803562641144 | Validation Accurancy:  0.9222664386034012\n",
      "Epoch:  6283 | Train Accurancy:  0.9266820177435875 | Validation Accurancy:  0.9222731292247772\n",
      "Epoch:  6284 | Train Accurancy:  0.9266838133335114 | Validation Accurancy:  0.9222791865468025\n",
      "Epoch:  6285 | Train Accurancy:  0.9266854748129845 | Validation Accurancy:  0.9222858399152756\n",
      "Epoch:  6286 | Train Accurancy:  0.9266871362924576 | Validation Accurancy:  0.922292061150074\n",
      "Epoch:  6287 | Train Accurancy:  0.9266888424754143 | Validation Accurancy:  0.9222985729575157\n",
      "Epoch:  6288 | Train Accurancy:  0.9266905784606934 | Validation Accurancy:  0.9223053008317947\n",
      "Epoch:  6289 | Train Accurancy:  0.9266923293471336 | Validation Accurancy:  0.9223111942410469\n",
      "Epoch:  6290 | Train Accurancy:  0.9266940057277679 | Validation Accurancy:  0.922317810356617\n",
      "Epoch:  6291 | Train Accurancy:  0.9266956746578217 | Validation Accurancy:  0.9223238602280617\n",
      "Epoch:  6292 | Train Accurancy:  0.9266973659396172 | Validation Accurancy:  0.9223305508494377\n",
      "Epoch:  6293 | Train Accurancy:  0.926699087023735 | Validation Accurancy:  0.922336533665657\n",
      "Epoch:  6294 | Train Accurancy:  0.9267007187008858 | Validation Accurancy:  0.9223433211445808\n",
      "Epoch:  6295 | Train Accurancy:  0.9267024472355843 | Validation Accurancy:  0.9223492443561554\n",
      "Epoch:  6296 | Train Accurancy:  0.9267041459679604 | Validation Accurancy:  0.9223558455705643\n",
      "Epoch:  6297 | Train Accurancy:  0.9267058596014977 | Validation Accurancy:  0.9223619624972343\n",
      "Epoch:  6298 | Train Accurancy:  0.9267075508832932 | Validation Accurancy:  0.9223686084151268\n",
      "Epoch:  6299 | Train Accurancy:  0.9267092570662498 | Validation Accurancy:  0.9223746433854103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6300 | Train Accurancy:  0.926710955798626 | Validation Accurancy:  0.9223812445998192\n",
      "Epoch:  6301 | Train Accurancy:  0.9267126321792603 | Validation Accurancy:  0.9223874062299728\n",
      "Epoch:  6302 | Train Accurancy:  0.9267143160104752 | Validation Accurancy:  0.9223939701914787\n",
      "Epoch:  6303 | Train Accurancy:  0.9267159923911095 | Validation Accurancy:  0.922400064766407\n",
      "Epoch:  6304 | Train Accurancy:  0.9267177060246468 | Validation Accurancy:  0.9224067032337189\n",
      "Epoch:  6305 | Train Accurancy:  0.9267194047570229 | Validation Accurancy:  0.9224131926894188\n",
      "Epoch:  6306 | Train Accurancy:  0.9267210811376572 | Validation Accurancy:  0.9224192276597023\n",
      "Epoch:  6307 | Train Accurancy:  0.9267228171229362 | Validation Accurancy:  0.9224258586764336\n",
      "Epoch:  6308 | Train Accurancy:  0.9267244786024094 | Validation Accurancy:  0.9224318191409111\n",
      "Epoch:  6309 | Train Accurancy:  0.9267261773347855 | Validation Accurancy:  0.9224384650588036\n",
      "Epoch:  6310 | Train Accurancy:  0.9267278462648392 | Validation Accurancy:  0.9224444404244423\n",
      "Epoch:  6311 | Train Accurancy:  0.9267295375466347 | Validation Accurancy:  0.9224511459469795\n",
      "Epoch:  6312 | Train Accurancy:  0.9267312660813332 | Validation Accurancy:  0.9224571511149406\n",
      "Epoch:  6313 | Train Accurancy:  0.9267328977584839 | Validation Accurancy:  0.9224637672305107\n",
      "Epoch:  6314 | Train Accurancy:  0.9267346486449242 | Validation Accurancy:  0.922469787299633\n",
      "Epoch:  6315 | Train Accurancy:  0.9267363101243973 | Validation Accurancy:  0.9224764853715897\n",
      "Epoch:  6316 | Train Accurancy:  0.926737941801548 | Validation Accurancy:  0.9224824756383896\n",
      "Epoch:  6317 | Train Accurancy:  0.9267396703362465 | Validation Accurancy:  0.9224891364574432\n",
      "Epoch:  6318 | Train Accurancy:  0.9267413839697838 | Validation Accurancy:  0.9224952384829521\n",
      "Epoch:  6319 | Train Accurancy:  0.9267430528998375 | Validation Accurancy:  0.9225018173456192\n",
      "Epoch:  6320 | Train Accurancy:  0.9267446994781494 | Validation Accurancy:  0.9225078299641609\n",
      "Epoch:  6321 | Train Accurancy:  0.9267464056611061 | Validation Accurancy:  0.9225143939256668\n",
      "Epoch:  6322 | Train Accurancy:  0.926748052239418 | Validation Accurancy:  0.9225204437971115\n",
      "Epoch:  6323 | Train Accurancy:  0.9267497956752777 | Validation Accurancy:  0.922527089715004\n",
      "Epoch:  6324 | Train Accurancy:  0.9267514571547508 | Validation Accurancy:  0.9225331023335457\n",
      "Epoch:  6325 | Train Accurancy:  0.9267530962824821 | Validation Accurancy:  0.9225396811962128\n",
      "Epoch:  6326 | Train Accurancy:  0.926754780113697 | Validation Accurancy:  0.9225461333990097\n",
      "Epoch:  6327 | Train Accurancy:  0.9267565011978149 | Validation Accurancy:  0.9225520938634872\n",
      "Epoch:  6328 | Train Accurancy:  0.926758162677288 | Validation Accurancy:  0.9225587397813797\n",
      "Epoch:  6329 | Train Accurancy:  0.9267598763108253 | Validation Accurancy:  0.9225647747516632\n",
      "Epoch:  6330 | Train Accurancy:  0.9267615303397179 | Validation Accurancy:  0.9225712791085243\n",
      "Epoch:  6331 | Train Accurancy:  0.9267632141709328 | Validation Accurancy:  0.922577366232872\n",
      "Epoch:  6332 | Train Accurancy:  0.9267649203538895 | Validation Accurancy:  0.9225839301943779\n",
      "Epoch:  6333 | Train Accurancy:  0.9267665594816208 | Validation Accurancy:  0.9225898757576942\n",
      "Epoch:  6334 | Train Accurancy:  0.9267682582139969 | Validation Accurancy:  0.922596387565136\n",
      "Epoch:  6335 | Train Accurancy:  0.9267699271440506 | Validation Accurancy:  0.922602541744709\n",
      "Epoch:  6336 | Train Accurancy:  0.9267715886235237 | Validation Accurancy:  0.9226090759038925\n",
      "Epoch:  6337 | Train Accurancy:  0.926773302257061 | Validation Accurancy:  0.9226151928305626\n",
      "Epoch:  6338 | Train Accurancy:  0.9267749562859535 | Validation Accurancy:  0.9226217269897461\n",
      "Epoch:  6339 | Train Accurancy:  0.9267765507102013 | Validation Accurancy:  0.9226276725530624\n",
      "Epoch:  6340 | Train Accurancy:  0.9267783388495445 | Validation Accurancy:  0.9226342663168907\n",
      "Epoch:  6341 | Train Accurancy:  0.9267799630761147 | Validation Accurancy:  0.9226402267813683\n",
      "Epoch:  6342 | Train Accurancy:  0.9267815873026848 | Validation Accurancy:  0.9226469174027443\n",
      "Epoch:  6343 | Train Accurancy:  0.9267832562327385 | Validation Accurancy:  0.9226528778672218\n",
      "Epoch:  6344 | Train Accurancy:  0.9267849773168564 | Validation Accurancy:  0.9226594418287277\n",
      "Epoch:  6345 | Train Accurancy:  0.9267866462469101 | Validation Accurancy:  0.9226654693484306\n",
      "Epoch:  6346 | Train Accurancy:  0.9267883226275444 | Validation Accurancy:  0.9226720631122589\n",
      "Epoch:  6347 | Train Accurancy:  0.9267899543046951 | Validation Accurancy:  0.9226780384778976\n",
      "Epoch:  6348 | Train Accurancy:  0.9267916306853294 | Validation Accurancy:  0.9226846396923065\n",
      "Epoch:  6349 | Train Accurancy:  0.9267933294177055 | Validation Accurancy:  0.9226911514997482\n",
      "Epoch:  6350 | Train Accurancy:  0.926795020699501 | Validation Accurancy:  0.9226971119642258\n",
      "Epoch:  6351 | Train Accurancy:  0.9267966449260712 | Validation Accurancy:  0.9227035716176033\n",
      "Epoch:  6352 | Train Accurancy:  0.9267983362078667 | Validation Accurancy:  0.922709546983242\n",
      "Epoch:  6353 | Train Accurancy:  0.926799975335598 | Validation Accurancy:  0.9227161258459091\n",
      "Epoch:  6354 | Train Accurancy:  0.9268016442656517 | Validation Accurancy:  0.9227219596505165\n",
      "Epoch:  6355 | Train Accurancy:  0.9268032982945442 | Validation Accurancy:  0.9227286651730537\n",
      "Epoch:  6356 | Train Accurancy:  0.9268049523234367 | Validation Accurancy:  0.9227345809340477\n",
      "Epoch:  6357 | Train Accurancy:  0.9268066212534904 | Validation Accurancy:  0.9227411895990372\n",
      "Epoch:  6358 | Train Accurancy:  0.9268083199858665 | Validation Accurancy:  0.9227471798658371\n",
      "Epoch:  6359 | Train Accurancy:  0.9268099889159203 | Validation Accurancy:  0.9227537289261818\n",
      "Epoch:  6360 | Train Accurancy:  0.9268115907907486 | Validation Accurancy:  0.9227596297860146\n",
      "Epoch:  6361 | Train Accurancy:  0.9268132895231247 | Validation Accurancy:  0.9227662235498428\n",
      "Epoch:  6362 | Train Accurancy:  0.9268149361014366 | Validation Accurancy:  0.9227722659707069\n",
      "Epoch:  6363 | Train Accurancy:  0.9268165975809097 | Validation Accurancy:  0.9227788150310516\n",
      "Epoch:  6364 | Train Accurancy:  0.9268182665109634 | Validation Accurancy:  0.922784760594368\n",
      "Epoch:  6365 | Train Accurancy:  0.9268199056386948 | Validation Accurancy:  0.9227912425994873\n",
      "Epoch:  6366 | Train Accurancy:  0.9268216043710709 | Validation Accurancy:  0.9227972328662872\n",
      "Epoch:  6367 | Train Accurancy:  0.9268232062458992 | Validation Accurancy:  0.9228037372231483\n",
      "Epoch:  6368 | Train Accurancy:  0.9268249273300171 | Validation Accurancy:  0.9228098541498184\n",
      "Epoch:  6369 | Train Accurancy:  0.9268265813589096 | Validation Accurancy:  0.9228162914514542\n",
      "Epoch:  6370 | Train Accurancy:  0.9268282130360603 | Validation Accurancy:  0.9228222668170929\n",
      "Epoch:  6371 | Train Accurancy:  0.926829881966114 | Validation Accurancy:  0.9228288680315018\n",
      "Epoch:  6372 | Train Accurancy:  0.9268315210938454 | Validation Accurancy:  0.9228348284959793\n",
      "Epoch:  6373 | Train Accurancy:  0.9268331676721573 | Validation Accurancy:  0.9228412806987762\n",
      "Epoch:  6374 | Train Accurancy:  0.9268348440527916 | Validation Accurancy:  0.9228478148579597\n",
      "Epoch:  6375 | Train Accurancy:  0.9268365353345871 | Validation Accurancy:  0.9228537753224373\n",
      "Epoch:  6376 | Train Accurancy:  0.9268381893634796 | Validation Accurancy:  0.9228601306676865\n",
      "Epoch:  6377 | Train Accurancy:  0.926839791238308 | Validation Accurancy:  0.922866091132164\n",
      "Epoch:  6378 | Train Accurancy:  0.9268414154648781 | Validation Accurancy:  0.9228726401925087\n",
      "Epoch:  6379 | Train Accurancy:  0.9268430843949318 | Validation Accurancy:  0.922878585755825\n",
      "Epoch:  6380 | Train Accurancy:  0.9268447384238243 | Validation Accurancy:  0.9228850826621056\n",
      "Epoch:  6381 | Train Accurancy:  0.926846407353878 | Validation Accurancy:  0.9228910729289055\n",
      "Epoch:  6382 | Train Accurancy:  0.9268480539321899 | Validation Accurancy:  0.9228974506258965\n",
      "Epoch:  6383 | Train Accurancy:  0.9268496781587601 | Validation Accurancy:  0.9229035079479218\n",
      "Epoch:  6384 | Train Accurancy:  0.9268513694405556 | Validation Accurancy:  0.9229100421071053\n",
      "Epoch:  6385 | Train Accurancy:  0.9268530085682869 | Validation Accurancy:  0.9229159206151962\n",
      "Epoch:  6386 | Train Accurancy:  0.9268546476960182 | Validation Accurancy:  0.9229224994778633\n",
      "Epoch:  6387 | Train Accurancy:  0.9268563166260719 | Validation Accurancy:  0.9229284599423409\n",
      "Epoch:  6388 | Train Accurancy:  0.9268579334020615 | Validation Accurancy:  0.9229350090026855\n",
      "Epoch:  6389 | Train Accurancy:  0.926859624683857 | Validation Accurancy:  0.9229409247636795\n",
      "Epoch:  6390 | Train Accurancy:  0.9268612191081047 | Validation Accurancy:  0.92294742166996\n",
      "Epoch:  6391 | Train Accurancy:  0.9268628805875778 | Validation Accurancy:  0.922953337430954\n",
      "Epoch:  6392 | Train Accurancy:  0.9268644899129868 | Validation Accurancy:  0.9229598194360733\n",
      "Epoch:  6393 | Train Accurancy:  0.9268661811947823 | Validation Accurancy:  0.9229658469557762\n",
      "Epoch:  6394 | Train Accurancy:  0.9268678054213524 | Validation Accurancy:  0.9229722991585732\n",
      "Epoch:  6395 | Train Accurancy:  0.9268694147467613 | Validation Accurancy:  0.9229781925678253\n",
      "Epoch:  6396 | Train Accurancy:  0.9268711060285568 | Validation Accurancy:  0.922984667122364\n",
      "Epoch:  6397 | Train Accurancy:  0.9268727675080299 | Validation Accurancy:  0.9229911640286446\n",
      "Epoch:  6398 | Train Accurancy:  0.9268743470311165 | Validation Accurancy:  0.9229970425367355\n",
      "Epoch:  6399 | Train Accurancy:  0.9268760159611702 | Validation Accurancy:  0.9230035170912743\n",
      "Epoch:  6400 | Train Accurancy:  0.9268776848912239 | Validation Accurancy:  0.9230094105005264\n",
      "Epoch:  6401 | Train Accurancy:  0.9268793165683746 | Validation Accurancy:  0.9230158776044846\n",
      "Epoch:  6402 | Train Accurancy:  0.9268809780478477 | Validation Accurancy:  0.9230217635631561\n",
      "Epoch:  6403 | Train Accurancy:  0.9268825799226761 | Validation Accurancy:  0.9230282753705978\n",
      "Epoch:  6404 | Train Accurancy:  0.9268841966986656 | Validation Accurancy:  0.9230341911315918\n",
      "Epoch:  6405 | Train Accurancy:  0.9268858283758163 | Validation Accurancy:  0.9230406954884529\n",
      "Epoch:  6406 | Train Accurancy:  0.9268874451518059 | Validation Accurancy:  0.9230465888977051\n",
      "Epoch:  6407 | Train Accurancy:  0.926889143884182 | Validation Accurancy:  0.9230529963970184\n",
      "Epoch:  6408 | Train Accurancy:  0.9268907681107521 | Validation Accurancy:  0.923058919608593\n",
      "Epoch:  6409 | Train Accurancy:  0.9268923997879028 | Validation Accurancy:  0.9230655059218407\n",
      "Epoch:  6410 | Train Accurancy:  0.9268940016627312 | Validation Accurancy:  0.9230713993310928\n",
      "Epoch:  6411 | Train Accurancy:  0.9268956482410431 | Validation Accurancy:  0.9230778068304062\n",
      "Epoch:  6412 | Train Accurancy:  0.926897332072258 | Validation Accurancy:  0.9230837523937225\n",
      "Epoch:  6413 | Train Accurancy:  0.9268989637494087 | Validation Accurancy:  0.9230902343988419\n",
      "Epoch:  6414 | Train Accurancy:  0.9269005879759789 | Validation Accurancy:  0.9230963066220284\n",
      "Epoch:  6415 | Train Accurancy:  0.926902174949646 | Validation Accurancy:  0.9231026992201805\n",
      "Epoch:  6416 | Train Accurancy:  0.9269038289785385 | Validation Accurancy:  0.9231086224317551\n",
      "Epoch:  6417 | Train Accurancy:  0.9269054606556892 | Validation Accurancy:  0.9231151565909386\n",
      "Epoch:  6418 | Train Accurancy:  0.926907129585743 | Validation Accurancy:  0.923120990395546\n",
      "Epoch:  6419 | Train Accurancy:  0.9269087314605713 | Validation Accurancy:  0.9231273829936981\n",
      "Epoch:  6420 | Train Accurancy:  0.9269104078412056 | Validation Accurancy:  0.9231333285570145\n",
      "Epoch:  6421 | Train Accurancy:  0.9269119799137115 | Validation Accurancy:  0.9231399074196815\n",
      "Epoch:  6422 | Train Accurancy:  0.9269136488437653 | Validation Accurancy:  0.9231456443667412\n",
      "Epoch:  6423 | Train Accurancy:  0.9269152358174324 | Validation Accurancy:  0.9231520965695381\n",
      "Epoch:  6424 | Train Accurancy:  0.9269168898463249 | Validation Accurancy:  0.9231585040688515\n",
      "Epoch:  6425 | Train Accurancy:  0.9269184991717339 | Validation Accurancy:  0.9231644123792648\n",
      "Epoch:  6426 | Train Accurancy:  0.9269201532006264 | Validation Accurancy:  0.9231708720326424\n",
      "Epoch:  6427 | Train Accurancy:  0.9269217923283577 | Validation Accurancy:  0.9231767505407333\n",
      "Epoch:  6428 | Train Accurancy:  0.9269233644008636 | Validation Accurancy:  0.9231831878423691\n",
      "Epoch:  6429 | Train Accurancy:  0.9269249960780144 | Validation Accurancy:  0.9231890961527824\n",
      "Epoch:  6430 | Train Accurancy:  0.9269266650080681 | Validation Accurancy:  0.9231954887509346\n",
      "Epoch:  6431 | Train Accurancy:  0.9269283041357994 | Validation Accurancy:  0.9232013076543808\n",
      "Epoch:  6432 | Train Accurancy:  0.926929883658886 | Validation Accurancy:  0.9232078567147255\n",
      "Epoch:  6433 | Train Accurancy:  0.9269314929842949 | Validation Accurancy:  0.9232136756181717\n",
      "Epoch:  6434 | Train Accurancy:  0.9269331246614456 | Validation Accurancy:  0.9232201278209686\n",
      "Epoch:  6435 | Train Accurancy:  0.9269347563385963 | Validation Accurancy:  0.9232260510325432\n",
      "Epoch:  6436 | Train Accurancy:  0.9269364327192307 | Validation Accurancy:  0.9232323840260506\n",
      "Epoch:  6437 | Train Accurancy:  0.9269380122423172 | Validation Accurancy:  0.9232384040951729\n",
      "Epoch:  6438 | Train Accurancy:  0.9269396290183067 | Validation Accurancy:  0.9232448115944862\n",
      "Epoch:  6439 | Train Accurancy:  0.9269412606954575 | Validation Accurancy:  0.9232506304979324\n",
      "Epoch:  6440 | Train Accurancy:  0.9269428625702858 | Validation Accurancy:  0.9232570976018906\n",
      "Epoch:  6441 | Train Accurancy:  0.9269445016980171 | Validation Accurancy:  0.9232630580663681\n",
      "Epoch:  6442 | Train Accurancy:  0.9269461184740067 | Validation Accurancy:  0.9232694134116173\n",
      "Epoch:  6443 | Train Accurancy:  0.926947720348835 | Validation Accurancy:  0.9232752323150635\n",
      "Epoch:  6444 | Train Accurancy:  0.9269493520259857 | Validation Accurancy:  0.9232816696166992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6445 | Train Accurancy:  0.9269510135054588 | Validation Accurancy:  0.9232876151800156\n",
      "Epoch:  6446 | Train Accurancy:  0.9269525334239006 | Validation Accurancy:  0.9232940524816513\n",
      "Epoch:  6447 | Train Accurancy:  0.9269541949033737 | Validation Accurancy:  0.9232999607920647\n",
      "Epoch:  6448 | Train Accurancy:  0.9269557744264603 | Validation Accurancy:  0.9233064353466034\n",
      "Epoch:  6449 | Train Accurancy:  0.9269574657082558 | Validation Accurancy:  0.9233122542500496\n",
      "Epoch:  6450 | Train Accurancy:  0.9269590154290199 | Validation Accurancy:  0.9233186095952988\n",
      "Epoch:  6451 | Train Accurancy:  0.9269606620073318 | Validation Accurancy:  0.9233245551586151\n",
      "Epoch:  6452 | Train Accurancy:  0.926962248980999 | Validation Accurancy:  0.9233309924602509\n",
      "Epoch:  6453 | Train Accurancy:  0.9269638806581497 | Validation Accurancy:  0.9233368709683418\n",
      "Epoch:  6454 | Train Accurancy:  0.9269655421376228 | Validation Accurancy:  0.9233432486653328\n",
      "Epoch:  6455 | Train Accurancy:  0.9269670620560646 | Validation Accurancy:  0.9233495742082596\n",
      "Epoch:  6456 | Train Accurancy:  0.9269687756896019 | Validation Accurancy:  0.923355370759964\n",
      "Epoch:  6457 | Train Accurancy:  0.9269703701138496 | Validation Accurancy:  0.9233616963028908\n",
      "Epoch:  6458 | Train Accurancy:  0.9269719272851944 | Validation Accurancy:  0.9233675822615623\n",
      "Epoch:  6459 | Train Accurancy:  0.9269735440611839 | Validation Accurancy:  0.9233739525079727\n",
      "Epoch:  6460 | Train Accurancy:  0.9269751235842705 | Validation Accurancy:  0.9233797565102577\n",
      "Epoch:  6461 | Train Accurancy:  0.926976777613163 | Validation Accurancy:  0.9233862087130547\n",
      "Epoch:  6462 | Train Accurancy:  0.9269783571362495 | Validation Accurancy:  0.9233920276165009\n",
      "Epoch:  6463 | Train Accurancy:  0.9269799962639809 | Validation Accurancy:  0.9233984276652336\n",
      "Epoch:  6464 | Train Accurancy:  0.9269815906882286 | Validation Accurancy:  0.923404261469841\n",
      "Epoch:  6465 | Train Accurancy:  0.9269831702113152 | Validation Accurancy:  0.9234106689691544\n",
      "Epoch:  6466 | Train Accurancy:  0.9269848018884659 | Validation Accurancy:  0.9234165847301483\n",
      "Epoch:  6467 | Train Accurancy:  0.9269864186644554 | Validation Accurancy:  0.9234229549765587\n",
      "Epoch:  6468 | Train Accurancy:  0.926988035440445 | Validation Accurancy:  0.9234287440776825\n",
      "Epoch:  6469 | Train Accurancy:  0.9269896224141121 | Validation Accurancy:  0.923435166478157\n",
      "Epoch:  6470 | Train Accurancy:  0.9269912540912628 | Validation Accurancy:  0.923441044986248\n",
      "Epoch:  6471 | Train Accurancy:  0.9269928708672523 | Validation Accurancy:  0.9234474003314972\n",
      "Epoch:  6472 | Train Accurancy:  0.9269943982362747 | Validation Accurancy:  0.9234532490372658\n",
      "Epoch:  6473 | Train Accurancy:  0.9269960150122643 | Validation Accurancy:  0.9234596863389015\n",
      "Epoch:  6474 | Train Accurancy:  0.9269976168870926 | Validation Accurancy:  0.9234655573964119\n",
      "Epoch:  6475 | Train Accurancy:  0.9269992262125015 | Validation Accurancy:  0.9234718456864357\n",
      "Epoch:  6476 | Train Accurancy:  0.9270008429884911 | Validation Accurancy:  0.9234776943922043\n",
      "Epoch:  6477 | Train Accurancy:  0.9270024523139 | Validation Accurancy:  0.9234840199351311\n",
      "Epoch:  6478 | Train Accurancy:  0.9270040318369865 | Validation Accurancy:  0.9234899207949638\n",
      "Epoch:  6479 | Train Accurancy:  0.9270056709647179 | Validation Accurancy:  0.9234963729977608\n",
      "Epoch:  6480 | Train Accurancy:  0.927007220685482 | Validation Accurancy:  0.9235026687383652\n",
      "Epoch:  6481 | Train Accurancy:  0.9270088598132133 | Validation Accurancy:  0.9235084727406502\n",
      "Epoch:  6482 | Train Accurancy:  0.9270104616880417 | Validation Accurancy:  0.9235147014260292\n",
      "Epoch:  6483 | Train Accurancy:  0.9270120710134506 | Validation Accurancy:  0.9235205203294754\n",
      "Epoch:  6484 | Train Accurancy:  0.9270136505365372 | Validation Accurancy:  0.923526905477047\n",
      "Epoch:  6485 | Train Accurancy:  0.9270152077078819 | Validation Accurancy:  0.9235326945781708\n",
      "Epoch:  6486 | Train Accurancy:  0.9270168244838715 | Validation Accurancy:  0.9235391169786453\n",
      "Epoch:  6487 | Train Accurancy:  0.9270184114575386 | Validation Accurancy:  0.9235449656844139\n",
      "Epoch:  6488 | Train Accurancy:  0.9270200207829475 | Validation Accurancy:  0.9235513210296631\n",
      "Epoch:  6489 | Train Accurancy:  0.9270216375589371 | Validation Accurancy:  0.923557236790657\n",
      "Epoch:  6490 | Train Accurancy:  0.9270232394337654 | Validation Accurancy:  0.9235634952783585\n",
      "Epoch:  6491 | Train Accurancy:  0.9270248636603355 | Validation Accurancy:  0.9235693141818047\n",
      "Epoch:  6492 | Train Accurancy:  0.9270263388752937 | Validation Accurancy:  0.9235756397247314\n",
      "Epoch:  6493 | Train Accurancy:  0.9270279854536057 | Validation Accurancy:  0.9235814288258553\n",
      "Epoch:  6494 | Train Accurancy:  0.9270295649766922 | Validation Accurancy:  0.923587828874588\n",
      "Epoch:  6495 | Train Accurancy:  0.9270311817526817 | Validation Accurancy:  0.9235936924815178\n",
      "Epoch:  6496 | Train Accurancy:  0.9270327910780907 | Validation Accurancy:  0.923599973320961\n",
      "Epoch:  6497 | Train Accurancy:  0.9270343855023384 | Validation Accurancy:  0.9236057624220848\n",
      "Epoch:  6498 | Train Accurancy:  0.9270359575748444 | Validation Accurancy:  0.9236120879650116\n",
      "Epoch:  6499 | Train Accurancy:  0.9270375445485115 | Validation Accurancy:  0.9236179664731026\n",
      "Epoch:  6500 | Train Accurancy:  0.9270391166210175 | Validation Accurancy:  0.923624262213707\n",
      "Epoch:  6501 | Train Accurancy:  0.927040696144104 | Validation Accurancy:  0.9236301258206367\n",
      "Epoch:  6502 | Train Accurancy:  0.9270422905683517 | Validation Accurancy:  0.9236364662647247\n",
      "Epoch:  6503 | Train Accurancy:  0.9270439296960831 | Validation Accurancy:  0.9236422553658485\n",
      "Epoch:  6504 | Train Accurancy:  0.9270454794168472 | Validation Accurancy:  0.9236485287547112\n",
      "Epoch:  6505 | Train Accurancy:  0.927047036588192 | Validation Accurancy:  0.9236545115709305\n",
      "Epoch:  6506 | Train Accurancy:  0.9270486906170845 | Validation Accurancy:  0.9236607104539871\n",
      "Epoch:  6507 | Train Accurancy:  0.9270502850413322 | Validation Accurancy:  0.9236665442585945\n",
      "Epoch:  6508 | Train Accurancy:  0.9270517975091934 | Validation Accurancy:  0.9236729592084885\n",
      "Epoch:  6509 | Train Accurancy:  0.9270533844828606 | Validation Accurancy:  0.9236787334084511\n",
      "Epoch:  6510 | Train Accurancy:  0.9270550012588501 | Validation Accurancy:  0.9236850589513779\n",
      "Epoch:  6511 | Train Accurancy:  0.9270565509796143 | Validation Accurancy:  0.9236908778548241\n",
      "Epoch:  6512 | Train Accurancy:  0.9270581528544426 | Validation Accurancy:  0.9236971884965897\n",
      "Epoch:  6513 | Train Accurancy:  0.9270597696304321 | Validation Accurancy:  0.9237029701471329\n",
      "Epoch:  6514 | Train Accurancy:  0.9270613342523575 | Validation Accurancy:  0.9237092807888985\n",
      "Epoch:  6515 | Train Accurancy:  0.9270628988742828 | Validation Accurancy:  0.923715129494667\n",
      "Epoch:  6516 | Train Accurancy:  0.9270644634962082 | Validation Accurancy:  0.923721469938755\n",
      "Epoch:  6517 | Train Accurancy:  0.9270660802721977 | Validation Accurancy:  0.9237277060747147\n",
      "Epoch:  6518 | Train Accurancy:  0.9270676746964455 | Validation Accurancy:  0.9237334281206131\n",
      "Epoch:  6519 | Train Accurancy:  0.9270692244172096 | Validation Accurancy:  0.9237397834658623\n",
      "Epoch:  6520 | Train Accurancy:  0.9270707741379738 | Validation Accurancy:  0.9237454757094383\n",
      "Epoch:  6521 | Train Accurancy:  0.9270724058151245 | Validation Accurancy:  0.9237517490983009\n",
      "Epoch:  6522 | Train Accurancy:  0.9270739704370499 | Validation Accurancy:  0.9237576201558113\n",
      "Epoch:  6523 | Train Accurancy:  0.9270755797624588 | Validation Accurancy:  0.9237638339400291\n",
      "Epoch:  6524 | Train Accurancy:  0.9270770996809006 | Validation Accurancy:  0.9237696677446365\n",
      "Epoch:  6525 | Train Accurancy:  0.9270787313580513 | Validation Accurancy:  0.9237760230898857\n",
      "Epoch:  6526 | Train Accurancy:  0.9270802587270737 | Validation Accurancy:  0.9237817749381065\n",
      "Epoch:  6527 | Train Accurancy:  0.927081860601902 | Validation Accurancy:  0.9237879887223244\n",
      "Epoch:  6528 | Train Accurancy:  0.9270834401249886 | Validation Accurancy:  0.9237938225269318\n",
      "Epoch:  6529 | Train Accurancy:  0.9270850047469139 | Validation Accurancy:  0.9238001331686974\n",
      "Epoch:  6530 | Train Accurancy:  0.9270865842700005 | Validation Accurancy:  0.9238059520721436\n",
      "Epoch:  6531 | Train Accurancy:  0.9270881563425064 | Validation Accurancy:  0.9238121509552002\n",
      "Epoch:  6532 | Train Accurancy:  0.927089735865593 | Validation Accurancy:  0.9238178730010986\n",
      "Epoch:  6533 | Train Accurancy:  0.9270913302898407 | Validation Accurancy:  0.9238243103027344\n",
      "Epoch:  6534 | Train Accurancy:  0.9270928725600243 | Validation Accurancy:  0.9238300770521164\n",
      "Epoch:  6535 | Train Accurancy:  0.9270944744348526 | Validation Accurancy:  0.9238363578915596\n",
      "Epoch:  6536 | Train Accurancy:  0.9270960465073586 | Validation Accurancy:  0.9238420948386192\n",
      "Epoch:  6537 | Train Accurancy:  0.9270975962281227 | Validation Accurancy:  0.923848420381546\n",
      "Epoch:  6538 | Train Accurancy:  0.9270991235971451 | Validation Accurancy:  0.9238542094826698\n",
      "Epoch:  6539 | Train Accurancy:  0.9271007552742958 | Validation Accurancy:  0.9238605499267578\n",
      "Epoch:  6540 | Train Accurancy:  0.9271023273468018 | Validation Accurancy:  0.9238662719726562\n",
      "Epoch:  6541 | Train Accurancy:  0.9271038919687271 | Validation Accurancy:  0.9238725006580353\n",
      "Epoch:  6542 | Train Accurancy:  0.9271054416894913 | Validation Accurancy:  0.9238783642649651\n",
      "Epoch:  6543 | Train Accurancy:  0.9271070137619972 | Validation Accurancy:  0.9238846153020859\n",
      "Epoch:  6544 | Train Accurancy:  0.9271086156368256 | Validation Accurancy:  0.9238903522491455\n",
      "Epoch:  6545 | Train Accurancy:  0.9271101653575897 | Validation Accurancy:  0.9238966181874275\n",
      "Epoch:  6546 | Train Accurancy:  0.9271117299795151 | Validation Accurancy:  0.9239023700356483\n",
      "Epoch:  6547 | Train Accurancy:  0.9271132871508598 | Validation Accurancy:  0.9239086955785751\n",
      "Epoch:  6548 | Train Accurancy:  0.9271148815751076 | Validation Accurancy:  0.9239143878221512\n",
      "Epoch:  6549 | Train Accurancy:  0.9271163940429688 | Validation Accurancy:  0.9239207878708839\n",
      "Epoch:  6550 | Train Accurancy:  0.9271179884672165 | Validation Accurancy:  0.9239265099167824\n",
      "Epoch:  6551 | Train Accurancy:  0.9271195307374 | Validation Accurancy:  0.923932820558548\n",
      "Epoch:  6552 | Train Accurancy:  0.9271211102604866 | Validation Accurancy:  0.9239386394619942\n",
      "Epoch:  6553 | Train Accurancy:  0.9271227121353149 | Validation Accurancy:  0.923944853246212\n",
      "Epoch:  6554 | Train Accurancy:  0.9271242395043373 | Validation Accurancy:  0.9239505752921104\n",
      "Epoch:  6555 | Train Accurancy:  0.9271257892251015 | Validation Accurancy:  0.923956885933876\n",
      "Epoch:  6556 | Train Accurancy:  0.927127368748188 | Validation Accurancy:  0.9239626079797745\n",
      "Epoch:  6557 | Train Accurancy:  0.9271289482712746 | Validation Accurancy:  0.9239688068628311\n",
      "Epoch:  6558 | Train Accurancy:  0.9271304905414581 | Validation Accurancy:  0.9239745587110519\n",
      "Epoch:  6559 | Train Accurancy:  0.9271320104598999 | Validation Accurancy:  0.9239809215068817\n",
      "Epoch:  6560 | Train Accurancy:  0.9271336048841476 | Validation Accurancy:  0.9239865764975548\n",
      "Epoch:  6561 | Train Accurancy:  0.9271351620554924 | Validation Accurancy:  0.9239927902817726\n",
      "Epoch:  6562 | Train Accurancy:  0.9271366968750954 | Validation Accurancy:  0.9239990264177322\n",
      "Epoch:  6563 | Train Accurancy:  0.9271382763981819 | Validation Accurancy:  0.9240047633647919\n",
      "Epoch:  6564 | Train Accurancy:  0.9271398857235909 | Validation Accurancy:  0.9240109920501709\n",
      "Epoch:  6565 | Train Accurancy:  0.9271414428949356 | Validation Accurancy:  0.9240167289972305\n",
      "Epoch:  6566 | Train Accurancy:  0.927142933011055 | Validation Accurancy:  0.9240229278802872\n",
      "Epoch:  6567 | Train Accurancy:  0.9271445199847221 | Validation Accurancy:  0.924028679728508\n",
      "Epoch:  6568 | Train Accurancy:  0.9271460771560669 | Validation Accurancy:  0.9240349009633064\n",
      "Epoch:  6569 | Train Accurancy:  0.9271476194262505 | Validation Accurancy:  0.9240405857563019\n",
      "Epoch:  6570 | Train Accurancy:  0.9271492213010788 | Validation Accurancy:  0.9240468516945839\n",
      "Epoch:  6571 | Train Accurancy:  0.9271507412195206 | Validation Accurancy:  0.9240525737404823\n",
      "Epoch:  6572 | Train Accurancy:  0.9271523058414459 | Validation Accurancy:  0.9240588322281837\n",
      "Epoch:  6573 | Train Accurancy:  0.9271538257598877 | Validation Accurancy:  0.9240645691752434\n",
      "Epoch:  6574 | Train Accurancy:  0.9271553978323936 | Validation Accurancy:  0.9240707531571388\n",
      "Epoch:  6575 | Train Accurancy:  0.9271569773554802 | Validation Accurancy:  0.9240765869617462\n",
      "Epoch:  6576 | Train Accurancy:  0.9271585196256638 | Validation Accurancy:  0.9240827411413193\n",
      "Epoch:  6577 | Train Accurancy:  0.9271600618958473 | Validation Accurancy:  0.9240884929895401\n",
      "Epoch:  6578 | Train Accurancy:  0.9271616041660309 | Validation Accurancy:  0.9240948185324669\n",
      "Epoch:  6579 | Train Accurancy:  0.927163191139698 | Validation Accurancy:  0.9241004437208176\n",
      "Epoch:  6580 | Train Accurancy:  0.9271647483110428 | Validation Accurancy:  0.9241067096590996\n",
      "Epoch:  6581 | Train Accurancy:  0.927166260778904 | Validation Accurancy:  0.9241124019026756\n",
      "Epoch:  6582 | Train Accurancy:  0.9271678179502487 | Validation Accurancy:  0.9241185486316681\n",
      "Epoch:  6583 | Train Accurancy:  0.9271693527698517 | Validation Accurancy:  0.9241243228316307\n",
      "Epoch:  6584 | Train Accurancy:  0.9271708950400352 | Validation Accurancy:  0.9241305068135262\n",
      "Epoch:  6585 | Train Accurancy:  0.9271724671125412 | Validation Accurancy:  0.9241363182663918\n",
      "Epoch:  6586 | Train Accurancy:  0.927173987030983 | Validation Accurancy:  0.9241425320506096\n",
      "Epoch:  6587 | Train Accurancy:  0.9271755293011665 | Validation Accurancy:  0.924148291349411\n",
      "Epoch:  6588 | Train Accurancy:  0.9271770939230919 | Validation Accurancy:  0.9241544753313065\n",
      "Epoch:  6589 | Train Accurancy:  0.9271786287426949 | Validation Accurancy:  0.9241602122783661\n",
      "Epoch:  6590 | Train Accurancy:  0.9271801486611366 | Validation Accurancy:  0.9241664111614227\n",
      "Epoch:  6591 | Train Accurancy:  0.9271817728877068 | Validation Accurancy:  0.9241721481084824\n",
      "Epoch:  6592 | Train Accurancy:  0.9271832406520844 | Validation Accurancy:  0.9241784289479256\n",
      "Epoch:  6593 | Train Accurancy:  0.9271848425269127 | Validation Accurancy:  0.924184039235115\n",
      "Epoch:  6594 | Train Accurancy:  0.9271863698959351 | Validation Accurancy:  0.9241903647780418\n",
      "Epoch:  6595 | Train Accurancy:  0.9271879196166992 | Validation Accurancy:  0.9241960048675537\n",
      "Epoch:  6596 | Train Accurancy:  0.9271894618868828 | Validation Accurancy:  0.9242022186517715\n",
      "Epoch:  6597 | Train Accurancy:  0.9271909967064857 | Validation Accurancy:  0.92420794069767\n",
      "Epoch:  6598 | Train Accurancy:  0.9271925389766693 | Validation Accurancy:  0.9242141395807266\n",
      "Epoch:  6599 | Train Accurancy:  0.9271940663456917 | Validation Accurancy:  0.9242198765277863\n",
      "Epoch:  6600 | Train Accurancy:  0.9271956533193588 | Validation Accurancy:  0.9242260158061981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6601 | Train Accurancy:  0.9271971955895424 | Validation Accurancy:  0.9242317229509354\n",
      "Epoch:  6602 | Train Accurancy:  0.927198700606823 | Validation Accurancy:  0.9242379516363144\n",
      "Epoch:  6603 | Train Accurancy:  0.9272002801299095 | Validation Accurancy:  0.9242440387606621\n",
      "Epoch:  6604 | Train Accurancy:  0.9272017702460289 | Validation Accurancy:  0.9242496639490128\n",
      "Epoch:  6605 | Train Accurancy:  0.9272033721208572 | Validation Accurancy:  0.9242557808756828\n",
      "Epoch:  6606 | Train Accurancy:  0.9272048622369766 | Validation Accurancy:  0.9242615699768066\n",
      "Epoch:  6607 | Train Accurancy:  0.9272063970565796 | Validation Accurancy:  0.9242677241563797\n",
      "Epoch:  6608 | Train Accurancy:  0.9272079691290855 | Validation Accurancy:  0.924273394048214\n",
      "Epoch:  6609 | Train Accurancy:  0.9272094815969467 | Validation Accurancy:  0.9242795780301094\n",
      "Epoch:  6610 | Train Accurancy:  0.9272110387682915 | Validation Accurancy:  0.9242852851748466\n",
      "Epoch:  6611 | Train Accurancy:  0.927212581038475 | Validation Accurancy:  0.9242914691567421\n",
      "Epoch:  6612 | Train Accurancy:  0.927214115858078 | Validation Accurancy:  0.9242971241474152\n",
      "Epoch:  6613 | Train Accurancy:  0.9272155985236168 | Validation Accurancy:  0.924303337931633\n",
      "Epoch:  6614 | Train Accurancy:  0.9272171556949615 | Validation Accurancy:  0.9243090003728867\n",
      "Epoch:  6615 | Train Accurancy:  0.9272187054157257 | Validation Accurancy:  0.9243152439594269\n",
      "Epoch:  6616 | Train Accurancy:  0.9272202253341675 | Validation Accurancy:  0.9243209362030029\n",
      "Epoch:  6617 | Train Accurancy:  0.9272217378020287 | Validation Accurancy:  0.924327090382576\n",
      "Epoch:  6618 | Train Accurancy:  0.9272232949733734 | Validation Accurancy:  0.9243327155709267\n",
      "Epoch:  6619 | Train Accurancy:  0.9272248521447182 | Validation Accurancy:  0.9243388473987579\n",
      "Epoch:  6620 | Train Accurancy:  0.927226297557354 | Validation Accurancy:  0.9243446364998817\n",
      "Epoch:  6621 | Train Accurancy:  0.9272278770804405 | Validation Accurancy:  0.9243508353829384\n",
      "Epoch:  6622 | Train Accurancy:  0.9272293895483017 | Validation Accurancy:  0.9243564754724503\n",
      "Epoch:  6623 | Train Accurancy:  0.9272309690713882 | Validation Accurancy:  0.9243627861142159\n",
      "Epoch:  6624 | Train Accurancy:  0.9272324815392494 | Validation Accurancy:  0.9243683815002441\n",
      "Epoch:  6625 | Train Accurancy:  0.9272339791059494 | Validation Accurancy:  0.9243745356798172\n",
      "Epoch:  6626 | Train Accurancy:  0.9272355362772942 | Validation Accurancy:  0.9243802577257156\n",
      "Epoch:  6627 | Train Accurancy:  0.9272370636463165 | Validation Accurancy:  0.924386277794838\n",
      "Epoch:  6628 | Train Accurancy:  0.9272385910153389 | Validation Accurancy:  0.9243919998407364\n",
      "Epoch:  6629 | Train Accurancy:  0.9272401258349419 | Validation Accurancy:  0.9243982136249542\n",
      "Epoch:  6630 | Train Accurancy:  0.9272416457533836 | Validation Accurancy:  0.9244038611650467\n",
      "Epoch:  6631 | Train Accurancy:  0.9272431805729866 | Validation Accurancy:  0.924409992992878\n",
      "Epoch:  6632 | Train Accurancy:  0.927244707942009 | Validation Accurancy:  0.9244156554341316\n",
      "Epoch:  6633 | Train Accurancy:  0.9272462502121925 | Validation Accurancy:  0.9244218021631241\n",
      "Epoch:  6634 | Train Accurancy:  0.9272477477788925 | Validation Accurancy:  0.9244275093078613\n",
      "Epoch:  6635 | Train Accurancy:  0.9272492900490761 | Validation Accurancy:  0.9244336411356926\n",
      "Epoch:  6636 | Train Accurancy:  0.9272507876157761 | Validation Accurancy:  0.9244393333792686\n",
      "Epoch:  6637 | Train Accurancy:  0.9272523373365402 | Validation Accurancy:  0.9244455024600029\n",
      "Epoch:  6638 | Train Accurancy:  0.9272537901997566 | Validation Accurancy:  0.9244511127471924\n",
      "Epoch:  6639 | Train Accurancy:  0.9272553846240044 | Validation Accurancy:  0.9244572445750237\n",
      "Epoch:  6640 | Train Accurancy:  0.9272569715976715 | Validation Accurancy:  0.9244629666209221\n",
      "Epoch:  6641 | Train Accurancy:  0.9272584244608879 | Validation Accurancy:  0.9244690611958504\n",
      "Epoch:  6642 | Train Accurancy:  0.9272599294781685 | Validation Accurancy:  0.9244747310876846\n",
      "Epoch:  6643 | Train Accurancy:  0.9272614642977715 | Validation Accurancy:  0.9244809150695801\n",
      "Epoch:  6644 | Train Accurancy:  0.9272630512714386 | Validation Accurancy:  0.9244866222143173\n",
      "Epoch:  6645 | Train Accurancy:  0.927264504134655 | Validation Accurancy:  0.924492709338665\n",
      "Epoch:  6646 | Train Accurancy:  0.9272659718990326 | Validation Accurancy:  0.9244983345270157\n",
      "Epoch:  6647 | Train Accurancy:  0.9272675514221191 | Validation Accurancy:  0.9245045036077499\n",
      "Epoch:  6648 | Train Accurancy:  0.9272691085934639 | Validation Accurancy:  0.9245100989937782\n",
      "Epoch:  6649 | Train Accurancy:  0.9272705614566803 | Validation Accurancy:  0.9245162829756737\n",
      "Epoch:  6650 | Train Accurancy:  0.9272721260786057 | Validation Accurancy:  0.9245219081640244\n",
      "Epoch:  6651 | Train Accurancy:  0.9272736459970474 | Validation Accurancy:  0.9245280921459198\n",
      "Epoch:  6652 | Train Accurancy:  0.9272751063108444 | Validation Accurancy:  0.9245336502790451\n",
      "Epoch:  6653 | Train Accurancy:  0.9272766560316086 | Validation Accurancy:  0.9245398864150047\n",
      "Epoch:  6654 | Train Accurancy:  0.9272781535983086 | Validation Accurancy:  0.9245454296469688\n",
      "Epoch:  6655 | Train Accurancy:  0.9272797182202339 | Validation Accurancy:  0.9245516285300255\n",
      "Epoch:  6656 | Train Accurancy:  0.9272811412811279 | Validation Accurancy:  0.9245576187968254\n",
      "Epoch:  6657 | Train Accurancy:  0.9272827282547951 | Validation Accurancy:  0.9245633631944656\n",
      "Epoch:  6658 | Train Accurancy:  0.9272842109203339 | Validation Accurancy:  0.9245694503188133\n",
      "Epoch:  6659 | Train Accurancy:  0.9272857457399368 | Validation Accurancy:  0.9245749935507774\n",
      "Epoch:  6660 | Train Accurancy:  0.9272872135043144 | Validation Accurancy:  0.9245811179280281\n",
      "Epoch:  6661 | Train Accurancy:  0.927288793027401 | Validation Accurancy:  0.9245867431163788\n",
      "Epoch:  6662 | Train Accurancy:  0.9272903054952621 | Validation Accurancy:  0.9245928302407265\n",
      "Epoch:  6663 | Train Accurancy:  0.9272918254137039 | Validation Accurancy:  0.9245984107255936\n",
      "Epoch:  6664 | Train Accurancy:  0.9272933006286621 | Validation Accurancy:  0.9246045872569084\n",
      "Epoch:  6665 | Train Accurancy:  0.9272948056459427 | Validation Accurancy:  0.9246101677417755\n",
      "Epoch:  6666 | Train Accurancy:  0.9272962957620621 | Validation Accurancy:  0.9246163368225098\n",
      "Epoch:  6667 | Train Accurancy:  0.9272978752851486 | Validation Accurancy:  0.9246218651533127\n",
      "Epoch:  6668 | Train Accurancy:  0.9272993952035904 | Validation Accurancy:  0.9246280342340469\n",
      "Epoch:  6669 | Train Accurancy:  0.9273008853197098 | Validation Accurancy:  0.9246335998177528\n",
      "Epoch:  6670 | Train Accurancy:  0.9273023456335068 | Validation Accurancy:  0.9246397688984871\n",
      "Epoch:  6671 | Train Accurancy:  0.9273038655519485 | Validation Accurancy:  0.9246453940868378\n",
      "Epoch:  6672 | Train Accurancy:  0.9273053854703903 | Validation Accurancy:  0.9246515408158302\n",
      "Epoch:  6673 | Train Accurancy:  0.9273068755865097 | Validation Accurancy:  0.9246571213006973\n",
      "Epoch:  6674 | Train Accurancy:  0.9273083880543709 | Validation Accurancy:  0.9246632233262062\n",
      "Epoch:  6675 | Train Accurancy:  0.9273098707199097 | Validation Accurancy:  0.9246688708662987\n",
      "Epoch:  6676 | Train Accurancy:  0.9273113757371902 | Validation Accurancy:  0.9246749579906464\n",
      "Epoch:  6677 | Train Accurancy:  0.927312970161438 | Validation Accurancy:  0.9246805384755135\n",
      "Epoch:  6678 | Train Accurancy:  0.9273144006729126 | Validation Accurancy:  0.9246867001056671\n",
      "Epoch:  6679 | Train Accurancy:  0.927315928041935 | Validation Accurancy:  0.9246923103928566\n",
      "Epoch:  6680 | Train Accurancy:  0.927317425608635 | Validation Accurancy:  0.9246983379125595\n",
      "Epoch:  6681 | Train Accurancy:  0.9273189306259155 | Validation Accurancy:  0.9247039929032326\n",
      "Epoch:  6682 | Train Accurancy:  0.9273204281926155 | Validation Accurancy:  0.9247100502252579\n",
      "Epoch:  6683 | Train Accurancy:  0.9273219108581543 | Validation Accurancy:  0.9247157126665115\n",
      "Epoch:  6684 | Train Accurancy:  0.9273234605789185 | Validation Accurancy:  0.9247217327356339\n",
      "Epoch:  6685 | Train Accurancy:  0.9273248761892319 | Validation Accurancy:  0.9247273579239845\n",
      "Epoch:  6686 | Train Accurancy:  0.9273264110088348 | Validation Accurancy:  0.9247334823012352\n",
      "Epoch:  6687 | Train Accurancy:  0.9273280203342438 | Validation Accurancy:  0.9247391521930695\n",
      "Epoch:  6688 | Train Accurancy:  0.9273295029997826 | Validation Accurancy:  0.9247451946139336\n",
      "Epoch:  6689 | Train Accurancy:  0.9273309037089348 | Validation Accurancy:  0.9247507899999619\n",
      "Epoch:  6690 | Train Accurancy:  0.927332416176796 | Validation Accurancy:  0.9247568622231483\n",
      "Epoch:  6691 | Train Accurancy:  0.9273339658975601 | Validation Accurancy:  0.924762487411499\n",
      "Epoch:  6692 | Train Accurancy:  0.9273354336619377 | Validation Accurancy:  0.9247685298323631\n",
      "Epoch:  6693 | Train Accurancy:  0.9273369535803795 | Validation Accurancy:  0.9247741848230362\n",
      "Epoch:  6694 | Train Accurancy:  0.9273383989930153 | Validation Accurancy:  0.9247801974415779\n",
      "Epoch:  6695 | Train Accurancy:  0.9273399263620377 | Validation Accurancy:  0.9247858375310898\n",
      "Epoch:  6696 | Train Accurancy:  0.9273414090275764 | Validation Accurancy:  0.9247920215129852\n",
      "Epoch:  6697 | Train Accurancy:  0.9273429811000824 | Validation Accurancy:  0.9247975498437881\n",
      "Epoch:  6698 | Train Accurancy:  0.9273444339632988 | Validation Accurancy:  0.9248036071658134\n",
      "Epoch:  6699 | Train Accurancy:  0.9273459389805794 | Validation Accurancy:  0.9248095974326134\n",
      "Epoch:  6700 | Train Accurancy:  0.9273474365472794 | Validation Accurancy:  0.9248150661587715\n",
      "Epoch:  6701 | Train Accurancy:  0.9273488968610764 | Validation Accurancy:  0.9248212054371834\n",
      "Epoch:  6702 | Train Accurancy:  0.9273504465818405 | Validation Accurancy:  0.9248267337679863\n",
      "Epoch:  6703 | Train Accurancy:  0.9273519217967987 | Validation Accurancy:  0.9248328059911728\n",
      "Epoch:  6704 | Train Accurancy:  0.9273533746600151 | Validation Accurancy:  0.9248383194208145\n",
      "Epoch:  6705 | Train Accurancy:  0.9273549169301987 | Validation Accurancy:  0.9248443618416786\n",
      "Epoch:  6706 | Train Accurancy:  0.9273563697934151 | Validation Accurancy:  0.9248500317335129\n",
      "Epoch:  6707 | Train Accurancy:  0.9273578450083733 | Validation Accurancy:  0.9248561039566994\n",
      "Epoch:  6708 | Train Accurancy:  0.9273594170808792 | Validation Accurancy:  0.9248616695404053\n",
      "Epoch:  6709 | Train Accurancy:  0.927360825240612 | Validation Accurancy:  0.9248677119612694\n",
      "Epoch:  6710 | Train Accurancy:  0.9273623526096344 | Validation Accurancy:  0.9248732551932335\n",
      "Epoch:  6711 | Train Accurancy:  0.9273638427257538 | Validation Accurancy:  0.9248793423175812\n",
      "Epoch:  6712 | Train Accurancy:  0.9273653849959373 | Validation Accurancy:  0.9248848408460617\n",
      "Epoch:  6713 | Train Accurancy:  0.9273668006062508 | Validation Accurancy:  0.9248908683657646\n",
      "Epoch:  6714 | Train Accurancy:  0.9273683056235313 | Validation Accurancy:  0.9248965233564377\n",
      "Epoch:  6715 | Train Accurancy:  0.9273697957396507 | Validation Accurancy:  0.9249026328325272\n",
      "Epoch:  6716 | Train Accurancy:  0.9273712933063507 | Validation Accurancy:  0.9249081313610077\n",
      "Epoch:  6717 | Train Accurancy:  0.9273727610707283 | Validation Accurancy:  0.9249142333865166\n",
      "Epoch:  6718 | Train Accurancy:  0.9273742735385895 | Validation Accurancy:  0.9249201789498329\n",
      "Epoch:  6719 | Train Accurancy:  0.9273757487535477 | Validation Accurancy:  0.9249256104230881\n",
      "Epoch:  6720 | Train Accurancy:  0.9273772314190865 | Validation Accurancy:  0.9249316528439522\n",
      "Epoch:  6721 | Train Accurancy:  0.9273787289857864 | Validation Accurancy:  0.9249372482299805\n",
      "Epoch:  6722 | Train Accurancy:  0.927380196750164 | Validation Accurancy:  0.924943320453167\n",
      "Epoch:  6723 | Train Accurancy:  0.9273817390203476 | Validation Accurancy:  0.9249489009380341\n",
      "Epoch:  6724 | Train Accurancy:  0.9273832067847252 | Validation Accurancy:  0.9249548614025116\n",
      "Epoch:  6725 | Train Accurancy:  0.9273846372961998 | Validation Accurancy:  0.9249603450298309\n",
      "Epoch:  6726 | Train Accurancy:  0.9273861646652222 | Validation Accurancy:  0.9249665066599846\n",
      "Epoch:  6727 | Train Accurancy:  0.9273876771330833 | Validation Accurancy:  0.9249720275402069\n",
      "Epoch:  6728 | Train Accurancy:  0.9273891448974609 | Validation Accurancy:  0.9249780848622322\n",
      "Epoch:  6729 | Train Accurancy:  0.9273906052112579 | Validation Accurancy:  0.9249836429953575\n",
      "Epoch:  6730 | Train Accurancy:  0.9273920357227325 | Validation Accurancy:  0.9249896183609962\n",
      "Epoch:  6731 | Train Accurancy:  0.9273935928940773 | Validation Accurancy:  0.9249952808022499\n",
      "Epoch:  6732 | Train Accurancy:  0.9273950234055519 | Validation Accurancy:  0.9250012412667274\n",
      "Epoch:  6733 | Train Accurancy:  0.9273965582251549 | Validation Accurancy:  0.9250067844986916\n",
      "Epoch:  6734 | Train Accurancy:  0.9273980334401131 | Validation Accurancy:  0.9250128269195557\n",
      "Epoch:  6735 | Train Accurancy:  0.9273994863033295 | Validation Accurancy:  0.9250183403491974\n",
      "Epoch:  6736 | Train Accurancy:  0.9274009838700294 | Validation Accurancy:  0.9250243380665779\n",
      "Epoch:  6737 | Train Accurancy:  0.9274023920297623 | Validation Accurancy:  0.9250299781560898\n",
      "Epoch:  6738 | Train Accurancy:  0.927403911948204 | Validation Accurancy:  0.9250360354781151\n",
      "Epoch:  6739 | Train Accurancy:  0.9274054244160652 | Validation Accurancy:  0.9250415489077568\n",
      "Epoch:  6740 | Train Accurancy:  0.9274068549275398 | Validation Accurancy:  0.9250475689768791\n",
      "Epoch:  6741 | Train Accurancy:  0.927408404648304 | Validation Accurancy:  0.9250531643629074\n",
      "Epoch:  6742 | Train Accurancy:  0.9274098202586174 | Validation Accurancy:  0.925059050321579\n",
      "Epoch:  6743 | Train Accurancy:  0.9274113476276398 | Validation Accurancy:  0.9250646308064461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6744 | Train Accurancy:  0.9274127781391144 | Validation Accurancy:  0.9250707179307938\n",
      "Epoch:  6745 | Train Accurancy:  0.9274142161011696 | Validation Accurancy:  0.9250762313604355\n",
      "Epoch:  6746 | Train Accurancy:  0.9274157211184502 | Validation Accurancy:  0.9250823333859444\n",
      "Epoch:  6747 | Train Accurancy:  0.9274172335863113 | Validation Accurancy:  0.9250877723097801\n",
      "Epoch:  6748 | Train Accurancy:  0.927418626844883 | Validation Accurancy:  0.9250936806201935\n",
      "Epoch:  6749 | Train Accurancy:  0.927420124411583 | Validation Accurancy:  0.925099328160286\n",
      "Epoch:  6750 | Train Accurancy:  0.9274215921759605 | Validation Accurancy:  0.9251052513718605\n",
      "Epoch:  6751 | Train Accurancy:  0.9274231120944023 | Validation Accurancy:  0.925110787153244\n",
      "Epoch:  6752 | Train Accurancy:  0.9274245649576187 | Validation Accurancy:  0.9251168221235275\n",
      "Epoch:  6753 | Train Accurancy:  0.9274260252714157 | Validation Accurancy:  0.9251224026083946\n",
      "Epoch:  6754 | Train Accurancy:  0.9274275228381157 | Validation Accurancy:  0.9251283928751945\n",
      "Epoch:  6755 | Train Accurancy:  0.9274289533495903 | Validation Accurancy:  0.9251339137554169\n",
      "Epoch:  6756 | Train Accurancy:  0.9274304434657097 | Validation Accurancy:  0.9251399710774422\n",
      "Epoch:  6757 | Train Accurancy:  0.9274318888783455 | Validation Accurancy:  0.9251454547047615\n",
      "Epoch:  6758 | Train Accurancy:  0.9274334162473679 | Validation Accurancy:  0.9251514449715614\n",
      "Epoch:  6759 | Train Accurancy:  0.9274348840117455 | Validation Accurancy:  0.925156943500042\n",
      "Epoch:  6760 | Train Accurancy:  0.9274363219738007 | Validation Accurancy:  0.9251629859209061\n",
      "Epoch:  6761 | Train Accurancy:  0.927437849342823 | Validation Accurancy:  0.9251684844493866\n",
      "Epoch:  6762 | Train Accurancy:  0.92743930965662 | Validation Accurancy:  0.9251745194196701\n",
      "Epoch:  6763 | Train Accurancy:  0.927440769970417 | Validation Accurancy:  0.9251800030469894\n",
      "Epoch:  6764 | Train Accurancy:  0.927442193031311 | Validation Accurancy:  0.925185963511467\n",
      "Epoch:  6765 | Train Accurancy:  0.927443690598011 | Validation Accurancy:  0.9251915290951729\n",
      "Epoch:  6766 | Train Accurancy:  0.927445150911808 | Validation Accurancy:  0.9251973628997803\n",
      "Epoch:  6767 | Train Accurancy:  0.9274466037750244 | Validation Accurancy:  0.9252029433846474\n",
      "Epoch:  6768 | Train Accurancy:  0.9274480640888214 | Validation Accurancy:  0.9252089783549309\n",
      "Epoch:  6769 | Train Accurancy:  0.9274495467543602 | Validation Accurancy:  0.9252149239182472\n",
      "Epoch:  6770 | Train Accurancy:  0.9274510145187378 | Validation Accurancy:  0.925220362842083\n",
      "Epoch:  6771 | Train Accurancy:  0.927452489733696 | Validation Accurancy:  0.9252264499664307\n",
      "Epoch:  6772 | Train Accurancy:  0.9274539425969124 | Validation Accurancy:  0.9252318516373634\n",
      "Epoch:  6773 | Train Accurancy:  0.9274554252624512 | Validation Accurancy:  0.9252377673983574\n",
      "Epoch:  6774 | Train Accurancy:  0.927456870675087 | Validation Accurancy:  0.9252433776855469\n",
      "Epoch:  6775 | Train Accurancy:  0.927458293735981 | Validation Accurancy:  0.9252493232488632\n",
      "Epoch:  6776 | Train Accurancy:  0.9274598360061646 | Validation Accurancy:  0.9252548217773438\n",
      "Epoch:  6777 | Train Accurancy:  0.9274612590670586 | Validation Accurancy:  0.9252607822418213\n",
      "Epoch:  6778 | Train Accurancy:  0.9274626672267914 | Validation Accurancy:  0.9252662509679794\n",
      "Epoch:  6779 | Train Accurancy:  0.9274641796946526 | Validation Accurancy:  0.9252721965312958\n",
      "Epoch:  6780 | Train Accurancy:  0.927465632557869 | Validation Accurancy:  0.9252777397632599\n",
      "Epoch:  6781 | Train Accurancy:  0.9274670779705048 | Validation Accurancy:  0.9252836033701897\n",
      "Epoch:  6782 | Train Accurancy:  0.9274685606360435 | Validation Accurancy:  0.9252891838550568\n",
      "Epoch:  6783 | Train Accurancy:  0.92747001349926 | Validation Accurancy:  0.9252951443195343\n",
      "Epoch:  6784 | Train Accurancy:  0.9274714812636375 | Validation Accurancy:  0.9253007099032402\n",
      "Epoch:  6785 | Train Accurancy:  0.927472896873951 | Validation Accurancy:  0.9253066033124924\n",
      "Epoch:  6786 | Train Accurancy:  0.9274744093418121 | Validation Accurancy:  0.9253121241927147\n",
      "Epoch:  6787 | Train Accurancy:  0.9274758100509644 | Validation Accurancy:  0.9253181293606758\n",
      "Epoch:  6788 | Train Accurancy:  0.9274773374199867 | Validation Accurancy:  0.9253235161304474\n",
      "Epoch:  6789 | Train Accurancy:  0.927478738129139 | Validation Accurancy:  0.9253295585513115\n",
      "Epoch:  6790 | Train Accurancy:  0.9274802207946777 | Validation Accurancy:  0.9253351017832756\n",
      "Epoch:  6791 | Train Accurancy:  0.9274816662073135 | Validation Accurancy:  0.9253410026431084\n",
      "Epoch:  6792 | Train Accurancy:  0.9274831861257553 | Validation Accurancy:  0.9253465682268143\n",
      "Epoch:  6793 | Train Accurancy:  0.9274845868349075 | Validation Accurancy:  0.9253524616360664\n",
      "Epoch:  6794 | Train Accurancy:  0.9274860247969627 | Validation Accurancy:  0.9253578633069992\n",
      "Epoch:  6795 | Train Accurancy:  0.9274874851107597 | Validation Accurancy:  0.9253639057278633\n",
      "Epoch:  6796 | Train Accurancy:  0.9274889454245567 | Validation Accurancy:  0.9253693893551826\n",
      "Epoch:  6797 | Train Accurancy:  0.9274904057383537 | Validation Accurancy:  0.9253752902150154\n",
      "Epoch:  6798 | Train Accurancy:  0.9274918735027313 | Validation Accurancy:  0.9253808185458183\n",
      "Epoch:  6799 | Train Accurancy:  0.9274932965636253 | Validation Accurancy:  0.9253867119550705\n",
      "Epoch:  6800 | Train Accurancy:  0.9274947419762611 | Validation Accurancy:  0.9253922328352928\n",
      "Epoch:  6801 | Train Accurancy:  0.9274962097406387 | Validation Accurancy:  0.9253982082009315\n",
      "Epoch:  6802 | Train Accurancy:  0.9274976924061775 | Validation Accurancy:  0.9254035949707031\n",
      "Epoch:  6803 | Train Accurancy:  0.9274991452693939 | Validation Accurancy:  0.9254095107316971\n",
      "Epoch:  6804 | Train Accurancy:  0.9275005832314491 | Validation Accurancy:  0.9254149720072746\n",
      "Epoch:  6805 | Train Accurancy:  0.9275019988417625 | Validation Accurancy:  0.9254210293292999\n",
      "Epoch:  6806 | Train Accurancy:  0.9275034368038177 | Validation Accurancy:  0.9254264682531357\n",
      "Epoch:  6807 | Train Accurancy:  0.9275048896670341 | Validation Accurancy:  0.925432376563549\n",
      "Epoch:  6808 | Train Accurancy:  0.9275063797831535 | Validation Accurancy:  0.9254378601908684\n",
      "Epoch:  6809 | Train Accurancy:  0.9275078102946281 | Validation Accurancy:  0.9254437610507011\n",
      "Epoch:  6810 | Train Accurancy:  0.927509255707264 | Validation Accurancy:  0.9254496246576309\n",
      "Epoch:  6811 | Train Accurancy:  0.9275107085704803 | Validation Accurancy:  0.9254551380872726\n",
      "Epoch:  6812 | Train Accurancy:  0.927512139081955 | Validation Accurancy:  0.9254610240459442\n",
      "Epoch:  6813 | Train Accurancy:  0.9275135695934296 | Validation Accurancy:  0.9254665523767471\n",
      "Epoch:  6814 | Train Accurancy:  0.9275150150060654 | Validation Accurancy:  0.9254723861813545\n",
      "Epoch:  6815 | Train Accurancy:  0.92751644551754 | Validation Accurancy:  0.9254778400063515\n",
      "Epoch:  6816 | Train Accurancy:  0.9275178909301758 | Validation Accurancy:  0.9254837706685066\n",
      "Epoch:  6817 | Train Accurancy:  0.9275193437933922 | Validation Accurancy:  0.925489217042923\n",
      "Epoch:  6818 | Train Accurancy:  0.9275208190083504 | Validation Accurancy:  0.9254951030015945\n",
      "Epoch:  6819 | Train Accurancy:  0.9275222569704056 | Validation Accurancy:  0.9255006015300751\n",
      "Epoch:  6820 | Train Accurancy:  0.9275237023830414 | Validation Accurancy:  0.9255064651370049\n",
      "Epoch:  6821 | Train Accurancy:  0.9275251179933548 | Validation Accurancy:  0.9255119040608406\n",
      "Epoch:  6822 | Train Accurancy:  0.92752655595541 | Validation Accurancy:  0.9255178943276405\n",
      "Epoch:  6823 | Train Accurancy:  0.9275280758738518 | Validation Accurancy:  0.9255233108997345\n",
      "Epoch:  6824 | Train Accurancy:  0.9275294914841652 | Validation Accurancy:  0.9255291968584061\n",
      "Epoch:  6825 | Train Accurancy:  0.9275309219956398 | Validation Accurancy:  0.9255345687270164\n",
      "Epoch:  6826 | Train Accurancy:  0.927532322704792 | Validation Accurancy:  0.9255405589938164\n",
      "Epoch:  6827 | Train Accurancy:  0.9275338128209114 | Validation Accurancy:  0.9255460128188133\n",
      "Epoch:  6828 | Train Accurancy:  0.9275351762771606 | Validation Accurancy:  0.9255518093705177\n",
      "Epoch:  6829 | Train Accurancy:  0.9275366440415382 | Validation Accurancy:  0.9255573451519012\n",
      "Epoch:  6830 | Train Accurancy:  0.9275381341576576 | Validation Accurancy:  0.9255632683634758\n",
      "Epoch:  6831 | Train Accurancy:  0.9275395646691322 | Validation Accurancy:  0.9255686774849892\n",
      "Epoch:  6832 | Train Accurancy:  0.927540972828865 | Validation Accurancy:  0.9255745857954025\n",
      "Epoch:  6833 | Train Accurancy:  0.9275424405932426 | Validation Accurancy:  0.9255800545215607\n",
      "Epoch:  6834 | Train Accurancy:  0.9275438562035561 | Validation Accurancy:  0.9255859404802322\n",
      "Epoch:  6835 | Train Accurancy:  0.9275452718138695 | Validation Accurancy:  0.9255913272500038\n",
      "Epoch:  6836 | Train Accurancy:  0.9275467246770859 | Validation Accurancy:  0.9255973175168037\n",
      "Epoch:  6837 | Train Accurancy:  0.9275481551885605 | Validation Accurancy:  0.9256026744842529\n",
      "Epoch:  6838 | Train Accurancy:  0.9275495707988739 | Validation Accurancy:  0.9256086200475693\n",
      "Epoch:  6839 | Train Accurancy:  0.9275510236620903 | Validation Accurancy:  0.925614133477211\n",
      "Epoch:  6840 | Train Accurancy:  0.9275524690747261 | Validation Accurancy:  0.9256199821829796\n",
      "Epoch:  6841 | Train Accurancy:  0.9275539219379425 | Validation Accurancy:  0.9256254807114601\n",
      "Epoch:  6842 | Train Accurancy:  0.9275553151965141 | Validation Accurancy:  0.9256313964724541\n",
      "Epoch:  6843 | Train Accurancy:  0.9275567680597305 | Validation Accurancy:  0.9256367534399033\n",
      "Epoch:  6844 | Train Accurancy:  0.9275581985712051 | Validation Accurancy:  0.9256422817707062\n",
      "Epoch:  6845 | Train Accurancy:  0.9275595769286156 | Validation Accurancy:  0.9256481677293777\n",
      "Epoch:  6846 | Train Accurancy:  0.927561067044735 | Validation Accurancy:  0.9256536513566971\n",
      "Epoch:  6847 | Train Accurancy:  0.9275624603033066 | Validation Accurancy:  0.9256596565246582\n",
      "Epoch:  6848 | Train Accurancy:  0.9275639727711678 | Validation Accurancy:  0.9256649985909462\n",
      "Epoch:  6849 | Train Accurancy:  0.927565410733223 | Validation Accurancy:  0.9256709292531013\n",
      "Epoch:  6850 | Train Accurancy:  0.9275668114423752 | Validation Accurancy:  0.9256763160228729\n",
      "Epoch:  6851 | Train Accurancy:  0.927568219602108 | Validation Accurancy:  0.9256822243332863\n",
      "Epoch:  6852 | Train Accurancy:  0.9275696948170662 | Validation Accurancy:  0.9256876781582832\n",
      "Epoch:  6853 | Train Accurancy:  0.927571102976799 | Validation Accurancy:  0.9256936237215996\n",
      "Epoch:  6854 | Train Accurancy:  0.92757248878479 | Validation Accurancy:  0.92569899559021\n",
      "Epoch:  6855 | Train Accurancy:  0.9275739192962646 | Validation Accurancy:  0.9257049262523651\n",
      "Epoch:  6856 | Train Accurancy:  0.927575372159481 | Validation Accurancy:  0.9257103279232979\n",
      "Epoch:  6857 | Train Accurancy:  0.9275767803192139 | Validation Accurancy:  0.9257162287831306\n",
      "Epoch:  6858 | Train Accurancy:  0.9275782555341721 | Validation Accurancy:  0.9257216304540634\n",
      "Epoch:  6859 | Train Accurancy:  0.9275796413421631 | Validation Accurancy:  0.9257274642586708\n",
      "Epoch:  6860 | Train Accurancy:  0.9275811240077019 | Validation Accurancy:  0.9257328808307648\n",
      "Epoch:  6861 | Train Accurancy:  0.9275825098156929 | Validation Accurancy:  0.9257387295365334\n",
      "Epoch:  6862 | Train Accurancy:  0.9275839179754257 | Validation Accurancy:  0.9257441014051437\n",
      "Epoch:  6863 | Train Accurancy:  0.9275853559374809 | Validation Accurancy:  0.9257499873638153\n",
      "Epoch:  6864 | Train Accurancy:  0.9275867715477943 | Validation Accurancy:  0.9257553741335869\n",
      "Epoch:  6865 | Train Accurancy:  0.9275882169604301 | Validation Accurancy:  0.9257612526416779\n",
      "Epoch:  6866 | Train Accurancy:  0.9275896549224854 | Validation Accurancy:  0.9257666915655136\n",
      "Epoch:  6867 | Train Accurancy:  0.927591048181057 | Validation Accurancy:  0.9257725849747658\n",
      "Epoch:  6868 | Train Accurancy:  0.9275924786925316 | Validation Accurancy:  0.9257780089974403\n",
      "Epoch:  6869 | Train Accurancy:  0.9275939241051674 | Validation Accurancy:  0.9257837310433388\n",
      "Epoch:  6870 | Train Accurancy:  0.9275953397154808 | Validation Accurancy:  0.9257892146706581\n",
      "Epoch:  6871 | Train Accurancy:  0.9275967627763748 | Validation Accurancy:  0.9257946982979774\n",
      "Epoch:  6872 | Train Accurancy:  0.927598163485527 | Validation Accurancy:  0.925800658762455\n",
      "Epoch:  6873 | Train Accurancy:  0.9275995716452599 | Validation Accurancy:  0.9258061423897743\n",
      "Epoch:  6874 | Train Accurancy:  0.9276010021567345 | Validation Accurancy:  0.9258119240403175\n",
      "Epoch:  6875 | Train Accurancy:  0.9276024401187897 | Validation Accurancy:  0.9258173778653145\n",
      "Epoch:  6876 | Train Accurancy:  0.9276038482785225 | Validation Accurancy:  0.9258232936263084\n",
      "Epoch:  6877 | Train Accurancy:  0.9276052266359329 | Validation Accurancy:  0.9258286952972412\n",
      "Epoch:  6878 | Train Accurancy:  0.9276066496968269 | Validation Accurancy:  0.9258346110582352\n",
      "Epoch:  6879 | Train Accurancy:  0.9276081323623657 | Validation Accurancy:  0.925839900970459\n",
      "Epoch:  6880 | Train Accurancy:  0.9276095181703568 | Validation Accurancy:  0.9258458316326141\n",
      "Epoch:  6881 | Train Accurancy:  0.9276109263300896 | Validation Accurancy:  0.9258511886000633\n",
      "Epoch:  6882 | Train Accurancy:  0.9276123121380806 | Validation Accurancy:  0.9258570224046707\n",
      "Epoch:  6883 | Train Accurancy:  0.9276138022542 | Validation Accurancy:  0.9258624091744423\n",
      "Epoch:  6884 | Train Accurancy:  0.9276152104139328 | Validation Accurancy:  0.9258682876825333\n",
      "Epoch:  6885 | Train Accurancy:  0.9276166185736656 | Validation Accurancy:  0.9258735328912735\n",
      "Epoch:  6886 | Train Accurancy:  0.9276180267333984 | Validation Accurancy:  0.9258794784545898\n",
      "Epoch:  6887 | Train Accurancy:  0.9276195019483566 | Validation Accurancy:  0.9258848801255226\n",
      "Epoch:  6888 | Train Accurancy:  0.9276208579540253 | Validation Accurancy:  0.9258907288312912\n",
      "Epoch:  6889 | Train Accurancy:  0.9276222959160805 | Validation Accurancy:  0.9258960708975792\n",
      "Epoch:  6890 | Train Accurancy:  0.9276237040758133 | Validation Accurancy:  0.9259015545248985\n",
      "Epoch:  6891 | Train Accurancy:  0.9276251345872879 | Validation Accurancy:  0.9259075000882149\n",
      "Epoch:  6892 | Train Accurancy:  0.9276265278458595 | Validation Accurancy:  0.9259128719568253\n",
      "Epoch:  6893 | Train Accurancy:  0.9276279360055923 | Validation Accurancy:  0.9259186610579491\n",
      "Epoch:  6894 | Train Accurancy:  0.9276293516159058 | Validation Accurancy:  0.9259240478277206\n",
      "Epoch:  6895 | Train Accurancy:  0.9276307821273804 | Validation Accurancy:  0.9259299114346504\n",
      "Epoch:  6896 | Train Accurancy:  0.927632175385952 | Validation Accurancy:  0.9259353950619698\n",
      "Epoch:  6897 | Train Accurancy:  0.9276335686445236 | Validation Accurancy:  0.9259411990642548\n",
      "Epoch:  6898 | Train Accurancy:  0.9276349693536758 | Validation Accurancy:  0.9259466454386711\n",
      "Epoch:  6899 | Train Accurancy:  0.9276363924145699 | Validation Accurancy:  0.9259524196386337\n",
      "Epoch:  6900 | Train Accurancy:  0.9276378229260445 | Validation Accurancy:  0.9259577617049217\n",
      "Epoch:  6901 | Train Accurancy:  0.9276392459869385 | Validation Accurancy:  0.9259636104106903\n",
      "Epoch:  6902 | Train Accurancy:  0.9276406317949295 | Validation Accurancy:  0.9259689003229141\n",
      "Epoch:  6903 | Train Accurancy:  0.9276420548558235 | Validation Accurancy:  0.9259748458862305\n",
      "Epoch:  6904 | Train Accurancy:  0.9276434406638145 | Validation Accurancy:  0.9259801357984543\n",
      "Epoch:  6905 | Train Accurancy:  0.9276448488235474 | Validation Accurancy:  0.9259860813617706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6906 | Train Accurancy:  0.9276462644338608 | Validation Accurancy:  0.9259913414716721\n",
      "Epoch:  6907 | Train Accurancy:  0.9276476800441742 | Validation Accurancy:  0.9259971901774406\n",
      "Epoch:  6908 | Train Accurancy:  0.9276490956544876 | Validation Accurancy:  0.9260025322437286\n",
      "Epoch:  6909 | Train Accurancy:  0.9276504665613174 | Validation Accurancy:  0.9260084182024002\n",
      "Epoch:  6910 | Train Accurancy:  0.9276518896222115 | Validation Accurancy:  0.9260138049721718\n",
      "Epoch:  6911 | Train Accurancy:  0.9276532903313637 | Validation Accurancy:  0.9260196536779404\n",
      "Epoch:  6912 | Train Accurancy:  0.9276547133922577 | Validation Accurancy:  0.9260248839855194\n",
      "Epoch:  6913 | Train Accurancy:  0.9276561364531517 | Validation Accurancy:  0.9260307475924492\n",
      "Epoch:  6914 | Train Accurancy:  0.9276575222611427 | Validation Accurancy:  0.9260360226035118\n",
      "Epoch:  6915 | Train Accurancy:  0.9276588931679726 | Validation Accurancy:  0.9260418564081192\n",
      "Epoch:  6916 | Train Accurancy:  0.927660308778286 | Validation Accurancy:  0.9260472133755684\n",
      "Epoch:  6917 | Train Accurancy:  0.92766173183918 | Validation Accurancy:  0.9260526821017265\n",
      "Epoch:  6918 | Train Accurancy:  0.9276630952954292 | Validation Accurancy:  0.9260584861040115\n",
      "Epoch:  6919 | Train Accurancy:  0.927664540708065 | Validation Accurancy:  0.9260638877749443\n",
      "Epoch:  6920 | Train Accurancy:  0.927665963768959 | Validation Accurancy:  0.9260697364807129\n",
      "Epoch:  6921 | Train Accurancy:  0.9276673421263695 | Validation Accurancy:  0.9260750487446785\n",
      "Epoch:  6922 | Train Accurancy:  0.9276687428355217 | Validation Accurancy:  0.9260808750987053\n",
      "Epoch:  6923 | Train Accurancy:  0.9276701658964157 | Validation Accurancy:  0.9260861873626709\n",
      "Epoch:  6924 | Train Accurancy:  0.9276715368032455 | Validation Accurancy:  0.9260920360684395\n",
      "Epoch:  6925 | Train Accurancy:  0.927672915160656 | Validation Accurancy:  0.9260973781347275\n",
      "Epoch:  6926 | Train Accurancy:  0.92767433822155 | Validation Accurancy:  0.9261031970381737\n",
      "Epoch:  6927 | Train Accurancy:  0.927675724029541 | Validation Accurancy:  0.9261085689067841\n",
      "Epoch:  6928 | Train Accurancy:  0.9276771321892738 | Validation Accurancy:  0.9261143505573273\n",
      "Epoch:  6929 | Train Accurancy:  0.9276785105466843 | Validation Accurancy:  0.9261197596788406\n",
      "Epoch:  6930 | Train Accurancy:  0.9276799857616425 | Validation Accurancy:  0.9261255264282227\n",
      "Epoch:  6931 | Train Accurancy:  0.9276813566684723 | Validation Accurancy:  0.9261308014392853\n",
      "Epoch:  6932 | Train Accurancy:  0.9276827499270439 | Validation Accurancy:  0.9261365383863449\n",
      "Epoch:  6933 | Train Accurancy:  0.9276841506361961 | Validation Accurancy:  0.9261419475078583\n",
      "Epoch:  6934 | Train Accurancy:  0.9276855140924454 | Validation Accurancy:  0.9261476993560791\n",
      "Epoch:  6935 | Train Accurancy:  0.9276869371533394 | Validation Accurancy:  0.926153153181076\n",
      "Epoch:  6936 | Train Accurancy:  0.927688330411911 | Validation Accurancy:  0.9261589720845222\n",
      "Epoch:  6937 | Train Accurancy:  0.9276897236704826 | Validation Accurancy:  0.9261642619967461\n",
      "Epoch:  6938 | Train Accurancy:  0.9276911243796349 | Validation Accurancy:  0.9261700138449669\n",
      "Epoch:  6939 | Train Accurancy:  0.9276924580335617 | Validation Accurancy:  0.9261753112077713\n",
      "Epoch:  6940 | Train Accurancy:  0.9276939406991005 | Validation Accurancy:  0.9261810779571533\n",
      "Epoch:  6941 | Train Accurancy:  0.9276953041553497 | Validation Accurancy:  0.9261865615844727\n",
      "Epoch:  6942 | Train Accurancy:  0.9276966974139214 | Validation Accurancy:  0.9261922165751457\n",
      "Epoch:  6943 | Train Accurancy:  0.9276980608701706 | Validation Accurancy:  0.9261976554989815\n",
      "Epoch:  6944 | Train Accurancy:  0.9276994913816452 | Validation Accurancy:  0.9262034073472023\n",
      "Epoch:  6945 | Train Accurancy:  0.9277008473873138 | Validation Accurancy:  0.9262086674571037\n",
      "Epoch:  6946 | Train Accurancy:  0.9277022331953049 | Validation Accurancy:  0.9262144565582275\n",
      "Epoch:  6947 | Train Accurancy:  0.9277036339044571 | Validation Accurancy:  0.9262197688221931\n",
      "Epoch:  6948 | Train Accurancy:  0.9277050271630287 | Validation Accurancy:  0.9262255653738976\n",
      "Epoch:  6949 | Train Accurancy:  0.9277064502239227 | Validation Accurancy:  0.9262308403849602\n",
      "Epoch:  6950 | Train Accurancy:  0.9277077838778496 | Validation Accurancy:  0.9262366145849228\n",
      "Epoch:  6951 | Train Accurancy:  0.927709236741066 | Validation Accurancy:  0.926241971552372\n",
      "Epoch:  6952 | Train Accurancy:  0.9277105778455734 | Validation Accurancy:  0.9262477532029152\n",
      "Epoch:  6953 | Train Accurancy:  0.9277120158076286 | Validation Accurancy:  0.9262530505657196\n",
      "Epoch:  6954 | Train Accurancy:  0.9277133867144585 | Validation Accurancy:  0.9262587204575539\n",
      "Epoch:  6955 | Train Accurancy:  0.9277147352695465 | Validation Accurancy:  0.926264114677906\n",
      "Epoch:  6956 | Train Accurancy:  0.9277161583304405 | Validation Accurancy:  0.9262697696685791\n",
      "Epoch:  6957 | Train Accurancy:  0.9277175739407539 | Validation Accurancy:  0.9262751713395119\n",
      "Epoch:  6958 | Train Accurancy:  0.9277189150452614 | Validation Accurancy:  0.9262808933854103\n",
      "Epoch:  6959 | Train Accurancy:  0.9277202561497688 | Validation Accurancy:  0.9262862652540207\n",
      "Epoch:  6960 | Train Accurancy:  0.9277217164635658 | Validation Accurancy:  0.9262920245528221\n",
      "Epoch:  6961 | Train Accurancy:  0.9277231320738792 | Validation Accurancy:  0.9262973293662071\n",
      "Epoch:  6962 | Train Accurancy:  0.9277245104312897 | Validation Accurancy:  0.9263030663132668\n",
      "Epoch:  6963 | Train Accurancy:  0.9277258589863777 | Validation Accurancy:  0.9263084754347801\n",
      "Epoch:  6964 | Train Accurancy:  0.9277272373437881 | Validation Accurancy:  0.9263141304254532\n",
      "Epoch:  6965 | Train Accurancy:  0.9277286231517792 | Validation Accurancy:  0.9263194873929024\n",
      "Epoch:  6966 | Train Accurancy:  0.927730031311512 | Validation Accurancy:  0.926324799656868\n",
      "Epoch:  6967 | Train Accurancy:  0.9277314096689224 | Validation Accurancy:  0.9263306483626366\n",
      "Epoch:  6968 | Train Accurancy:  0.9277327731251717 | Validation Accurancy:  0.9263359680771828\n",
      "Epoch:  6969 | Train Accurancy:  0.9277341738343239 | Validation Accurancy:  0.9263416603207588\n",
      "Epoch:  6970 | Train Accurancy:  0.9277355447411537 | Validation Accurancy:  0.9263470321893692\n",
      "Epoch:  6971 | Train Accurancy:  0.9277369305491447 | Validation Accurancy:  0.9263527691364288\n",
      "Epoch:  6972 | Train Accurancy:  0.927738294005394 | Validation Accurancy:  0.9263581112027168\n",
      "Epoch:  6973 | Train Accurancy:  0.9277396872639656 | Validation Accurancy:  0.9263639450073242\n",
      "Epoch:  6974 | Train Accurancy:  0.9277411177754402 | Validation Accurancy:  0.9263692051172256\n",
      "Epoch:  6975 | Train Accurancy:  0.9277424737811089 | Validation Accurancy:  0.9263749122619629\n",
      "Epoch:  6976 | Train Accurancy:  0.9277438446879387 | Validation Accurancy:  0.9263801723718643\n",
      "Epoch:  6977 | Train Accurancy:  0.9277451783418655 | Validation Accurancy:  0.9263859465718269\n",
      "Epoch:  6978 | Train Accurancy:  0.9277466163039207 | Validation Accurancy:  0.9263912215828896\n",
      "Epoch:  6979 | Train Accurancy:  0.9277479723095894 | Validation Accurancy:  0.9263969883322716\n",
      "Epoch:  6980 | Train Accurancy:  0.9277493581175804 | Validation Accurancy:  0.926402360200882\n",
      "Epoch:  6981 | Train Accurancy:  0.9277507066726685 | Validation Accurancy:  0.9264079555869102\n",
      "Epoch:  6982 | Train Accurancy:  0.9277521148324013 | Validation Accurancy:  0.9264132976531982\n",
      "Epoch:  6983 | Train Accurancy:  0.9277534782886505 | Validation Accurancy:  0.9264189898967743\n",
      "Epoch:  6984 | Train Accurancy:  0.9277548789978027 | Validation Accurancy:  0.9264243766665459\n",
      "Epoch:  6985 | Train Accurancy:  0.927756205201149 | Validation Accurancy:  0.9264300316572189\n",
      "Epoch:  6986 | Train Accurancy:  0.9277576133608818 | Validation Accurancy:  0.9264353737235069\n",
      "Epoch:  6987 | Train Accurancy:  0.9277589693665504 | Validation Accurancy:  0.926441065967083\n",
      "Epoch:  6988 | Train Accurancy:  0.9277604073286057 | Validation Accurancy:  0.926446296274662\n",
      "Epoch:  6989 | Train Accurancy:  0.9277617707848549 | Validation Accurancy:  0.9264520034193993\n",
      "Epoch:  6990 | Train Accurancy:  0.9277630969882011 | Validation Accurancy:  0.9264573901891708\n",
      "Epoch:  6991 | Train Accurancy:  0.9277644529938698 | Validation Accurancy:  0.9264629855751991\n",
      "Epoch:  6992 | Train Accurancy:  0.927765853703022 | Validation Accurancy:  0.9264683276414871\n",
      "Epoch:  6993 | Train Accurancy:  0.9277671948075294 | Validation Accurancy:  0.9264740124344826\n",
      "Epoch:  6994 | Train Accurancy:  0.9277686253190041 | Validation Accurancy:  0.926479309797287\n",
      "Epoch:  6995 | Train Accurancy:  0.9277700036764145 | Validation Accurancy:  0.92648496478796\n",
      "Epoch:  6996 | Train Accurancy:  0.9277714043855667 | Validation Accurancy:  0.9264903366565704\n",
      "Epoch:  6997 | Train Accurancy:  0.927772730588913 | Validation Accurancy:  0.9264960289001465\n",
      "Epoch:  6998 | Train Accurancy:  0.927774153649807 | Validation Accurancy:  0.9265013039112091\n",
      "Epoch:  6999 | Train Accurancy:  0.9277754575014114 | Validation Accurancy:  0.9265070408582687\n",
      "Epoch:  7000 | Train Accurancy:  0.9277768582105637 | Validation Accurancy:  0.9265123531222343\n",
      "Epoch:  7001 | Train Accurancy:  0.9277781993150711 | Validation Accurancy:  0.9265180081129074\n",
      "Epoch:  7002 | Train Accurancy:  0.9277795925736427 | Validation Accurancy:  0.9265232905745506\n",
      "Epoch:  7003 | Train Accurancy:  0.927780956029892 | Validation Accurancy:  0.9265288636088371\n",
      "Epoch:  7004 | Train Accurancy:  0.9277823194861412 | Validation Accurancy:  0.9265342727303505\n",
      "Epoch:  7005 | Train Accurancy:  0.9277836829423904 | Validation Accurancy:  0.9265399426221848\n",
      "Epoch:  7006 | Train Accurancy:  0.9277851358056068 | Validation Accurancy:  0.9265452548861504\n",
      "Epoch:  7007 | Train Accurancy:  0.9277864545583725 | Validation Accurancy:  0.9265509471297264\n",
      "Epoch:  7008 | Train Accurancy:  0.9277877807617188 | Validation Accurancy:  0.9265561923384666\n",
      "Epoch:  7009 | Train Accurancy:  0.927789144217968 | Validation Accurancy:  0.9265618771314621\n",
      "Epoch:  7010 | Train Accurancy:  0.927790492773056 | Validation Accurancy:  0.9265671893954277\n",
      "Epoch:  7011 | Train Accurancy:  0.9277918711304665 | Validation Accurancy:  0.9265728816390038\n",
      "Epoch:  7012 | Train Accurancy:  0.9277932643890381 | Validation Accurancy:  0.9265780746936798\n",
      "Epoch:  7013 | Train Accurancy:  0.9277946203947067 | Validation Accurancy:  0.9265838116407394\n",
      "Epoch:  7014 | Train Accurancy:  0.9277959987521172 | Validation Accurancy:  0.9265891090035439\n",
      "Epoch:  7015 | Train Accurancy:  0.927797369658947 | Validation Accurancy:  0.9265947490930557\n",
      "Epoch:  7016 | Train Accurancy:  0.927798718214035 | Validation Accurancy:  0.9266001060605049\n",
      "Epoch:  7017 | Train Accurancy:  0.9278000891208649 | Validation Accurancy:  0.9266057163476944\n",
      "Epoch:  7018 | Train Accurancy:  0.9278014674782753 | Validation Accurancy:  0.9266110435128212\n",
      "Epoch:  7019 | Train Accurancy:  0.9278028160333633 | Validation Accurancy:  0.9266167134046555\n",
      "Epoch:  7020 | Train Accurancy:  0.9278042018413544 | Validation Accurancy:  0.9266219288110733\n",
      "Epoch:  7021 | Train Accurancy:  0.9278055354952812 | Validation Accurancy:  0.9266275689005852\n",
      "Epoch:  7022 | Train Accurancy:  0.9278069287538528 | Validation Accurancy:  0.926632896065712\n",
      "Epoch:  7023 | Train Accurancy:  0.9278082773089409 | Validation Accurancy:  0.9266385212540627\n",
      "Epoch:  7024 | Train Accurancy:  0.9278096333146095 | Validation Accurancy:  0.9266437366604805\n",
      "Epoch:  7025 | Train Accurancy:  0.92781101167202 | Validation Accurancy:  0.9266494289040565\n",
      "Epoch:  7026 | Train Accurancy:  0.9278123900294304 | Validation Accurancy:  0.926654689013958\n",
      "Epoch:  7027 | Train Accurancy:  0.927813746035099 | Validation Accurancy:  0.926660381257534\n",
      "Epoch:  7028 | Train Accurancy:  0.9278150275349617 | Validation Accurancy:  0.9266656115651131\n",
      "Epoch:  7029 | Train Accurancy:  0.9278164580464363 | Validation Accurancy:  0.9266713336110115\n",
      "Epoch:  7030 | Train Accurancy:  0.9278178364038467 | Validation Accurancy:  0.9266765415668488\n",
      "Epoch:  7031 | Train Accurancy:  0.9278191477060318 | Validation Accurancy:  0.9266822040081024\n",
      "Epoch:  7032 | Train Accurancy:  0.927820511162281 | Validation Accurancy:  0.9266875088214874\n",
      "Epoch:  7033 | Train Accurancy:  0.9278218522667885 | Validation Accurancy:  0.9266931042075157\n",
      "Epoch:  7034 | Train Accurancy:  0.9278232827782631 | Validation Accurancy:  0.9266983643174171\n",
      "Epoch:  7035 | Train Accurancy:  0.9278246164321899 | Validation Accurancy:  0.9267040565609932\n",
      "Epoch:  7036 | Train Accurancy:  0.927825964987278 | Validation Accurancy:  0.9267093017697334\n",
      "Epoch:  7037 | Train Accurancy:  0.9278272837400436 | Validation Accurancy:  0.9267148673534393\n",
      "Epoch:  7038 | Train Accurancy:  0.9278286918997765 | Validation Accurancy:  0.9267201572656631\n",
      "Epoch:  7039 | Train Accurancy:  0.9278300479054451 | Validation Accurancy:  0.926725834608078\n",
      "Epoch:  7040 | Train Accurancy:  0.9278313294053078 | Validation Accurancy:  0.9267310798168182\n",
      "Epoch:  7041 | Train Accurancy:  0.9278327226638794 | Validation Accurancy:  0.9267367199063301\n",
      "Epoch:  7042 | Train Accurancy:  0.9278341084718704 | Validation Accurancy:  0.9267419204115868\n",
      "Epoch:  7043 | Train Accurancy:  0.9278354346752167 | Validation Accurancy:  0.926747627556324\n",
      "Epoch:  7044 | Train Accurancy:  0.9278367906808853 | Validation Accurancy:  0.9267529174685478\n",
      "Epoch:  7045 | Train Accurancy:  0.9278381615877151 | Validation Accurancy:  0.9267584457993507\n",
      "Epoch:  7046 | Train Accurancy:  0.9278395473957062 | Validation Accurancy:  0.9267637878656387\n",
      "Epoch:  7047 | Train Accurancy:  0.9278408512473106 | Validation Accurancy:  0.9267694503068924\n",
      "Epoch:  7048 | Train Accurancy:  0.9278422147035599 | Validation Accurancy:  0.9267745316028595\n",
      "Epoch:  7049 | Train Accurancy:  0.9278435930609703 | Validation Accurancy:  0.9267803356051445\n",
      "Epoch:  7050 | Train Accurancy:  0.9278448894619942 | Validation Accurancy:  0.9267854541540146\n",
      "Epoch:  7051 | Train Accurancy:  0.9278462752699852 | Validation Accurancy:  0.9267911240458488\n",
      "Epoch:  7052 | Train Accurancy:  0.927847608923912 | Validation Accurancy:  0.9267963543534279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7053 | Train Accurancy:  0.9278489723801613 | Validation Accurancy:  0.9268020465970039\n",
      "Epoch:  7054 | Train Accurancy:  0.9278502836823463 | Validation Accurancy:  0.9268072098493576\n",
      "Epoch:  7055 | Train Accurancy:  0.927851639688015 | Validation Accurancy:  0.9268129020929337\n",
      "Epoch:  7056 | Train Accurancy:  0.9278530105948448 | Validation Accurancy:  0.9268181771039963\n",
      "Epoch:  7057 | Train Accurancy:  0.9278543889522552 | Validation Accurancy:  0.9268236830830574\n",
      "Epoch:  7058 | Train Accurancy:  0.9278557002544403 | Validation Accurancy:  0.92682895809412\n",
      "Epoch:  7059 | Train Accurancy:  0.9278570637106895 | Validation Accurancy:  0.9268346130847931\n",
      "Epoch:  7060 | Train Accurancy:  0.9278584271669388 | Validation Accurancy:  0.9268398433923721\n",
      "Epoch:  7061 | Train Accurancy:  0.927859716117382 | Validation Accurancy:  0.9268454685807228\n",
      "Epoch:  7062 | Train Accurancy:  0.9278611093759537 | Validation Accurancy:  0.9268506839871407\n",
      "Epoch:  7063 | Train Accurancy:  0.9278624206781387 | Validation Accurancy:  0.9268563911318779\n",
      "Epoch:  7064 | Train Accurancy:  0.9278638437390327 | Validation Accurancy:  0.9268615692853928\n",
      "Epoch:  7065 | Train Accurancy:  0.9278651475906372 | Validation Accurancy:  0.9268671497702599\n",
      "Epoch:  7066 | Train Accurancy:  0.9278665408492088 | Validation Accurancy:  0.9268722981214523\n",
      "Epoch:  7067 | Train Accurancy:  0.9278678894042969 | Validation Accurancy:  0.9268780425190926\n",
      "Epoch:  7068 | Train Accurancy:  0.9278692081570625 | Validation Accurancy:  0.9268832057714462\n",
      "Epoch:  7069 | Train Accurancy:  0.9278705641627312 | Validation Accurancy:  0.9268887713551521\n",
      "Epoch:  7070 | Train Accurancy:  0.9278718382120132 | Validation Accurancy:  0.9268940463662148\n",
      "Epoch:  7071 | Train Accurancy:  0.9278732165694237 | Validation Accurancy:  0.9268996268510818\n",
      "Epoch:  7072 | Train Accurancy:  0.9278745427727699 | Validation Accurancy:  0.9269049316644669\n",
      "Epoch:  7073 | Train Accurancy:  0.9278759509325027 | Validation Accurancy:  0.9269105270504951\n",
      "Epoch:  7074 | Train Accurancy:  0.9278772845864296 | Validation Accurancy:  0.9269157722592354\n",
      "Epoch:  7075 | Train Accurancy:  0.9278786107897758 | Validation Accurancy:  0.9269212856888771\n",
      "Epoch:  7076 | Train Accurancy:  0.9278799220919609 | Validation Accurancy:  0.9269265681505203\n",
      "Epoch:  7077 | Train Accurancy:  0.9278813228011131 | Validation Accurancy:  0.9269322231411934\n",
      "Epoch:  7078 | Train Accurancy:  0.9278826266527176 | Validation Accurancy:  0.9269374087452888\n",
      "Epoch:  7079 | Train Accurancy:  0.9278839826583862 | Validation Accurancy:  0.9269429817795753\n",
      "Epoch:  7080 | Train Accurancy:  0.9278852939605713 | Validation Accurancy:  0.9269482642412186\n",
      "Epoch:  7081 | Train Accurancy:  0.9278866201639175 | Validation Accurancy:  0.9269537478685379\n",
      "Epoch:  7082 | Train Accurancy:  0.9278879463672638 | Validation Accurancy:  0.9269589930772781\n",
      "Epoch:  7083 | Train Accurancy:  0.9278893247246742 | Validation Accurancy:  0.92696463316679\n",
      "Epoch:  7084 | Train Accurancy:  0.9278906434774399 | Validation Accurancy:  0.9269697815179825\n",
      "Epoch:  7085 | Train Accurancy:  0.9278919845819473 | Validation Accurancy:  0.9269753620028496\n",
      "Epoch:  7086 | Train Accurancy:  0.9278933554887772 | Validation Accurancy:  0.9269806072115898\n",
      "Epoch:  7087 | Train Accurancy:  0.9278946965932846 | Validation Accurancy:  0.9269861876964569\n",
      "Epoch:  7088 | Train Accurancy:  0.9278960004448891 | Validation Accurancy:  0.9269914329051971\n",
      "Epoch:  7089 | Train Accurancy:  0.9278973340988159 | Validation Accurancy:  0.9269970133900642\n",
      "Epoch:  7090 | Train Accurancy:  0.9278986752033234 | Validation Accurancy:  0.9270022064447403\n",
      "Epoch:  7091 | Train Accurancy:  0.9279000386595726 | Validation Accurancy:  0.927007831633091\n",
      "Epoch:  7092 | Train Accurancy:  0.9279013723134995 | Validation Accurancy:  0.9270129054784775\n",
      "Epoch:  7093 | Train Accurancy:  0.9279027134180069 | Validation Accurancy:  0.9270185604691505\n",
      "Epoch:  7094 | Train Accurancy:  0.927904024720192 | Validation Accurancy:  0.9270236939191818\n",
      "Epoch:  7095 | Train Accurancy:  0.92790537327528 | Validation Accurancy:  0.9270293414592743\n",
      "Epoch:  7096 | Train Accurancy:  0.9279066771268845 | Validation Accurancy:  0.9270345717668533\n",
      "Epoch:  7097 | Train Accurancy:  0.9279080703854561 | Validation Accurancy:  0.9270401448011398\n",
      "Epoch:  7098 | Train Accurancy:  0.9279093891382217 | Validation Accurancy:  0.9270452782511711\n",
      "Epoch:  7099 | Train Accurancy:  0.9279107078909874 | Validation Accurancy:  0.927050843834877\n",
      "Epoch:  7100 | Train Accurancy:  0.9279120340943336 | Validation Accurancy:  0.9270561039447784\n",
      "Epoch:  7101 | Train Accurancy:  0.9279133975505829 | Validation Accurancy:  0.927061639726162\n",
      "Epoch:  7102 | Train Accurancy:  0.9279147684574127 | Validation Accurancy:  0.9270668029785156\n",
      "Epoch:  7103 | Train Accurancy:  0.9279160723090172 | Validation Accurancy:  0.9270725101232529\n",
      "Epoch:  7104 | Train Accurancy:  0.927917405962944 | Validation Accurancy:  0.9270775467157364\n",
      "Epoch:  7105 | Train Accurancy:  0.9279187172651291 | Validation Accurancy:  0.9270832538604736\n",
      "Epoch:  7106 | Train Accurancy:  0.9279200211167336 | Validation Accurancy:  0.9270884171128273\n",
      "Epoch:  7107 | Train Accurancy:  0.927921399474144 | Validation Accurancy:  0.927093967795372\n",
      "Epoch:  7108 | Train Accurancy:  0.9279226958751678 | Validation Accurancy:  0.9270991012454033\n",
      "Epoch:  7109 | Train Accurancy:  0.9279240295290947 | Validation Accurancy:  0.9271046817302704\n",
      "Epoch:  7110 | Train Accurancy:  0.9279253780841827 | Validation Accurancy:  0.9271101802587509\n",
      "Epoch:  7111 | Train Accurancy:  0.9279266521334648 | Validation Accurancy:  0.9271153584122658\n",
      "Epoch:  7112 | Train Accurancy:  0.9279280677437782 | Validation Accurancy:  0.9271209388971329\n",
      "Epoch:  7113 | Train Accurancy:  0.9279293790459633 | Validation Accurancy:  0.9271260723471642\n",
      "Epoch:  7114 | Train Accurancy:  0.9279306754469872 | Validation Accurancy:  0.9271316379308701\n",
      "Epoch:  7115 | Train Accurancy:  0.927932046353817 | Validation Accurancy:  0.9271367713809013\n",
      "Epoch:  7116 | Train Accurancy:  0.9279333204030991 | Validation Accurancy:  0.9271422848105431\n",
      "Epoch:  7117 | Train Accurancy:  0.9279347434639931 | Validation Accurancy:  0.9271474853157997\n",
      "Epoch:  7118 | Train Accurancy:  0.9279360100626945 | Validation Accurancy:  0.927153043448925\n",
      "Epoch:  7119 | Train Accurancy:  0.927937313914299 | Validation Accurancy:  0.9271582290530205\n",
      "Epoch:  7120 | Train Accurancy:  0.9279386550188065 | Validation Accurancy:  0.9271637573838234\n",
      "Epoch:  7121 | Train Accurancy:  0.9279400110244751 | Validation Accurancy:  0.92716895788908\n",
      "Epoch:  7122 | Train Accurancy:  0.9279413223266602 | Validation Accurancy:  0.927174486219883\n",
      "Epoch:  7123 | Train Accurancy:  0.927942655980587 | Validation Accurancy:  0.9271797016263008\n",
      "Epoch:  7124 | Train Accurancy:  0.9279439151287079 | Validation Accurancy:  0.9271852523088455\n",
      "Epoch:  7125 | Train Accurancy:  0.9279452487826347 | Validation Accurancy:  0.9271903336048126\n",
      "Epoch:  7126 | Train Accurancy:  0.9279466345906258 | Validation Accurancy:  0.9271958693861961\n",
      "Epoch:  7127 | Train Accurancy:  0.9279479309916496 | Validation Accurancy:  0.9272010177373886\n",
      "Epoch:  7128 | Train Accurancy:  0.9279492273926735 | Validation Accurancy:  0.9272066876292229\n",
      "Epoch:  7129 | Train Accurancy:  0.9279505461454391 | Validation Accurancy:  0.9272118285298347\n",
      "Epoch:  7130 | Train Accurancy:  0.9279519096016884 | Validation Accurancy:  0.9272174537181854\n",
      "Epoch:  7131 | Train Accurancy:  0.9279532358050346 | Validation Accurancy:  0.9272225871682167\n",
      "Epoch:  7132 | Train Accurancy:  0.9279545694589615 | Validation Accurancy:  0.9272281005978584\n",
      "Epoch:  7133 | Train Accurancy:  0.9279558882117271 | Validation Accurancy:  0.9272332042455673\n",
      "Epoch:  7134 | Train Accurancy:  0.9279571995139122 | Validation Accurancy:  0.9272388145327568\n",
      "Epoch:  7135 | Train Accurancy:  0.9279585108160973 | Validation Accurancy:  0.9272438809275627\n",
      "Epoch:  7136 | Train Accurancy:  0.9279598295688629 | Validation Accurancy:  0.9272495582699776\n",
      "Epoch:  7137 | Train Accurancy:  0.9279611334204674 | Validation Accurancy:  0.9272546097636223\n",
      "Epoch:  7138 | Train Accurancy:  0.9279624968767166 | Validation Accurancy:  0.927260160446167\n",
      "Epoch:  7139 | Train Accurancy:  0.9279638156294823 | Validation Accurancy:  0.9272653758525848\n",
      "Epoch:  7140 | Train Accurancy:  0.9279651120305061 | Validation Accurancy:  0.927270844578743\n",
      "Epoch:  7141 | Train Accurancy:  0.927966445684433 | Validation Accurancy:  0.9272759258747101\n",
      "Epoch:  7142 | Train Accurancy:  0.927967756986618 | Validation Accurancy:  0.9272815510630608\n",
      "Epoch:  7143 | Train Accurancy:  0.9279690682888031 | Validation Accurancy:  0.9272870048880577\n",
      "Epoch:  7144 | Train Accurancy:  0.92797040194273 | Validation Accurancy:  0.9272921085357666\n",
      "Epoch:  7145 | Train Accurancy:  0.9279717057943344 | Validation Accurancy:  0.9272976890206337\n",
      "Epoch:  7146 | Train Accurancy:  0.9279730170965195 | Validation Accurancy:  0.9273027554154396\n",
      "Epoch:  7147 | Train Accurancy:  0.9279743283987045 | Validation Accurancy:  0.9273082762956619\n",
      "Epoch:  7148 | Train Accurancy:  0.927975632250309 | Validation Accurancy:  0.927313469350338\n",
      "Epoch:  7149 | Train Accurancy:  0.9279769659042358 | Validation Accurancy:  0.9273190200328827\n",
      "Epoch:  7150 | Train Accurancy:  0.9279783144593239 | Validation Accurancy:  0.9273241385817528\n",
      "Epoch:  7151 | Train Accurancy:  0.9279795810580254 | Validation Accurancy:  0.9273296520113945\n",
      "Epoch:  7152 | Train Accurancy:  0.9279809147119522 | Validation Accurancy:  0.9273347556591034\n",
      "Epoch:  7153 | Train Accurancy:  0.9279822334647179 | Validation Accurancy:  0.9273402988910675\n",
      "Epoch:  7154 | Train Accurancy:  0.9279835075139999 | Validation Accurancy:  0.9273454025387764\n",
      "Epoch:  7155 | Train Accurancy:  0.9279849007725716 | Validation Accurancy:  0.9273509979248047\n",
      "Epoch:  7156 | Train Accurancy:  0.9279861524701118 | Validation Accurancy:  0.9273560047149658\n",
      "Epoch:  7157 | Train Accurancy:  0.9279875010251999 | Validation Accurancy:  0.9273616597056389\n",
      "Epoch:  7158 | Train Accurancy:  0.9279887974262238 | Validation Accurancy:  0.9273666515946388\n",
      "Epoch:  7159 | Train Accurancy:  0.9279901310801506 | Validation Accurancy:  0.9273722171783447\n",
      "Epoch:  7160 | Train Accurancy:  0.9279914125800133 | Validation Accurancy:  0.9273777008056641\n",
      "Epoch:  7161 | Train Accurancy:  0.9279926866292953 | Validation Accurancy:  0.9273827075958252\n",
      "Epoch:  7162 | Train Accurancy:  0.9279940202832222 | Validation Accurancy:  0.9273883029818535\n",
      "Epoch:  7163 | Train Accurancy:  0.9279953688383102 | Validation Accurancy:  0.9273933917284012\n",
      "Epoch:  7164 | Train Accurancy:  0.9279966875910759 | Validation Accurancy:  0.9273988902568817\n",
      "Epoch:  7165 | Train Accurancy:  0.9279979690909386 | Validation Accurancy:  0.9274039268493652\n",
      "Epoch:  7166 | Train Accurancy:  0.9279992505908012 | Validation Accurancy:  0.9274095222353935\n",
      "Epoch:  7167 | Train Accurancy:  0.9280005916953087 | Validation Accurancy:  0.9274146258831024\n",
      "Epoch:  7168 | Train Accurancy:  0.9280019327998161 | Validation Accurancy:  0.9274201095104218\n",
      "Epoch:  7169 | Train Accurancy:  0.9280032366514206 | Validation Accurancy:  0.9274251908063889\n",
      "Epoch:  7170 | Train Accurancy:  0.9280045703053474 | Validation Accurancy:  0.9274307861924171\n",
      "Epoch:  7171 | Train Accurancy:  0.9280058369040489 | Validation Accurancy:  0.9274358451366425\n",
      "Epoch:  7172 | Train Accurancy:  0.9280071333050728 | Validation Accurancy:  0.927441343665123\n",
      "Epoch:  7173 | Train Accurancy:  0.9280084744095802 | Validation Accurancy:  0.9274464771151543\n",
      "Epoch:  7174 | Train Accurancy:  0.9280097335577011 | Validation Accurancy:  0.9274519607424736\n",
      "Epoch:  7175 | Train Accurancy:  0.9280110597610474 | Validation Accurancy:  0.9274571239948273\n",
      "Epoch:  7176 | Train Accurancy:  0.9280123636126518 | Validation Accurancy:  0.9274626076221466\n",
      "Epoch:  7177 | Train Accurancy:  0.9280136823654175 | Validation Accurancy:  0.9274676665663719\n",
      "Epoch:  7178 | Train Accurancy:  0.9280149713158607 | Validation Accurancy:  0.9274732246994972\n",
      "Epoch:  7179 | Train Accurancy:  0.928016297519207 | Validation Accurancy:  0.9274782463908195\n",
      "Epoch:  7180 | Train Accurancy:  0.9280175939202309 | Validation Accurancy:  0.9274838119745255\n",
      "Epoch:  7181 | Train Accurancy:  0.9280189126729965 | Validation Accurancy:  0.9274892508983612\n",
      "Epoch:  7182 | Train Accurancy:  0.9280202239751816 | Validation Accurancy:  0.9274943843483925\n",
      "Epoch:  7183 | Train Accurancy:  0.9280215725302696 | Validation Accurancy:  0.9274997413158417\n",
      "Epoch:  7184 | Train Accurancy:  0.9280228167772293 | Validation Accurancy:  0.9275048598647118\n",
      "Epoch:  7185 | Train Accurancy:  0.9280241504311562 | Validation Accurancy:  0.9275103732943535\n",
      "Epoch:  7186 | Train Accurancy:  0.9280254170298576 | Validation Accurancy:  0.9275154620409012\n",
      "Epoch:  7187 | Train Accurancy:  0.9280266761779785 | Validation Accurancy:  0.9275209605693817\n",
      "Epoch:  7188 | Train Accurancy:  0.928028017282486 | Validation Accurancy:  0.9275259971618652\n",
      "Epoch:  7189 | Train Accurancy:  0.9280293211340904 | Validation Accurancy:  0.9275315478444099\n",
      "Epoch:  7190 | Train Accurancy:  0.9280306398868561 | Validation Accurancy:  0.9275365173816681\n",
      "Epoch:  7191 | Train Accurancy:  0.9280319064855576 | Validation Accurancy:  0.927542082965374\n",
      "Epoch:  7192 | Train Accurancy:  0.928033247590065 | Validation Accurancy:  0.9275472015142441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7193 | Train Accurancy:  0.9280345588922501 | Validation Accurancy:  0.9275527149438858\n",
      "Epoch:  7194 | Train Accurancy:  0.9280358180403709 | Validation Accurancy:  0.9275577738881111\n",
      "Epoch:  7195 | Train Accurancy:  0.9280371218919754 | Validation Accurancy:  0.9275633171200752\n",
      "Epoch:  7196 | Train Accurancy:  0.9280384331941605 | Validation Accurancy:  0.9275683388113976\n",
      "Epoch:  7197 | Train Accurancy:  0.9280397444963455 | Validation Accurancy:  0.9275739043951035\n",
      "Epoch:  7198 | Train Accurancy:  0.92804104834795 | Validation Accurancy:  0.927578940987587\n",
      "Epoch:  7199 | Train Accurancy:  0.9280423298478127 | Validation Accurancy:  0.9275844767689705\n",
      "Epoch:  7200 | Train Accurancy:  0.9280436336994171 | Validation Accurancy:  0.9275899082422256\n",
      "Epoch:  7201 | Train Accurancy:  0.9280448630452156 | Validation Accurancy:  0.9275948852300644\n",
      "Epoch:  7202 | Train Accurancy:  0.9280462935566902 | Validation Accurancy:  0.9276003390550613\n",
      "Epoch:  7203 | Train Accurancy:  0.9280475229024887 | Validation Accurancy:  0.927605390548706\n",
      "Epoch:  7204 | Train Accurancy:  0.9280488342046738 | Validation Accurancy:  0.927610918879509\n",
      "Epoch:  7205 | Train Accurancy:  0.9280501306056976 | Validation Accurancy:  0.9276159629225731\n",
      "Epoch:  7206 | Train Accurancy:  0.9280514046549797 | Validation Accurancy:  0.9276213943958282\n",
      "Epoch:  7207 | Train Accurancy:  0.928052730858326 | Validation Accurancy:  0.9276264384388924\n",
      "Epoch:  7208 | Train Accurancy:  0.9280539900064468 | Validation Accurancy:  0.9276319518685341\n",
      "Epoch:  7209 | Train Accurancy:  0.9280552715063095 | Validation Accurancy:  0.927637055516243\n",
      "Epoch:  7210 | Train Accurancy:  0.928056575357914 | Validation Accurancy:  0.9276425018906593\n",
      "Epoch:  7211 | Train Accurancy:  0.9280579090118408 | Validation Accurancy:  0.9276475459337234\n",
      "Epoch:  7212 | Train Accurancy:  0.9280592203140259 | Validation Accurancy:  0.9276529774069786\n",
      "Epoch:  7213 | Train Accurancy:  0.9280604794621468 | Validation Accurancy:  0.9276584759354591\n",
      "Epoch:  7214 | Train Accurancy:  0.9280617386102676 | Validation Accurancy:  0.9276634529232979\n",
      "Epoch:  7215 | Train Accurancy:  0.9280630424618721 | Validation Accurancy:  0.9276689514517784\n",
      "Epoch:  7216 | Train Accurancy:  0.9280643537640572 | Validation Accurancy:  0.9276739284396172\n",
      "Epoch:  7217 | Train Accurancy:  0.9280656352639198 | Validation Accurancy:  0.9276794418692589\n",
      "Epoch:  7218 | Train Accurancy:  0.9280669316649437 | Validation Accurancy:  0.9276844188570976\n",
      "Epoch:  7219 | Train Accurancy:  0.9280682131648064 | Validation Accurancy:  0.9276898875832558\n",
      "Epoch:  7220 | Train Accurancy:  0.9280695244669914 | Validation Accurancy:  0.9276949390769005\n",
      "Epoch:  7221 | Train Accurancy:  0.9280707985162735 | Validation Accurancy:  0.9277004525065422\n",
      "Epoch:  7222 | Train Accurancy:  0.9280720874667168 | Validation Accurancy:  0.9277054592967033\n",
      "Epoch:  7223 | Train Accurancy:  0.9280734360218048 | Validation Accurancy:  0.9277108833193779\n",
      "Epoch:  7224 | Train Accurancy:  0.9280747026205063 | Validation Accurancy:  0.9277159348130226\n",
      "Epoch:  7225 | Train Accurancy:  0.9280760064721107 | Validation Accurancy:  0.9277214333415031\n",
      "Epoch:  7226 | Train Accurancy:  0.9280772507190704 | Validation Accurancy:  0.9277265071868896\n",
      "Epoch:  7227 | Train Accurancy:  0.9280785694718361 | Validation Accurancy:  0.9277320057153702\n",
      "Epoch:  7228 | Train Accurancy:  0.928079828619957 | Validation Accurancy:  0.9277373626828194\n",
      "Epoch:  7229 | Train Accurancy:  0.9280811473727226 | Validation Accurancy:  0.9277423545718193\n",
      "Epoch:  7230 | Train Accurancy:  0.9280823916196823 | Validation Accurancy:  0.9277478232979774\n",
      "Epoch:  7231 | Train Accurancy:  0.9280836954712868 | Validation Accurancy:  0.9277528449892998\n",
      "Epoch:  7232 | Train Accurancy:  0.9280849993228912 | Validation Accurancy:  0.9277583137154579\n",
      "Epoch:  7233 | Train Accurancy:  0.9280862882733345 | Validation Accurancy:  0.9277633652091026\n",
      "Epoch:  7234 | Train Accurancy:  0.9280875846743584 | Validation Accurancy:  0.9277687519788742\n",
      "Epoch:  7235 | Train Accurancy:  0.9280888512730598 | Validation Accurancy:  0.9277738258242607\n",
      "Epoch:  7236 | Train Accurancy:  0.9280901253223419 | Validation Accurancy:  0.9277792423963547\n",
      "Epoch:  7237 | Train Accurancy:  0.9280914142727852 | Validation Accurancy:  0.9277842491865158\n",
      "Epoch:  7238 | Train Accurancy:  0.9280927255749702 | Validation Accurancy:  0.9277897328138351\n",
      "Epoch:  7239 | Train Accurancy:  0.9280939847230911 | Validation Accurancy:  0.9277948513627052\n",
      "Epoch:  7240 | Train Accurancy:  0.928095243871212 | Validation Accurancy:  0.9278002232313156\n",
      "Epoch:  7241 | Train Accurancy:  0.9280965477228165 | Validation Accurancy:  0.9278053939342499\n",
      "Epoch:  7242 | Train Accurancy:  0.9280978888273239 | Validation Accurancy:  0.9278107658028603\n",
      "Epoch:  7243 | Train Accurancy:  0.9280991330742836 | Validation Accurancy:  0.927815742790699\n",
      "Epoch:  7244 | Train Accurancy:  0.9281004443764687 | Validation Accurancy:  0.9278212413191795\n",
      "Epoch:  7245 | Train Accurancy:  0.9281016960740089 | Validation Accurancy:  0.9278266131877899\n",
      "Epoch:  7246 | Train Accurancy:  0.9281029924750328 | Validation Accurancy:  0.9278315827250481\n",
      "Epoch:  7247 | Train Accurancy:  0.9281042516231537 | Validation Accurancy:  0.9278369918465614\n",
      "Epoch:  7248 | Train Accurancy:  0.9281055480241776 | Validation Accurancy:  0.9278420582413673\n",
      "Epoch:  7249 | Train Accurancy:  0.9281068071722984 | Validation Accurancy:  0.9278474152088165\n",
      "Epoch:  7250 | Train Accurancy:  0.9281080439686775 | Validation Accurancy:  0.9278524219989777\n",
      "Epoch:  7251 | Train Accurancy:  0.9281093403697014 | Validation Accurancy:  0.927857793867588\n",
      "Epoch:  7252 | Train Accurancy:  0.9281106740236282 | Validation Accurancy:  0.9278630092740059\n",
      "Epoch:  7253 | Train Accurancy:  0.9281119480729103 | Validation Accurancy:  0.9278682693839073\n",
      "Epoch:  7254 | Train Accurancy:  0.9281132146716118 | Validation Accurancy:  0.9278732910752296\n",
      "Epoch:  7255 | Train Accurancy:  0.928114503622055 | Validation Accurancy:  0.9278786852955818\n",
      "Epoch:  7256 | Train Accurancy:  0.9281157776713371 | Validation Accurancy:  0.9278838336467743\n",
      "Epoch:  7257 | Train Accurancy:  0.9281171038746834 | Validation Accurancy:  0.9278891906142235\n",
      "Epoch:  7258 | Train Accurancy:  0.9281183630228043 | Validation Accurancy:  0.927894227206707\n",
      "Epoch:  7259 | Train Accurancy:  0.9281195849180222 | Validation Accurancy:  0.927899681031704\n",
      "Epoch:  7260 | Train Accurancy:  0.928120918571949 | Validation Accurancy:  0.9279050678014755\n",
      "Epoch:  7261 | Train Accurancy:  0.9281221851706505 | Validation Accurancy:  0.9279100075364113\n",
      "Epoch:  7262 | Train Accurancy:  0.9281234890222549 | Validation Accurancy:  0.9279153794050217\n",
      "Epoch:  7263 | Train Accurancy:  0.9281247183680534 | Validation Accurancy:  0.9279204532504082\n",
      "Epoch:  7264 | Train Accurancy:  0.9281260147690773 | Validation Accurancy:  0.9279257580637932\n",
      "Epoch:  7265 | Train Accurancy:  0.9281272888183594 | Validation Accurancy:  0.9279309585690498\n",
      "Epoch:  7266 | Train Accurancy:  0.928128570318222 | Validation Accurancy:  0.9279363453388214\n",
      "Epoch:  7267 | Train Accurancy:  0.9281298294663429 | Validation Accurancy:  0.9279413670301437\n",
      "Epoch:  7268 | Train Accurancy:  0.9281310960650444 | Validation Accurancy:  0.9279467388987541\n",
      "Epoch:  7269 | Train Accurancy:  0.9281323924660683 | Validation Accurancy:  0.927951768040657\n",
      "Epoch:  7270 | Train Accurancy:  0.928133636713028 | Validation Accurancy:  0.927957184612751\n",
      "Epoch:  7271 | Train Accurancy:  0.9281349182128906 | Validation Accurancy:  0.927962176501751\n",
      "Epoch:  7272 | Train Accurancy:  0.9281362146139145 | Validation Accurancy:  0.9279675781726837\n",
      "Epoch:  7273 | Train Accurancy:  0.9281374514102936 | Validation Accurancy:  0.9279725849628448\n",
      "Epoch:  7274 | Train Accurancy:  0.9281387105584145 | Validation Accurancy:  0.9279779940843582\n",
      "Epoch:  7275 | Train Accurancy:  0.9281400293111801 | Validation Accurancy:  0.9279832988977432\n",
      "Epoch:  7276 | Train Accurancy:  0.9281413033604622 | Validation Accurancy:  0.9279883056879044\n",
      "Epoch:  7277 | Train Accurancy:  0.9281425848603249 | Validation Accurancy:  0.9279936775565147\n",
      "Epoch:  7278 | Train Accurancy:  0.9281438514590263 | Validation Accurancy:  0.9279986843466759\n",
      "Epoch:  7279 | Train Accurancy:  0.9281450882554054 | Validation Accurancy:  0.9280039966106415\n",
      "Epoch:  7280 | Train Accurancy:  0.9281464293599129 | Validation Accurancy:  0.9280090481042862\n",
      "Epoch:  7281 | Train Accurancy:  0.9281476736068726 | Validation Accurancy:  0.9280144199728966\n",
      "Epoch:  7282 | Train Accurancy:  0.9281489104032516 | Validation Accurancy:  0.928019717335701\n",
      "Epoch:  7283 | Train Accurancy:  0.9281502068042755 | Validation Accurancy:  0.9280247539281845\n",
      "Epoch:  7284 | Train Accurancy:  0.928151473402977 | Validation Accurancy:  0.9280300810933113\n",
      "Epoch:  7285 | Train Accurancy:  0.9281527325510979 | Validation Accurancy:  0.9280351474881172\n",
      "Epoch:  7286 | Train Accurancy:  0.9281540140509605 | Validation Accurancy:  0.9280405193567276\n",
      "Epoch:  7287 | Train Accurancy:  0.928155280649662 | Validation Accurancy:  0.9280454814434052\n",
      "Epoch:  7288 | Train Accurancy:  0.9281565248966217 | Validation Accurancy:  0.928050771355629\n",
      "Epoch:  7289 | Train Accurancy:  0.9281577914953232 | Validation Accurancy:  0.928055889904499\n",
      "Epoch:  7290 | Train Accurancy:  0.9281590506434441 | Validation Accurancy:  0.9280612170696259\n",
      "Epoch:  7291 | Train Accurancy:  0.9281603842973709 | Validation Accurancy:  0.928066223859787\n",
      "Epoch:  7292 | Train Accurancy:  0.9281615689396858 | Validation Accurancy:  0.9280715808272362\n",
      "Epoch:  7293 | Train Accurancy:  0.9281629174947739 | Validation Accurancy:  0.9280769377946854\n",
      "Epoch:  7294 | Train Accurancy:  0.92816411703825 | Validation Accurancy:  0.9280818924307823\n",
      "Epoch:  7295 | Train Accurancy:  0.9281654208898544 | Validation Accurancy:  0.9280872642993927\n",
      "Epoch:  7296 | Train Accurancy:  0.9281666651368141 | Validation Accurancy:  0.9280922412872314\n",
      "Epoch:  7297 | Train Accurancy:  0.9281679391860962 | Validation Accurancy:  0.9280975162982941\n",
      "Epoch:  7298 | Train Accurancy:  0.9281691983342171 | Validation Accurancy:  0.9281026050448418\n",
      "Epoch:  7299 | Train Accurancy:  0.928170457482338 | Validation Accurancy:  0.9281080588698387\n",
      "Epoch:  7300 | Train Accurancy:  0.9281717389822006 | Validation Accurancy:  0.9281129539012909\n",
      "Epoch:  7301 | Train Accurancy:  0.9281730353832245 | Validation Accurancy:  0.9281182959675789\n",
      "Epoch:  7302 | Train Accurancy:  0.9281742945313454 | Validation Accurancy:  0.9281232357025146\n",
      "Epoch:  7303 | Train Accurancy:  0.9281755462288857 | Validation Accurancy:  0.928128719329834\n",
      "Epoch:  7304 | Train Accurancy:  0.9281768128275871 | Validation Accurancy:  0.928134061396122\n",
      "Epoch:  7305 | Train Accurancy:  0.9281780794262886 | Validation Accurancy:  0.9281389713287354\n",
      "Epoch:  7306 | Train Accurancy:  0.9281793460249901 | Validation Accurancy:  0.9281443879008293\n",
      "Epoch:  7307 | Train Accurancy:  0.928180567920208 | Validation Accurancy:  0.9281493201851845\n",
      "Epoch:  7308 | Train Accurancy:  0.9281818345189095 | Validation Accurancy:  0.9281545951962471\n",
      "Epoch:  7309 | Train Accurancy:  0.9281830936670303 | Validation Accurancy:  0.9281595200300217\n",
      "Epoch:  7310 | Train Accurancy:  0.9281843900680542 | Validation Accurancy:  0.9281649738550186\n",
      "Epoch:  7311 | Train Accurancy:  0.9281856268644333 | Validation Accurancy:  0.9281698539853096\n",
      "Epoch:  7312 | Train Accurancy:  0.9281868785619736 | Validation Accurancy:  0.9281753823161125\n",
      "Epoch:  7313 | Train Accurancy:  0.9281881302595139 | Validation Accurancy:  0.9281803146004677\n",
      "Epoch:  7314 | Train Accurancy:  0.9281894117593765 | Validation Accurancy:  0.9281857162714005\n",
      "Epoch:  7315 | Train Accurancy:  0.9281906336545944 | Validation Accurancy:  0.9281909763813019\n",
      "Epoch:  7316 | Train Accurancy:  0.9281919449567795 | Validation Accurancy:  0.928195908665657\n",
      "Epoch:  7317 | Train Accurancy:  0.928193137049675 | Validation Accurancy:  0.9282012954354286\n",
      "Epoch:  7318 | Train Accurancy:  0.9281944260001183 | Validation Accurancy:  0.9282061606645584\n",
      "Epoch:  7319 | Train Accurancy:  0.9281956627964973 | Validation Accurancy:  0.9282115623354912\n",
      "Epoch:  7320 | Train Accurancy:  0.9281969368457794 | Validation Accurancy:  0.9282164722681046\n",
      "Epoch:  7321 | Train Accurancy:  0.9281982108950615 | Validation Accurancy:  0.9282218590378761\n",
      "Epoch:  7322 | Train Accurancy:  0.9281994551420212 | Validation Accurancy:  0.9282267913222313\n",
      "Epoch:  7323 | Train Accurancy:  0.9282007366418839 | Validation Accurancy:  0.9282321482896805\n",
      "Epoch:  7324 | Train Accurancy:  0.9282019883394241 | Validation Accurancy:  0.9282373711466789\n",
      "Epoch:  7325 | Train Accurancy:  0.9282032251358032 | Validation Accurancy:  0.9282423481345177\n",
      "Epoch:  7326 | Train Accurancy:  0.9282044842839241 | Validation Accurancy:  0.9282477051019669\n",
      "Epoch:  7327 | Train Accurancy:  0.9282057359814644 | Validation Accurancy:  0.9282526150345802\n",
      "Epoch:  7328 | Train Accurancy:  0.9282069951295853 | Validation Accurancy:  0.9282578751444817\n",
      "Epoch:  7329 | Train Accurancy:  0.9282082542777061 | Validation Accurancy:  0.9282629489898682\n",
      "Epoch:  7330 | Train Accurancy:  0.9282094985246658 | Validation Accurancy:  0.9282682612538338\n",
      "Epoch:  7331 | Train Accurancy:  0.9282107576727867 | Validation Accurancy:  0.9282735213637352\n",
      "Epoch:  7332 | Train Accurancy:  0.9282120540738106 | Validation Accurancy:  0.9282784909009933\n",
      "Epoch:  7333 | Train Accurancy:  0.9282132685184479 | Validation Accurancy:  0.9282838478684425\n",
      "Epoch:  7334 | Train Accurancy:  0.9282145202159882 | Validation Accurancy:  0.9282886832952499\n",
      "Epoch:  7335 | Train Accurancy:  0.9282157644629478 | Validation Accurancy:  0.9282940253615379\n",
      "Epoch:  7336 | Train Accurancy:  0.9282170236110687 | Validation Accurancy:  0.9282989650964737\n",
      "Epoch:  7337 | Train Accurancy:  0.9282182827591896 | Validation Accurancy:  0.9283043667674065\n",
      "Epoch:  7338 | Train Accurancy:  0.9282195493578911 | Validation Accurancy:  0.928309328854084\n",
      "Epoch:  7339 | Train Accurancy:  0.9282207638025284 | Validation Accurancy:  0.928314559161663\n",
      "Epoch:  7340 | Train Accurancy:  0.9282220304012299 | Validation Accurancy:  0.9283196479082108\n",
      "Epoch:  7341 | Train Accurancy:  0.9282232969999313 | Validation Accurancy:  0.928324967622757\n",
      "Epoch:  7342 | Train Accurancy:  0.9282245486974716 | Validation Accurancy:  0.9283299148082733\n",
      "Epoch:  7343 | Train Accurancy:  0.9282257705926895 | Validation Accurancy:  0.9283353015780449\n",
      "Epoch:  7344 | Train Accurancy:  0.9282270446419716 | Validation Accurancy:  0.9283404648303986\n",
      "Epoch:  7345 | Train Accurancy:  0.9282282739877701 | Validation Accurancy:  0.9283453747630119\n",
      "Epoch:  7346 | Train Accurancy:  0.928229495882988 | Validation Accurancy:  0.9283506870269775\n",
      "Epoch:  7347 | Train Accurancy:  0.9282307475805283 | Validation Accurancy:  0.9283555671572685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7348 | Train Accurancy:  0.9282320737838745 | Validation Accurancy:  0.9283610060811043\n",
      "Epoch:  7349 | Train Accurancy:  0.92823326587677 | Validation Accurancy:  0.9283658638596535\n",
      "Epoch:  7350 | Train Accurancy:  0.9282345548272133 | Validation Accurancy:  0.9283712580800056\n",
      "Epoch:  7351 | Train Accurancy:  0.9282357692718506 | Validation Accurancy:  0.9283760711550713\n",
      "Epoch:  7352 | Train Accurancy:  0.9282370284199715 | Validation Accurancy:  0.9283814281225204\n",
      "Epoch:  7353 | Train Accurancy:  0.92823825776577 | Validation Accurancy:  0.9283867329359055\n",
      "Epoch:  7354 | Train Accurancy:  0.9282394796609879 | Validation Accurancy:  0.9283915683627129\n",
      "Epoch:  7355 | Train Accurancy:  0.9282407984137535 | Validation Accurancy:  0.9283970072865486\n",
      "Epoch:  7356 | Train Accurancy:  0.9282420128583908 | Validation Accurancy:  0.9284017905592918\n",
      "Epoch:  7357 | Train Accurancy:  0.9282432794570923 | Validation Accurancy:  0.9284071624279022\n",
      "Epoch:  7358 | Train Accurancy:  0.9282445088028908 | Validation Accurancy:  0.9284120053052902\n",
      "Epoch:  7359 | Train Accurancy:  0.9282457530498505 | Validation Accurancy:  0.928417444229126\n",
      "Epoch:  7360 | Train Accurancy:  0.9282470047473907 | Validation Accurancy:  0.9284223392605782\n",
      "Epoch:  7361 | Train Accurancy:  0.9282482340931892 | Validation Accurancy:  0.9284276813268661\n",
      "Epoch:  7362 | Train Accurancy:  0.9282494932413101 | Validation Accurancy:  0.92843297123909\n",
      "Epoch:  7363 | Train Accurancy:  0.9282507374882698 | Validation Accurancy:  0.9284378662705421\n",
      "Epoch:  7364 | Train Accurancy:  0.9282519668340683 | Validation Accurancy:  0.9284430965781212\n",
      "Epoch:  7365 | Train Accurancy:  0.9282532408833504 | Validation Accurancy:  0.9284480735659599\n",
      "Epoch:  7366 | Train Accurancy:  0.9282544478774071 | Validation Accurancy:  0.9284534007310867\n",
      "Epoch:  7367 | Train Accurancy:  0.928255707025528 | Validation Accurancy:  0.9284582808613777\n",
      "Epoch:  7368 | Train Accurancy:  0.928256943821907 | Validation Accurancy:  0.928463526070118\n",
      "Epoch:  7369 | Train Accurancy:  0.9282581657171249 | Validation Accurancy:  0.928468830883503\n",
      "Epoch:  7370 | Train Accurancy:  0.9282594248652458 | Validation Accurancy:  0.9284737780690193\n",
      "Epoch:  7371 | Train Accurancy:  0.9282606840133667 | Validation Accurancy:  0.9284789860248566\n",
      "Epoch:  7372 | Train Accurancy:  0.9282619208097458 | Validation Accurancy:  0.9284838512539864\n",
      "Epoch:  7373 | Train Accurancy:  0.9282631427049637 | Validation Accurancy:  0.9284892529249191\n",
      "Epoch:  7374 | Train Accurancy:  0.9282643795013428 | Validation Accurancy:  0.9284939914941788\n",
      "Epoch:  7375 | Train Accurancy:  0.9282656535506248 | Validation Accurancy:  0.928499348461628\n",
      "Epoch:  7376 | Train Accurancy:  0.9282668679952621 | Validation Accurancy:  0.9285045936703682\n",
      "Epoch:  7377 | Train Accurancy:  0.9282681494951248 | Validation Accurancy:  0.9285095185041428\n",
      "Epoch:  7378 | Train Accurancy:  0.9282693788409233 | Validation Accurancy:  0.928514800965786\n",
      "Epoch:  7379 | Train Accurancy:  0.9282706007361412 | Validation Accurancy:  0.9285197556018829\n",
      "Epoch:  7380 | Train Accurancy:  0.9282718598842621 | Validation Accurancy:  0.9285250157117844\n",
      "Epoch:  7381 | Train Accurancy:  0.9282730668783188 | Validation Accurancy:  0.9285298958420753\n",
      "Epoch:  7382 | Train Accurancy:  0.9282743260264397 | Validation Accurancy:  0.9285351559519768\n",
      "Epoch:  7383 | Train Accurancy:  0.928275540471077 | Validation Accurancy:  0.9285400360822678\n",
      "Epoch:  7384 | Train Accurancy:  0.9282767698168755 | Validation Accurancy:  0.9285454452037811\n",
      "Epoch:  7385 | Train Accurancy:  0.9282779917120934 | Validation Accurancy:  0.9285505935549736\n",
      "Epoch:  7386 | Train Accurancy:  0.9282792434096336 | Validation Accurancy:  0.9285555332899094\n",
      "Epoch:  7387 | Train Accurancy:  0.9282804951071739 | Validation Accurancy:  0.9285607486963272\n",
      "Epoch:  7388 | Train Accurancy:  0.9282817021012306 | Validation Accurancy:  0.928565725684166\n",
      "Epoch:  7389 | Train Accurancy:  0.9282829239964485 | Validation Accurancy:  0.9285709410905838\n",
      "Epoch:  7390 | Train Accurancy:  0.9282841980457306 | Validation Accurancy:  0.9285758510231972\n",
      "Epoch:  7391 | Train Accurancy:  0.9282854273915291 | Validation Accurancy:  0.9285810962319374\n",
      "Epoch:  7392 | Train Accurancy:  0.9282866343855858 | Validation Accurancy:  0.9285859614610672\n",
      "Epoch:  7393 | Train Accurancy:  0.9282878786325455 | Validation Accurancy:  0.9285913333296776\n",
      "Epoch:  7394 | Train Accurancy:  0.9282890483736992 | Validation Accurancy:  0.9285965412855148\n",
      "Epoch:  7395 | Train Accurancy:  0.9282903373241425 | Validation Accurancy:  0.9286013469099998\n",
      "Epoch:  7396 | Train Accurancy:  0.9282916039228439 | Validation Accurancy:  0.9286066517233849\n",
      "Epoch:  7397 | Train Accurancy:  0.9282928258180618 | Validation Accurancy:  0.9286115020513535\n",
      "Epoch:  7398 | Train Accurancy:  0.9282940626144409 | Validation Accurancy:  0.9286168441176414\n",
      "Epoch:  7399 | Train Accurancy:  0.92829529941082 | Validation Accurancy:  0.9286216273903847\n",
      "Epoch:  7400 | Train Accurancy:  0.9282964915037155 | Validation Accurancy:  0.9286269843578339\n",
      "Epoch:  7401 | Train Accurancy:  0.9282977804541588 | Validation Accurancy:  0.9286321774125099\n",
      "Epoch:  7402 | Train Accurancy:  0.9282990172505379 | Validation Accurancy:  0.9286370277404785\n",
      "Epoch:  7403 | Train Accurancy:  0.9283002316951752 | Validation Accurancy:  0.9286422580480576\n",
      "Epoch:  7404 | Train Accurancy:  0.9283014535903931 | Validation Accurancy:  0.9286471530795097\n",
      "Epoch:  7405 | Train Accurancy:  0.9283026680350304 | Validation Accurancy:  0.9286524280905724\n",
      "Epoch:  7406 | Train Accurancy:  0.9283039048314095 | Validation Accurancy:  0.928657166659832\n",
      "Epoch:  7407 | Train Accurancy:  0.9283051192760468 | Validation Accurancy:  0.9286625236272812\n",
      "Epoch:  7408 | Train Accurancy:  0.9283063933253288 | Validation Accurancy:  0.928667813539505\n",
      "Epoch:  7409 | Train Accurancy:  0.9283076077699661 | Validation Accurancy:  0.9286726489663124\n",
      "Epoch:  7410 | Train Accurancy:  0.9283088520169258 | Validation Accurancy:  0.9286778420209885\n",
      "Epoch:  7411 | Train Accurancy:  0.9283101037144661 | Validation Accurancy:  0.9286828190088272\n",
      "Epoch:  7412 | Train Accurancy:  0.9283113554120064 | Validation Accurancy:  0.9286879673600197\n",
      "Epoch:  7413 | Train Accurancy:  0.9283125549554825 | Validation Accurancy:  0.9286928623914719\n",
      "Epoch:  7414 | Train Accurancy:  0.9283137544989586 | Validation Accurancy:  0.9286980181932449\n",
      "Epoch:  7415 | Train Accurancy:  0.9283149987459183 | Validation Accurancy:  0.9287033379077911\n",
      "Epoch:  7416 | Train Accurancy:  0.928316205739975 | Validation Accurancy:  0.9287081584334373\n",
      "Epoch:  7417 | Train Accurancy:  0.9283174425363541 | Validation Accurancy:  0.9287134334445\n",
      "Epoch:  7418 | Train Accurancy:  0.9283186420798302 | Validation Accurancy:  0.9287181869149208\n",
      "Epoch:  7419 | Train Accurancy:  0.9283198863267899 | Validation Accurancy:  0.928723506629467\n",
      "Epoch:  7420 | Train Accurancy:  0.9283210784196854 | Validation Accurancy:  0.9287287071347237\n",
      "Epoch:  7421 | Train Accurancy:  0.9283223524689674 | Validation Accurancy:  0.9287334904074669\n",
      "Epoch:  7422 | Train Accurancy:  0.9283236190676689 | Validation Accurancy:  0.9287387356162071\n",
      "Epoch:  7423 | Train Accurancy:  0.9283247962594032 | Validation Accurancy:  0.9287436977028847\n",
      "Epoch:  7424 | Train Accurancy:  0.9283260256052017 | Validation Accurancy:  0.9287488460540771\n",
      "Epoch:  7425 | Train Accurancy:  0.928327240049839 | Validation Accurancy:  0.9287538081407547\n",
      "Epoch:  7426 | Train Accurancy:  0.9283284693956375 | Validation Accurancy:  0.9287589713931084\n",
      "Epoch:  7427 | Train Accurancy:  0.9283297061920166 | Validation Accurancy:  0.928764171898365\n",
      "Epoch:  7428 | Train Accurancy:  0.9283309131860733 | Validation Accurancy:  0.9287689849734306\n",
      "Epoch:  7429 | Train Accurancy:  0.9283321276307106 | Validation Accurancy:  0.9287742599844933\n",
      "Epoch:  7430 | Train Accurancy:  0.9283333346247673 | Validation Accurancy:  0.9287791401147842\n",
      "Epoch:  7431 | Train Accurancy:  0.9283345639705658 | Validation Accurancy:  0.9287843406200409\n",
      "Epoch:  7432 | Train Accurancy:  0.9283357933163643 | Validation Accurancy:  0.9287891238927841\n",
      "Epoch:  7433 | Train Accurancy:  0.9283370226621628 | Validation Accurancy:  0.928794339299202\n",
      "Epoch:  7434 | Train Accurancy:  0.9283382147550583 | Validation Accurancy:  0.9287995845079422\n",
      "Epoch:  7435 | Train Accurancy:  0.9283394441008568 | Validation Accurancy:  0.9288044944405556\n",
      "Epoch:  7436 | Train Accurancy:  0.9283406883478165 | Validation Accurancy:  0.9288095980882645\n",
      "Epoch:  7437 | Train Accurancy:  0.928341880440712 | Validation Accurancy:  0.9288144782185555\n",
      "Epoch:  7438 | Train Accurancy:  0.9283431768417358 | Validation Accurancy:  0.9288197010755539\n",
      "Epoch:  7439 | Train Accurancy:  0.928344339132309 | Validation Accurancy:  0.9288246184587479\n",
      "Epoch:  7440 | Train Accurancy:  0.9283455461263657 | Validation Accurancy:  0.9288297966122627\n",
      "Epoch:  7441 | Train Accurancy:  0.9283467903733253 | Validation Accurancy:  0.9288349971175194\n",
      "Epoch:  7442 | Train Accurancy:  0.928347997367382 | Validation Accurancy:  0.9288398250937462\n",
      "Epoch:  7443 | Train Accurancy:  0.9283492490649223 | Validation Accurancy:  0.9288449585437775\n",
      "Epoch:  7444 | Train Accurancy:  0.928350418806076 | Validation Accurancy:  0.9288498237729073\n",
      "Epoch:  7445 | Train Accurancy:  0.9283516705036163 | Validation Accurancy:  0.9288550391793251\n",
      "Epoch:  7446 | Train Accurancy:  0.9283528700470924 | Validation Accurancy:  0.92886021733284\n",
      "Epoch:  7447 | Train Accurancy:  0.9283541142940521 | Validation Accurancy:  0.9288650527596474\n",
      "Epoch:  7448 | Train Accurancy:  0.9283553212881088 | Validation Accurancy:  0.928870216012001\n",
      "Epoch:  7449 | Train Accurancy:  0.9283565357327461 | Validation Accurancy:  0.9288751110434532\n",
      "Epoch:  7450 | Train Accurancy:  0.9283577129244804 | Validation Accurancy:  0.9288802146911621\n",
      "Epoch:  7451 | Train Accurancy:  0.9283589869737625 | Validation Accurancy:  0.9288851246237755\n",
      "Epoch:  7452 | Train Accurancy:  0.9283601343631744 | Validation Accurancy:  0.928890272974968\n",
      "Epoch:  7453 | Train Accurancy:  0.9283613786101341 | Validation Accurancy:  0.9288952350616455\n",
      "Epoch:  7454 | Train Accurancy:  0.9283625781536102 | Validation Accurancy:  0.9289002865552902\n",
      "Epoch:  7455 | Train Accurancy:  0.9283638522028923 | Validation Accurancy:  0.9289054870605469\n",
      "Epoch:  7456 | Train Accurancy:  0.9283649995923042 | Validation Accurancy:  0.9289103224873543\n",
      "Epoch:  7457 | Train Accurancy:  0.9283662512898445 | Validation Accurancy:  0.9289155974984169\n",
      "Epoch:  7458 | Train Accurancy:  0.9283674731850624 | Validation Accurancy:  0.9289204403758049\n",
      "Epoch:  7459 | Train Accurancy:  0.9283686801791191 | Validation Accurancy:  0.9289257377386093\n",
      "Epoch:  7460 | Train Accurancy:  0.928369902074337 | Validation Accurancy:  0.9289305657148361\n",
      "Epoch:  7461 | Train Accurancy:  0.9283711016178131 | Validation Accurancy:  0.9289357662200928\n",
      "Epoch:  7462 | Train Accurancy:  0.9283723309636116 | Validation Accurancy:  0.9289405345916748\n",
      "Epoch:  7463 | Train Accurancy:  0.9283735603094101 | Validation Accurancy:  0.9289456978440285\n",
      "Epoch:  7464 | Train Accurancy:  0.9283747300505638 | Validation Accurancy:  0.9289506152272224\n",
      "Epoch:  7465 | Train Accurancy:  0.9283759593963623 | Validation Accurancy:  0.9289557784795761\n",
      "Epoch:  7466 | Train Accurancy:  0.9283771365880966 | Validation Accurancy:  0.9289606884121895\n",
      "Epoch:  7467 | Train Accurancy:  0.9283783882856369 | Validation Accurancy:  0.9289659038186073\n",
      "Epoch:  7468 | Train Accurancy:  0.9283795356750488 | Validation Accurancy:  0.9289707466959953\n",
      "Epoch:  7469 | Train Accurancy:  0.9283808320760727 | Validation Accurancy:  0.928975947201252\n",
      "Epoch:  7470 | Train Accurancy:  0.928382009267807 | Validation Accurancy:  0.928980715572834\n",
      "Epoch:  7471 | Train Accurancy:  0.9283831939101219 | Validation Accurancy:  0.9289860054850578\n",
      "Epoch:  7472 | Train Accurancy:  0.9283844456076622 | Validation Accurancy:  0.9289907440543175\n",
      "Epoch:  7473 | Train Accurancy:  0.9283856377005577 | Validation Accurancy:  0.9289960563182831\n",
      "Epoch:  7474 | Train Accurancy:  0.9283867925405502 | Validation Accurancy:  0.9290012046694756\n",
      "Epoch:  7475 | Train Accurancy:  0.9283880144357681 | Validation Accurancy:  0.9290059432387352\n",
      "Epoch:  7476 | Train Accurancy:  0.928389236330986 | Validation Accurancy:  0.9290112033486366\n",
      "Epoch:  7477 | Train Accurancy:  0.9283904582262039 | Validation Accurancy:  0.9290160164237022\n",
      "Epoch:  7478 | Train Accurancy:  0.9283916652202606 | Validation Accurancy:  0.9290211498737335\n",
      "Epoch:  7479 | Train Accurancy:  0.9283928796648979 | Validation Accurancy:  0.9290259853005409\n",
      "Epoch:  7480 | Train Accurancy:  0.9283940717577934 | Validation Accurancy:  0.929031178355217\n",
      "Epoch:  7481 | Train Accurancy:  0.9283952862024307 | Validation Accurancy:  0.9290359988808632\n",
      "Epoch:  7482 | Train Accurancy:  0.928396463394165 | Validation Accurancy:  0.9290412738919258\n",
      "Epoch:  7483 | Train Accurancy:  0.9283977299928665 | Validation Accurancy:  0.929046280682087\n",
      "Epoch:  7484 | Train Accurancy:  0.9283989146351814 | Validation Accurancy:  0.9290510788559914\n",
      "Epoch:  7485 | Train Accurancy:  0.9284001290798187 | Validation Accurancy:  0.9290562644600868\n",
      "Epoch:  7486 | Train Accurancy:  0.928401306271553 | Validation Accurancy:  0.92906104773283\n",
      "Epoch:  7487 | Train Accurancy:  0.9284025356173515 | Validation Accurancy:  0.9290662929415703\n",
      "Epoch:  7488 | Train Accurancy:  0.9284037202596664 | Validation Accurancy:  0.9290711432695389\n",
      "Epoch:  7489 | Train Accurancy:  0.9284049496054649 | Validation Accurancy:  0.9290763214230537\n",
      "Epoch:  7490 | Train Accurancy:  0.9284062087535858 | Validation Accurancy:  0.9290810748934746\n",
      "Epoch:  7491 | Train Accurancy:  0.9284073486924171 | Validation Accurancy:  0.9290862902998924\n",
      "Epoch:  7492 | Train Accurancy:  0.9284085482358932 | Validation Accurancy:  0.9290912002325058\n",
      "Epoch:  7493 | Train Accurancy:  0.9284097626805305 | Validation Accurancy:  0.9290963336825371\n",
      "Epoch:  7494 | Train Accurancy:  0.9284109696745872 | Validation Accurancy:  0.9291011020541191\n",
      "Epoch:  7495 | Train Accurancy:  0.9284121617674828 | Validation Accurancy:  0.9291063621640205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7496 | Train Accurancy:  0.9284133613109589 | Validation Accurancy:  0.9291111454367638\n",
      "Epoch:  7497 | Train Accurancy:  0.9284145683050156 | Validation Accurancy:  0.929116278886795\n",
      "Epoch:  7498 | Train Accurancy:  0.9284157454967499 | Validation Accurancy:  0.9291214644908905\n",
      "Epoch:  7499 | Train Accurancy:  0.9284169748425484 | Validation Accurancy:  0.9291263073682785\n",
      "Epoch:  7500 | Train Accurancy:  0.9284181594848633 | Validation Accurancy:  0.9291314780712128\n",
      "Epoch:  7501 | Train Accurancy:  0.9284193813800812 | Validation Accurancy:  0.9291362315416336\n",
      "Epoch:  7502 | Train Accurancy:  0.9284205585718155 | Validation Accurancy:  0.9291412979364395\n",
      "Epoch:  7503 | Train Accurancy:  0.9284217581152916 | Validation Accurancy:  0.9291461184620857\n",
      "Epoch:  7504 | Train Accurancy:  0.9284229651093483 | Validation Accurancy:  0.929151326417923\n",
      "Epoch:  7505 | Train Accurancy:  0.9284241646528244 | Validation Accurancy:  0.929156132042408\n",
      "Epoch:  7506 | Train Accurancy:  0.9284254163503647 | Validation Accurancy:  0.9291613399982452\n",
      "Epoch:  7507 | Train Accurancy:  0.928426556289196 | Validation Accurancy:  0.9291661903262138\n",
      "Epoch:  7508 | Train Accurancy:  0.9284278005361557 | Validation Accurancy:  0.9291713088750839\n",
      "Epoch:  7509 | Train Accurancy:  0.92842897772789 | Validation Accurancy:  0.9291761592030525\n",
      "Epoch:  7510 | Train Accurancy:  0.9284301623702049 | Validation Accurancy:  0.9291812554001808\n",
      "Epoch:  7511 | Train Accurancy:  0.9284314066171646 | Validation Accurancy:  0.9291863590478897\n",
      "Epoch:  7512 | Train Accurancy:  0.9284325689077377 | Validation Accurancy:  0.9291912093758583\n",
      "Epoch:  7513 | Train Accurancy:  0.9284337610006332 | Validation Accurancy:  0.9291963130235672\n",
      "Epoch:  7514 | Train Accurancy:  0.9284349605441093 | Validation Accurancy:  0.9292010441422462\n",
      "Epoch:  7515 | Train Accurancy:  0.928436167538166 | Validation Accurancy:  0.9292062595486641\n",
      "Epoch:  7516 | Train Accurancy:  0.9284373596310616 | Validation Accurancy:  0.9292110949754715\n",
      "Epoch:  7517 | Train Accurancy:  0.9284385740756989 | Validation Accurancy:  0.929216243326664\n",
      "Epoch:  7518 | Train Accurancy:  0.9284397289156914 | Validation Accurancy:  0.9292209446430206\n",
      "Epoch:  7519 | Train Accurancy:  0.9284409359097481 | Validation Accurancy:  0.9292261451482773\n",
      "Epoch:  7520 | Train Accurancy:  0.9284421429038048 | Validation Accurancy:  0.9292313233017921\n",
      "Epoch:  7521 | Train Accurancy:  0.9284433200955391 | Validation Accurancy:  0.9292360916733742\n",
      "Epoch:  7522 | Train Accurancy:  0.9284445270895958 | Validation Accurancy:  0.9292411506175995\n",
      "Epoch:  7523 | Train Accurancy:  0.9284457340836525 | Validation Accurancy:  0.9292459040880203\n",
      "Epoch:  7524 | Train Accurancy:  0.9284468814730644 | Validation Accurancy:  0.9292511269450188\n",
      "Epoch:  7525 | Train Accurancy:  0.9284481257200241 | Validation Accurancy:  0.9292559176683426\n",
      "Epoch:  7526 | Train Accurancy:  0.9284493029117584 | Validation Accurancy:  0.9292610362172127\n",
      "Epoch:  7527 | Train Accurancy:  0.9284505322575569 | Validation Accurancy:  0.9292658790946007\n",
      "Epoch:  7528 | Train Accurancy:  0.9284517094492912 | Validation Accurancy:  0.9292709976434708\n",
      "Epoch:  7529 | Train Accurancy:  0.9284528940916061 | Validation Accurancy:  0.9292758330702782\n",
      "Epoch:  7530 | Train Accurancy:  0.9284540489315987 | Validation Accurancy:  0.9292808845639229\n",
      "Epoch:  7531 | Train Accurancy:  0.9284552708268166 | Validation Accurancy:  0.9292860180139542\n",
      "Epoch:  7532 | Train Accurancy:  0.9284564405679703 | Validation Accurancy:  0.9292907044291496\n",
      "Epoch:  7533 | Train Accurancy:  0.9284576401114464 | Validation Accurancy:  0.9292958602309227\n",
      "Epoch:  7534 | Train Accurancy:  0.9284588471055031 | Validation Accurancy:  0.9293006137013435\n",
      "Epoch:  7535 | Train Accurancy:  0.928460069000721 | Validation Accurancy:  0.929305762052536\n",
      "Epoch:  7536 | Train Accurancy:  0.9284612387418747 | Validation Accurancy:  0.929310530424118\n",
      "Epoch:  7537 | Train Accurancy:  0.9284624755382538 | Validation Accurancy:  0.9293156117200851\n",
      "Epoch:  7538 | Train Accurancy:  0.9284636005759239 | Validation Accurancy:  0.9293205440044403\n",
      "Epoch:  7539 | Train Accurancy:  0.9284647852182388 | Validation Accurancy:  0.9293256103992462\n",
      "Epoch:  7540 | Train Accurancy:  0.9284660145640373 | Validation Accurancy:  0.9293304309248924\n",
      "Epoch:  7541 | Train Accurancy:  0.9284671396017075 | Validation Accurancy:  0.9293355122208595\n",
      "Epoch:  7542 | Train Accurancy:  0.9284683614969254 | Validation Accurancy:  0.9293406009674072\n",
      "Epoch:  7543 | Train Accurancy:  0.9284695312380791 | Validation Accurancy:  0.9293454363942146\n",
      "Epoch:  7544 | Train Accurancy:  0.9284707754850388 | Validation Accurancy:  0.9293504729866982\n",
      "Epoch:  7545 | Train Accurancy:  0.9284719675779343 | Validation Accurancy:  0.9293552562594414\n",
      "Epoch:  7546 | Train Accurancy:  0.9284731075167656 | Validation Accurancy:  0.9293603748083115\n",
      "Epoch:  7547 | Train Accurancy:  0.9284743070602417 | Validation Accurancy:  0.9293651282787323\n",
      "Epoch:  7548 | Train Accurancy:  0.9284754619002342 | Validation Accurancy:  0.929370291531086\n",
      "Epoch:  7549 | Train Accurancy:  0.9284767061471939 | Validation Accurancy:  0.9293749779462814\n",
      "Epoch:  7550 | Train Accurancy:  0.928477868437767 | Validation Accurancy:  0.9293800964951515\n",
      "Epoch:  7551 | Train Accurancy:  0.9284790307283401 | Validation Accurancy:  0.9293851852416992\n",
      "Epoch:  7552 | Train Accurancy:  0.9284802153706551 | Validation Accurancy:  0.9293900355696678\n",
      "Epoch:  7553 | Train Accurancy:  0.9284813851118088 | Validation Accurancy:  0.9293951168656349\n",
      "Epoch:  7554 | Train Accurancy:  0.9284825995564461 | Validation Accurancy:  0.9293998554348946\n",
      "Epoch:  7555 | Train Accurancy:  0.9284837767481804 | Validation Accurancy:  0.9294048771262169\n",
      "Epoch:  7556 | Train Accurancy:  0.9284849613904953 | Validation Accurancy:  0.9294096305966377\n",
      "Epoch:  7557 | Train Accurancy:  0.9284861534833908 | Validation Accurancy:  0.9294147491455078\n",
      "Epoch:  7558 | Train Accurancy:  0.9284873232245445 | Validation Accurancy:  0.9294199123978615\n",
      "Epoch:  7559 | Train Accurancy:  0.9284885302186012 | Validation Accurancy:  0.9294246658682823\n",
      "Epoch:  7560 | Train Accurancy:  0.9284897074103355 | Validation Accurancy:  0.9294297695159912\n",
      "Epoch:  7561 | Train Accurancy:  0.9284908622503281 | Validation Accurancy:  0.9294344931840897\n",
      "Epoch:  7562 | Train Accurancy:  0.9284920692443848 | Validation Accurancy:  0.9294396564364433\n",
      "Epoch:  7563 | Train Accurancy:  0.9284932315349579 | Validation Accurancy:  0.9294443577528\n",
      "Epoch:  7564 | Train Accurancy:  0.928494431078434 | Validation Accurancy:  0.9294494614005089\n",
      "Epoch:  7565 | Train Accurancy:  0.9284956380724907 | Validation Accurancy:  0.9294542595744133\n",
      "Epoch:  7566 | Train Accurancy:  0.9284968078136444 | Validation Accurancy:  0.9294593632221222\n",
      "Epoch:  7567 | Train Accurancy:  0.9284979626536369 | Validation Accurancy:  0.9294644519686699\n",
      "Epoch:  7568 | Train Accurancy:  0.9284991398453712 | Validation Accurancy:  0.9294691756367683\n",
      "Epoch:  7569 | Train Accurancy:  0.9285003915429115 | Validation Accurancy:  0.9294742122292519\n",
      "Epoch:  7570 | Train Accurancy:  0.9285015538334846 | Validation Accurancy:  0.9294790104031563\n",
      "Epoch:  7571 | Train Accurancy:  0.9285027235746384 | Validation Accurancy:  0.9294840171933174\n",
      "Epoch:  7572 | Train Accurancy:  0.9285039380192757 | Validation Accurancy:  0.9294888973236084\n",
      "Epoch:  7573 | Train Accurancy:  0.9285050481557846 | Validation Accurancy:  0.9294939488172531\n",
      "Epoch:  7574 | Train Accurancy:  0.9285062775015831 | Validation Accurancy:  0.9294990077614784\n",
      "Epoch:  7575 | Train Accurancy:  0.9285074472427368 | Validation Accurancy:  0.9295037910342216\n",
      "Epoch:  7576 | Train Accurancy:  0.9285085946321487 | Validation Accurancy:  0.929508812725544\n",
      "Epoch:  7577 | Train Accurancy:  0.9285098239779472 | Validation Accurancy:  0.9295134991407394\n",
      "Epoch:  7578 | Train Accurancy:  0.9285109341144562 | Validation Accurancy:  0.9295186176896095\n",
      "Epoch:  7579 | Train Accurancy:  0.9285121485590935 | Validation Accurancy:  0.929523229598999\n",
      "Epoch:  7580 | Train Accurancy:  0.9285133183002472 | Validation Accurancy:  0.9295284748077393\n",
      "Epoch:  7581 | Train Accurancy:  0.9285144954919815 | Validation Accurancy:  0.9295332282781601\n",
      "Epoch:  7582 | Train Accurancy:  0.9285156801342964 | Validation Accurancy:  0.9295383915305138\n",
      "Epoch:  7583 | Train Accurancy:  0.9285168126225471 | Validation Accurancy:  0.9295434504747391\n",
      "Epoch:  7584 | Train Accurancy:  0.9285180047154427 | Validation Accurancy:  0.929548092186451\n",
      "Epoch:  7585 | Train Accurancy:  0.9285191297531128 | Validation Accurancy:  0.9295532554388046\n",
      "Epoch:  7586 | Train Accurancy:  0.9285203665494919 | Validation Accurancy:  0.9295579418540001\n",
      "Epoch:  7587 | Train Accurancy:  0.9285215362906456 | Validation Accurancy:  0.9295630156993866\n",
      "Epoch:  7588 | Train Accurancy:  0.9285227432847023 | Validation Accurancy:  0.9295677021145821\n",
      "Epoch:  7589 | Train Accurancy:  0.928523913025856 | Validation Accurancy:  0.929572805762291\n",
      "Epoch:  7590 | Train Accurancy:  0.9285250827670097 | Validation Accurancy:  0.9295778274536133\n",
      "Epoch:  7591 | Train Accurancy:  0.9285262525081635 | Validation Accurancy:  0.9295824840664864\n",
      "Epoch:  7592 | Train Accurancy:  0.9285274222493172 | Validation Accurancy:  0.9295876324176788\n",
      "Epoch:  7593 | Train Accurancy:  0.9285285472869873 | Validation Accurancy:  0.9295923709869385\n",
      "Epoch:  7594 | Train Accurancy:  0.9285297840833664 | Validation Accurancy:  0.9295974224805832\n",
      "Epoch:  7595 | Train Accurancy:  0.9285309538245201 | Validation Accurancy:  0.9296020492911339\n",
      "Epoch:  7596 | Train Accurancy:  0.9285321235656738 | Validation Accurancy:  0.9296071827411652\n",
      "Epoch:  7597 | Train Accurancy:  0.9285333007574081 | Validation Accurancy:  0.9296122565865517\n",
      "Epoch:  7598 | Train Accurancy:  0.9285344704985619 | Validation Accurancy:  0.9296168461441994\n",
      "Epoch:  7599 | Train Accurancy:  0.9285356476902962 | Validation Accurancy:  0.9296219646930695\n",
      "Epoch:  7600 | Train Accurancy:  0.9285368397831917 | Validation Accurancy:  0.9296266734600067\n",
      "Epoch:  7601 | Train Accurancy:  0.92853794246912 | Validation Accurancy:  0.9296317771077156\n",
      "Epoch:  7602 | Train Accurancy:  0.9285391122102737 | Validation Accurancy:  0.9296364933252335\n",
      "Epoch:  7603 | Train Accurancy:  0.9285402670502663 | Validation Accurancy:  0.92964156717062\n",
      "Epoch:  7604 | Train Accurancy:  0.9285415187478065 | Validation Accurancy:  0.9296466186642647\n",
      "Epoch:  7605 | Train Accurancy:  0.9285426586866379 | Validation Accurancy:  0.9296513572335243\n",
      "Epoch:  7606 | Train Accurancy:  0.9285438135266304 | Validation Accurancy:  0.9296563789248466\n",
      "Epoch:  7607 | Train Accurancy:  0.9285449534654617 | Validation Accurancy:  0.9296610206365585\n",
      "Epoch:  7608 | Train Accurancy:  0.928546167910099 | Validation Accurancy:  0.9296660721302032\n",
      "Epoch:  7609 | Train Accurancy:  0.9285473451018333 | Validation Accurancy:  0.9296711161732674\n",
      "Epoch:  7610 | Train Accurancy:  0.92854855209589 | Validation Accurancy:  0.9296757504343987\n",
      "Epoch:  7611 | Train Accurancy:  0.9285496547818184 | Validation Accurancy:  0.9296809062361717\n",
      "Epoch:  7612 | Train Accurancy:  0.9285508170723915 | Validation Accurancy:  0.9296856597065926\n",
      "Epoch:  7613 | Train Accurancy:  0.9285520017147064 | Validation Accurancy:  0.9296907261013985\n",
      "Epoch:  7614 | Train Accurancy:  0.9285531863570213 | Validation Accurancy:  0.929695300757885\n",
      "Epoch:  7615 | Train Accurancy:  0.9285543113946915 | Validation Accurancy:  0.9297003448009491\n",
      "Epoch:  7616 | Train Accurancy:  0.9285555705428123 | Validation Accurancy:  0.929705411195755\n",
      "Epoch:  7617 | Train Accurancy:  0.9285566881299019 | Validation Accurancy:  0.9297101050615311\n",
      "Epoch:  7618 | Train Accurancy:  0.9285578578710556 | Validation Accurancy:  0.9297150447964668\n",
      "Epoch:  7619 | Train Accurancy:  0.9285590499639511 | Validation Accurancy:  0.9297198131680489\n",
      "Epoch:  7620 | Train Accurancy:  0.9285601824522018 | Validation Accurancy:  0.9297247901558876\n",
      "Epoch:  7621 | Train Accurancy:  0.9285613521933556 | Validation Accurancy:  0.9297296553850174\n",
      "Epoch:  7622 | Train Accurancy:  0.9285625144839287 | Validation Accurancy:  0.9297347515821457\n",
      "Epoch:  7623 | Train Accurancy:  0.9285636395215988 | Validation Accurancy:  0.9297396689653397\n",
      "Epoch:  7624 | Train Accurancy:  0.9285648018121719 | Validation Accurancy:  0.9297443255782127\n",
      "Epoch:  7625 | Train Accurancy:  0.9285660460591316 | Validation Accurancy:  0.9297492951154709\n",
      "Epoch:  7626 | Train Accurancy:  0.9285672083497047 | Validation Accurancy:  0.9297541901469231\n",
      "Epoch:  7627 | Train Accurancy:  0.9285683259367943 | Validation Accurancy:  0.929759219288826\n",
      "Epoch:  7628 | Train Accurancy:  0.9285694509744644 | Validation Accurancy:  0.9297638759016991\n",
      "Epoch:  7629 | Train Accurancy:  0.9285707026720047 | Validation Accurancy:  0.9297689124941826\n",
      "Epoch:  7630 | Train Accurancy:  0.9285718724131584 | Validation Accurancy:  0.9297739341855049\n",
      "Epoch:  7631 | Train Accurancy:  0.928572990000248 | Validation Accurancy:  0.9297786206007004\n",
      "Epoch:  7632 | Train Accurancy:  0.9285742044448853 | Validation Accurancy:  0.9297836646437645\n",
      "Epoch:  7633 | Train Accurancy:  0.9285752847790718 | Validation Accurancy:  0.9297883957624435\n",
      "Epoch:  7634 | Train Accurancy:  0.9285764619708061 | Validation Accurancy:  0.9297933578491211\n",
      "Epoch:  7635 | Train Accurancy:  0.9285776242613792 | Validation Accurancy:  0.9297983199357986\n",
      "Epoch:  7636 | Train Accurancy:  0.9285787716507912 | Validation Accurancy:  0.9298029616475105\n",
      "Epoch:  7637 | Train Accurancy:  0.9285799264907837 | Validation Accurancy:  0.929807998239994\n",
      "Epoch:  7638 | Train Accurancy:  0.9285811558365822 | Validation Accurancy:  0.9298126250505447\n",
      "Epoch:  7639 | Train Accurancy:  0.9285822585225105 | Validation Accurancy:  0.9298176765441895\n",
      "Epoch:  7640 | Train Accurancy:  0.9285834282636642 | Validation Accurancy:  0.9298223480582237\n",
      "Epoch:  7641 | Train Accurancy:  0.928584598004818 | Validation Accurancy:  0.9298274517059326\n",
      "Epoch:  7642 | Train Accurancy:  0.9285857528448105 | Validation Accurancy:  0.9298324584960938\n",
      "Epoch:  7643 | Train Accurancy:  0.9285869374871254 | Validation Accurancy:  0.9298371151089668\n",
      "Epoch:  7644 | Train Accurancy:  0.9285880997776985 | Validation Accurancy:  0.9298420771956444\n",
      "Epoch:  7645 | Train Accurancy:  0.9285892024636269 | Validation Accurancy:  0.9298467487096786\n",
      "Epoch:  7646 | Train Accurancy:  0.928590439260006 | Validation Accurancy:  0.9298518374562263\n",
      "Epoch:  7647 | Train Accurancy:  0.9285915642976761 | Validation Accurancy:  0.9298568069934845\n",
      "Epoch:  7648 | Train Accurancy:  0.928592748939991 | Validation Accurancy:  0.9298614487051964\n",
      "Epoch:  7649 | Train Accurancy:  0.9285938888788223 | Validation Accurancy:  0.9298664405941963\n",
      "Epoch:  7650 | Train Accurancy:  0.9285950362682343 | Validation Accurancy:  0.9298711270093918\n",
      "Epoch:  7651 | Train Accurancy:  0.9285962209105492 | Validation Accurancy:  0.9298761337995529\n",
      "Epoch:  7652 | Train Accurancy:  0.9285973310470581 | Validation Accurancy:  0.9298810511827469\n",
      "Epoch:  7653 | Train Accurancy:  0.9285984933376312 | Validation Accurancy:  0.9298858195543289\n",
      "Epoch:  7654 | Train Accurancy:  0.9285996928811073 | Validation Accurancy:  0.9298907741904259\n",
      "Epoch:  7655 | Train Accurancy:  0.9286008030176163 | Validation Accurancy:  0.9298954829573631\n",
      "Epoch:  7656 | Train Accurancy:  0.9286019876599312 | Validation Accurancy:  0.9299004524946213\n",
      "Epoch:  7657 | Train Accurancy:  0.9286031499505043 | Validation Accurancy:  0.9299054592847824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7658 | Train Accurancy:  0.928604245185852 | Validation Accurancy:  0.9299100860953331\n",
      "Epoch:  7659 | Train Accurancy:  0.92860546708107 | Validation Accurancy:  0.9299150481820107\n",
      "Epoch:  7660 | Train Accurancy:  0.9286066070199013 | Validation Accurancy:  0.9299197867512703\n",
      "Epoch:  7661 | Train Accurancy:  0.928607776761055 | Validation Accurancy:  0.9299247562885284\n",
      "Epoch:  7662 | Train Accurancy:  0.9286088943481445 | Validation Accurancy:  0.9299298003315926\n",
      "Epoch:  7663 | Train Accurancy:  0.9286100417375565 | Validation Accurancy:  0.9299343302845955\n",
      "Epoch:  7664 | Train Accurancy:  0.9286112040281296 | Validation Accurancy:  0.9299393817782402\n",
      "Epoch:  7665 | Train Accurancy:  0.9286123290657997 | Validation Accurancy:  0.9299440383911133\n",
      "Epoch:  7666 | Train Accurancy:  0.9286134988069534 | Validation Accurancy:  0.9299490451812744\n",
      "Epoch:  7667 | Train Accurancy:  0.9286146685481071 | Validation Accurancy:  0.9299539402127266\n",
      "Epoch:  7668 | Train Accurancy:  0.9286158457398415 | Validation Accurancy:  0.9299586787819862\n",
      "Epoch:  7669 | Train Accurancy:  0.9286169558763504 | Validation Accurancy:  0.9299636036157608\n",
      "Epoch:  7670 | Train Accurancy:  0.9286181479692459 | Validation Accurancy:  0.9299683719873428\n",
      "Epoch:  7671 | Train Accurancy:  0.9286192581057549 | Validation Accurancy:  0.9299733191728592\n",
      "Epoch:  7672 | Train Accurancy:  0.928620420396328 | Validation Accurancy:  0.9299784004688263\n",
      "Epoch:  7673 | Train Accurancy:  0.9286215752363205 | Validation Accurancy:  0.9299829825758934\n",
      "Epoch:  7674 | Train Accurancy:  0.928622767329216 | Validation Accurancy:  0.9299879372119904\n",
      "Epoch:  7675 | Train Accurancy:  0.9286239147186279 | Validation Accurancy:  0.9299926459789276\n",
      "Epoch:  7676 | Train Accurancy:  0.9286250695586205 | Validation Accurancy:  0.9299976527690887\n",
      "Epoch:  7677 | Train Accurancy:  0.9286261945962906 | Validation Accurancy:  0.9300023093819618\n",
      "Epoch:  7678 | Train Accurancy:  0.9286273494362831 | Validation Accurancy:  0.9300072640180588\n",
      "Epoch:  7679 | Train Accurancy:  0.9286284893751144 | Validation Accurancy:  0.9300122559070587\n",
      "Epoch:  7680 | Train Accurancy:  0.928629606962204 | Validation Accurancy:  0.9300167858600616\n",
      "Epoch:  7681 | Train Accurancy:  0.9286307841539383 | Validation Accurancy:  0.9300218746066093\n",
      "Epoch:  7682 | Train Accurancy:  0.9286319464445114 | Validation Accurancy:  0.93002650141716\n",
      "Epoch:  7683 | Train Accurancy:  0.9286330714821815 | Validation Accurancy:  0.9300315231084824\n",
      "Epoch:  7684 | Train Accurancy:  0.9286342188715935 | Validation Accurancy:  0.9300364330410957\n",
      "Epoch:  7685 | Train Accurancy:  0.9286354035139084 | Validation Accurancy:  0.9300411716103554\n",
      "Epoch:  7686 | Train Accurancy:  0.9286365136504173 | Validation Accurancy:  0.9300460666418076\n",
      "Epoch:  7687 | Train Accurancy:  0.9286376684904099 | Validation Accurancy:  0.9300507679581642\n",
      "Epoch:  7688 | Train Accurancy:  0.9286388084292412 | Validation Accurancy:  0.9300556480884552\n",
      "Epoch:  7689 | Train Accurancy:  0.9286399632692337 | Validation Accurancy:  0.9300607070326805\n",
      "Epoch:  7690 | Train Accurancy:  0.9286410808563232 | Validation Accurancy:  0.9300652369856834\n",
      "Epoch:  7691 | Train Accurancy:  0.9286422654986382 | Validation Accurancy:  0.9300702065229416\n",
      "Epoch:  7692 | Train Accurancy:  0.9286434426903725 | Validation Accurancy:  0.9300749003887177\n",
      "Epoch:  7693 | Train Accurancy:  0.9286445379257202 | Validation Accurancy:  0.93007992208004\n",
      "Epoch:  7694 | Train Accurancy:  0.9286456629633904 | Validation Accurancy:  0.9300847724080086\n",
      "Epoch:  7695 | Train Accurancy:  0.9286468401551247 | Validation Accurancy:  0.9300894290208817\n",
      "Epoch:  7696 | Train Accurancy:  0.928647980093956 | Validation Accurancy:  0.930094413459301\n",
      "Epoch:  7697 | Train Accurancy:  0.9286490976810455 | Validation Accurancy:  0.9300993606448174\n",
      "Epoch:  7698 | Train Accurancy:  0.9286503121256828 | Validation Accurancy:  0.9301039054989815\n",
      "Epoch:  7699 | Train Accurancy:  0.9286514446139336 | Validation Accurancy:  0.9301088005304337\n",
      "Epoch:  7700 | Train Accurancy:  0.9286526143550873 | Validation Accurancy:  0.9301134869456291\n",
      "Epoch:  7701 | Train Accurancy:  0.9286537170410156 | Validation Accurancy:  0.9301184639334679\n",
      "Epoch:  7702 | Train Accurancy:  0.9286548718810081 | Validation Accurancy:  0.9301233142614365\n",
      "Epoch:  7703 | Train Accurancy:  0.9286559894680977 | Validation Accurancy:  0.9301280975341797\n",
      "Epoch:  7704 | Train Accurancy:  0.9286571368575096 | Validation Accurancy:  0.9301330074667931\n",
      "Epoch:  7705 | Train Accurancy:  0.9286582916975021 | Validation Accurancy:  0.9301376342773438\n",
      "Epoch:  7706 | Train Accurancy:  0.9286594539880753 | Validation Accurancy:  0.9301425591111183\n",
      "Epoch:  7707 | Train Accurancy:  0.928660586476326 | Validation Accurancy:  0.9301474541425705\n",
      "Epoch:  7708 | Train Accurancy:  0.9286617413163185 | Validation Accurancy:  0.9301521107554436\n",
      "Epoch:  7709 | Train Accurancy:  0.928662858903408 | Validation Accurancy:  0.9301570728421211\n",
      "Epoch:  7710 | Train Accurancy:  0.9286640211939812 | Validation Accurancy:  0.930161602795124\n",
      "Epoch:  7711 | Train Accurancy:  0.9286651238799095 | Validation Accurancy:  0.9301666244864464\n",
      "Epoch:  7712 | Train Accurancy:  0.9286662861704826 | Validation Accurancy:  0.9301715567708015\n",
      "Epoch:  7713 | Train Accurancy:  0.9286674186587334 | Validation Accurancy:  0.9301761612296104\n",
      "Epoch:  7714 | Train Accurancy:  0.9286685809493065 | Validation Accurancy:  0.930181123316288\n",
      "Epoch:  7715 | Train Accurancy:  0.928669698536396 | Validation Accurancy:  0.9301857501268387\n",
      "Epoch:  7716 | Train Accurancy:  0.9286708384752274 | Validation Accurancy:  0.9301906749606133\n",
      "Epoch:  7717 | Train Accurancy:  0.9286719709634781 | Validation Accurancy:  0.930195651948452\n",
      "Epoch:  7718 | Train Accurancy:  0.9286731407046318 | Validation Accurancy:  0.9302002713084221\n",
      "Epoch:  7719 | Train Accurancy:  0.9286742657423019 | Validation Accurancy:  0.9302052184939384\n",
      "Epoch:  7720 | Train Accurancy:  0.9286754503846169 | Validation Accurancy:  0.9302098080515862\n",
      "Epoch:  7721 | Train Accurancy:  0.9286765530705452 | Validation Accurancy:  0.9302147999405861\n",
      "Epoch:  7722 | Train Accurancy:  0.9286776930093765 | Validation Accurancy:  0.9302197471261024\n",
      "Epoch:  7723 | Train Accurancy:  0.9286787807941437 | Validation Accurancy:  0.9302242919802666\n",
      "Epoch:  7724 | Train Accurancy:  0.9286799505352974 | Validation Accurancy:  0.9302292168140411\n",
      "Epoch:  7725 | Train Accurancy:  0.9286810681223869 | Validation Accurancy:  0.930233784019947\n",
      "Epoch:  7726 | Train Accurancy:  0.92868223041296 | Validation Accurancy:  0.9302387535572052\n",
      "Epoch:  7727 | Train Accurancy:  0.9286833629012108 | Validation Accurancy:  0.9302436634898186\n",
      "Epoch:  7728 | Train Accurancy:  0.9286844953894615 | Validation Accurancy:  0.9302483275532722\n",
      "Epoch:  7729 | Train Accurancy:  0.9286856278777122 | Validation Accurancy:  0.9302532225847244\n",
      "Epoch:  7730 | Train Accurancy:  0.9286868274211884 | Validation Accurancy:  0.9302580803632736\n",
      "Epoch:  7731 | Train Accurancy:  0.9286879077553749 | Validation Accurancy:  0.9302627220749855\n",
      "Epoch:  7732 | Train Accurancy:  0.9286889955401421 | Validation Accurancy:  0.9302676022052765\n",
      "Epoch:  7733 | Train Accurancy:  0.9286901280283928 | Validation Accurancy:  0.9302721843123436\n",
      "Epoch:  7734 | Train Accurancy:  0.9286913201212883 | Validation Accurancy:  0.9302771911025047\n",
      "Epoch:  7735 | Train Accurancy:  0.9286924302577972 | Validation Accurancy:  0.9302821010351181\n",
      "Epoch:  7736 | Train Accurancy:  0.9286936149001122 | Validation Accurancy:  0.9302867129445076\n",
      "Epoch:  7737 | Train Accurancy:  0.9286946877837181 | Validation Accurancy:  0.9302916079759598\n",
      "Epoch:  7738 | Train Accurancy:  0.9286958053708076 | Validation Accurancy:  0.930296503007412\n",
      "Epoch:  7739 | Train Accurancy:  0.9286969900131226 | Validation Accurancy:  0.9303010180592537\n",
      "Epoch:  7740 | Train Accurancy:  0.9286980926990509 | Validation Accurancy:  0.9303059428930283\n",
      "Epoch:  7741 | Train Accurancy:  0.928699254989624 | Validation Accurancy:  0.930310882627964\n",
      "Epoch:  7742 | Train Accurancy:  0.9287004098296165 | Validation Accurancy:  0.9303154945373535\n",
      "Epoch:  7743 | Train Accurancy:  0.9287015274167061 | Validation Accurancy:  0.9303204193711281\n",
      "Epoch:  7744 | Train Accurancy:  0.9287026226520538 | Validation Accurancy:  0.9303250014781952\n",
      "Epoch:  7745 | Train Accurancy:  0.9287037700414658 | Validation Accurancy:  0.9303299114108086\n",
      "Epoch:  7746 | Train Accurancy:  0.9287049025297165 | Validation Accurancy:  0.9303348362445831\n",
      "Epoch:  7747 | Train Accurancy:  0.9287060648202896 | Validation Accurancy:  0.9303393661975861\n",
      "Epoch:  7748 | Train Accurancy:  0.9287071153521538 | Validation Accurancy:  0.9303442314267159\n",
      "Epoch:  7749 | Train Accurancy:  0.9287083148956299 | Validation Accurancy:  0.9303488880395889\n",
      "Epoch:  7750 | Train Accurancy:  0.9287093877792358 | Validation Accurancy:  0.9303537234663963\n",
      "Epoch:  7751 | Train Accurancy:  0.9287105575203896 | Validation Accurancy:  0.9303588047623634\n",
      "Epoch:  7752 | Train Accurancy:  0.9287116974592209 | Validation Accurancy:  0.9303632900118828\n",
      "Epoch:  7753 | Train Accurancy:  0.9287128373980522 | Validation Accurancy:  0.9303682297468185\n",
      "Epoch:  7754 | Train Accurancy:  0.9287139326334 | Validation Accurancy:  0.9303727000951767\n",
      "Epoch:  7755 | Train Accurancy:  0.9287150874733925 | Validation Accurancy:  0.9303776770830154\n",
      "Epoch:  7756 | Train Accurancy:  0.9287161976099014 | Validation Accurancy:  0.93038260191679\n",
      "Epoch:  7757 | Train Accurancy:  0.9287173226475716 | Validation Accurancy:  0.9303871616721153\n",
      "Epoch:  7758 | Train Accurancy:  0.9287184476852417 | Validation Accurancy:  0.9303920418024063\n",
      "Epoch:  7759 | Train Accurancy:  0.9287195727229118 | Validation Accurancy:  0.9303969517350197\n",
      "Epoch:  7760 | Train Accurancy:  0.9287207201123238 | Validation Accurancy:  0.930401548743248\n",
      "Epoch:  7761 | Train Accurancy:  0.9287218600511551 | Validation Accurancy:  0.930406428873539\n",
      "Epoch:  7762 | Train Accurancy:  0.9287229850888252 | Validation Accurancy:  0.93041130900383\n",
      "Epoch:  7763 | Train Accurancy:  0.9287240952253342 | Validation Accurancy:  0.9304158538579941\n",
      "Epoch:  7764 | Train Accurancy:  0.9287252202630043 | Validation Accurancy:  0.9304207637906075\n",
      "Epoch:  7765 | Train Accurancy:  0.9287263825535774 | Validation Accurancy:  0.9304253086447716\n",
      "Epoch:  7766 | Train Accurancy:  0.9287274181842804 | Validation Accurancy:  0.9304302856326103\n",
      "Epoch:  7767 | Train Accurancy:  0.9287286251783371 | Validation Accurancy:  0.9304351657629013\n",
      "Epoch:  7768 | Train Accurancy:  0.928729735314846 | Validation Accurancy:  0.930439755320549\n",
      "Epoch:  7769 | Train Accurancy:  0.928730882704258 | Validation Accurancy:  0.9304446056485176\n",
      "Epoch:  7770 | Train Accurancy:  0.9287319853901863 | Validation Accurancy:  0.9304494708776474\n",
      "Epoch:  7771 | Train Accurancy:  0.9287330731749535 | Validation Accurancy:  0.9304539710283279\n",
      "Epoch:  7772 | Train Accurancy:  0.9287342131137848 | Validation Accurancy:  0.9304588958621025\n",
      "Epoch:  7773 | Train Accurancy:  0.9287353456020355 | Validation Accurancy:  0.9304634556174278\n",
      "Epoch:  7774 | Train Accurancy:  0.9287364631891251 | Validation Accurancy:  0.9304684177041054\n",
      "Epoch:  7775 | Train Accurancy:  0.9287375584244728 | Validation Accurancy:  0.9304732158780098\n",
      "Epoch:  7776 | Train Accurancy:  0.9287387058138847 | Validation Accurancy:  0.9304777309298515\n",
      "Epoch:  7777 | Train Accurancy:  0.9287398681044579 | Validation Accurancy:  0.9304826930165291\n",
      "Epoch:  7778 | Train Accurancy:  0.9287409782409668 | Validation Accurancy:  0.9304875507950783\n",
      "Epoch:  7779 | Train Accurancy:  0.9287420734763145 | Validation Accurancy:  0.9304920360445976\n",
      "Epoch:  7780 | Train Accurancy:  0.9287432208657265 | Validation Accurancy:  0.9304969161748886\n",
      "Epoch:  7781 | Train Accurancy:  0.9287443235516548 | Validation Accurancy:  0.930501826107502\n",
      "Epoch:  7782 | Train Accurancy:  0.9287454336881638 | Validation Accurancy:  0.9305064007639885\n",
      "Epoch:  7783 | Train Accurancy:  0.9287466630339622 | Validation Accurancy:  0.9305112808942795\n",
      "Epoch:  7784 | Train Accurancy:  0.9287476912140846 | Validation Accurancy:  0.9305161312222481\n",
      "Epoch:  7785 | Train Accurancy:  0.9287488162517548 | Validation Accurancy:  0.9305207431316376\n",
      "Epoch:  7786 | Train Accurancy:  0.9287499412894249 | Validation Accurancy:  0.9305255115032196\n",
      "Epoch:  7787 | Train Accurancy:  0.9287510216236115 | Validation Accurancy:  0.9305301010608673\n",
      "Epoch:  7788 | Train Accurancy:  0.9287521690130234 | Validation Accurancy:  0.930535078048706\n",
      "Epoch:  7789 | Train Accurancy:  0.9287533015012741 | Validation Accurancy:  0.9305399283766747\n",
      "Epoch:  7790 | Train Accurancy:  0.928754448890686 | Validation Accurancy:  0.930544376373291\n",
      "Epoch:  7791 | Train Accurancy:  0.928755521774292 | Validation Accurancy:  0.9305493012070656\n",
      "Epoch:  7792 | Train Accurancy:  0.9287566691637039 | Validation Accurancy:  0.930554136633873\n",
      "Epoch:  7793 | Train Accurancy:  0.9287577643990517 | Validation Accurancy:  0.9305586963891983\n",
      "Epoch:  7794 | Train Accurancy:  0.9287589117884636 | Validation Accurancy:  0.9305635616183281\n",
      "Epoch:  7795 | Train Accurancy:  0.9287600666284561 | Validation Accurancy:  0.9305681735277176\n",
      "Epoch:  7796 | Train Accurancy:  0.9287611767649651 | Validation Accurancy:  0.9305730536580086\n",
      "Epoch:  7797 | Train Accurancy:  0.9287622645497322 | Validation Accurancy:  0.930577926337719\n",
      "Epoch:  7798 | Train Accurancy:  0.92876335978508 | Validation Accurancy:  0.9305824413895607\n",
      "Epoch:  7799 | Train Accurancy:  0.9287645071744919 | Validation Accurancy:  0.9305872619152069\n",
      "Epoch:  7800 | Train Accurancy:  0.9287656396627426 | Validation Accurancy:  0.9305921271443367\n",
      "Epoch:  7801 | Train Accurancy:  0.9287667348980904 | Validation Accurancy:  0.9305965453386307\n",
      "Epoch:  7802 | Train Accurancy:  0.9287678375840187 | Validation Accurancy:  0.9306014403700829\n",
      "Epoch:  7803 | Train Accurancy:  0.92876897752285 | Validation Accurancy:  0.9306060150265694\n",
      "Epoch:  7804 | Train Accurancy:  0.9287700727581978 | Validation Accurancy:  0.9306108802556992\n",
      "Epoch:  7805 | Train Accurancy:  0.9287711828947067 | Validation Accurancy:  0.930615745484829\n",
      "Epoch:  7806 | Train Accurancy:  0.928772322833538 | Validation Accurancy:  0.9306202754378319\n",
      "Epoch:  7807 | Train Accurancy:  0.9287734031677246 | Validation Accurancy:  0.9306251183152199\n",
      "Epoch:  7808 | Train Accurancy:  0.9287745580077171 | Validation Accurancy:  0.9306300655007362\n",
      "Epoch:  7809 | Train Accurancy:  0.9287756532430649 | Validation Accurancy:  0.9306345656514168\n",
      "Epoch:  7810 | Train Accurancy:  0.9287767708301544 | Validation Accurancy:  0.930639423429966\n",
      "Epoch:  7811 | Train Accurancy:  0.9287778958678246 | Validation Accurancy:  0.9306442588567734\n",
      "Epoch:  7812 | Train Accurancy:  0.9287790134549141 | Validation Accurancy:  0.9306487590074539\n",
      "Epoch:  7813 | Train Accurancy:  0.9287801012396812 | Validation Accurancy:  0.9306535720825195\n",
      "Epoch:  7814 | Train Accurancy:  0.9287811815738678 | Validation Accurancy:  0.9306584373116493\n",
      "Epoch:  7815 | Train Accurancy:  0.9287823736667633 | Validation Accurancy:  0.9306629821658134\n",
      "Epoch:  7816 | Train Accurancy:  0.9287834390997887 | Validation Accurancy:  0.930667832493782\n",
      "Epoch:  7817 | Train Accurancy:  0.9287845715880394 | Validation Accurancy:  0.9306726902723312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7818 | Train Accurancy:  0.9287856817245483 | Validation Accurancy:  0.9306771755218506\n",
      "Epoch:  7819 | Train Accurancy:  0.9287867471575737 | Validation Accurancy:  0.9306820407509804\n",
      "Epoch:  7820 | Train Accurancy:  0.9287878721952438 | Validation Accurancy:  0.9306868091225624\n",
      "Epoch:  7821 | Train Accurancy:  0.9287890419363976 | Validation Accurancy:  0.9306913390755653\n",
      "Epoch:  7822 | Train Accurancy:  0.9287901595234871 | Validation Accurancy:  0.9306961223483086\n",
      "Epoch:  7823 | Train Accurancy:  0.9287912547588348 | Validation Accurancy:  0.9307010024785995\n",
      "Epoch:  7824 | Train Accurancy:  0.928792342543602 | Validation Accurancy:  0.9307054653763771\n",
      "Epoch:  7825 | Train Accurancy:  0.9287934452295303 | Validation Accurancy:  0.9307103008031845\n",
      "Epoch:  7826 | Train Accurancy:  0.9287945702672005 | Validation Accurancy:  0.9307148456573486\n",
      "Epoch:  7827 | Train Accurancy:  0.9287956655025482 | Validation Accurancy:  0.930719643831253\n",
      "Epoch:  7828 | Train Accurancy:  0.928796760737896 | Validation Accurancy:  0.9307244792580605\n",
      "Epoch:  7829 | Train Accurancy:  0.9287979602813721 | Validation Accurancy:  0.9307290390133858\n",
      "Epoch:  7830 | Train Accurancy:  0.9287990480661392 | Validation Accurancy:  0.930733934044838\n",
      "Epoch:  7831 | Train Accurancy:  0.9288001134991646 | Validation Accurancy:  0.9307387545704842\n",
      "Epoch:  7832 | Train Accurancy:  0.9288011863827705 | Validation Accurancy:  0.9307431727647781\n",
      "Epoch:  7833 | Train Accurancy:  0.9288023486733437 | Validation Accurancy:  0.9307480156421661\n",
      "Epoch:  7834 | Train Accurancy:  0.9288034290075302 | Validation Accurancy:  0.9307528361678123\n",
      "Epoch:  7835 | Train Accurancy:  0.9288045093417168 | Validation Accurancy:  0.9307573512196541\n",
      "Epoch:  7836 | Train Accurancy:  0.9288056641817093 | Validation Accurancy:  0.9307621195912361\n",
      "Epoch:  7837 | Train Accurancy:  0.9288067668676376 | Validation Accurancy:  0.9307669922709465\n",
      "Epoch:  7838 | Train Accurancy:  0.9288078397512436 | Validation Accurancy:  0.930771492421627\n",
      "Epoch:  7839 | Train Accurancy:  0.9288089647889137 | Validation Accurancy:  0.9307763427495956\n",
      "Epoch:  7840 | Train Accurancy:  0.9288100674748421 | Validation Accurancy:  0.9307810962200165\n",
      "Epoch:  7841 | Train Accurancy:  0.9288111925125122 | Validation Accurancy:  0.9307855889201164\n",
      "Epoch:  7842 | Train Accurancy:  0.9288123100996017 | Validation Accurancy:  0.9307905212044716\n",
      "Epoch:  7843 | Train Accurancy:  0.9288133904337883 | Validation Accurancy:  0.9307952895760536\n",
      "Epoch:  7844 | Train Accurancy:  0.928814522922039 | Validation Accurancy:  0.9307997524738312\n",
      "Epoch:  7845 | Train Accurancy:  0.928815595805645 | Validation Accurancy:  0.9308045879006386\n",
      "Epoch:  7846 | Train Accurancy:  0.9288166984915733 | Validation Accurancy:  0.9308094009757042\n",
      "Epoch:  7847 | Train Accurancy:  0.9288178384304047 | Validation Accurancy:  0.9308139011263847\n",
      "Epoch:  7848 | Train Accurancy:  0.92881890386343 | Validation Accurancy:  0.9308187142014503\n",
      "Epoch:  7849 | Train Accurancy:  0.9288200661540031 | Validation Accurancy:  0.9308231174945831\n",
      "Epoch:  7850 | Train Accurancy:  0.9288211613893509 | Validation Accurancy:  0.9308280795812607\n",
      "Epoch:  7851 | Train Accurancy:  0.928822249174118 | Validation Accurancy:  0.9308328777551651\n",
      "Epoch:  7852 | Train Accurancy:  0.9288233816623688 | Validation Accurancy:  0.9308373928070068\n",
      "Epoch:  7853 | Train Accurancy:  0.9288244768977165 | Validation Accurancy:  0.9308422282338142\n",
      "Epoch:  7854 | Train Accurancy:  0.9288255348801613 | Validation Accurancy:  0.9308469593524933\n",
      "Epoch:  7855 | Train Accurancy:  0.9288266524672508 | Validation Accurancy:  0.9308514446020126\n",
      "Epoch:  7856 | Train Accurancy:  0.9288277477025986 | Validation Accurancy:  0.9308562725782394\n",
      "Epoch:  7857 | Train Accurancy:  0.9288288727402687 | Validation Accurancy:  0.9308610633015633\n",
      "Epoch:  7858 | Train Accurancy:  0.9288299530744553 | Validation Accurancy:  0.9308655261993408\n",
      "Epoch:  7859 | Train Accurancy:  0.9288310557603836 | Validation Accurancy:  0.9308702945709229\n",
      "Epoch:  7860 | Train Accurancy:  0.9288321509957314 | Validation Accurancy:  0.9308751598000526\n",
      "Epoch:  7861 | Train Accurancy:  0.9288332611322403 | Validation Accurancy:  0.9308796375989914\n",
      "Epoch:  7862 | Train Accurancy:  0.9288343489170074 | Validation Accurancy:  0.9308844432234764\n",
      "Epoch:  7863 | Train Accurancy:  0.9288354963064194 | Validation Accurancy:  0.9308891743421555\n",
      "Epoch:  7864 | Train Accurancy:  0.9288365393877029 | Validation Accurancy:  0.9308936893939972\n",
      "Epoch:  7865 | Train Accurancy:  0.9288376867771149 | Validation Accurancy:  0.9308984279632568\n",
      "Epoch:  7866 | Train Accurancy:  0.9288388043642044 | Validation Accurancy:  0.9309032410383224\n",
      "Epoch:  7867 | Train Accurancy:  0.9288398995995522 | Validation Accurancy:  0.9309077262878418\n",
      "Epoch:  7868 | Train Accurancy:  0.9288410097360611 | Validation Accurancy:  0.9309126064181328\n",
      "Epoch:  7869 | Train Accurancy:  0.9288421049714088 | Validation Accurancy:  0.9309173747897148\n",
      "Epoch:  7870 | Train Accurancy:  0.9288431629538536 | Validation Accurancy:  0.9309218898415565\n",
      "Epoch:  7871 | Train Accurancy:  0.9288442507386208 | Validation Accurancy:  0.9309266284108162\n",
      "Epoch:  7872 | Train Accurancy:  0.9288453236222267 | Validation Accurancy:  0.9309313967823982\n",
      "Epoch:  7873 | Train Accurancy:  0.9288464561104774 | Validation Accurancy:  0.9309359043836594\n",
      "Epoch:  7874 | Train Accurancy:  0.928847573697567 | Validation Accurancy:  0.9309405982494354\n",
      "Epoch:  7875 | Train Accurancy:  0.9288486391305923 | Validation Accurancy:  0.9309454262256622\n",
      "Epoch:  7876 | Train Accurancy:  0.9288497492671013 | Validation Accurancy:  0.9309498965740204\n",
      "Epoch:  7877 | Train Accurancy:  0.9288508892059326 | Validation Accurancy:  0.9309547916054726\n",
      "Epoch:  7878 | Train Accurancy:  0.9288519099354744 | Validation Accurancy:  0.9309595078229904\n",
      "Epoch:  7879 | Train Accurancy:  0.9288530498743057 | Validation Accurancy:  0.9309640601277351\n",
      "Epoch:  7880 | Train Accurancy:  0.9288541451096535 | Validation Accurancy:  0.930968776345253\n",
      "Epoch:  7881 | Train Accurancy:  0.9288552477955818 | Validation Accurancy:  0.930973544716835\n",
      "Epoch:  7882 | Train Accurancy:  0.9288563430309296 | Validation Accurancy:  0.9309779927134514\n",
      "Epoch:  7883 | Train Accurancy:  0.9288574010133743 | Validation Accurancy:  0.9309828281402588\n",
      "Epoch:  7884 | Train Accurancy:  0.9288585558533669 | Validation Accurancy:  0.9309875145554543\n",
      "Epoch:  7885 | Train Accurancy:  0.9288596212863922 | Validation Accurancy:  0.9309920445084572\n",
      "Epoch:  7886 | Train Accurancy:  0.9288607016205788 | Validation Accurancy:  0.9309967830777168\n",
      "Epoch:  7887 | Train Accurancy:  0.9288618117570877 | Validation Accurancy:  0.9310016632080078\n",
      "Epoch:  7888 | Train Accurancy:  0.9288629069924355 | Validation Accurancy:  0.9310060366988182\n",
      "Epoch:  7889 | Train Accurancy:  0.9288640022277832 | Validation Accurancy:  0.931010864675045\n",
      "Epoch:  7890 | Train Accurancy:  0.9288651049137115 | Validation Accurancy:  0.9310156181454659\n",
      "Epoch:  7891 | Train Accurancy:  0.9288662001490593 | Validation Accurancy:  0.9310203716158867\n",
      "Epoch:  7892 | Train Accurancy:  0.928867295384407 | Validation Accurancy:  0.9310247227549553\n",
      "Epoch:  7893 | Train Accurancy:  0.928868405520916 | Validation Accurancy:  0.9310296252369881\n",
      "Epoch:  7894 | Train Accurancy:  0.9288694635033607 | Validation Accurancy:  0.9310343265533447\n",
      "Epoch:  7895 | Train Accurancy:  0.9288705959916115 | Validation Accurancy:  0.9310387894511223\n",
      "Epoch:  7896 | Train Accurancy:  0.9288716688752174 | Validation Accurancy:  0.9310434833168983\n",
      "Epoch:  7897 | Train Accurancy:  0.9288727268576622 | Validation Accurancy:  0.9310482665896416\n",
      "Epoch:  7898 | Train Accurancy:  0.92887382209301 | Validation Accurancy:  0.931052640080452\n",
      "Epoch:  7899 | Train Accurancy:  0.9288749396800995 | Validation Accurancy:  0.9310575649142265\n",
      "Epoch:  7900 | Train Accurancy:  0.9288760125637054 | Validation Accurancy:  0.9310623779892921\n",
      "Epoch:  7901 | Train Accurancy:  0.9288771227002144 | Validation Accurancy:  0.9310667663812637\n",
      "Epoch:  7902 | Train Accurancy:  0.9288781881332397 | Validation Accurancy:  0.9310715347528458\n",
      "Epoch:  7903 | Train Accurancy:  0.9288792833685875 | Validation Accurancy:  0.9310762882232666\n",
      "Epoch:  7904 | Train Accurancy:  0.9288804084062576 | Validation Accurancy:  0.931080773472786\n",
      "Epoch:  7905 | Train Accurancy:  0.9288815259933472 | Validation Accurancy:  0.9310856014490128\n",
      "Epoch:  7906 | Train Accurancy:  0.9288825616240501 | Validation Accurancy:  0.931090272963047\n",
      "Epoch:  7907 | Train Accurancy:  0.9288836494088173 | Validation Accurancy:  0.9310947135090828\n",
      "Epoch:  7908 | Train Accurancy:  0.9288847893476486 | Validation Accurancy:  0.931099459528923\n",
      "Epoch:  7909 | Train Accurancy:  0.9288858249783516 | Validation Accurancy:  0.9311041682958603\n",
      "Epoch:  7910 | Train Accurancy:  0.9288869202136993 | Validation Accurancy:  0.9311086311936378\n",
      "Epoch:  7911 | Train Accurancy:  0.9288879930973053 | Validation Accurancy:  0.9311135113239288\n",
      "Epoch:  7912 | Train Accurancy:  0.9288891106843948 | Validation Accurancy:  0.9311182051897049\n",
      "Epoch:  7913 | Train Accurancy:  0.928890161216259 | Validation Accurancy:  0.9311229735612869\n",
      "Epoch:  7914 | Train Accurancy:  0.9288912564516068 | Validation Accurancy:  0.9311273545026779\n",
      "Epoch:  7915 | Train Accurancy:  0.9288923591375351 | Validation Accurancy:  0.9311320334672928\n",
      "Epoch:  7916 | Train Accurancy:  0.9288934245705605 | Validation Accurancy:  0.9311367645859718\n",
      "Epoch:  7917 | Train Accurancy:  0.9288945645093918 | Validation Accurancy:  0.93114123493433\n",
      "Epoch:  7918 | Train Accurancy:  0.9288956448435783 | Validation Accurancy:  0.9311459735035896\n",
      "Epoch:  7919 | Train Accurancy:  0.9288967102766037 | Validation Accurancy:  0.9311507046222687\n",
      "Epoch:  7920 | Train Accurancy:  0.9288978278636932 | Validation Accurancy:  0.9311551749706268\n",
      "Epoch:  7921 | Train Accurancy:  0.9288989156484604 | Validation Accurancy:  0.9311599582433701\n",
      "Epoch:  7922 | Train Accurancy:  0.9289000108838081 | Validation Accurancy:  0.9311647266149521\n",
      "Epoch:  7923 | Train Accurancy:  0.9289010465145111 | Validation Accurancy:  0.9311691150069237\n",
      "Epoch:  7924 | Train Accurancy:  0.9289021715521812 | Validation Accurancy:  0.9311738163232803\n",
      "Epoch:  7925 | Train Accurancy:  0.9289032593369484 | Validation Accurancy:  0.93117855489254\n",
      "Epoch:  7926 | Train Accurancy:  0.928904302418232 | Validation Accurancy:  0.9311830028891563\n",
      "Epoch:  7927 | Train Accurancy:  0.9289054423570633 | Validation Accurancy:  0.9311878234148026\n",
      "Epoch:  7928 | Train Accurancy:  0.9289064630866051 | Validation Accurancy:  0.9311925396323204\n",
      "Epoch:  7929 | Train Accurancy:  0.9289075955748558 | Validation Accurancy:  0.9311969727277756\n",
      "Epoch:  7930 | Train Accurancy:  0.9289086982607841 | Validation Accurancy:  0.9312016144394875\n",
      "Epoch:  7931 | Train Accurancy:  0.9289097338914871 | Validation Accurancy:  0.9312063679099083\n",
      "Epoch:  7932 | Train Accurancy:  0.9289108216762543 | Validation Accurancy:  0.9312112033367157\n",
      "Epoch:  7933 | Train Accurancy:  0.9289118871092796 | Validation Accurancy:  0.9312154576182365\n",
      "Epoch:  7934 | Train Accurancy:  0.928912989795208 | Validation Accurancy:  0.931220293045044\n",
      "Epoch:  7935 | Train Accurancy:  0.9289140701293945 | Validation Accurancy:  0.931224949657917\n",
      "Epoch:  7936 | Train Accurancy:  0.928915224969387 | Validation Accurancy:  0.9312294647097588\n",
      "Epoch:  7937 | Train Accurancy:  0.9289163053035736 | Validation Accurancy:  0.9312341883778572\n",
      "Epoch:  7938 | Train Accurancy:  0.9289173632860184 | Validation Accurancy:  0.9312389045953751\n",
      "Epoch:  7939 | Train Accurancy:  0.9289184361696243 | Validation Accurancy:  0.9312432929873466\n",
      "Epoch:  7940 | Train Accurancy:  0.9289195165038109 | Validation Accurancy:  0.9312480613589287\n",
      "Epoch:  7941 | Train Accurancy:  0.9289205744862556 | Validation Accurancy:  0.9312527477741241\n",
      "Epoch:  7942 | Train Accurancy:  0.9289216548204422 | Validation Accurancy:  0.9312572479248047\n",
      "Epoch:  7943 | Train Accurancy:  0.9289227947592735 | Validation Accurancy:  0.9312620013952255\n",
      "Epoch:  7944 | Train Accurancy:  0.9289238303899765 | Validation Accurancy:  0.9312666580080986\n",
      "Epoch:  7945 | Train Accurancy:  0.9289249032735825 | Validation Accurancy:  0.9312711581587791\n",
      "Epoch:  7946 | Train Accurancy:  0.9289259910583496 | Validation Accurancy:  0.9312758147716522\n",
      "Epoch:  7947 | Train Accurancy:  0.9289270713925362 | Validation Accurancy:  0.9312805011868477\n",
      "Epoch:  7948 | Train Accurancy:  0.9289281517267227 | Validation Accurancy:  0.9312852248549461\n",
      "Epoch:  7949 | Train Accurancy:  0.9289292544126511 | Validation Accurancy:  0.9312895908951759\n",
      "Epoch:  7950 | Train Accurancy:  0.9289303198456764 | Validation Accurancy:  0.9312943741679192\n",
      "Epoch:  7951 | Train Accurancy:  0.9289313703775406 | Validation Accurancy:  0.931299015879631\n",
      "Epoch:  7952 | Train Accurancy:  0.9289324656128883 | Validation Accurancy:  0.9313033893704414\n",
      "Epoch:  7953 | Train Accurancy:  0.9289335310459137 | Validation Accurancy:  0.9313081428408623\n",
      "Epoch:  7954 | Train Accurancy:  0.9289345741271973 | Validation Accurancy:  0.9313129708170891\n",
      "Epoch:  7955 | Train Accurancy:  0.9289356619119644 | Validation Accurancy:  0.9313172996044159\n",
      "Epoch:  7956 | Train Accurancy:  0.9289367944002151 | Validation Accurancy:  0.9313220307230949\n",
      "Epoch:  7957 | Train Accurancy:  0.9289378747344017 | Validation Accurancy:  0.9313266724348068\n",
      "Epoch:  7958 | Train Accurancy:  0.9289389625191689 | Validation Accurancy:  0.9313314110040665\n",
      "Epoch:  7959 | Train Accurancy:  0.928940013051033 | Validation Accurancy:  0.9313358291983604\n",
      "Epoch:  7960 | Train Accurancy:  0.9289411082863808 | Validation Accurancy:  0.9313405230641365\n",
      "Epoch:  7961 | Train Accurancy:  0.9289421513676643 | Validation Accurancy:  0.931345097720623\n",
      "Epoch:  7962 | Train Accurancy:  0.9289432466030121 | Validation Accurancy:  0.931349515914917\n",
      "Epoch:  7963 | Train Accurancy:  0.928944319486618 | Validation Accurancy:  0.9313543140888214\n",
      "Epoch:  7964 | Train Accurancy:  0.9289453849196434 | Validation Accurancy:  0.9313590079545975\n",
      "Epoch:  7965 | Train Accurancy:  0.9289464801549911 | Validation Accurancy:  0.9313637241721153\n",
      "Epoch:  7966 | Train Accurancy:  0.9289475604891777 | Validation Accurancy:  0.9313681125640869\n",
      "Epoch:  7967 | Train Accurancy:  0.9289485961198807 | Validation Accurancy:  0.9313728138804436\n",
      "Epoch:  7968 | Train Accurancy:  0.9289497062563896 | Validation Accurancy:  0.931377537548542\n",
      "Epoch:  7969 | Train Accurancy:  0.928950771689415 | Validation Accurancy:  0.9313819110393524\n",
      "Epoch:  7970 | Train Accurancy:  0.9289518296718597 | Validation Accurancy:  0.9313866645097733\n",
      "Epoch:  7971 | Train Accurancy:  0.9289529249072075 | Validation Accurancy:  0.9313912838697433\n",
      "Epoch:  7972 | Train Accurancy:  0.9289539903402328 | Validation Accurancy:  0.9313957244157791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7973 | Train Accurancy:  0.9289550706744194 | Validation Accurancy:  0.9314004108309746\n",
      "Epoch:  7974 | Train Accurancy:  0.9289560988545418 | Validation Accurancy:  0.9314051121473312\n",
      "Epoch:  7975 | Train Accurancy:  0.9289572313427925 | Validation Accurancy:  0.9314097538590431\n",
      "Epoch:  7976 | Train Accurancy:  0.9289582669734955 | Validation Accurancy:  0.9314140826463699\n",
      "Epoch:  7977 | Train Accurancy:  0.928959347307682 | Validation Accurancy:  0.9314188286662102\n",
      "Epoch:  7978 | Train Accurancy:  0.9289603978395462 | Validation Accurancy:  0.931423507630825\n",
      "Epoch:  7979 | Train Accurancy:  0.9289615154266357 | Validation Accurancy:  0.9314278587698936\n",
      "Epoch:  7980 | Train Accurancy:  0.9289625510573387 | Validation Accurancy:  0.9314326122403145\n",
      "Epoch:  7981 | Train Accurancy:  0.9289636239409447 | Validation Accurancy:  0.9314373359084129\n",
      "Epoch:  7982 | Train Accurancy:  0.9289647191762924 | Validation Accurancy:  0.931441955268383\n",
      "Epoch:  7983 | Train Accurancy:  0.9289657548069954 | Validation Accurancy:  0.9314462840557098\n",
      "Epoch:  7984 | Train Accurancy:  0.9289668649435043 | Validation Accurancy:  0.9314509853720665\n",
      "Epoch:  7985 | Train Accurancy:  0.9289679378271103 | Validation Accurancy:  0.9314556419849396\n",
      "Epoch:  7986 | Train Accurancy:  0.928969033062458 | Validation Accurancy:  0.9314601123332977\n",
      "Epoch:  7987 | Train Accurancy:  0.9289700537919998 | Validation Accurancy:  0.9314648285508156\n",
      "Epoch:  7988 | Train Accurancy:  0.928971104323864 | Validation Accurancy:  0.9314695224165916\n",
      "Epoch:  7989 | Train Accurancy:  0.9289722219109535 | Validation Accurancy:  0.9314738884568214\n",
      "Epoch:  7990 | Train Accurancy:  0.9289732724428177 | Validation Accurancy:  0.9314786419272423\n",
      "Epoch:  7991 | Train Accurancy:  0.9289743453264236 | Validation Accurancy:  0.9314832985401154\n",
      "Epoch:  7992 | Train Accurancy:  0.9289754405617714 | Validation Accurancy:  0.9314878657460213\n",
      "Epoch:  7993 | Train Accurancy:  0.9289764240384102 | Validation Accurancy:  0.9314922988414764\n",
      "Epoch:  7994 | Train Accurancy:  0.9289775788784027 | Validation Accurancy:  0.9314969554543495\n",
      "Epoch:  7995 | Train Accurancy:  0.9289786368608475 | Validation Accurancy:  0.9315016567707062\n",
      "Epoch:  7996 | Train Accurancy:  0.9289797246456146 | Validation Accurancy:  0.9315060451626778\n",
      "Epoch:  7997 | Train Accurancy:  0.9289807602763176 | Validation Accurancy:  0.9315107017755508\n",
      "Epoch:  7998 | Train Accurancy:  0.9289817735552788 | Validation Accurancy:  0.9315154999494553\n",
      "Epoch:  7999 | Train Accurancy:  0.9289828687906265 | Validation Accurancy:  0.9315201118588448\n",
      "Epoch:  8000 | Train Accurancy:  0.9289839118719101 | Validation Accurancy:  0.931524433195591\n",
      "Epoch:  8001 | Train Accurancy:  0.9289849698543549 | Validation Accurancy:  0.931529089808464\n",
      "Epoch:  8002 | Train Accurancy:  0.9289860725402832 | Validation Accurancy:  0.9315337017178535\n",
      "Epoch:  8003 | Train Accurancy:  0.928987167775631 | Validation Accurancy:  0.9315381050109863\n",
      "Epoch:  8004 | Train Accurancy:  0.9289882481098175 | Validation Accurancy:  0.9315427467226982\n",
      "Epoch:  8005 | Train Accurancy:  0.9289892911911011 | Validation Accurancy:  0.9315474331378937\n",
      "Epoch:  8006 | Train Accurancy:  0.9289903864264488 | Validation Accurancy:  0.9315520450472832\n",
      "Epoch:  8007 | Train Accurancy:  0.9289913922548294 | Validation Accurancy:  0.9315564781427383\n",
      "Epoch:  8008 | Train Accurancy:  0.9289924427866936 | Validation Accurancy:  0.9315611198544502\n",
      "Epoch:  8009 | Train Accurancy:  0.9289935529232025 | Validation Accurancy:  0.9315658584237099\n",
      "Epoch:  8010 | Train Accurancy:  0.9289946034550667 | Validation Accurancy:  0.9315704628825188\n",
      "Epoch:  8011 | Train Accurancy:  0.9289956539869308 | Validation Accurancy:  0.9315747767686844\n",
      "Epoch:  8012 | Train Accurancy:  0.9289967492222786 | Validation Accurancy:  0.9315793961286545\n",
      "Epoch:  8013 | Train Accurancy:  0.9289978072047234 | Validation Accurancy:  0.9315840750932693\n",
      "Epoch:  8014 | Train Accurancy:  0.9289989173412323 | Validation Accurancy:  0.9315884783864021\n",
      "Epoch:  8015 | Train Accurancy:  0.9289999455213547 | Validation Accurancy:  0.9315930977463722\n",
      "Epoch:  8016 | Train Accurancy:  0.9290010035037994 | Validation Accurancy:  0.9315977916121483\n",
      "Epoch:  8017 | Train Accurancy:  0.9290020540356636 | Validation Accurancy:  0.9316023960709572\n",
      "Epoch:  8018 | Train Accurancy:  0.929003119468689 | Validation Accurancy:  0.9316067695617676\n",
      "Epoch:  8019 | Train Accurancy:  0.9290041401982307 | Validation Accurancy:  0.9316114410758018\n",
      "Epoch:  8020 | Train Accurancy:  0.9290052354335785 | Validation Accurancy:  0.9316160827875137\n",
      "Epoch:  8021 | Train Accurancy:  0.9290063232183456 | Validation Accurancy:  0.9316205307841301\n",
      "Epoch:  8022 | Train Accurancy:  0.9290073737502098 | Validation Accurancy:  0.9316252246499062\n",
      "Epoch:  8023 | Train Accurancy:  0.929008461534977 | Validation Accurancy:  0.9316297844052315\n",
      "Epoch:  8024 | Train Accurancy:  0.9290094450116158 | Validation Accurancy:  0.9316344261169434\n",
      "Epoch:  8025 | Train Accurancy:  0.9290105998516083 | Validation Accurancy:  0.9316387325525284\n",
      "Epoch:  8026 | Train Accurancy:  0.9290115982294083 | Validation Accurancy:  0.9316435158252716\n",
      "Epoch:  8027 | Train Accurancy:  0.9290126338601112 | Validation Accurancy:  0.9316481277346611\n",
      "Epoch:  8028 | Train Accurancy:  0.9290137439966202 | Validation Accurancy:  0.9316527545452118\n",
      "Epoch:  8029 | Train Accurancy:  0.9290148019790649 | Validation Accurancy:  0.9316570311784744\n",
      "Epoch:  8030 | Train Accurancy:  0.9290158525109291 | Validation Accurancy:  0.9316617026925087\n",
      "Epoch:  8031 | Train Accurancy:  0.9290168955922127 | Validation Accurancy:  0.9316663444042206\n",
      "Epoch:  8032 | Train Accurancy:  0.9290179833769798 | Validation Accurancy:  0.9316709861159325\n",
      "Epoch:  8033 | Train Accurancy:  0.9290190562605858 | Validation Accurancy:  0.9316752254962921\n",
      "Epoch:  8034 | Train Accurancy:  0.9290200844407082 | Validation Accurancy:  0.9316799640655518\n",
      "Epoch:  8035 | Train Accurancy:  0.9290211871266365 | Validation Accurancy:  0.931684635579586\n",
      "Epoch:  8036 | Train Accurancy:  0.9290222004055977 | Validation Accurancy:  0.931689165532589\n",
      "Epoch:  8037 | Train Accurancy:  0.929023265838623 | Validation Accurancy:  0.9316934421658516\n",
      "Epoch:  8038 | Train Accurancy:  0.9290243312716484 | Validation Accurancy:  0.9316981285810471\n",
      "Epoch:  8039 | Train Accurancy:  0.9290253892540932 | Validation Accurancy:  0.9317027255892754\n",
      "Epoch:  8040 | Train Accurancy:  0.9290264397859573 | Validation Accurancy:  0.9317070618271828\n",
      "Epoch:  8041 | Train Accurancy:  0.9290275052189827 | Validation Accurancy:  0.9317117407917976\n",
      "Epoch:  8042 | Train Accurancy:  0.9290285333991051 | Validation Accurancy:  0.9317164272069931\n",
      "Epoch:  8043 | Train Accurancy:  0.9290296211838722 | Validation Accurancy:  0.9317211285233498\n",
      "Epoch:  8044 | Train Accurancy:  0.9290306940674782 | Validation Accurancy:  0.9317253306508064\n",
      "Epoch:  8045 | Train Accurancy:  0.9290317222476006 | Validation Accurancy:  0.9317300617694855\n",
      "Epoch:  8046 | Train Accurancy:  0.9290328249335289 | Validation Accurancy:  0.9317346438765526\n",
      "Epoch:  8047 | Train Accurancy:  0.9290338978171349 | Validation Accurancy:  0.9317389950156212\n",
      "Epoch:  8048 | Train Accurancy:  0.9290349334478378 | Validation Accurancy:  0.9317436665296555\n",
      "Epoch:  8049 | Train Accurancy:  0.929035946726799 | Validation Accurancy:  0.931748278439045\n",
      "Epoch:  8050 | Train Accurancy:  0.9290370047092438 | Validation Accurancy:  0.9317528754472733\n",
      "Epoch:  8051 | Train Accurancy:  0.9290380850434303 | Validation Accurancy:  0.9317572265863419\n",
      "Epoch:  8052 | Train Accurancy:  0.9290391504764557 | Validation Accurancy:  0.9317618384957314\n",
      "Epoch:  8053 | Train Accurancy:  0.9290402084589005 | Validation Accurancy:  0.931766465306282\n",
      "Epoch:  8054 | Train Accurancy:  0.9290412589907646 | Validation Accurancy:  0.9317710846662521\n",
      "Epoch:  8055 | Train Accurancy:  0.9290422946214676 | Validation Accurancy:  0.9317755028605461\n",
      "Epoch:  8056 | Train Accurancy:  0.9290433302521706 | Validation Accurancy:  0.9317800998687744\n",
      "Epoch:  8057 | Train Accurancy:  0.9290443882346153 | Validation Accurancy:  0.9317846968770027\n",
      "Epoch:  8058 | Train Accurancy:  0.9290454462170601 | Validation Accurancy:  0.9317889362573624\n",
      "Epoch:  8059 | Train Accurancy:  0.9290465041995049 | Validation Accurancy:  0.9317937046289444\n",
      "Epoch:  8060 | Train Accurancy:  0.929047554731369 | Validation Accurancy:  0.9317982196807861\n",
      "Epoch:  8061 | Train Accurancy:  0.929048590362072 | Validation Accurancy:  0.9318028762936592\n",
      "Epoch:  8062 | Train Accurancy:  0.9290496781468391 | Validation Accurancy:  0.9318071082234383\n",
      "Epoch:  8063 | Train Accurancy:  0.9290506914258003 | Validation Accurancy:  0.9318117424845695\n",
      "Epoch:  8064 | Train Accurancy:  0.9290517568588257 | Validation Accurancy:  0.9318163394927979\n",
      "Epoch:  8065 | Train Accurancy:  0.9290528148412704 | Validation Accurancy:  0.9318210780620575\n",
      "Epoch:  8066 | Train Accurancy:  0.9290538802742958 | Validation Accurancy:  0.9318256378173828\n",
      "Epoch:  8067 | Train Accurancy:  0.929054893553257 | Validation Accurancy:  0.9318298175930977\n",
      "Epoch:  8068 | Train Accurancy:  0.929055966436863 | Validation Accurancy:  0.9318344593048096\n",
      "Epoch:  8069 | Train Accurancy:  0.9290570467710495 | Validation Accurancy:  0.9318391159176826\n",
      "Epoch:  8070 | Train Accurancy:  0.9290580376982689 | Validation Accurancy:  0.9318437427282333\n",
      "Epoch:  8071 | Train Accurancy:  0.9290591180324554 | Validation Accurancy:  0.9318480044603348\n",
      "Epoch:  8072 | Train Accurancy:  0.9290601462125778 | Validation Accurancy:  0.9318525493144989\n",
      "Epoch:  8073 | Train Accurancy:  0.9290612190961838 | Validation Accurancy:  0.9318571537733078\n",
      "Epoch:  8074 | Train Accurancy:  0.9290622621774673 | Validation Accurancy:  0.9318617507815361\n",
      "Epoch:  8075 | Train Accurancy:  0.9290633276104927 | Validation Accurancy:  0.9318660423159599\n",
      "Epoch:  8076 | Train Accurancy:  0.9290644004940987 | Validation Accurancy:  0.9318706318736076\n",
      "Epoch:  8077 | Train Accurancy:  0.929065428674221 | Validation Accurancy:  0.9318753108382225\n",
      "Epoch:  8078 | Train Accurancy:  0.929066464304924 | Validation Accurancy:  0.9318799301981926\n",
      "Epoch:  8079 | Train Accurancy:  0.9290675446391106 | Validation Accurancy:  0.9318842589855194\n",
      "Epoch:  8080 | Train Accurancy:  0.9290685951709747 | Validation Accurancy:  0.9318888038396835\n",
      "Epoch:  8081 | Train Accurancy:  0.9290696084499359 | Validation Accurancy:  0.9318934306502342\n",
      "Epoch:  8082 | Train Accurancy:  0.9290706142783165 | Validation Accurancy:  0.931897908449173\n",
      "Epoch:  8083 | Train Accurancy:  0.9290716871619225 | Validation Accurancy:  0.931902326643467\n",
      "Epoch:  8084 | Train Accurancy:  0.9290727376937866 | Validation Accurancy:  0.9319069236516953\n",
      "Epoch:  8085 | Train Accurancy:  0.929073765873909 | Validation Accurancy:  0.931911438703537\n",
      "Epoch:  8086 | Train Accurancy:  0.9290748462080956 | Validation Accurancy:  0.9319159537553787\n",
      "Epoch:  8087 | Train Accurancy:  0.9290758818387985 | Validation Accurancy:  0.9319202750921249\n",
      "Epoch:  8088 | Train Accurancy:  0.9290769100189209 | Validation Accurancy:  0.9319250136613846\n",
      "Epoch:  8089 | Train Accurancy:  0.9290779754519463 | Validation Accurancy:  0.9319295212626457\n",
      "Epoch:  8090 | Train Accurancy:  0.9290790259838104 | Validation Accurancy:  0.9319341033697128\n",
      "Epoch:  8091 | Train Accurancy:  0.9290800541639328 | Validation Accurancy:  0.9319384098052979\n",
      "Epoch:  8092 | Train Accurancy:  0.9290811270475388 | Validation Accurancy:  0.9319430366158485\n",
      "Epoch:  8093 | Train Accurancy:  0.9290821775794029 | Validation Accurancy:  0.931947611272335\n",
      "Epoch:  8094 | Train Accurancy:  0.9290832057595253 | Validation Accurancy:  0.9319521710276604\n",
      "Epoch:  8095 | Train Accurancy:  0.9290842339396477 | Validation Accurancy:  0.9319564327597618\n",
      "Epoch:  8096 | Train Accurancy:  0.9290853217244148 | Validation Accurancy:  0.9319610297679901\n",
      "Epoch:  8097 | Train Accurancy:  0.9290863201022148 | Validation Accurancy:  0.931965634226799\n",
      "Epoch:  8098 | Train Accurancy:  0.9290873929858208 | Validation Accurancy:  0.9319702163338661\n",
      "Epoch:  8099 | Train Accurancy:  0.9290884733200073 | Validation Accurancy:  0.9319745823740959\n",
      "Epoch:  8100 | Train Accurancy:  0.9290894493460655 | Validation Accurancy:  0.9319791942834854\n",
      "Epoch:  8101 | Train Accurancy:  0.9290905296802521 | Validation Accurancy:  0.931983694434166\n",
      "Epoch:  8102 | Train Accurancy:  0.9290916100144386 | Validation Accurancy:  0.9319883361458778\n",
      "Epoch:  8103 | Train Accurancy:  0.9290926530957222 | Validation Accurancy:  0.9319925978779793\n",
      "Epoch:  8104 | Train Accurancy:  0.929093673825264 | Validation Accurancy:  0.931997187435627\n",
      "Epoch:  8105 | Train Accurancy:  0.9290947541594505 | Validation Accurancy:  0.9320017471909523\n",
      "Epoch:  8106 | Train Accurancy:  0.9290957450866699 | Validation Accurancy:  0.9320063889026642\n",
      "Epoch:  8107 | Train Accurancy:  0.9290967807173729 | Validation Accurancy:  0.9320105835795403\n",
      "Epoch:  8108 | Train Accurancy:  0.9290977790951729 | Validation Accurancy:  0.9320151507854462\n",
      "Epoch:  8109 | Train Accurancy:  0.9290988594293594 | Validation Accurancy:  0.9320197105407715\n",
      "Epoch:  8110 | Train Accurancy:  0.9290998727083206 | Validation Accurancy:  0.932024285197258\n",
      "Epoch:  8111 | Train Accurancy:  0.9291009679436684 | Validation Accurancy:  0.932028517127037\n",
      "Epoch:  8112 | Train Accurancy:  0.9291020259261131 | Validation Accurancy:  0.9320331588387489\n",
      "Epoch:  8113 | Train Accurancy:  0.9291030243039131 | Validation Accurancy:  0.9320377334952354\n",
      "Epoch:  8114 | Train Accurancy:  0.9291040673851967 | Validation Accurancy:  0.9320422187447548\n",
      "Epoch:  8115 | Train Accurancy:  0.9291050806641579 | Validation Accurancy:  0.9320464953780174\n",
      "Epoch:  8116 | Train Accurancy:  0.9291061535477638 | Validation Accurancy:  0.9320511817932129\n",
      "Epoch:  8117 | Train Accurancy:  0.9291071891784668 | Validation Accurancy:  0.9320557564496994\n",
      "Epoch:  8118 | Train Accurancy:  0.9291082248091698 | Validation Accurancy:  0.9320603385567665\n",
      "Epoch:  8119 | Train Accurancy:  0.9291092604398727 | Validation Accurancy:  0.9320648014545441\n",
      "Epoch:  8120 | Train Accurancy:  0.9291102886199951 | Validation Accurancy:  0.9320689961314201\n",
      "Epoch:  8121 | Train Accurancy:  0.9291113615036011 | Validation Accurancy:  0.9320736601948738\n",
      "Epoch:  8122 | Train Accurancy:  0.9291123598814011 | Validation Accurancy:  0.9320782348513603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8123 | Train Accurancy:  0.9291134104132652 | Validation Accurancy:  0.9320827946066856\n",
      "Epoch:  8124 | Train Accurancy:  0.9291144832968712 | Validation Accurancy:  0.9320870116353035\n",
      "Epoch:  8125 | Train Accurancy:  0.92911546677351 | Validation Accurancy:  0.9320916011929512\n",
      "Epoch:  8126 | Train Accurancy:  0.9291165545582771 | Validation Accurancy:  0.9320961311459541\n",
      "Epoch:  8127 | Train Accurancy:  0.9291175976395607 | Validation Accurancy:  0.9321006163954735\n",
      "Epoch:  8128 | Train Accurancy:  0.9291186258196831 | Validation Accurancy:  0.9321052208542824\n",
      "Epoch:  8129 | Train Accurancy:  0.9291196018457413 | Validation Accurancy:  0.932109497487545\n",
      "Epoch:  8130 | Train Accurancy:  0.9291206672787666 | Validation Accurancy:  0.9321140423417091\n",
      "Epoch:  8131 | Train Accurancy:  0.9291216656565666 | Validation Accurancy:  0.9321185722947121\n",
      "Epoch:  8132 | Train Accurancy:  0.9291227385401726 | Validation Accurancy:  0.932123102247715\n",
      "Epoch:  8133 | Train Accurancy:  0.9291237890720367 | Validation Accurancy:  0.9321276322007179\n",
      "Epoch:  8134 | Train Accurancy:  0.9291248247027397 | Validation Accurancy:  0.9321319237351418\n",
      "Epoch:  8135 | Train Accurancy:  0.9291258677840233 | Validation Accurancy:  0.9321364909410477\n",
      "Epoch:  8136 | Train Accurancy:  0.9291269108653069 | Validation Accurancy:  0.9321409985423088\n",
      "Epoch:  8137 | Train Accurancy:  0.929127961397171 | Validation Accurancy:  0.9321454986929893\n",
      "Epoch:  8138 | Train Accurancy:  0.9291289672255516 | Validation Accurancy:  0.9321497455239296\n",
      "Epoch:  8139 | Train Accurancy:  0.9291300103068352 | Validation Accurancy:  0.9321543499827385\n",
      "Epoch:  8140 | Train Accurancy:  0.9291310384869576 | Validation Accurancy:  0.932158961892128\n",
      "Epoch:  8141 | Train Accurancy:  0.9291321039199829 | Validation Accurancy:  0.9321634471416473\n",
      "Epoch:  8142 | Train Accurancy:  0.9291331544518471 | Validation Accurancy:  0.9321678802371025\n",
      "Epoch:  8143 | Train Accurancy:  0.9291341528296471 | Validation Accurancy:  0.9321721568703651\n",
      "Epoch:  8144 | Train Accurancy:  0.92913518846035 | Validation Accurancy:  0.9321767464280128\n",
      "Epoch:  8145 | Train Accurancy:  0.929136224091053 | Validation Accurancy:  0.9321813732385635\n",
      "Epoch:  8146 | Train Accurancy:  0.9291372150182724 | Validation Accurancy:  0.9321859180927277\n",
      "Epoch:  8147 | Train Accurancy:  0.9291383102536201 | Validation Accurancy:  0.9321901351213455\n",
      "Epoch:  8148 | Train Accurancy:  0.9291392937302589 | Validation Accurancy:  0.9321947395801544\n",
      "Epoch:  8149 | Train Accurancy:  0.9291403293609619 | Validation Accurancy:  0.9321991950273514\n",
      "Epoch:  8150 | Train Accurancy:  0.9291413947939873 | Validation Accurancy:  0.9322037398815155\n",
      "Epoch:  8151 | Train Accurancy:  0.9291424229741096 | Validation Accurancy:  0.9322080165147781\n",
      "Epoch:  8152 | Train Accurancy:  0.9291434064507484 | Validation Accurancy:  0.9322126731276512\n",
      "Epoch:  8153 | Train Accurancy:  0.9291444569826126 | Validation Accurancy:  0.9322172179818153\n",
      "Epoch:  8154 | Train Accurancy:  0.929145522415638 | Validation Accurancy:  0.9322217330336571\n",
      "Epoch:  8155 | Train Accurancy:  0.9291465431451797 | Validation Accurancy:  0.9322259724140167\n",
      "Epoch:  8156 | Train Accurancy:  0.9291476085782051 | Validation Accurancy:  0.9322305172681808\n",
      "Epoch:  8157 | Train Accurancy:  0.9291486367583275 | Validation Accurancy:  0.9322351142764091\n",
      "Epoch:  8158 | Train Accurancy:  0.9291496276855469 | Validation Accurancy:  0.9322395771741867\n",
      "Epoch:  8159 | Train Accurancy:  0.929150678217411 | Validation Accurancy:  0.9322440326213837\n",
      "Epoch:  8160 | Train Accurancy:  0.929151676595211 | Validation Accurancy:  0.9322482272982597\n",
      "Epoch:  8161 | Train Accurancy:  0.929152712225914 | Validation Accurancy:  0.932252787053585\n",
      "Epoch:  8162 | Train Accurancy:  0.9291537702083588 | Validation Accurancy:  0.9322573319077492\n",
      "Epoch:  8163 | Train Accurancy:  0.9291547611355782 | Validation Accurancy:  0.9322619289159775\n",
      "Epoch:  8164 | Train Accurancy:  0.9291557818651199 | Validation Accurancy:  0.9322661384940147\n",
      "Epoch:  8165 | Train Accurancy:  0.9291568845510483 | Validation Accurancy:  0.9322706982493401\n",
      "Epoch:  8166 | Train Accurancy:  0.9291578456759453 | Validation Accurancy:  0.9322751685976982\n",
      "Epoch:  8167 | Train Accurancy:  0.9291588589549065 | Validation Accurancy:  0.9322797283530235\n",
      "Epoch:  8168 | Train Accurancy:  0.9291599094867706 | Validation Accurancy:  0.9322841465473175\n",
      "Epoch:  8169 | Train Accurancy:  0.9291609525680542 | Validation Accurancy:  0.9322884753346443\n",
      "Epoch:  8170 | Train Accurancy:  0.9291619956493378 | Validation Accurancy:  0.9322929531335831\n",
      "Epoch:  8171 | Train Accurancy:  0.9291629940271378 | Validation Accurancy:  0.9322975799441338\n",
      "Epoch:  8172 | Train Accurancy:  0.9291640222072601 | Validation Accurancy:  0.9323019832372665\n",
      "Epoch:  8173 | Train Accurancy:  0.9291650578379631 | Validation Accurancy:  0.9323065131902695\n",
      "Epoch:  8174 | Train Accurancy:  0.9291660711169243 | Validation Accurancy:  0.9323107525706291\n",
      "Epoch:  8175 | Train Accurancy:  0.9291670843958855 | Validation Accurancy:  0.932315282523632\n",
      "Epoch:  8176 | Train Accurancy:  0.9291681423783302 | Validation Accurancy:  0.9323197826743126\n",
      "Epoch:  8177 | Train Accurancy:  0.9291691705584526 | Validation Accurancy:  0.9323243126273155\n",
      "Epoch:  8178 | Train Accurancy:  0.929170235991478 | Validation Accurancy:  0.9323287457227707\n",
      "Epoch:  8179 | Train Accurancy:  0.9291712418198586 | Validation Accurancy:  0.9323329105973244\n",
      "Epoch:  8180 | Train Accurancy:  0.9291722327470779 | Validation Accurancy:  0.9323375895619392\n",
      "Epoch:  8181 | Train Accurancy:  0.9291732832789421 | Validation Accurancy:  0.9323420971632004\n",
      "Epoch:  8182 | Train Accurancy:  0.9291742518544197 | Validation Accurancy:  0.9323465526103973\n",
      "Epoch:  8183 | Train Accurancy:  0.9291753470897675 | Validation Accurancy:  0.9323509857058525\n",
      "Epoch:  8184 | Train Accurancy:  0.9291763305664062 | Validation Accurancy:  0.9323551952838898\n",
      "Epoch:  8185 | Train Accurancy:  0.9291773661971092 | Validation Accurancy:  0.9323597773909569\n",
      "Epoch:  8186 | Train Accurancy:  0.9291783794760704 | Validation Accurancy:  0.9323642924427986\n",
      "Epoch:  8187 | Train Accurancy:  0.9291794374585152 | Validation Accurancy:  0.9323687106370926\n",
      "Epoch:  8188 | Train Accurancy:  0.929180458188057 | Validation Accurancy:  0.9323731735348701\n",
      "Epoch:  8189 | Train Accurancy:  0.9291814863681793 | Validation Accurancy:  0.9323775619268417\n",
      "Epoch:  8190 | Train Accurancy:  0.9291825145483017 | Validation Accurancy:  0.9323818683624268\n",
      "Epoch:  8191 | Train Accurancy:  0.9291835054755211 | Validation Accurancy:  0.9323864802718163\n",
      "Epoch:  8192 | Train Accurancy:  0.9291845709085464 | Validation Accurancy:  0.9323909729719162\n",
      "Epoch:  8193 | Train Accurancy:  0.9291854947805405 | Validation Accurancy:  0.9323953911662102\n",
      "Epoch:  8194 | Train Accurancy:  0.9291865825653076 | Validation Accurancy:  0.9323999211192131\n",
      "Epoch:  8195 | Train Accurancy:  0.9291875809431076 | Validation Accurancy:  0.9324041083455086\n",
      "Epoch:  8196 | Train Accurancy:  0.9291886240243912 | Validation Accurancy:  0.9324085712432861\n",
      "Epoch:  8197 | Train Accurancy:  0.9291896745562553 | Validation Accurancy:  0.9324130862951279\n",
      "Epoch:  8198 | Train Accurancy:  0.9291906878352165 | Validation Accurancy:  0.9324176460504532\n",
      "Epoch:  8199 | Train Accurancy:  0.9291916936635971 | Validation Accurancy:  0.9324220344424248\n",
      "Epoch:  8200 | Train Accurancy:  0.9291927143931389 | Validation Accurancy:  0.9324262961745262\n",
      "Epoch:  8201 | Train Accurancy:  0.9291937425732613 | Validation Accurancy:  0.9324308410286903\n",
      "Epoch:  8202 | Train Accurancy:  0.9291947707533836 | Validation Accurancy:  0.9324352741241455\n",
      "Epoch:  8203 | Train Accurancy:  0.929195836186409 | Validation Accurancy:  0.9324398338794708\n",
      "Epoch:  8204 | Train Accurancy:  0.929196834564209 | Validation Accurancy:  0.932444304227829\n",
      "Epoch:  8205 | Train Accurancy:  0.9291978552937508 | Validation Accurancy:  0.9324484691023827\n",
      "Epoch:  8206 | Train Accurancy:  0.9291988611221313 | Validation Accurancy:  0.9324529990553856\n",
      "Epoch:  8207 | Train Accurancy:  0.9291998893022537 | Validation Accurancy:  0.9324575141072273\n",
      "Epoch:  8208 | Train Accurancy:  0.9292008578777313 | Validation Accurancy:  0.9324619472026825\n",
      "Epoch:  8209 | Train Accurancy:  0.9292019233107567 | Validation Accurancy:  0.93246641010046\n",
      "Epoch:  8210 | Train Accurancy:  0.9292029514908791 | Validation Accurancy:  0.9324705898761749\n",
      "Epoch:  8211 | Train Accurancy:  0.9292039424180984 | Validation Accurancy:  0.932475134730339\n",
      "Epoch:  8212 | Train Accurancy:  0.9292049705982208 | Validation Accurancy:  0.9324796348810196\n",
      "Epoch:  8213 | Train Accurancy:  0.9292059764266014 | Validation Accurancy:  0.9324840232729912\n",
      "Epoch:  8214 | Train Accurancy:  0.9292069748044014 | Validation Accurancy:  0.932488203048706\n",
      "Epoch:  8215 | Train Accurancy:  0.929208017885685 | Validation Accurancy:  0.9324926882982254\n",
      "Epoch:  8216 | Train Accurancy:  0.9292090311646461 | Validation Accurancy:  0.9324972629547119\n",
      "Epoch:  8217 | Train Accurancy:  0.9292100518941879 | Validation Accurancy:  0.9325017258524895\n",
      "Epoch:  8218 | Train Accurancy:  0.9292110875248909 | Validation Accurancy:  0.93250622600317\n",
      "Epoch:  8219 | Train Accurancy:  0.9292121082544327 | Validation Accurancy:  0.9325104579329491\n",
      "Epoch:  8220 | Train Accurancy:  0.9292130768299103 | Validation Accurancy:  0.932514876127243\n",
      "Epoch:  8221 | Train Accurancy:  0.9292140975594521 | Validation Accurancy:  0.9325193911790848\n",
      "Epoch:  8222 | Train Accurancy:  0.9292151257395744 | Validation Accurancy:  0.9325239360332489\n",
      "Epoch:  8223 | Train Accurancy:  0.9292161911725998 | Validation Accurancy:  0.9325283393263817\n",
      "Epoch:  8224 | Train Accurancy:  0.9292171746492386 | Validation Accurancy:  0.9325327724218369\n",
      "Epoch:  8225 | Train Accurancy:  0.929218165576458 | Validation Accurancy:  0.9325368851423264\n",
      "Epoch:  8226 | Train Accurancy:  0.9292191714048386 | Validation Accurancy:  0.9325414672493935\n",
      "Epoch:  8227 | Train Accurancy:  0.9292202442884445 | Validation Accurancy:  0.9325459152460098\n",
      "Epoch:  8228 | Train Accurancy:  0.9292212501168251 | Validation Accurancy:  0.9325504004955292\n",
      "Epoch:  8229 | Train Accurancy:  0.9292222484946251 | Validation Accurancy:  0.9325549453496933\n",
      "Epoch:  8230 | Train Accurancy:  0.9292232766747475 | Validation Accurancy:  0.9325591251254082\n",
      "Epoch:  8231 | Train Accurancy:  0.9292242899537086 | Validation Accurancy:  0.9325635731220245\n",
      "Epoch:  8232 | Train Accurancy:  0.9292252883315086 | Validation Accurancy:  0.9325679913163185\n",
      "Epoch:  8233 | Train Accurancy:  0.929226279258728 | Validation Accurancy:  0.9325724616646767\n",
      "Epoch:  8234 | Train Accurancy:  0.9292273074388504 | Validation Accurancy:  0.9325768798589706\n",
      "Epoch:  8235 | Train Accurancy:  0.9292283356189728 | Validation Accurancy:  0.9325813427567482\n",
      "Epoch:  8236 | Train Accurancy:  0.9292293339967728 | Validation Accurancy:  0.9325854629278183\n",
      "Epoch:  8237 | Train Accurancy:  0.9292303994297981 | Validation Accurancy:  0.9325898960232735\n",
      "Epoch:  8238 | Train Accurancy:  0.9292313829064369 | Validation Accurancy:  0.93259447067976\n",
      "Epoch:  8239 | Train Accurancy:  0.9292323887348175 | Validation Accurancy:  0.9325989112257957\n",
      "Epoch:  8240 | Train Accurancy:  0.9292334020137787 | Validation Accurancy:  0.9326033741235733\n",
      "Epoch:  8241 | Train Accurancy:  0.9292344227433205 | Validation Accurancy:  0.9326075538992882\n",
      "Epoch:  8242 | Train Accurancy:  0.9292354211211205 | Validation Accurancy:  0.9326119720935822\n",
      "Epoch:  8243 | Train Accurancy:  0.929236389696598 | Validation Accurancy:  0.9326164871454239\n",
      "Epoch:  8244 | Train Accurancy:  0.929237462580204 | Validation Accurancy:  0.932620957493782\n",
      "Epoch:  8245 | Train Accurancy:  0.9292384758591652 | Validation Accurancy:  0.9326253235340118\n",
      "Epoch:  8246 | Train Accurancy:  0.9292394444346428 | Validation Accurancy:  0.932629756629467\n",
      "Epoch:  8247 | Train Accurancy:  0.9292404651641846 | Validation Accurancy:  0.9326339215040207\n",
      "Epoch:  8248 | Train Accurancy:  0.9292414709925652 | Validation Accurancy:  0.9326384738087654\n",
      "Epoch:  8249 | Train Accurancy:  0.9292424917221069 | Validation Accurancy:  0.9326428547501564\n",
      "Epoch:  8250 | Train Accurancy:  0.9292435720562935 | Validation Accurancy:  0.9326473101973534\n",
      "Epoch:  8251 | Train Accurancy:  0.9292445555329323 | Validation Accurancy:  0.9326517879962921\n",
      "Epoch:  8252 | Train Accurancy:  0.9292455762624741 | Validation Accurancy:  0.9326561614871025\n",
      "Epoch:  8253 | Train Accurancy:  0.9292465448379517 | Validation Accurancy:  0.9326603561639786\n",
      "Epoch:  8254 | Train Accurancy:  0.9292475804686546 | Validation Accurancy:  0.9326648712158203\n",
      "Epoch:  8255 | Train Accurancy:  0.9292485788464546 | Validation Accurancy:  0.9326693043112755\n",
      "Epoch:  8256 | Train Accurancy:  0.9292495548725128 | Validation Accurancy:  0.9326736778020859\n",
      "Epoch:  8257 | Train Accurancy:  0.9292505905032158 | Validation Accurancy:  0.93267822265625\n",
      "Epoch:  8258 | Train Accurancy:  0.92925164103508 | Validation Accurancy:  0.9326825961470604\n",
      "Epoch:  8259 | Train Accurancy:  0.9292526245117188 | Validation Accurancy:  0.9326870292425156\n",
      "Epoch:  8260 | Train Accurancy:  0.9292535856366158 | Validation Accurancy:  0.9326912239193916\n",
      "Epoch:  8261 | Train Accurancy:  0.9292546138167381 | Validation Accurancy:  0.9326956421136856\n",
      "Epoch:  8262 | Train Accurancy:  0.9292556047439575 | Validation Accurancy:  0.932700015604496\n",
      "Epoch:  8263 | Train Accurancy:  0.9292566403746605 | Validation Accurancy:  0.9327045306563377\n",
      "Epoch:  8264 | Train Accurancy:  0.9292576536536217 | Validation Accurancy:  0.9327089339494705\n",
      "Epoch:  8265 | Train Accurancy:  0.9292586222290993 | Validation Accurancy:  0.9327130615711212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8266 | Train Accurancy:  0.9292596504092216 | Validation Accurancy:  0.9327175617218018\n",
      "Epoch:  8267 | Train Accurancy:  0.9292606562376022 | Validation Accurancy:  0.9327219650149345\n",
      "Epoch:  8268 | Train Accurancy:  0.9292616322636604 | Validation Accurancy:  0.9327265098690987\n",
      "Epoch:  8269 | Train Accurancy:  0.9292627200484276 | Validation Accurancy:  0.9327308982610703\n",
      "Epoch:  8270 | Train Accurancy:  0.929263673722744 | Validation Accurancy:  0.932735301554203\n",
      "Epoch:  8271 | Train Accurancy:  0.9292646571993828 | Validation Accurancy:  0.9327393844723701\n",
      "Epoch:  8272 | Train Accurancy:  0.9292657151818275 | Validation Accurancy:  0.9327439144253731\n",
      "Epoch:  8273 | Train Accurancy:  0.9292666390538216 | Validation Accurancy:  0.9327483028173447\n",
      "Epoch:  8274 | Train Accurancy:  0.9292677417397499 | Validation Accurancy:  0.932752750813961\n",
      "Epoch:  8275 | Train Accurancy:  0.9292686879634857 | Validation Accurancy:  0.9327571392059326\n",
      "Epoch:  8276 | Train Accurancy:  0.9292697235941887 | Validation Accurancy:  0.9327616393566132\n",
      "Epoch:  8277 | Train Accurancy:  0.9292707294225693 | Validation Accurancy:  0.9327657073736191\n",
      "Epoch:  8278 | Train Accurancy:  0.9292717278003693 | Validation Accurancy:  0.9327702224254608\n",
      "Epoch:  8279 | Train Accurancy:  0.9292726889252663 | Validation Accurancy:  0.9327746108174324\n",
      "Epoch:  8280 | Train Accurancy:  0.9292737618088722 | Validation Accurancy:  0.9327789917588234\n",
      "Epoch:  8281 | Train Accurancy:  0.9292747676372528 | Validation Accurancy:  0.9327834621071815\n",
      "Epoch:  8282 | Train Accurancy:  0.929275818169117 | Validation Accurancy:  0.9327878803014755\n",
      "Epoch:  8283 | Train Accurancy:  0.9292767494916916 | Validation Accurancy:  0.932792030274868\n",
      "Epoch:  8284 | Train Accurancy:  0.9292777702212334 | Validation Accurancy:  0.9327964782714844\n",
      "Epoch:  8285 | Train Accurancy:  0.9292787462472916 | Validation Accurancy:  0.9328008964657784\n",
      "Epoch:  8286 | Train Accurancy:  0.929279699921608 | Validation Accurancy:  0.9328053668141365\n",
      "Epoch:  8287 | Train Accurancy:  0.9292807802557945 | Validation Accurancy:  0.9328097477555275\n",
      "Epoch:  8288 | Train Accurancy:  0.9292817562818527 | Validation Accurancy:  0.9328141510486603\n",
      "Epoch:  8289 | Train Accurancy:  0.9292827770113945 | Validation Accurancy:  0.9328183457255363\n",
      "Epoch:  8290 | Train Accurancy:  0.9292837753891945 | Validation Accurancy:  0.932822659611702\n",
      "Epoch:  8291 | Train Accurancy:  0.9292847663164139 | Validation Accurancy:  0.9328271076083183\n",
      "Epoch:  8292 | Train Accurancy:  0.9292857423424721 | Validation Accurancy:  0.9328314810991287\n",
      "Epoch:  8293 | Train Accurancy:  0.9292867928743362 | Validation Accurancy:  0.9328359439969063\n",
      "Epoch:  8294 | Train Accurancy:  0.929287776350975 | Validation Accurancy:  0.9328403770923615\n",
      "Epoch:  8295 | Train Accurancy:  0.9292887598276138 | Validation Accurancy:  0.9328445121645927\n",
      "Epoch:  8296 | Train Accurancy:  0.9292897954583168 | Validation Accurancy:  0.9328489005565643\n",
      "Epoch:  8297 | Train Accurancy:  0.9292907565832138 | Validation Accurancy:  0.9328532889485359\n",
      "Epoch:  8298 | Train Accurancy:  0.9292917922139168 | Validation Accurancy:  0.9328576847910881\n",
      "Epoch:  8299 | Train Accurancy:  0.9292927533388138 | Validation Accurancy:  0.9328621402382851\n",
      "Epoch:  8300 | Train Accurancy:  0.9292937740683556 | Validation Accurancy:  0.9328665882349014\n",
      "Epoch:  8301 | Train Accurancy:  0.929294727742672 | Validation Accurancy:  0.9328709319233894\n",
      "Epoch:  8302 | Train Accurancy:  0.9292957633733749 | Validation Accurancy:  0.9328750297427177\n",
      "Epoch:  8303 | Train Accurancy:  0.9292968139052391 | Validation Accurancy:  0.9328794181346893\n",
      "Epoch:  8304 | Train Accurancy:  0.9292977899312973 | Validation Accurancy:  0.9328838661313057\n",
      "Epoch:  8305 | Train Accurancy:  0.9292987883090973 | Validation Accurancy:  0.9328882992267609\n",
      "Epoch:  8306 | Train Accurancy:  0.9292997792363167 | Validation Accurancy:  0.9328927025198936\n",
      "Epoch:  8307 | Train Accurancy:  0.9293007180094719 | Validation Accurancy:  0.9328970462083817\n",
      "Epoch:  8308 | Train Accurancy:  0.9293017685413361 | Validation Accurancy:  0.9329014271497726\n",
      "Epoch:  8309 | Train Accurancy:  0.9293027892708778 | Validation Accurancy:  0.9329058453440666\n",
      "Epoch:  8310 | Train Accurancy:  0.9293037503957748 | Validation Accurancy:  0.9329099655151367\n",
      "Epoch:  8311 | Train Accurancy:  0.9293047562241554 | Validation Accurancy:  0.9329143986105919\n",
      "Epoch:  8312 | Train Accurancy:  0.9293057769536972 | Validation Accurancy:  0.93291886895895\n",
      "Epoch:  8313 | Train Accurancy:  0.9293067455291748 | Validation Accurancy:  0.9329232349991798\n",
      "Epoch:  8314 | Train Accurancy:  0.9293077737092972 | Validation Accurancy:  0.9329276382923126\n",
      "Epoch:  8315 | Train Accurancy:  0.9293087348341942 | Validation Accurancy:  0.9329319670796394\n",
      "Epoch:  8316 | Train Accurancy:  0.9293097406625748 | Validation Accurancy:  0.9329363331198692\n",
      "Epoch:  8317 | Train Accurancy:  0.9293107613921165 | Validation Accurancy:  0.9329404532909393\n",
      "Epoch:  8318 | Train Accurancy:  0.9293117448687553 | Validation Accurancy:  0.9329448863863945\n",
      "Epoch:  8319 | Train Accurancy:  0.9293127283453941 | Validation Accurancy:  0.9329493045806885\n",
      "Epoch:  8320 | Train Accurancy:  0.9293137267231941 | Validation Accurancy:  0.9329536929726601\n",
      "Epoch:  8321 | Train Accurancy:  0.9293147251009941 | Validation Accurancy:  0.9329581260681152\n",
      "Epoch:  8322 | Train Accurancy:  0.9293156936764717 | Validation Accurancy:  0.9329624474048615\n",
      "Epoch:  8323 | Train Accurancy:  0.9293166771531105 | Validation Accurancy:  0.9329667389392853\n",
      "Epoch:  8324 | Train Accurancy:  0.9293177053332329 | Validation Accurancy:  0.9329709708690643\n",
      "Epoch:  8325 | Train Accurancy:  0.929318755865097 | Validation Accurancy:  0.9329753741621971\n",
      "Epoch:  8326 | Train Accurancy:  0.9293197095394135 | Validation Accurancy:  0.9329797402024269\n",
      "Epoch:  8327 | Train Accurancy:  0.9293207228183746 | Validation Accurancy:  0.9329840838909149\n",
      "Epoch:  8328 | Train Accurancy:  0.9293217286467552 | Validation Accurancy:  0.9329885169863701\n",
      "Epoch:  8329 | Train Accurancy:  0.929322712123394 | Validation Accurancy:  0.9329928085207939\n",
      "Epoch:  8330 | Train Accurancy:  0.9293236806988716 | Validation Accurancy:  0.9329972416162491\n",
      "Epoch:  8331 | Train Accurancy:  0.9293246641755104 | Validation Accurancy:  0.9330015480518341\n",
      "Epoch:  8332 | Train Accurancy:  0.9293256551027298 | Validation Accurancy:  0.9330055862665176\n",
      "Epoch:  8333 | Train Accurancy:  0.9293266609311104 | Validation Accurancy:  0.9330100864171982\n",
      "Epoch:  8334 | Train Accurancy:  0.9293276593089104 | Validation Accurancy:  0.9330145493149757\n",
      "Epoch:  8335 | Train Accurancy:  0.9293286725878716 | Validation Accurancy:  0.9330188557505608\n",
      "Epoch:  8336 | Train Accurancy:  0.9293296486139297 | Validation Accurancy:  0.9330233111977577\n",
      "Epoch:  8337 | Train Accurancy:  0.9293306544423103 | Validation Accurancy:  0.9330275505781174\n",
      "Epoch:  8338 | Train Accurancy:  0.9293315932154655 | Validation Accurancy:  0.9330318942666054\n",
      "Epoch:  8339 | Train Accurancy:  0.9293325915932655 | Validation Accurancy:  0.9330360069870949\n",
      "Epoch:  8340 | Train Accurancy:  0.9293335899710655 | Validation Accurancy:  0.9330404251813889\n",
      "Epoch:  8341 | Train Accurancy:  0.9293346032500267 | Validation Accurancy:  0.9330448433756828\n",
      "Epoch:  8342 | Train Accurancy:  0.9293356090784073 | Validation Accurancy:  0.9330491870641708\n",
      "Epoch:  8343 | Train Accurancy:  0.9293365702033043 | Validation Accurancy:  0.9330535605549812\n",
      "Epoch:  8344 | Train Accurancy:  0.9293375238776207 | Validation Accurancy:  0.9330579414963722\n",
      "Epoch:  8345 | Train Accurancy:  0.9293385669589043 | Validation Accurancy:  0.9330622851848602\n",
      "Epoch:  8346 | Train Accurancy:  0.9293395653367043 | Validation Accurancy:  0.9330666363239288\n",
      "Epoch:  8347 | Train Accurancy:  0.9293405190110207 | Validation Accurancy:  0.9330706894397736\n",
      "Epoch:  8348 | Train Accurancy:  0.9293415620923042 | Validation Accurancy:  0.9330750778317451\n",
      "Epoch:  8349 | Train Accurancy:  0.9293425232172012 | Validation Accurancy:  0.9330794960260391\n",
      "Epoch:  8350 | Train Accurancy:  0.9293435141444206 | Validation Accurancy:  0.9330838844180107\n",
      "Epoch:  8351 | Train Accurancy:  0.9293444901704788 | Validation Accurancy:  0.9330883175134659\n",
      "Epoch:  8352 | Train Accurancy:  0.9293454587459564 | Validation Accurancy:  0.9330926612019539\n",
      "Epoch:  8353 | Train Accurancy:  0.9293464347720146 | Validation Accurancy:  0.9330968707799911\n",
      "Epoch:  8354 | Train Accurancy:  0.9293474704027176 | Validation Accurancy:  0.933101050555706\n",
      "Epoch:  8355 | Train Accurancy:  0.9293484464287758 | Validation Accurancy:  0.9331053867936134\n",
      "Epoch:  8356 | Train Accurancy:  0.9293494150042534 | Validation Accurancy:  0.9331098273396492\n",
      "Epoch:  8357 | Train Accurancy:  0.9293504729866982 | Validation Accurancy:  0.9331141337752342\n",
      "Epoch:  8358 | Train Accurancy:  0.929351419210434 | Validation Accurancy:  0.9331184551119804\n",
      "Epoch:  8359 | Train Accurancy:  0.9293523877859116 | Validation Accurancy:  0.9331227913498878\n",
      "Epoch:  8360 | Train Accurancy:  0.929353378713131 | Validation Accurancy:  0.9331271648406982\n",
      "Epoch:  8361 | Train Accurancy:  0.9293544217944145 | Validation Accurancy:  0.9331315830349922\n",
      "Epoch:  8362 | Train Accurancy:  0.9293553605675697 | Validation Accurancy:  0.9331359714269638\n",
      "Epoch:  8363 | Train Accurancy:  0.9293563440442085 | Validation Accurancy:  0.9331399127840996\n",
      "Epoch:  8364 | Train Accurancy:  0.9293573796749115 | Validation Accurancy:  0.9331443309783936\n",
      "Epoch:  8365 | Train Accurancy:  0.9293583407998085 | Validation Accurancy:  0.933148704469204\n",
      "Epoch:  8366 | Train Accurancy:  0.9293592944741249 | Validation Accurancy:  0.9331530407071114\n",
      "Epoch:  8367 | Train Accurancy:  0.9293603226542473 | Validation Accurancy:  0.9331574440002441\n",
      "Epoch:  8368 | Train Accurancy:  0.9293612912297249 | Validation Accurancy:  0.9331617206335068\n",
      "Epoch:  8369 | Train Accurancy:  0.9293622225522995 | Validation Accurancy:  0.933166153728962\n",
      "Epoch:  8370 | Train Accurancy:  0.9293632358312607 | Validation Accurancy:  0.9331704452633858\n",
      "Epoch:  8371 | Train Accurancy:  0.9293642491102219 | Validation Accurancy:  0.9331748336553574\n",
      "Epoch:  8372 | Train Accurancy:  0.9293652400374413 | Validation Accurancy:  0.9331788197159767\n",
      "Epoch:  8373 | Train Accurancy:  0.9293662160634995 | Validation Accurancy:  0.9331832379102707\n",
      "Epoch:  8374 | Train Accurancy:  0.929367184638977 | Validation Accurancy:  0.9331875964999199\n",
      "Epoch:  8375 | Train Accurancy:  0.9293682128190994 | Validation Accurancy:  0.9331919476389885\n",
      "Epoch:  8376 | Train Accurancy:  0.9293691590428352 | Validation Accurancy:  0.9331962764263153\n",
      "Epoch:  8377 | Train Accurancy:  0.9293701276183128 | Validation Accurancy:  0.9332006648182869\n",
      "Epoch:  8378 | Train Accurancy:  0.9293711334466934 | Validation Accurancy:  0.9332048892974854\n",
      "Epoch:  8379 | Train Accurancy:  0.9293721169233322 | Validation Accurancy:  0.933209165930748\n",
      "Epoch:  8380 | Train Accurancy:  0.9293730929493904 | Validation Accurancy:  0.9332132488489151\n",
      "Epoch:  8381 | Train Accurancy:  0.9293740764260292 | Validation Accurancy:  0.9332176670432091\n",
      "Epoch:  8382 | Train Accurancy:  0.9293750524520874 | Validation Accurancy:  0.933222085237503\n",
      "Epoch:  8383 | Train Accurancy:  0.9293760806322098 | Validation Accurancy:  0.9332263618707657\n",
      "Epoch:  8384 | Train Accurancy:  0.9293770417571068 | Validation Accurancy:  0.9332306534051895\n",
      "Epoch:  8385 | Train Accurancy:  0.929378017783165 | Validation Accurancy:  0.9332350268959999\n",
      "Epoch:  8386 | Train Accurancy:  0.9293790087103844 | Validation Accurancy:  0.9332394450902939\n",
      "Epoch:  8387 | Train Accurancy:  0.929379977285862 | Validation Accurancy:  0.9332436546683311\n",
      "Epoch:  8388 | Train Accurancy:  0.9293809682130814 | Validation Accurancy:  0.9332479983568192\n",
      "Epoch:  8389 | Train Accurancy:  0.9293819442391396 | Validation Accurancy:  0.9332520961761475\n",
      "Epoch:  8390 | Train Accurancy:  0.929382935166359 | Validation Accurancy:  0.9332564026117325\n",
      "Epoch:  8391 | Train Accurancy:  0.9293839186429977 | Validation Accurancy:  0.9332607612013817\n",
      "Epoch:  8392 | Train Accurancy:  0.9293848797678947 | Validation Accurancy:  0.9332651123404503\n",
      "Epoch:  8393 | Train Accurancy:  0.92938581854105 | Validation Accurancy:  0.9332694336771965\n",
      "Epoch:  8394 | Train Accurancy:  0.9293868467211723 | Validation Accurancy:  0.9332737624645233\n",
      "Epoch:  8395 | Train Accurancy:  0.9293878152966499 | Validation Accurancy:  0.9332780838012695\n",
      "Epoch:  8396 | Train Accurancy:  0.9293888360261917 | Validation Accurancy:  0.9332824721932411\n",
      "Epoch:  8397 | Train Accurancy:  0.9293897673487663 | Validation Accurancy:  0.9332866668701172\n",
      "Epoch:  8398 | Train Accurancy:  0.9293907731771469 | Validation Accurancy:  0.9332907348871231\n",
      "Epoch:  8399 | Train Accurancy:  0.9293917343020439 | Validation Accurancy:  0.9332951083779335\n",
      "Epoch:  8400 | Train Accurancy:  0.9293926656246185 | Validation Accurancy:  0.9332995265722275\n",
      "Epoch:  8401 | Train Accurancy:  0.9293937161564827 | Validation Accurancy:  0.9333037883043289\n",
      "Epoch:  8402 | Train Accurancy:  0.9293946698307991 | Validation Accurancy:  0.9333081543445587\n",
      "Epoch:  8403 | Train Accurancy:  0.9293956086039543 | Validation Accurancy:  0.9333124160766602\n",
      "Epoch:  8404 | Train Accurancy:  0.9293965995311737 | Validation Accurancy:  0.9333167374134064\n",
      "Epoch:  8405 | Train Accurancy:  0.9293976202607155 | Validation Accurancy:  0.9333210662007332\n",
      "Epoch:  8406 | Train Accurancy:  0.9293985813856125 | Validation Accurancy:  0.9333250671625137\n",
      "Epoch:  8407 | Train Accurancy:  0.9293995276093483 | Validation Accurancy:  0.9333294853568077\n",
      "Epoch:  8408 | Train Accurancy:  0.9294005483388901 | Validation Accurancy:  0.9333337768912315\n",
      "Epoch:  8409 | Train Accurancy:  0.9294015467166901 | Validation Accurancy:  0.9333381205797195\n",
      "Epoch:  8410 | Train Accurancy:  0.9294024705886841 | Validation Accurancy:  0.9333423748612404\n",
      "Epoch:  8411 | Train Accurancy:  0.9294034764170647 | Validation Accurancy:  0.933346763253212\n",
      "Epoch:  8412 | Train Accurancy:  0.9294044300913811 | Validation Accurancy:  0.9333511069417\n",
      "Epoch:  8413 | Train Accurancy:  0.9294054284691811 | Validation Accurancy:  0.9333553984761238\n",
      "Epoch:  8414 | Train Accurancy:  0.9294063895940781 | Validation Accurancy:  0.9333596900105476\n",
      "Epoch:  8415 | Train Accurancy:  0.9294074028730392 | Validation Accurancy:  0.9333640113472939\n",
      "Epoch:  8416 | Train Accurancy:  0.9294083416461945 | Validation Accurancy:  0.9333680346608162\n",
      "Epoch:  8417 | Train Accurancy:  0.9294093102216721 | Validation Accurancy:  0.9333723410964012\n",
      "Epoch:  8418 | Train Accurancy:  0.9294102862477303 | Validation Accurancy:  0.9333766922354698\n",
      "Epoch:  8419 | Train Accurancy:  0.9294113218784332 | Validation Accurancy:  0.9333809688687325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8420 | Train Accurancy:  0.9294122457504272 | Validation Accurancy:  0.9333852306008339\n",
      "Epoch:  8421 | Train Accurancy:  0.9294132441282272 | Validation Accurancy:  0.9333895817399025\n",
      "Epoch:  8422 | Train Accurancy:  0.9294141829013824 | Validation Accurancy:  0.9333938732743263\n",
      "Epoch:  8423 | Train Accurancy:  0.9294152110815048 | Validation Accurancy:  0.9333982020616531\n",
      "Epoch:  8424 | Train Accurancy:  0.92941614985466 | Validation Accurancy:  0.9334025532007217\n",
      "Epoch:  8425 | Train Accurancy:  0.9294171333312988 | Validation Accurancy:  0.9334068447351456\n",
      "Epoch:  8426 | Train Accurancy:  0.9294180870056152 | Validation Accurancy:  0.9334111213684082\n",
      "Epoch:  8427 | Train Accurancy:  0.9294190555810928 | Validation Accurancy:  0.9334151595830917\n",
      "Epoch:  8428 | Train Accurancy:  0.9294200912117958 | Validation Accurancy:  0.9334194958209991\n",
      "Epoch:  8429 | Train Accurancy:  0.929420992732048 | Validation Accurancy:  0.9334238544106483\n",
      "Epoch:  8430 | Train Accurancy:  0.9294219836592674 | Validation Accurancy:  0.9334281757473946\n",
      "Epoch:  8431 | Train Accurancy:  0.9294229671359062 | Validation Accurancy:  0.9334324523806572\n",
      "Epoch:  8432 | Train Accurancy:  0.9294239431619644 | Validation Accurancy:  0.9334367290139198\n",
      "Epoch:  8433 | Train Accurancy:  0.9294248968362808 | Validation Accurancy:  0.9334410354495049\n",
      "Epoch:  8434 | Train Accurancy:  0.9294258430600166 | Validation Accurancy:  0.9334453269839287\n",
      "Epoch:  8435 | Train Accurancy:  0.929426871240139 | Validation Accurancy:  0.9334495365619659\n",
      "Epoch:  8436 | Train Accurancy:  0.9294278174638748 | Validation Accurancy:  0.9334538951516151\n",
      "Epoch:  8437 | Train Accurancy:  0.9294287860393524 | Validation Accurancy:  0.933458186686039\n",
      "Epoch:  8438 | Train Accurancy:  0.9294297620654106 | Validation Accurancy:  0.9334624782204628\n",
      "Epoch:  8439 | Train Accurancy:  0.9294307008385658 | Validation Accurancy:  0.9334667176008224\n",
      "Epoch:  8440 | Train Accurancy:  0.9294317066669464 | Validation Accurancy:  0.9334706589579582\n",
      "Epoch:  8441 | Train Accurancy:  0.9294327050447464 | Validation Accurancy:  0.9334750175476074\n",
      "Epoch:  8442 | Train Accurancy:  0.9294336587190628 | Validation Accurancy:  0.9334793537855148\n",
      "Epoch:  8443 | Train Accurancy:  0.929434634745121 | Validation Accurancy:  0.9334836453199387\n",
      "Epoch:  8444 | Train Accurancy:  0.9294355437159538 | Validation Accurancy:  0.9334879219532013\n",
      "Epoch:  8445 | Train Accurancy:  0.9294365644454956 | Validation Accurancy:  0.9334921985864639\n",
      "Epoch:  8446 | Train Accurancy:  0.9294375702738762 | Validation Accurancy:  0.933496505022049\n",
      "Epoch:  8447 | Train Accurancy:  0.929438516497612 | Validation Accurancy:  0.9335007965564728\n",
      "Epoch:  8448 | Train Accurancy:  0.9294395074248314 | Validation Accurancy:  0.9335050582885742\n",
      "Epoch:  8449 | Train Accurancy:  0.9294405281543732 | Validation Accurancy:  0.9335093051195145\n",
      "Epoch:  8450 | Train Accurancy:  0.9294414222240448 | Validation Accurancy:  0.9335136115550995\n",
      "Epoch:  8451 | Train Accurancy:  0.929442398250103 | Validation Accurancy:  0.9335178062319756\n",
      "Epoch:  8452 | Train Accurancy:  0.9294433444738388 | Validation Accurancy:  0.9335218444466591\n",
      "Epoch:  8453 | Train Accurancy:  0.9294443875551224 | Validation Accurancy:  0.9335261359810829\n",
      "Epoch:  8454 | Train Accurancy:  0.9294452890753746 | Validation Accurancy:  0.9335304275155067\n",
      "Epoch:  8455 | Train Accurancy:  0.9294462874531746 | Validation Accurancy:  0.9335348159074783\n",
      "Epoch:  8456 | Train Accurancy:  0.9294472634792328 | Validation Accurancy:  0.9335391521453857\n",
      "Epoch:  8457 | Train Accurancy:  0.9294482320547104 | Validation Accurancy:  0.9335433170199394\n",
      "Epoch:  8458 | Train Accurancy:  0.929449200630188 | Validation Accurancy:  0.933547668159008\n",
      "Epoch:  8459 | Train Accurancy:  0.9294501394033432 | Validation Accurancy:  0.9335519149899483\n",
      "Epoch:  8460 | Train Accurancy:  0.9294511079788208 | Validation Accurancy:  0.9335561916232109\n",
      "Epoch:  8461 | Train Accurancy:  0.9294521063566208 | Validation Accurancy:  0.9335604533553123\n",
      "Epoch:  8462 | Train Accurancy:  0.9294530525803566 | Validation Accurancy:  0.9335647597908974\n",
      "Epoch:  8463 | Train Accurancy:  0.929454043507576 | Validation Accurancy:  0.9335687160491943\n",
      "Epoch:  8464 | Train Accurancy:  0.9294549971818924 | Validation Accurancy:  0.9335730373859406\n",
      "Epoch:  8465 | Train Accurancy:  0.9294559210538864 | Validation Accurancy:  0.9335773810744286\n",
      "Epoch:  8466 | Train Accurancy:  0.929456926882267 | Validation Accurancy:  0.9335816353559494\n",
      "Epoch:  8467 | Train Accurancy:  0.9294579103589058 | Validation Accurancy:  0.933585911989212\n",
      "Epoch:  8468 | Train Accurancy:  0.9294588640332222 | Validation Accurancy:  0.9335901290178299\n",
      "Epoch:  8469 | Train Accurancy:  0.9294598028063774 | Validation Accurancy:  0.9335944354534149\n",
      "Epoch:  8470 | Train Accurancy:  0.9294607937335968 | Validation Accurancy:  0.9335986003279686\n",
      "Epoch:  8471 | Train Accurancy:  0.9294617846608162 | Validation Accurancy:  0.9336029216647148\n",
      "Epoch:  8472 | Train Accurancy:  0.9294627159833908 | Validation Accurancy:  0.9336071461439133\n",
      "Epoch:  8473 | Train Accurancy:  0.9294636622071266 | Validation Accurancy:  0.9336114078760147\n",
      "Epoch:  8474 | Train Accurancy:  0.9294645860791206 | Validation Accurancy:  0.9336156994104385\n",
      "Epoch:  8475 | Train Accurancy:  0.9294655993580818 | Validation Accurancy:  0.9336200207471848\n",
      "Epoch:  8476 | Train Accurancy:  0.92946657538414 | Validation Accurancy:  0.9336242005228996\n",
      "Epoch:  8477 | Train Accurancy:  0.929467536509037 | Validation Accurancy:  0.9336281940340996\n",
      "Epoch:  8478 | Train Accurancy:  0.9294685274362564 | Validation Accurancy:  0.9336325153708458\n",
      "Epoch:  8479 | Train Accurancy:  0.9294694513082504 | Validation Accurancy:  0.9336367473006248\n",
      "Epoch:  8480 | Train Accurancy:  0.9294704347848892 | Validation Accurancy:  0.9336409717798233\n",
      "Epoch:  8481 | Train Accurancy:  0.9294713959097862 | Validation Accurancy:  0.9336452335119247\n",
      "Epoch:  8482 | Train Accurancy:  0.9294723570346832 | Validation Accurancy:  0.9336495250463486\n",
      "Epoch:  8483 | Train Accurancy:  0.9294733330607414 | Validation Accurancy:  0.9336538165807724\n",
      "Epoch:  8484 | Train Accurancy:  0.9294743090867996 | Validation Accurancy:  0.9336580261588097\n",
      "Epoch:  8485 | Train Accurancy:  0.9294752329587936 | Validation Accurancy:  0.9336623698472977\n",
      "Epoch:  8486 | Train Accurancy:  0.92947618663311 | Validation Accurancy:  0.9336665794253349\n",
      "Epoch:  8487 | Train Accurancy:  0.9294771254062653 | Validation Accurancy:  0.93367088586092\n",
      "Epoch:  8488 | Train Accurancy:  0.9294781535863876 | Validation Accurancy:  0.933675117790699\n",
      "Epoch:  8489 | Train Accurancy:  0.9294790923595428 | Validation Accurancy:  0.9336793571710587\n",
      "Epoch:  8490 | Train Accurancy:  0.9294800832867622 | Validation Accurancy:  0.9336835518479347\n",
      "Epoch:  8491 | Train Accurancy:  0.9294809922575951 | Validation Accurancy:  0.9336878135800362\n",
      "Epoch:  8492 | Train Accurancy:  0.929482027888298 | Validation Accurancy:  0.9336920604109764\n",
      "Epoch:  8493 | Train Accurancy:  0.929482951760292 | Validation Accurancy:  0.9336962252855301\n",
      "Epoch:  8494 | Train Accurancy:  0.9294838830828667 | Validation Accurancy:  0.9337005168199539\n",
      "Epoch:  8495 | Train Accurancy:  0.9294848516583443 | Validation Accurancy:  0.9337044879794121\n",
      "Epoch:  8496 | Train Accurancy:  0.9294858425855637 | Validation Accurancy:  0.9337087348103523\n",
      "Epoch:  8497 | Train Accurancy:  0.9294867962598801 | Validation Accurancy:  0.9337130710482597\n",
      "Epoch:  8498 | Train Accurancy:  0.9294877499341965 | Validation Accurancy:  0.9337173327803612\n",
      "Epoch:  8499 | Train Accurancy:  0.9294887259602547 | Validation Accurancy:  0.9337215572595596\n",
      "Epoch:  8500 | Train Accurancy:  0.9294896796345711 | Validation Accurancy:  0.9337258189916611\n",
      "Epoch:  8501 | Train Accurancy:  0.9294906109571457 | Validation Accurancy:  0.9337300956249237\n",
      "Epoch:  8502 | Train Accurancy:  0.9294915869832039 | Validation Accurancy:  0.9337342754006386\n",
      "Epoch:  8503 | Train Accurancy:  0.9294925183057785 | Validation Accurancy:  0.9337385967373848\n",
      "Epoch:  8504 | Train Accurancy:  0.9294934719800949 | Validation Accurancy:  0.9337427616119385\n",
      "Epoch:  8505 | Train Accurancy:  0.9294944703578949 | Validation Accurancy:  0.9337469413876534\n",
      "Epoch:  8506 | Train Accurancy:  0.9294954091310501 | Validation Accurancy:  0.9337511360645294\n",
      "Epoch:  8507 | Train Accurancy:  0.9294963777065277 | Validation Accurancy:  0.9337553679943085\n",
      "Epoch:  8508 | Train Accurancy:  0.9294972866773605 | Validation Accurancy:  0.9337597191333771\n",
      "Epoch:  8509 | Train Accurancy:  0.9294982925057411 | Validation Accurancy:  0.9337638542056084\n",
      "Epoch:  8510 | Train Accurancy:  0.9294992461800575 | Validation Accurancy:  0.9337681606411934\n",
      "Epoch:  8511 | Train Accurancy:  0.9295001775026321 | Validation Accurancy:  0.9337723255157471\n",
      "Epoch:  8512 | Train Accurancy:  0.929501123726368 | Validation Accurancy:  0.9337765201926231\n",
      "Epoch:  8513 | Train Accurancy:  0.9295021295547485 | Validation Accurancy:  0.9337807670235634\n",
      "Epoch:  8514 | Train Accurancy:  0.9295030534267426 | Validation Accurancy:  0.933785006403923\n",
      "Epoch:  8515 | Train Accurancy:  0.9295040294528008 | Validation Accurancy:  0.9337892234325409\n",
      "Epoch:  8516 | Train Accurancy:  0.9295049756765366 | Validation Accurancy:  0.9337935298681259\n",
      "Epoch:  8517 | Train Accurancy:  0.929505966603756 | Validation Accurancy:  0.9337976649403572\n",
      "Epoch:  8518 | Train Accurancy:  0.92950689047575 | Validation Accurancy:  0.9338018894195557\n",
      "Epoch:  8519 | Train Accurancy:  0.929507851600647 | Validation Accurancy:  0.9338061362504959\n",
      "Epoch:  8520 | Train Accurancy:  0.9295088052749634 | Validation Accurancy:  0.9338103905320168\n",
      "Epoch:  8521 | Train Accurancy:  0.9295097589492798 | Validation Accurancy:  0.9338145926594734\n",
      "Epoch:  8522 | Train Accurancy:  0.929510734975338 | Validation Accurancy:  0.9338187202811241\n",
      "Epoch:  8523 | Train Accurancy:  0.9295116737484932 | Validation Accurancy:  0.9338226616382599\n",
      "Epoch:  8524 | Train Accurancy:  0.9295126125216484 | Validation Accurancy:  0.9338269233703613\n",
      "Epoch:  8525 | Train Accurancy:  0.929513581097126 | Validation Accurancy:  0.9338312149047852\n",
      "Epoch:  8526 | Train Accurancy:  0.9295145347714424 | Validation Accurancy:  0.9338354393839836\n",
      "Epoch:  8527 | Train Accurancy:  0.929515466094017 | Validation Accurancy:  0.9338397309184074\n",
      "Epoch:  8528 | Train Accurancy:  0.9295164495706558 | Validation Accurancy:  0.9338440075516701\n",
      "Epoch:  8529 | Train Accurancy:  0.9295174032449722 | Validation Accurancy:  0.9338482394814491\n",
      "Epoch:  8530 | Train Accurancy:  0.929518312215805 | Validation Accurancy:  0.933852419257164\n",
      "Epoch:  8531 | Train Accurancy:  0.9295193329453468 | Validation Accurancy:  0.9338566586375237\n",
      "Epoch:  8532 | Train Accurancy:  0.9295202568173409 | Validation Accurancy:  0.9338608607649803\n",
      "Epoch:  8533 | Train Accurancy:  0.9295212253928185 | Validation Accurancy:  0.9338650703430176\n",
      "Epoch:  8534 | Train Accurancy:  0.9295221865177155 | Validation Accurancy:  0.9338691681623459\n",
      "Epoch:  8535 | Train Accurancy:  0.9295230731368065 | Validation Accurancy:  0.9338734298944473\n",
      "Epoch:  8536 | Train Accurancy:  0.9295240864157677 | Validation Accurancy:  0.9338776245713234\n",
      "Epoch:  8537 | Train Accurancy:  0.9295250251889229 | Validation Accurancy:  0.933881901204586\n",
      "Epoch:  8538 | Train Accurancy:  0.9295259490609169 | Validation Accurancy:  0.9338861331343651\n",
      "Epoch:  8539 | Train Accurancy:  0.9295269325375557 | Validation Accurancy:  0.9338902458548546\n",
      "Epoch:  8540 | Train Accurancy:  0.9295278936624527 | Validation Accurancy:  0.9338945224881172\n",
      "Epoch:  8541 | Train Accurancy:  0.9295287802815437 | Validation Accurancy:  0.9338985159993172\n",
      "Epoch:  8542 | Train Accurancy:  0.9295297488570213 | Validation Accurancy:  0.9339026585221291\n",
      "Epoch:  8543 | Train Accurancy:  0.9295307174324989 | Validation Accurancy:  0.9339069500565529\n",
      "Epoch:  8544 | Train Accurancy:  0.9295317009091377 | Validation Accurancy:  0.9339111298322678\n",
      "Epoch:  8545 | Train Accurancy:  0.9295326694846153 | Validation Accurancy:  0.9339154213666916\n",
      "Epoch:  8546 | Train Accurancy:  0.9295336231589317 | Validation Accurancy:  0.933919683098793\n",
      "Epoch:  8547 | Train Accurancy:  0.9295345470309258 | Validation Accurancy:  0.9339238926768303\n",
      "Epoch:  8548 | Train Accurancy:  0.9295354709029198 | Validation Accurancy:  0.933928057551384\n",
      "Epoch:  8549 | Train Accurancy:  0.9295364394783974 | Validation Accurancy:  0.9339322224259377\n",
      "Epoch:  8550 | Train Accurancy:  0.929537370800972 | Validation Accurancy:  0.9339364022016525\n",
      "Epoch:  8551 | Train Accurancy:  0.9295383393764496 | Validation Accurancy:  0.9339406192302704\n",
      "Epoch:  8552 | Train Accurancy:  0.9295392706990242 | Validation Accurancy:  0.9339448437094688\n",
      "Epoch:  8553 | Train Accurancy:  0.929540291428566 | Validation Accurancy:  0.9339490383863449\n",
      "Epoch:  8554 | Train Accurancy:  0.9295412003993988 | Validation Accurancy:  0.9339531734585762\n",
      "Epoch:  8555 | Train Accurancy:  0.9295421689748764 | Validation Accurancy:  0.9339573681354523\n",
      "Epoch:  8556 | Train Accurancy:  0.9295430928468704 | Validation Accurancy:  0.9339616149663925\n",
      "Epoch:  8557 | Train Accurancy:  0.9295440167188644 | Validation Accurancy:  0.9339658245444298\n",
      "Epoch:  8558 | Train Accurancy:  0.9295449703931808 | Validation Accurancy:  0.9339700564742088\n",
      "Epoch:  8559 | Train Accurancy:  0.9295459315180779 | Validation Accurancy:  0.9339742809534073\n",
      "Epoch:  8560 | Train Accurancy:  0.9295468702912331 | Validation Accurancy:  0.9339783489704132\n",
      "Epoch:  8561 | Train Accurancy:  0.9295478016138077 | Validation Accurancy:  0.9339825809001923\n",
      "Epoch:  8562 | Train Accurancy:  0.9295487329363823 | Validation Accurancy:  0.9339867755770683\n",
      "Epoch:  8563 | Train Accurancy:  0.9295496866106987 | Validation Accurancy:  0.9339908584952354\n",
      "Epoch:  8564 | Train Accurancy:  0.9295506402850151 | Validation Accurancy:  0.9339952170848846\n",
      "Epoch:  8565 | Train Accurancy:  0.9295515939593315 | Validation Accurancy:  0.9339993447065353\n",
      "Epoch:  8566 | Train Accurancy:  0.9295525923371315 | Validation Accurancy:  0.9340035617351532\n",
      "Epoch:  8567 | Train Accurancy:  0.9295535534620285 | Validation Accurancy:  0.9340076744556427\n",
      "Epoch:  8568 | Train Accurancy:  0.9295544698834419 | Validation Accurancy:  0.934011921286583\n",
      "Epoch:  8569 | Train Accurancy:  0.9295554235577583 | Validation Accurancy:  0.9340161830186844\n",
      "Epoch:  8570 | Train Accurancy:  0.9295563623309135 | Validation Accurancy:  0.9340202361345291\n",
      "Epoch:  8571 | Train Accurancy:  0.9295573234558105 | Validation Accurancy:  0.9340244010090828\n",
      "Epoch:  8572 | Train Accurancy:  0.9295582473278046 | Validation Accurancy:  0.9340286701917648\n",
      "Epoch:  8573 | Train Accurancy:  0.9295591861009598 | Validation Accurancy:  0.9340329021215439\n",
      "Epoch:  8574 | Train Accurancy:  0.9295601546764374 | Validation Accurancy:  0.9340370818972588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8575 | Train Accurancy:  0.9295611009001732 | Validation Accurancy:  0.93404121696949\n",
      "Epoch:  8576 | Train Accurancy:  0.9295620173215866 | Validation Accurancy:  0.9340454414486885\n",
      "Epoch:  8577 | Train Accurancy:  0.9295629933476448 | Validation Accurancy:  0.934049591422081\n",
      "Epoch:  8578 | Train Accurancy:  0.9295638799667358 | Validation Accurancy:  0.9340538308024406\n",
      "Epoch:  8579 | Train Accurancy:  0.9295648336410522 | Validation Accurancy:  0.9340579658746719\n",
      "Epoch:  8580 | Train Accurancy:  0.9295658022165298 | Validation Accurancy:  0.9340621456503868\n",
      "Epoch:  8581 | Train Accurancy:  0.9295667707920074 | Validation Accurancy:  0.9340663403272629\n",
      "Epoch:  8582 | Train Accurancy:  0.9295676946640015 | Validation Accurancy:  0.9340704455971718\n",
      "Epoch:  8583 | Train Accurancy:  0.9295686632394791 | Validation Accurancy:  0.9340746849775314\n",
      "Epoch:  8584 | Train Accurancy:  0.9295695945620537 | Validation Accurancy:  0.9340788647532463\n",
      "Epoch:  8585 | Train Accurancy:  0.9295705556869507 | Validation Accurancy:  0.9340830296278\n",
      "Epoch:  8586 | Train Accurancy:  0.9295714870095253 | Validation Accurancy:  0.9340872094035149\n",
      "Epoch:  8587 | Train Accurancy:  0.9295724108815193 | Validation Accurancy:  0.9340913444757462\n",
      "Epoch:  8588 | Train Accurancy:  0.9295733124017715 | Validation Accurancy:  0.9340954944491386\n",
      "Epoch:  8589 | Train Accurancy:  0.9295743405818939 | Validation Accurancy:  0.9340997189283371\n",
      "Epoch:  8590 | Train Accurancy:  0.9295752122998238 | Validation Accurancy:  0.9341038689017296\n",
      "Epoch:  8591 | Train Accurancy:  0.9295761361718178 | Validation Accurancy:  0.9341080337762833\n",
      "Epoch:  8592 | Train Accurancy:  0.9295771196484566 | Validation Accurancy:  0.9341122806072235\n",
      "Epoch:  8593 | Train Accurancy:  0.9295780435204506 | Validation Accurancy:  0.9341164454817772\n",
      "Epoch:  8594 | Train Accurancy:  0.9295789897441864 | Validation Accurancy:  0.9341205283999443\n",
      "Epoch:  8595 | Train Accurancy:  0.9295798912644386 | Validation Accurancy:  0.9341247901320457\n",
      "Epoch:  8596 | Train Accurancy:  0.9295808747410774 | Validation Accurancy:  0.9341286644339561\n",
      "Epoch:  8597 | Train Accurancy:  0.9295818358659744 | Validation Accurancy:  0.9341329112648964\n",
      "Epoch:  8598 | Train Accurancy:  0.9295827522873878 | Validation Accurancy:  0.9341370239853859\n",
      "Epoch:  8599 | Train Accurancy:  0.9295837432146072 | Validation Accurancy:  0.9341411888599396\n",
      "Epoch:  8600 | Train Accurancy:  0.9295846745371819 | Validation Accurancy:  0.9341455176472664\n",
      "Epoch:  8601 | Train Accurancy:  0.9295856133103371 | Validation Accurancy:  0.9341497123241425\n",
      "Epoch:  8602 | Train Accurancy:  0.9295865148305893 | Validation Accurancy:  0.9341538622975349\n",
      "Epoch:  8603 | Train Accurancy:  0.9295875281095505 | Validation Accurancy:  0.9341579899191856\n",
      "Epoch:  8604 | Train Accurancy:  0.9295884147286415 | Validation Accurancy:  0.9341621845960617\n",
      "Epoch:  8605 | Train Accurancy:  0.9295893535017967 | Validation Accurancy:  0.9341663047671318\n",
      "Epoch:  8606 | Train Accurancy:  0.9295902997255325 | Validation Accurancy:  0.9341705292463303\n",
      "Epoch:  8607 | Train Accurancy:  0.9295912012457848 | Validation Accurancy:  0.934174619615078\n",
      "Epoch:  8608 | Train Accurancy:  0.9295921623706818 | Validation Accurancy:  0.934178814291954\n",
      "Epoch:  8609 | Train Accurancy:  0.9295931160449982 | Validation Accurancy:  0.9341829270124435\n",
      "Epoch:  8610 | Train Accurancy:  0.9295940399169922 | Validation Accurancy:  0.9341870620846748\n",
      "Epoch:  8611 | Train Accurancy:  0.9295949712395668 | Validation Accurancy:  0.9341913536190987\n",
      "Epoch:  8612 | Train Accurancy:  0.9295959547162056 | Validation Accurancy:  0.9341955035924911\n",
      "Epoch:  8613 | Train Accurancy:  0.9295968860387802 | Validation Accurancy:  0.9341995716094971\n",
      "Epoch:  8614 | Train Accurancy:  0.9295978248119354 | Validation Accurancy:  0.9342037662863731\n",
      "Epoch:  8615 | Train Accurancy:  0.9295987710356712 | Validation Accurancy:  0.9342079311609268\n",
      "Epoch:  8616 | Train Accurancy:  0.9295996874570847 | Validation Accurancy:  0.9342120811343193\n",
      "Epoch:  8617 | Train Accurancy:  0.9296005964279175 | Validation Accurancy:  0.9342162609100342\n",
      "Epoch:  8618 | Train Accurancy:  0.9296015873551369 | Validation Accurancy:  0.9342204257845879\n",
      "Epoch:  8619 | Train Accurancy:  0.9296024665236473 | Validation Accurancy:  0.9342245906591415\n",
      "Epoch:  8620 | Train Accurancy:  0.9296034425497055 | Validation Accurancy:  0.9342287555336952\n",
      "Epoch:  8621 | Train Accurancy:  0.9296043440699577 | Validation Accurancy:  0.9342328533530235\n",
      "Epoch:  8622 | Train Accurancy:  0.9296053126454353 | Validation Accurancy:  0.9342370182275772\n",
      "Epoch:  8623 | Train Accurancy:  0.9296062290668488 | Validation Accurancy:  0.9342411011457443\n",
      "Epoch:  8624 | Train Accurancy:  0.9296071752905846 | Validation Accurancy:  0.9342452213168144\n",
      "Epoch:  8625 | Train Accurancy:  0.929608128964901 | Validation Accurancy:  0.9342494010925293\n",
      "Epoch:  8626 | Train Accurancy:  0.929609052836895 | Validation Accurancy:  0.9342535808682442\n",
      "Epoch:  8627 | Train Accurancy:  0.9296099692583084 | Validation Accurancy:  0.9342577010393143\n",
      "Epoch:  8628 | Train Accurancy:  0.9296109229326248 | Validation Accurancy:  0.9342618435621262\n",
      "Epoch:  8629 | Train Accurancy:  0.929611898958683 | Validation Accurancy:  0.9342659935355186\n",
      "Epoch:  8630 | Train Accurancy:  0.9296127781271935 | Validation Accurancy:  0.9342701882123947\n",
      "Epoch:  8631 | Train Accurancy:  0.9296137094497681 | Validation Accurancy:  0.9342742636799812\n",
      "Epoch:  8632 | Train Accurancy:  0.9296146407723427 | Validation Accurancy:  0.9342783614993095\n",
      "Epoch:  8633 | Train Accurancy:  0.9296156316995621 | Validation Accurancy:  0.934282623231411\n",
      "Epoch:  8634 | Train Accurancy:  0.9296165183186531 | Validation Accurancy:  0.9342867061495781\n",
      "Epoch:  8635 | Train Accurancy:  0.9296174570918083 | Validation Accurancy:  0.934290885925293\n",
      "Epoch:  8636 | Train Accurancy:  0.9296183884143829 | Validation Accurancy:  0.9342949390411377\n",
      "Epoch:  8637 | Train Accurancy:  0.9296193644404411 | Validation Accurancy:  0.934299074113369\n",
      "Epoch:  8638 | Train Accurancy:  0.929620273411274 | Validation Accurancy:  0.9343032166361809\n",
      "Epoch:  8639 | Train Accurancy:  0.9296211451292038 | Validation Accurancy:  0.9343074634671211\n",
      "Epoch:  8640 | Train Accurancy:  0.9296220988035202 | Validation Accurancy:  0.9343115016818047\n",
      "Epoch:  8641 | Train Accurancy:  0.929623045027256 | Validation Accurancy:  0.9343156963586807\n",
      "Epoch:  8642 | Train Accurancy:  0.9296239838004112 | Validation Accurancy:  0.934319831430912\n",
      "Epoch:  8643 | Train Accurancy:  0.9296249523758888 | Validation Accurancy:  0.9343239441514015\n",
      "Epoch:  8644 | Train Accurancy:  0.9296258613467216 | Validation Accurancy:  0.9343280121684074\n",
      "Epoch:  8645 | Train Accurancy:  0.9296268075704575 | Validation Accurancy:  0.9343322589993477\n",
      "Epoch:  8646 | Train Accurancy:  0.9296277463436127 | Validation Accurancy:  0.9343364238739014\n",
      "Epoch:  8647 | Train Accurancy:  0.9296286553144455 | Validation Accurancy:  0.9343405067920685\n",
      "Epoch:  8648 | Train Accurancy:  0.9296295866370201 | Validation Accurancy:  0.9343446716666222\n",
      "Epoch:  8649 | Train Accurancy:  0.9296304881572723 | Validation Accurancy:  0.9343487545847893\n",
      "Epoch:  8650 | Train Accurancy:  0.9296314418315887 | Validation Accurancy:  0.9343529865145683\n",
      "Epoch:  8651 | Train Accurancy:  0.929632380604744 | Validation Accurancy:  0.934357039630413\n",
      "Epoch:  8652 | Train Accurancy:  0.929633304476738 | Validation Accurancy:  0.9343611523509026\n",
      "Epoch:  8653 | Train Accurancy:  0.9296342134475708 | Validation Accurancy:  0.9343652874231339\n",
      "Epoch:  8654 | Train Accurancy:  0.9296352043747902 | Validation Accurancy:  0.934369407594204\n",
      "Epoch:  8655 | Train Accurancy:  0.9296361058950424 | Validation Accurancy:  0.9343735203146935\n",
      "Epoch:  8656 | Train Accurancy:  0.9296370297670364 | Validation Accurancy:  0.9343776553869247\n",
      "Epoch:  8657 | Train Accurancy:  0.9296379536390305 | Validation Accurancy:  0.934381864964962\n",
      "Epoch:  8658 | Train Accurancy:  0.9296389445662498 | Validation Accurancy:  0.9343859851360321\n",
      "Epoch:  8659 | Train Accurancy:  0.9296398386359215 | Validation Accurancy:  0.9343900233507156\n",
      "Epoch:  8660 | Train Accurancy:  0.9296407327055931 | Validation Accurancy:  0.9343942180275917\n",
      "Epoch:  8661 | Train Accurancy:  0.9296416789293289 | Validation Accurancy:  0.9343983680009842\n",
      "Epoch:  8662 | Train Accurancy:  0.9296426475048065 | Validation Accurancy:  0.9344024211168289\n",
      "Epoch:  8663 | Train Accurancy:  0.9296435490250587 | Validation Accurancy:  0.934406504034996\n",
      "Epoch:  8664 | Train Accurancy:  0.9296444579958916 | Validation Accurancy:  0.9344107285141945\n",
      "Epoch:  8665 | Train Accurancy:  0.9296453818678856 | Validation Accurancy:  0.9344148188829422\n",
      "Epoch:  8666 | Train Accurancy:  0.9296463280916214 | Validation Accurancy:  0.9344188868999481\n",
      "Epoch:  8667 | Train Accurancy:  0.9296472072601318 | Validation Accurancy:  0.9344230815768242\n",
      "Epoch:  8668 | Train Accurancy:  0.9296481683850288 | Validation Accurancy:  0.9344271793961525\n",
      "Epoch:  8669 | Train Accurancy:  0.9296490922570229 | Validation Accurancy:  0.934431329369545\n",
      "Epoch:  8670 | Train Accurancy:  0.9296500310301781 | Validation Accurancy:  0.9344354346394539\n",
      "Epoch:  8671 | Train Accurancy:  0.9296509772539139 | Validation Accurancy:  0.9344395622611046\n",
      "Epoch:  8672 | Train Accurancy:  0.9296518638730049 | Validation Accurancy:  0.9344436451792717\n",
      "Epoch:  8673 | Train Accurancy:  0.9296528026461601 | Validation Accurancy:  0.9344477504491806\n",
      "Epoch:  8674 | Train Accurancy:  0.9296537563204765 | Validation Accurancy:  0.9344518631696701\n",
      "Epoch:  8675 | Train Accurancy:  0.9296546876430511 | Validation Accurancy:  0.9344560652971268\n",
      "Epoch:  8676 | Train Accurancy:  0.9296556040644646 | Validation Accurancy:  0.9344602078199387\n",
      "Epoch:  8677 | Train Accurancy:  0.9296565055847168 | Validation Accurancy:  0.9344642981886864\n",
      "Epoch:  8678 | Train Accurancy:  0.929657444357872 | Validation Accurancy:  0.9344684109091759\n",
      "Epoch:  8679 | Train Accurancy:  0.929658368229866 | Validation Accurancy:  0.934472493827343\n",
      "Epoch:  8680 | Train Accurancy:  0.9296593442559242 | Validation Accurancy:  0.9344766288995743\n",
      "Epoch:  8681 | Train Accurancy:  0.9296602234244347 | Validation Accurancy:  0.9344806671142578\n",
      "Epoch:  8682 | Train Accurancy:  0.9296611621975899 | Validation Accurancy:  0.9344847351312637\n",
      "Epoch:  8683 | Train Accurancy:  0.9296620786190033 | Validation Accurancy:  0.9344889149069786\n",
      "Epoch:  8684 | Train Accurancy:  0.9296630248427391 | Validation Accurancy:  0.9344929680228233\n",
      "Epoch:  8685 | Train Accurancy:  0.9296639114618301 | Validation Accurancy:  0.9344970881938934\n",
      "Epoch:  8686 | Train Accurancy:  0.9296648800373077 | Validation Accurancy:  0.9345012828707695\n",
      "Epoch:  8687 | Train Accurancy:  0.9296657741069794 | Validation Accurancy:  0.9345053806900978\n",
      "Epoch:  8688 | Train Accurancy:  0.9296667501330376 | Validation Accurancy:  0.9345094338059425\n",
      "Epoch:  8689 | Train Accurancy:  0.9296676218509674 | Validation Accurancy:  0.9345135688781738\n",
      "Epoch:  8690 | Train Accurancy:  0.9296685606241226 | Validation Accurancy:  0.9345176517963409\n",
      "Epoch:  8691 | Train Accurancy:  0.9296695068478584 | Validation Accurancy:  0.9345217570662498\n",
      "Epoch:  8692 | Train Accurancy:  0.9296704307198524 | Validation Accurancy:  0.9345257952809334\n",
      "Epoch:  8693 | Train Accurancy:  0.9296713322401047 | Validation Accurancy:  0.9345299080014229\n",
      "Epoch:  8694 | Train Accurancy:  0.9296722933650017 | Validation Accurancy:  0.9345340430736542\n",
      "Epoch:  8695 | Train Accurancy:  0.9296731501817703 | Validation Accurancy:  0.9345381259918213\n",
      "Epoch:  8696 | Train Accurancy:  0.9296740740537643 | Validation Accurancy:  0.9345423355698586\n",
      "Epoch:  8697 | Train Accurancy:  0.9296750500798225 | Validation Accurancy:  0.9345463737845421\n",
      "Epoch:  8698 | Train Accurancy:  0.9296759516000748 | Validation Accurancy:  0.9345505237579346\n",
      "Epoch:  8699 | Train Accurancy:  0.9296768829226494 | Validation Accurancy:  0.9345545917749405\n",
      "Epoch:  8700 | Train Accurancy:  0.929677814245224 | Validation Accurancy:  0.9345587119460106\n",
      "Epoch:  8701 | Train Accurancy:  0.9296787083148956 | Validation Accurancy:  0.9345628768205643\n",
      "Epoch:  8702 | Train Accurancy:  0.9296796396374702 | Validation Accurancy:  0.934566892683506\n",
      "Epoch:  8703 | Train Accurancy:  0.9296805635094643 | Validation Accurancy:  0.9345709607005119\n",
      "Epoch:  8704 | Train Accurancy:  0.9296814501285553 | Validation Accurancy:  0.934575080871582\n",
      "Epoch:  8705 | Train Accurancy:  0.9296823590993881 | Validation Accurancy:  0.9345792308449745\n",
      "Epoch:  8706 | Train Accurancy:  0.9296833351254463 | Validation Accurancy:  0.9345833286643028\n",
      "Epoch:  8707 | Train Accurancy:  0.9296842366456985 | Validation Accurancy:  0.9345874488353729\n",
      "Epoch:  8708 | Train Accurancy:  0.9296851456165314 | Validation Accurancy:  0.9345915988087654\n",
      "Epoch:  8709 | Train Accurancy:  0.9296860918402672 | Validation Accurancy:  0.934595599770546\n",
      "Epoch:  8710 | Train Accurancy:  0.9296869859099388 | Validation Accurancy:  0.9345997050404549\n",
      "Epoch:  8711 | Train Accurancy:  0.9296879395842552 | Validation Accurancy:  0.9346038177609444\n",
      "Epoch:  8712 | Train Accurancy:  0.9296888634562492 | Validation Accurancy:  0.9346078708767891\n",
      "Epoch:  8713 | Train Accurancy:  0.9296897500753403 | Validation Accurancy:  0.9346120059490204\n",
      "Epoch:  8714 | Train Accurancy:  0.9296906664967537 | Validation Accurancy:  0.9346161186695099\n",
      "Epoch:  8715 | Train Accurancy:  0.9296916723251343 | Validation Accurancy:  0.9346201717853546\n",
      "Epoch:  8716 | Train Accurancy:  0.9296925291419029 | Validation Accurancy:  0.934624195098877\n",
      "Epoch:  8717 | Train Accurancy:  0.9296934232115746 | Validation Accurancy:  0.9346283748745918\n",
      "Epoch:  8718 | Train Accurancy:  0.929694339632988 | Validation Accurancy:  0.9346324428915977\n",
      "Epoch:  8719 | Train Accurancy:  0.9296952933073044 | Validation Accurancy:  0.9346365258097649\n",
      "Epoch:  8720 | Train Accurancy:  0.9296962022781372 | Validation Accurancy:  0.9346407130360603\n",
      "Epoch:  8721 | Train Accurancy:  0.9296970888972282 | Validation Accurancy:  0.9346447810530663\n",
      "Epoch:  8722 | Train Accurancy:  0.9296980947256088 | Validation Accurancy:  0.934648834168911\n",
      "Epoch:  8723 | Train Accurancy:  0.9296989664435387 | Validation Accurancy:  0.9346528723835945\n",
      "Epoch:  8724 | Train Accurancy:  0.9296999126672745 | Validation Accurancy:  0.9346570521593094\n",
      "Epoch:  8725 | Train Accurancy:  0.9297008141875267 | Validation Accurancy:  0.9346611797809601\n",
      "Epoch:  8726 | Train Accurancy:  0.9297017380595207 | Validation Accurancy:  0.9346652179956436\n",
      "Epoch:  8727 | Train Accurancy:  0.9297026693820953 | Validation Accurancy:  0.9346693009138107\n",
      "Epoch:  8728 | Train Accurancy:  0.9297035560011864 | Validation Accurancy:  0.9346734508872032\n",
      "Epoch:  8729 | Train Accurancy:  0.9297044798731804 | Validation Accurancy:  0.9346774891018867\n",
      "Epoch:  8730 | Train Accurancy:  0.9297054037451744 | Validation Accurancy:  0.9346815124154091\n",
      "Epoch:  8731 | Train Accurancy:  0.9297063276171684 | Validation Accurancy:  0.9346856400370598\n",
      "Epoch:  8732 | Train Accurancy:  0.9297071993350983 | Validation Accurancy:  0.9346897304058075\n",
      "Epoch:  8733 | Train Accurancy:  0.9297081679105759 | Validation Accurancy:  0.934693731367588\n",
      "Epoch:  8734 | Train Accurancy:  0.9297090321779251 | Validation Accurancy:  0.9346978217363358\n",
      "Epoch:  8735 | Train Accurancy:  0.9297099858522415 | Validation Accurancy:  0.9347019866108894\n",
      "Epoch:  8736 | Train Accurancy:  0.9297108426690102 | Validation Accurancy:  0.9347060173749924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8737 | Train Accurancy:  0.9297118037939072 | Validation Accurancy:  0.9347100928425789\n",
      "Epoch:  8738 | Train Accurancy:  0.9297127425670624 | Validation Accurancy:  0.9347141459584236\n",
      "Epoch:  8739 | Train Accurancy:  0.9297136887907982 | Validation Accurancy:  0.9347182288765907\n",
      "Epoch:  8740 | Train Accurancy:  0.9297145754098892 | Validation Accurancy:  0.9347223117947578\n",
      "Epoch:  8741 | Train Accurancy:  0.9297154918313026 | Validation Accurancy:  0.934726394712925\n",
      "Epoch:  8742 | Train Accurancy:  0.9297163709998131 | Validation Accurancy:  0.9347304850816727\n",
      "Epoch:  8743 | Train Accurancy:  0.9297172874212265 | Validation Accurancy:  0.9347346127033234\n",
      "Epoch:  8744 | Train Accurancy:  0.9297182261943817 | Validation Accurancy:  0.9347385913133621\n",
      "Epoch:  8745 | Train Accurancy:  0.929719090461731 | Validation Accurancy:  0.9347427040338516\n",
      "Epoch:  8746 | Train Accurancy:  0.9297200590372086 | Validation Accurancy:  0.9347467720508575\n",
      "Epoch:  8747 | Train Accurancy:  0.9297209307551384 | Validation Accurancy:  0.9347507804632187\n",
      "Epoch:  8748 | Train Accurancy:  0.9297218546271324 | Validation Accurancy:  0.9347549304366112\n",
      "Epoch:  8749 | Train Accurancy:  0.9297227784991264 | Validation Accurancy:  0.9347589313983917\n",
      "Epoch:  8750 | Train Accurancy:  0.9297237172722816 | Validation Accurancy:  0.9347629845142365\n",
      "Epoch:  8751 | Train Accurancy:  0.9297245815396309 | Validation Accurancy:  0.9347670748829842\n",
      "Epoch:  8752 | Train Accurancy:  0.9297255054116249 | Validation Accurancy:  0.9347711056470871\n",
      "Epoch:  8753 | Train Accurancy:  0.9297264590859413 | Validation Accurancy:  0.9347752556204796\n",
      "Epoch:  8754 | Train Accurancy:  0.9297273606061935 | Validation Accurancy:  0.9347793087363243\n",
      "Epoch:  8755 | Train Accurancy:  0.929728277027607 | Validation Accurancy:  0.9347833767533302\n",
      "Epoch:  8756 | Train Accurancy:  0.9297292083501816 | Validation Accurancy:  0.9347874000668526\n",
      "Epoch:  8757 | Train Accurancy:  0.9297300949692726 | Validation Accurancy:  0.9347914531826973\n",
      "Epoch:  8758 | Train Accurancy:  0.929730974137783 | Validation Accurancy:  0.934795506298542\n",
      "Epoch:  8759 | Train Accurancy:  0.9297319203615189 | Validation Accurancy:  0.9347996413707733\n",
      "Epoch:  8760 | Train Accurancy:  0.9297328367829323 | Validation Accurancy:  0.9348036572337151\n",
      "Epoch:  8761 | Train Accurancy:  0.9297337457537651 | Validation Accurancy:  0.9348076954483986\n",
      "Epoch:  8762 | Train Accurancy:  0.9297346547245979 | Validation Accurancy:  0.9348117187619209\n",
      "Epoch:  8763 | Train Accurancy:  0.9297355562448502 | Validation Accurancy:  0.9348157569766045\n",
      "Epoch:  8764 | Train Accurancy:  0.9297365173697472 | Validation Accurancy:  0.934819869697094\n",
      "Epoch:  8765 | Train Accurancy:  0.9297374114394188 | Validation Accurancy:  0.9348239600658417\n",
      "Epoch:  8766 | Train Accurancy:  0.9297382980585098 | Validation Accurancy:  0.9348280131816864\n",
      "Epoch:  8767 | Train Accurancy:  0.9297392070293427 | Validation Accurancy:  0.9348320960998535\n",
      "Epoch:  8768 | Train Accurancy:  0.9297401010990143 | Validation Accurancy:  0.9348361045122147\n",
      "Epoch:  8769 | Train Accurancy:  0.9297410398721695 | Validation Accurancy:  0.9348401874303818\n",
      "Epoch:  8770 | Train Accurancy:  0.9297419264912605 | Validation Accurancy:  0.9348442405462265\n",
      "Epoch:  8771 | Train Accurancy:  0.9297428131103516 | Validation Accurancy:  0.93484827876091\n",
      "Epoch:  8772 | Train Accurancy:  0.929743766784668 | Validation Accurancy:  0.9348523616790771\n",
      "Epoch:  8773 | Train Accurancy:  0.9297446087002754 | Validation Accurancy:  0.9348564445972443\n",
      "Epoch:  8774 | Train Accurancy:  0.9297456219792366 | Validation Accurancy:  0.9348604828119278\n",
      "Epoch:  8775 | Train Accurancy:  0.9297465234994888 | Validation Accurancy:  0.9348645359277725\n",
      "Epoch:  8776 | Train Accurancy:  0.9297473877668381 | Validation Accurancy:  0.9348686039447784\n",
      "Epoch:  8777 | Train Accurancy:  0.9297483265399933 | Validation Accurancy:  0.934872642159462\n",
      "Epoch:  8778 | Train Accurancy:  0.9297491982579231 | Validation Accurancy:  0.9348766356706619\n",
      "Epoch:  8779 | Train Accurancy:  0.9297500997781754 | Validation Accurancy:  0.9348807483911514\n",
      "Epoch:  8780 | Train Accurancy:  0.92975103110075 | Validation Accurancy:  0.9348848015069962\n",
      "Epoch:  8781 | Train Accurancy:  0.929751917719841 | Validation Accurancy:  0.9348888546228409\n",
      "Epoch:  8782 | Train Accurancy:  0.9297528341412544 | Validation Accurancy:  0.9348929077386856\n",
      "Epoch:  8783 | Train Accurancy:  0.9297537431120872 | Validation Accurancy:  0.9348969906568527\n",
      "Epoch:  8784 | Train Accurancy:  0.9297546669840813 | Validation Accurancy:  0.9349010437726974\n",
      "Epoch:  8785 | Train Accurancy:  0.9297555908560753 | Validation Accurancy:  0.9349050521850586\n",
      "Epoch:  8786 | Train Accurancy:  0.9297564849257469 | Validation Accurancy:  0.9349091723561287\n",
      "Epoch:  8787 | Train Accurancy:  0.9297573938965797 | Validation Accurancy:  0.9349131733179092\n",
      "Epoch:  8788 | Train Accurancy:  0.9297583103179932 | Validation Accurancy:  0.9349172115325928\n",
      "Epoch:  8789 | Train Accurancy:  0.9297591969370842 | Validation Accurancy:  0.9349212944507599\n",
      "Epoch:  8790 | Train Accurancy:  0.9297600761055946 | Validation Accurancy:  0.9349252730607986\n",
      "Epoch:  8791 | Train Accurancy:  0.9297610446810722 | Validation Accurancy:  0.9349293038249016\n",
      "Epoch:  8792 | Train Accurancy:  0.9297619387507439 | Validation Accurancy:  0.9349334239959717\n",
      "Epoch:  8793 | Train Accurancy:  0.9297628030180931 | Validation Accurancy:  0.934937410056591\n",
      "Epoch:  8794 | Train Accurancy:  0.9297637119889259 | Validation Accurancy:  0.9349415004253387\n",
      "Epoch:  8795 | Train Accurancy:  0.9297646433115005 | Validation Accurancy:  0.9349455013871193\n",
      "Epoch:  8796 | Train Accurancy:  0.9297655522823334 | Validation Accurancy:  0.934949554502964\n",
      "Epoch:  8797 | Train Accurancy:  0.9297664314508438 | Validation Accurancy:  0.9349536746740341\n",
      "Epoch:  8798 | Train Accurancy:  0.9297673776745796 | Validation Accurancy:  0.9349576309323311\n",
      "Epoch:  8799 | Train Accurancy:  0.9297683015465736 | Validation Accurancy:  0.9349616840481758\n",
      "Epoch:  8800 | Train Accurancy:  0.9297691434621811 | Validation Accurancy:  0.9349657669663429\n",
      "Epoch:  8801 | Train Accurancy:  0.9297700449824333 | Validation Accurancy:  0.9349697753787041\n",
      "Epoch:  8802 | Train Accurancy:  0.9297709539532661 | Validation Accurancy:  0.93497384339571\n",
      "Epoch:  8803 | Train Accurancy:  0.9297718703746796 | Validation Accurancy:  0.9349778518080711\n",
      "Epoch:  8804 | Train Accurancy:  0.9297727644443512 | Validation Accurancy:  0.9349819198250771\n",
      "Epoch:  8805 | Train Accurancy:  0.9297737553715706 | Validation Accurancy:  0.934985876083374\n",
      "Epoch:  8806 | Train Accurancy:  0.9297746419906616 | Validation Accurancy:  0.9349899590015411\n",
      "Epoch:  8807 | Train Accurancy:  0.9297755137085915 | Validation Accurancy:  0.9349939525127411\n",
      "Epoch:  8808 | Train Accurancy:  0.9297763779759407 | Validation Accurancy:  0.934998020529747\n",
      "Epoch:  8809 | Train Accurancy:  0.9297773018479347 | Validation Accurancy:  0.9350020736455917\n",
      "Epoch:  8810 | Train Accurancy:  0.9297782406210899 | Validation Accurancy:  0.9350059330463409\n",
      "Epoch:  8811 | Train Accurancy:  0.9297791048884392 | Validation Accurancy:  0.9350100234150887\n",
      "Epoch:  8812 | Train Accurancy:  0.929779976606369 | Validation Accurancy:  0.9350141659379005\n",
      "Epoch:  8813 | Train Accurancy:  0.9297809228301048 | Validation Accurancy:  0.9350181743502617\n",
      "Epoch:  8814 | Train Accurancy:  0.92978186160326 | Validation Accurancy:  0.9350222274661064\n",
      "Epoch:  8815 | Train Accurancy:  0.9297827184200287 | Validation Accurancy:  0.9350262358784676\n",
      "Epoch:  8816 | Train Accurancy:  0.9297836571931839 | Validation Accurancy:  0.9350301921367645\n",
      "Epoch:  8817 | Train Accurancy:  0.9297844991087914 | Validation Accurancy:  0.9350342452526093\n",
      "Epoch:  8818 | Train Accurancy:  0.9297854453325272 | Validation Accurancy:  0.9350382834672928\n",
      "Epoch:  8819 | Train Accurancy:  0.9297863021492958 | Validation Accurancy:  0.9350422248244286\n",
      "Epoch:  8820 | Train Accurancy:  0.9297872111201286 | Validation Accurancy:  0.9350463077425957\n",
      "Epoch:  8821 | Train Accurancy:  0.9297881126403809 | Validation Accurancy:  0.9350503161549568\n",
      "Epoch:  8822 | Train Accurancy:  0.9297890365123749 | Validation Accurancy:  0.9350543469190598\n",
      "Epoch:  8823 | Train Accurancy:  0.9297899529337883 | Validation Accurancy:  0.9350583702325821\n",
      "Epoch:  8824 | Train Accurancy:  0.9297908768057823 | Validation Accurancy:  0.935062475502491\n",
      "Epoch:  8825 | Train Accurancy:  0.929791733622551 | Validation Accurancy:  0.9350664764642715\n",
      "Epoch:  8826 | Train Accurancy:  0.9297926649451256 | Validation Accurancy:  0.9350704848766327\n",
      "Epoch:  8827 | Train Accurancy:  0.9297935664653778 | Validation Accurancy:  0.9350745379924774\n",
      "Epoch:  8828 | Train Accurancy:  0.929794430732727 | Validation Accurancy:  0.9350785538554192\n",
      "Epoch:  8829 | Train Accurancy:  0.9297953546047211 | Validation Accurancy:  0.9350826442241669\n",
      "Epoch:  8830 | Train Accurancy:  0.9297962561249733 | Validation Accurancy:  0.9350865855813026\n",
      "Epoch:  8831 | Train Accurancy:  0.9297970980405807 | Validation Accurancy:  0.9350906237959862\n",
      "Epoch:  8832 | Train Accurancy:  0.9297980070114136 | Validation Accurancy:  0.9350946247577667\n",
      "Epoch:  8833 | Train Accurancy:  0.9297989457845688 | Validation Accurancy:  0.9350986927747726\n",
      "Epoch:  8834 | Train Accurancy:  0.9297998696565628 | Validation Accurancy:  0.9351027458906174\n",
      "Epoch:  8835 | Train Accurancy:  0.9298007488250732 | Validation Accurancy:  0.9351067543029785\n",
      "Epoch:  8836 | Train Accurancy:  0.9298016056418419 | Validation Accurancy:  0.9351106956601143\n",
      "Epoch:  8837 | Train Accurancy:  0.9298025816679001 | Validation Accurancy:  0.9351147338747978\n",
      "Epoch:  8838 | Train Accurancy:  0.9298035055398941 | Validation Accurancy:  0.9351188167929649\n",
      "Epoch:  8839 | Train Accurancy:  0.929804340004921 | Validation Accurancy:  0.9351227134466171\n",
      "Epoch:  8840 | Train Accurancy:  0.929805263876915 | Validation Accurancy:  0.935126781463623\n",
      "Epoch:  8841 | Train Accurancy:  0.929806150496006 | Validation Accurancy:  0.9351307898759842\n",
      "Epoch:  8842 | Train Accurancy:  0.9298070594668388 | Validation Accurancy:  0.9351348206400871\n",
      "Epoch:  8843 | Train Accurancy:  0.9298079013824463 | Validation Accurancy:  0.9351388141512871\n",
      "Epoch:  8844 | Train Accurancy:  0.9298088476061821 | Validation Accurancy:  0.935142882168293\n",
      "Epoch:  8845 | Train Accurancy:  0.9298097118735313 | Validation Accurancy:  0.9351468086242676\n",
      "Epoch:  8846 | Train Accurancy:  0.9298105761408806 | Validation Accurancy:  0.9351508915424347\n",
      "Epoch:  8847 | Train Accurancy:  0.9298115223646164 | Validation Accurancy:  0.9351548701524734\n",
      "Epoch:  8848 | Train Accurancy:  0.929812416434288 | Validation Accurancy:  0.9351588562130928\n",
      "Epoch:  8849 | Train Accurancy:  0.9298133328557014 | Validation Accurancy:  0.9351629242300987\n",
      "Epoch:  8850 | Train Accurancy:  0.9298142269253731 | Validation Accurancy:  0.9351668208837509\n",
      "Epoch:  8851 | Train Accurancy:  0.9298150911927223 | Validation Accurancy:  0.9351708739995956\n",
      "Epoch:  8852 | Train Accurancy:  0.9298160076141357 | Validation Accurancy:  0.9351749420166016\n",
      "Epoch:  8853 | Train Accurancy:  0.929816871881485 | Validation Accurancy:  0.9351788982748985\n",
      "Epoch:  8854 | Train Accurancy:  0.9298177734017372 | Validation Accurancy:  0.9351828917860985\n",
      "Epoch:  8855 | Train Accurancy:  0.9298186972737312 | Validation Accurancy:  0.9351870194077492\n",
      "Epoch:  8856 | Train Accurancy:  0.9298195540904999 | Validation Accurancy:  0.9351909309625626\n",
      "Epoch:  8857 | Train Accurancy:  0.9298205152153969 | Validation Accurancy:  0.9351949393749237\n",
      "Epoch:  8858 | Train Accurancy:  0.9298214018344879 | Validation Accurancy:  0.9351990073919296\n",
      "Epoch:  8859 | Train Accurancy:  0.9298222959041595 | Validation Accurancy:  0.9352029487490654\n",
      "Epoch:  8860 | Train Accurancy:  0.9298231974244118 | Validation Accurancy:  0.9352069720625877\n",
      "Epoch:  8861 | Train Accurancy:  0.929824061691761 | Validation Accurancy:  0.9352109879255295\n",
      "Epoch:  8862 | Train Accurancy:  0.9298249557614326 | Validation Accurancy:  0.9352149814367294\n",
      "Epoch:  8863 | Train Accurancy:  0.9298258572816849 | Validation Accurancy:  0.9352189376950264\n",
      "Epoch:  8864 | Train Accurancy:  0.9298267662525177 | Validation Accurancy:  0.9352229312062263\n",
      "Epoch:  8865 | Train Accurancy:  0.9298276454210281 | Validation Accurancy:  0.9352269470691681\n",
      "Epoch:  8866 | Train Accurancy:  0.929828517138958 | Validation Accurancy:  0.935231015086174\n",
      "Epoch:  8867 | Train Accurancy:  0.9298294112086296 | Validation Accurancy:  0.935235008597374\n",
      "Epoch:  8868 | Train Accurancy:  0.9298303052783012 | Validation Accurancy:  0.9352389499545097\n",
      "Epoch:  8869 | Train Accurancy:  0.9298312216997147 | Validation Accurancy:  0.9352429211139679\n",
      "Epoch:  8870 | Train Accurancy:  0.9298320710659027 | Validation Accurancy:  0.9352470114827156\n",
      "Epoch:  8871 | Train Accurancy:  0.9298329874873161 | Validation Accurancy:  0.9352509304881096\n",
      "Epoch:  8872 | Train Accurancy:  0.9298339188098907 | Validation Accurancy:  0.9352549836039543\n",
      "Epoch:  8873 | Train Accurancy:  0.9298348054289818 | Validation Accurancy:  0.9352589100599289\n",
      "Epoch:  8874 | Train Accurancy:  0.9298356845974922 | Validation Accurancy:  0.9352628514170647\n",
      "Epoch:  8875 | Train Accurancy:  0.9298365563154221 | Validation Accurancy:  0.935266874730587\n",
      "Epoch:  8876 | Train Accurancy:  0.9298374280333519 | Validation Accurancy:  0.9352709129452705\n",
      "Epoch:  8877 | Train Accurancy:  0.9298383519053459 | Validation Accurancy:  0.9352748692035675\n",
      "Epoch:  8878 | Train Accurancy:  0.9298392310738564 | Validation Accurancy:  0.9352788776159286\n",
      "Epoch:  8879 | Train Accurancy:  0.9298401549458504 | Validation Accurancy:  0.9352828040719032\n",
      "Epoch:  8880 | Train Accurancy:  0.9298410564661026 | Validation Accurancy:  0.9352868422865868\n",
      "Epoch:  8881 | Train Accurancy:  0.9298419132828712 | Validation Accurancy:  0.9352908283472061\n",
      "Epoch:  8882 | Train Accurancy:  0.9298427551984787 | Validation Accurancy:  0.9352948814630508\n",
      "Epoch:  8883 | Train Accurancy:  0.9298437163233757 | Validation Accurancy:  0.9352987930178642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8884 | Train Accurancy:  0.9298446252942085 | Validation Accurancy:  0.9353027790784836\n",
      "Epoch:  8885 | Train Accurancy:  0.929845467209816 | Validation Accurancy:  0.9353067725896835\n",
      "Epoch:  8886 | Train Accurancy:  0.9298463389277458 | Validation Accurancy:  0.9353107437491417\n",
      "Epoch:  8887 | Train Accurancy:  0.929847277700901 | Validation Accurancy:  0.9353148490190506\n",
      "Epoch:  8888 | Train Accurancy:  0.9298481494188309 | Validation Accurancy:  0.9353189021348953\n",
      "Epoch:  8889 | Train Accurancy:  0.9298490211367607 | Validation Accurancy:  0.9353228062391281\n",
      "Epoch:  8890 | Train Accurancy:  0.9298499152064323 | Validation Accurancy:  0.9353267997503281\n",
      "Epoch:  8891 | Train Accurancy:  0.9298508390784264 | Validation Accurancy:  0.9353307858109474\n",
      "Epoch:  8892 | Train Accurancy:  0.9298517182469368 | Validation Accurancy:  0.9353347942233086\n",
      "Epoch:  8893 | Train Accurancy:  0.9298526272177696 | Validation Accurancy:  0.9353387653827667\n",
      "Epoch:  8894 | Train Accurancy:  0.9298535212874413 | Validation Accurancy:  0.9353427216410637\n",
      "Epoch:  8895 | Train Accurancy:  0.9298543781042099 | Validation Accurancy:  0.9353467002511024\n",
      "Epoch:  8896 | Train Accurancy:  0.9298552647233009 | Validation Accurancy:  0.9353507533669472\n",
      "Epoch:  8897 | Train Accurancy:  0.9298561811447144 | Validation Accurancy:  0.9353545680642128\n",
      "Epoch:  8898 | Train Accurancy:  0.9298570901155472 | Validation Accurancy:  0.9353586211800575\n",
      "Epoch:  8899 | Train Accurancy:  0.9298579320311546 | Validation Accurancy:  0.9353626444935799\n",
      "Epoch:  8900 | Train Accurancy:  0.9298588335514069 | Validation Accurancy:  0.9353666603565216\n",
      "Epoch:  8901 | Train Accurancy:  0.9298597127199173 | Validation Accurancy:  0.9353706166148186\n",
      "Epoch:  8902 | Train Accurancy:  0.9298606216907501 | Validation Accurancy:  0.9353745952248573\n",
      "Epoch:  8903 | Train Accurancy:  0.9298614636063576 | Validation Accurancy:  0.9353785812854767\n",
      "Epoch:  8904 | Train Accurancy:  0.9298623725771904 | Validation Accurancy:  0.9353824928402901\n",
      "Epoch:  8905 | Train Accurancy:  0.9298632442951202 | Validation Accurancy:  0.935386449098587\n",
      "Epoch:  8906 | Train Accurancy:  0.9298641532659531 | Validation Accurancy:  0.9353904575109482\n",
      "Epoch:  8907 | Train Accurancy:  0.9298650398850441 | Validation Accurancy:  0.9353944808244705\n",
      "Epoch:  8908 | Train Accurancy:  0.9298659041523933 | Validation Accurancy:  0.9353984668850899\n",
      "Epoch:  8909 | Train Accurancy:  0.9298667907714844 | Validation Accurancy:  0.935402438044548\n",
      "Epoch:  8910 | Train Accurancy:  0.9298677071928978 | Validation Accurancy:  0.9354063645005226\n",
      "Epoch:  8911 | Train Accurancy:  0.929868571460247 | Validation Accurancy:  0.9354103580117226\n",
      "Epoch:  8912 | Train Accurancy:  0.9298694357275963 | Validation Accurancy:  0.9354143962264061\n",
      "Epoch:  8913 | Train Accurancy:  0.9298703595995903 | Validation Accurancy:  0.9354183524847031\n",
      "Epoch:  8914 | Train Accurancy:  0.9298712387681007 | Validation Accurancy:  0.9354223385453224\n",
      "Epoch:  8915 | Train Accurancy:  0.929872140288353 | Validation Accurancy:  0.9354262501001358\n",
      "Epoch:  8916 | Train Accurancy:  0.9298729673027992 | Validation Accurancy:  0.9354302436113358\n",
      "Epoch:  8917 | Train Accurancy:  0.9298738911747932 | Validation Accurancy:  0.9354341700673103\n",
      "Epoch:  8918 | Train Accurancy:  0.9298747852444649 | Validation Accurancy:  0.9354381710290909\n",
      "Epoch:  8919 | Train Accurancy:  0.9298756569623947 | Validation Accurancy:  0.935442142188549\n",
      "Epoch:  8920 | Train Accurancy:  0.9298765510320663 | Validation Accurancy:  0.9354460388422012\n",
      "Epoch:  8921 | Train Accurancy:  0.9298773929476738 | Validation Accurancy:  0.9354500100016594\n",
      "Epoch:  8922 | Train Accurancy:  0.9298782795667648 | Validation Accurancy:  0.9354539886116982\n",
      "Epoch:  8923 | Train Accurancy:  0.9298791959881783 | Validation Accurancy:  0.9354579746723175\n",
      "Epoch:  8924 | Train Accurancy:  0.9298800975084305 | Validation Accurancy:  0.935462012887001\n",
      "Epoch:  8925 | Train Accurancy:  0.9298809617757797 | Validation Accurancy:  0.935465894639492\n",
      "Epoch:  8926 | Train Accurancy:  0.9298818409442902 | Validation Accurancy:  0.9354699105024338\n",
      "Epoch:  8927 | Train Accurancy:  0.9298827648162842 | Validation Accurancy:  0.9354738220572472\n",
      "Epoch:  8928 | Train Accurancy:  0.9298836439847946 | Validation Accurancy:  0.9354777783155441\n",
      "Epoch:  8929 | Train Accurancy:  0.929884523153305 | Validation Accurancy:  0.9354817420244217\n",
      "Epoch:  8930 | Train Accurancy:  0.9298853799700737 | Validation Accurancy:  0.9354856163263321\n",
      "Epoch:  8931 | Train Accurancy:  0.9298863187432289 | Validation Accurancy:  0.9354895874857903\n",
      "Epoch:  8932 | Train Accurancy:  0.9298871904611588 | Validation Accurancy:  0.9354936107993126\n",
      "Epoch:  8933 | Train Accurancy:  0.9298880770802498 | Validation Accurancy:  0.9354974925518036\n",
      "Epoch:  8934 | Train Accurancy:  0.929888941347599 | Validation Accurancy:  0.9355015307664871\n",
      "Epoch:  8935 | Train Accurancy:  0.9298898354172707 | Validation Accurancy:  0.9355054348707199\n",
      "Epoch:  8936 | Train Accurancy:  0.9298907145857811 | Validation Accurancy:  0.9355094283819199\n",
      "Epoch:  8937 | Train Accurancy:  0.9298915863037109 | Validation Accurancy:  0.9355134293437004\n",
      "Epoch:  8938 | Train Accurancy:  0.9298924505710602 | Validation Accurancy:  0.935517355799675\n",
      "Epoch:  8939 | Train Accurancy:  0.9298933297395706 | Validation Accurancy:  0.9355213642120361\n",
      "Epoch:  8940 | Train Accurancy:  0.9298942014575005 | Validation Accurancy:  0.9355252906680107\n",
      "Epoch:  8941 | Train Accurancy:  0.9298950806260109 | Validation Accurancy:  0.9355291873216629\n",
      "Epoch:  8942 | Train Accurancy:  0.9298960268497467 | Validation Accurancy:  0.9355332180857658\n",
      "Epoch:  8943 | Train Accurancy:  0.929896853864193 | Validation Accurancy:  0.9355371966958046\n",
      "Epoch:  8944 | Train Accurancy:  0.9298977553844452 | Validation Accurancy:  0.935541108250618\n",
      "Epoch:  8945 | Train Accurancy:  0.9298986420035362 | Validation Accurancy:  0.9355450496077538\n",
      "Epoch:  8946 | Train Accurancy:  0.9298994764685631 | Validation Accurancy:  0.9355489909648895\n",
      "Epoch:  8947 | Train Accurancy:  0.9299003556370735 | Validation Accurancy:  0.9355529919266701\n",
      "Epoch:  8948 | Train Accurancy:  0.9299012795090675 | Validation Accurancy:  0.9355569034814835\n",
      "Epoch:  8949 | Train Accurancy:  0.9299021735787392 | Validation Accurancy:  0.9355608448386192\n",
      "Epoch:  8950 | Train Accurancy:  0.929903008043766 | Validation Accurancy:  0.9355648383498192\n",
      "Epoch:  8951 | Train Accurancy:  0.9299038723111153 | Validation Accurancy:  0.9355687275528908\n",
      "Epoch:  8952 | Train Accurancy:  0.9299047738313675 | Validation Accurancy:  0.9355727061629295\n",
      "Epoch:  8953 | Train Accurancy:  0.9299056753516197 | Validation Accurancy:  0.9355766624212265\n",
      "Epoch:  8954 | Train Accurancy:  0.9299065098166466 | Validation Accurancy:  0.9355805739760399\n",
      "Epoch:  8955 | Train Accurancy:  0.92990742623806 | Validation Accurancy:  0.9355845153331757\n",
      "Epoch:  8956 | Train Accurancy:  0.9299082979559898 | Validation Accurancy:  0.935588501393795\n",
      "Epoch:  8957 | Train Accurancy:  0.9299092143774033 | Validation Accurancy:  0.9355924129486084\n",
      "Epoch:  8958 | Train Accurancy:  0.9299101009964943 | Validation Accurancy:  0.9355964511632919\n",
      "Epoch:  8959 | Train Accurancy:  0.9299109503626823 | Validation Accurancy:  0.9356004223227501\n",
      "Epoch:  8960 | Train Accurancy:  0.929911844432354 | Validation Accurancy:  0.9356043338775635\n",
      "Epoch:  8961 | Train Accurancy:  0.929912656545639 | Validation Accurancy:  0.9356082901358604\n",
      "Epoch:  8962 | Train Accurancy:  0.9299135506153107 | Validation Accurancy:  0.9356122016906738\n",
      "Epoch:  8963 | Train Accurancy:  0.9299144297838211 | Validation Accurancy:  0.9356161430478096\n",
      "Epoch:  8964 | Train Accurancy:  0.9299153313040733 | Validation Accurancy:  0.9356200844049454\n",
      "Epoch:  8965 | Train Accurancy:  0.9299162104725838 | Validation Accurancy:  0.93562401086092\n",
      "Epoch:  8966 | Train Accurancy:  0.9299170970916748 | Validation Accurancy:  0.9356279671192169\n",
      "Epoch:  8967 | Train Accurancy:  0.9299179762601852 | Validation Accurancy:  0.9356318786740303\n",
      "Epoch:  8968 | Train Accurancy:  0.9299188554286957 | Validation Accurancy:  0.9356358870863914\n",
      "Epoch:  8969 | Train Accurancy:  0.9299197271466255 | Validation Accurancy:  0.9356398433446884\n",
      "Epoch:  8970 | Train Accurancy:  0.9299206212162971 | Validation Accurancy:  0.9356437399983406\n",
      "Epoch:  8971 | Train Accurancy:  0.9299214705824852 | Validation Accurancy:  0.9356476292014122\n",
      "Epoch:  8972 | Train Accurancy:  0.9299223721027374 | Validation Accurancy:  0.935651570558548\n",
      "Epoch:  8973 | Train Accurancy:  0.9299232289195061 | Validation Accurancy:  0.9356556087732315\n",
      "Epoch:  8974 | Train Accurancy:  0.9299240931868553 | Validation Accurancy:  0.9356595352292061\n",
      "Epoch:  8975 | Train Accurancy:  0.9299249649047852 | Validation Accurancy:  0.9356634467840195\n",
      "Epoch:  8976 | Train Accurancy:  0.9299258515238762 | Validation Accurancy:  0.9356673061847687\n",
      "Epoch:  8977 | Train Accurancy:  0.929926723241806 | Validation Accurancy:  0.9356712177395821\n",
      "Epoch:  8978 | Train Accurancy:  0.9299275726079941 | Validation Accurancy:  0.9356751441955566\n",
      "Epoch:  8979 | Train Accurancy:  0.9299284964799881 | Validation Accurancy:  0.93567905575037\n",
      "Epoch:  8980 | Train Accurancy:  0.9299293830990791 | Validation Accurancy:  0.935683012008667\n",
      "Epoch:  8981 | Train Accurancy:  0.9299302250146866 | Validation Accurancy:  0.935686968266964\n",
      "Epoch:  8982 | Train Accurancy:  0.9299311190843582 | Validation Accurancy:  0.935690812766552\n",
      "Epoch:  8983 | Train Accurancy:  0.9299320131540298 | Validation Accurancy:  0.9356948509812355\n",
      "Epoch:  8984 | Train Accurancy:  0.9299328476190567 | Validation Accurancy:  0.9356987774372101\n",
      "Epoch:  8985 | Train Accurancy:  0.9299337640404701 | Validation Accurancy:  0.9357026070356369\n",
      "Epoch:  8986 | Train Accurancy:  0.9299345910549164 | Validation Accurancy:  0.9357066601514816\n",
      "Epoch:  8987 | Train Accurancy:  0.9299354627728462 | Validation Accurancy:  0.9357106387615204\n",
      "Epoch:  8988 | Train Accurancy:  0.9299363791942596 | Validation Accurancy:  0.9357144683599472\n",
      "Epoch:  8989 | Train Accurancy:  0.9299372211098671 | Validation Accurancy:  0.935718409717083\n",
      "Epoch:  8990 | Train Accurancy:  0.9299381226301193 | Validation Accurancy:  0.9357223212718964\n",
      "Epoch:  8991 | Train Accurancy:  0.9299389496445656 | Validation Accurancy:  0.9357261955738068\n",
      "Epoch:  8992 | Train Accurancy:  0.9299398586153984 | Validation Accurancy:  0.9357301890850067\n",
      "Epoch:  8993 | Train Accurancy:  0.929940789937973 | Validation Accurancy:  0.9357341602444649\n",
      "Epoch:  8994 | Train Accurancy:  0.9299415722489357 | Validation Accurancy:  0.9357380867004395\n",
      "Epoch:  8995 | Train Accurancy:  0.9299424663186073 | Validation Accurancy:  0.9357419982552528\n",
      "Epoch:  8996 | Train Accurancy:  0.9299433678388596 | Validation Accurancy:  0.935745857656002\n",
      "Epoch:  8997 | Train Accurancy:  0.9299442619085312 | Validation Accurancy:  0.9357497990131378\n",
      "Epoch:  8998 | Train Accurancy:  0.9299451112747192 | Validation Accurancy:  0.9357537776231766\n",
      "Epoch:  8999 | Train Accurancy:  0.9299459978938103 | Validation Accurancy:  0.9357576370239258\n",
      "Epoch:  9000 | Train Accurancy:  0.9299468621611595 | Validation Accurancy:  0.935761496424675\n",
      "Epoch:  9001 | Train Accurancy:  0.9299477487802505 | Validation Accurancy:  0.9357654228806496\n",
      "Epoch:  9002 | Train Accurancy:  0.9299485757946968 | Validation Accurancy:  0.9357694163918495\n",
      "Epoch:  9003 | Train Accurancy:  0.9299494549632072 | Validation Accurancy:  0.9357732906937599\n",
      "Epoch:  9004 | Train Accurancy:  0.9299502894282341 | Validation Accurancy:  0.9357772693037987\n",
      "Epoch:  9005 | Train Accurancy:  0.9299511983990669 | Validation Accurancy:  0.9357812404632568\n",
      "Epoch:  9006 | Train Accurancy:  0.9299521073698997 | Validation Accurancy:  0.9357851669192314\n",
      "Epoch:  9007 | Train Accurancy:  0.9299529269337654 | Validation Accurancy:  0.9357890412211418\n",
      "Epoch:  9008 | Train Accurancy:  0.9299537688493729 | Validation Accurancy:  0.9357929080724716\n",
      "Epoch:  9009 | Train Accurancy:  0.9299546107649803 | Validation Accurancy:  0.9357968494296074\n",
      "Epoch:  9010 | Train Accurancy:  0.9299555718898773 | Validation Accurancy:  0.9358008727431297\n",
      "Epoch:  9011 | Train Accurancy:  0.929956428706646 | Validation Accurancy:  0.9358047172427177\n",
      "Epoch:  9012 | Train Accurancy:  0.929957278072834 | Validation Accurancy:  0.9358085617423058\n",
      "Epoch:  9013 | Train Accurancy:  0.9299581721425056 | Validation Accurancy:  0.9358125552535057\n",
      "Epoch:  9014 | Train Accurancy:  0.9299590364098549 | Validation Accurancy:  0.9358164146542549\n",
      "Epoch:  9015 | Train Accurancy:  0.9299599304795265 | Validation Accurancy:  0.9358202964067459\n",
      "Epoch:  9016 | Train Accurancy:  0.9299607574939728 | Validation Accurancy:  0.9358241856098175\n",
      "Epoch:  9017 | Train Accurancy:  0.9299616292119026 | Validation Accurancy:  0.9358281940221786\n",
      "Epoch:  9018 | Train Accurancy:  0.9299624860286713 | Validation Accurancy:  0.935832105576992\n",
      "Epoch:  9019 | Train Accurancy:  0.9299633949995041 | Validation Accurancy:  0.9358359351754189\n",
      "Epoch:  9020 | Train Accurancy:  0.9299642890691757 | Validation Accurancy:  0.9358398094773293\n",
      "Epoch:  9021 | Train Accurancy:  0.929965116083622 | Validation Accurancy:  0.9358437359333038\n",
      "Epoch:  9022 | Train Accurancy:  0.9299659729003906 | Validation Accurancy:  0.935847632586956\n",
      "Epoch:  9023 | Train Accurancy:  0.9299668297171593 | Validation Accurancy:  0.9358515590429306\n",
      "Epoch:  9024 | Train Accurancy:  0.9299677610397339 | Validation Accurancy:  0.9358554556965828\n",
      "Epoch:  9025 | Train Accurancy:  0.9299685880541801 | Validation Accurancy:  0.935859426856041\n",
      "Epoch:  9026 | Train Accurancy:  0.9299694299697876 | Validation Accurancy:  0.935863271355629\n",
      "Epoch:  9027 | Train Accurancy:  0.9299703016877174 | Validation Accurancy:  0.9358671978116035\n",
      "Epoch:  9028 | Train Accurancy:  0.9299711808562279 | Validation Accurancy:  0.9358711093664169\n",
      "Epoch:  9029 | Train Accurancy:  0.9299720749258995 | Validation Accurancy:  0.9358750656247139\n",
      "Epoch:  9030 | Train Accurancy:  0.9299729242920876 | Validation Accurancy:  0.9358789473772049\n",
      "Epoch:  9031 | Train Accurancy:  0.929973766207695 | Validation Accurancy:  0.9358828067779541\n",
      "Epoch:  9032 | Train Accurancy:  0.9299746602773666 | Validation Accurancy:  0.9358867928385735\n",
      "Epoch:  9033 | Train Accurancy:  0.9299755319952965 | Validation Accurancy:  0.9358906298875809\n",
      "Epoch:  9034 | Train Accurancy:  0.9299763739109039 | Validation Accurancy:  0.9358945041894913\n",
      "Epoch:  9035 | Train Accurancy:  0.929977223277092 | Validation Accurancy:  0.9358984306454659\n",
      "Epoch:  9036 | Train Accurancy:  0.9299781173467636 | Validation Accurancy:  0.935902327299118\n",
      "Epoch:  9037 | Train Accurancy:  0.9299790114164352 | Validation Accurancy:  0.9359062165021896\n",
      "Epoch:  9038 | Train Accurancy:  0.9299798831343651 | Validation Accurancy:  0.9359101131558418\n",
      "Epoch:  9039 | Train Accurancy:  0.9299806877970695 | Validation Accurancy:  0.935914009809494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9040 | Train Accurancy:  0.929981604218483 | Validation Accurancy:  0.935917966067791\n",
      "Epoch:  9041 | Train Accurancy:  0.9299824610352516 | Validation Accurancy:  0.9359218403697014\n",
      "Epoch:  9042 | Train Accurancy:  0.9299833029508591 | Validation Accurancy:  0.9359257891774178\n",
      "Epoch:  9043 | Train Accurancy:  0.9299841821193695 | Validation Accurancy:  0.935929648578167\n",
      "Epoch:  9044 | Train Accurancy:  0.929985024034977 | Validation Accurancy:  0.9359335079789162\n",
      "Epoch:  9045 | Train Accurancy:  0.9299859032034874 | Validation Accurancy:  0.935937374830246\n",
      "Epoch:  9046 | Train Accurancy:  0.9299867674708366 | Validation Accurancy:  0.9359412640333176\n",
      "Epoch:  9047 | Train Accurancy:  0.9299876764416695 | Validation Accurancy:  0.9359452053904533\n",
      "Epoch:  9048 | Train Accurancy:  0.9299885183572769 | Validation Accurancy:  0.9359491020441055\n",
      "Epoch:  9049 | Train Accurancy:  0.9299893751740456 | Validation Accurancy:  0.9359529167413712\n",
      "Epoch:  9050 | Train Accurancy:  0.9299902468919754 | Validation Accurancy:  0.9359568580985069\n",
      "Epoch:  9051 | Train Accurancy:  0.9299911111593246 | Validation Accurancy:  0.9359606727957726\n",
      "Epoch:  9052 | Train Accurancy:  0.9299919456243515 | Validation Accurancy:  0.9359645694494247\n",
      "Epoch:  9053 | Train Accurancy:  0.9299928322434425 | Validation Accurancy:  0.9359684959053993\n",
      "Epoch:  9054 | Train Accurancy:  0.92999367415905 | Validation Accurancy:  0.9359723702073097\n",
      "Epoch:  9055 | Train Accurancy:  0.9299945160746574 | Validation Accurancy:  0.9359763339161873\n",
      "Epoch:  9056 | Train Accurancy:  0.9299954324960709 | Validation Accurancy:  0.9359802529215813\n",
      "Epoch:  9057 | Train Accurancy:  0.9299962818622589 | Validation Accurancy:  0.9359841048717499\n",
      "Epoch:  9058 | Train Accurancy:  0.929997131228447 | Validation Accurancy:  0.9359879791736603\n",
      "Epoch:  9059 | Train Accurancy:  0.9299980401992798 | Validation Accurancy:  0.9359918609261513\n",
      "Epoch:  9060 | Train Accurancy:  0.9299988746643066 | Validation Accurancy:  0.9359958469867706\n",
      "Epoch:  9061 | Train Accurancy:  0.9299997463822365 | Validation Accurancy:  0.9359996765851974\n",
      "Epoch:  9062 | Train Accurancy:  0.9300005584955215 | Validation Accurancy:  0.9360035434365273\n",
      "Epoch:  9063 | Train Accurancy:  0.9300014153122902 | Validation Accurancy:  0.9360074698925018\n",
      "Epoch:  9064 | Train Accurancy:  0.9300022944808006 | Validation Accurancy:  0.9360113814473152\n",
      "Epoch:  9065 | Train Accurancy:  0.9300031736493111 | Validation Accurancy:  0.936015285551548\n",
      "Epoch:  9066 | Train Accurancy:  0.9300041049718857 | Validation Accurancy:  0.9360191375017166\n",
      "Epoch:  9067 | Train Accurancy:  0.9300049468874931 | Validation Accurancy:  0.9360230937600136\n",
      "Epoch:  9068 | Train Accurancy:  0.9300058037042618 | Validation Accurancy:  0.9360268786549568\n",
      "Epoch:  9069 | Train Accurancy:  0.9300066232681274 | Validation Accurancy:  0.9360307827591896\n",
      "Epoch:  9070 | Train Accurancy:  0.9300075024366379 | Validation Accurancy:  0.936034694314003\n",
      "Epoch:  9071 | Train Accurancy:  0.9300083294510841 | Validation Accurancy:  0.9360384941101074\n",
      "Epoch:  9072 | Train Accurancy:  0.9300092309713364 | Validation Accurancy:  0.9360424801707268\n",
      "Epoch:  9073 | Train Accurancy:  0.9300100579857826 | Validation Accurancy:  0.9360462948679924\n",
      "Epoch:  9074 | Train Accurancy:  0.9300108999013901 | Validation Accurancy:  0.9360502734780312\n",
      "Epoch:  9075 | Train Accurancy:  0.9300117716193199 | Validation Accurancy:  0.9360540583729744\n",
      "Epoch:  9076 | Train Accurancy:  0.9300126507878304 | Validation Accurancy:  0.9360578879714012\n",
      "Epoch:  9077 | Train Accurancy:  0.9300135299563408 | Validation Accurancy:  0.9360617622733116\n",
      "Epoch:  9078 | Train Accurancy:  0.9300143867731094 | Validation Accurancy:  0.9360656440258026\n",
      "Epoch:  9079 | Train Accurancy:  0.9300152361392975 | Validation Accurancy:  0.9360695332288742\n",
      "Epoch:  9080 | Train Accurancy:  0.9300160557031631 | Validation Accurancy:  0.9360734969377518\n",
      "Epoch:  9081 | Train Accurancy:  0.930016927421093 | Validation Accurancy:  0.9360772594809532\n",
      "Epoch:  9082 | Train Accurancy:  0.930017814040184 | Validation Accurancy:  0.936081126332283\n",
      "Epoch:  9083 | Train Accurancy:  0.9300186485052109 | Validation Accurancy:  0.9360850155353546\n",
      "Epoch:  9084 | Train Accurancy:  0.9300195425748825 | Validation Accurancy:  0.9360888302326202\n",
      "Epoch:  9085 | Train Accurancy:  0.9300204068422318 | Validation Accurancy:  0.9360926449298859\n",
      "Epoch:  9086 | Train Accurancy:  0.9300212860107422 | Validation Accurancy:  0.9360966235399246\n",
      "Epoch:  9087 | Train Accurancy:  0.9300220906734467 | Validation Accurancy:  0.9361004531383514\n",
      "Epoch:  9088 | Train Accurancy:  0.9300229623913765 | Validation Accurancy:  0.9361043944954872\n",
      "Epoch:  9089 | Train Accurancy:  0.9300238564610481 | Validation Accurancy:  0.9361082389950752\n",
      "Epoch:  9090 | Train Accurancy:  0.9300246462225914 | Validation Accurancy:  0.9361121505498886\n",
      "Epoch:  9091 | Train Accurancy:  0.9300254881381989 | Validation Accurancy:  0.9361160472035408\n",
      "Epoch:  9092 | Train Accurancy:  0.9300263822078705 | Validation Accurancy:  0.9361198768019676\n",
      "Epoch:  9093 | Train Accurancy:  0.9300272464752197 | Validation Accurancy:  0.9361236914992332\n",
      "Epoch:  9094 | Train Accurancy:  0.9300280958414078 | Validation Accurancy:  0.936127632856369\n",
      "Epoch:  9095 | Train Accurancy:  0.9300289675593376 | Validation Accurancy:  0.9361314326524734\n",
      "Epoch:  9096 | Train Accurancy:  0.9300298318266869 | Validation Accurancy:  0.9361353367567062\n",
      "Epoch:  9097 | Train Accurancy:  0.9300306662917137 | Validation Accurancy:  0.9361391067504883\n",
      "Epoch:  9098 | Train Accurancy:  0.9300315678119659 | Validation Accurancy:  0.9361431151628494\n",
      "Epoch:  9099 | Train Accurancy:  0.9300324022769928 | Validation Accurancy:  0.9361469894647598\n",
      "Epoch:  9100 | Train Accurancy:  0.9300332516431808 | Validation Accurancy:  0.9361508712172508\n",
      "Epoch:  9101 | Train Accurancy:  0.9300340712070465 | Validation Accurancy:  0.9361546859145164\n",
      "Epoch:  9102 | Train Accurancy:  0.9300350099802017 | Validation Accurancy:  0.9361585304141045\n",
      "Epoch:  9103 | Train Accurancy:  0.9300358444452286 | Validation Accurancy:  0.9361624717712402\n",
      "Epoch:  9104 | Train Accurancy:  0.9300366640090942 | Validation Accurancy:  0.9361662566661835\n",
      "Epoch:  9105 | Train Accurancy:  0.9300375506281853 | Validation Accurancy:  0.9361701458692551\n",
      "Epoch:  9106 | Train Accurancy:  0.9300384223461151 | Validation Accurancy:  0.9361739978194237\n",
      "Epoch:  9107 | Train Accurancy:  0.9300392717123032 | Validation Accurancy:  0.9361778423190117\n",
      "Epoch:  9108 | Train Accurancy:  0.930040143430233 | Validation Accurancy:  0.9361817538738251\n",
      "Epoch:  9109 | Train Accurancy:  0.9300409629940987 | Validation Accurancy:  0.9361856803297997\n",
      "Epoch:  9110 | Train Accurancy:  0.9300418049097061 | Validation Accurancy:  0.9361894801259041\n",
      "Epoch:  9111 | Train Accurancy:  0.9300427064299583 | Validation Accurancy:  0.9361933097243309\n",
      "Epoch:  9112 | Train Accurancy:  0.9300435110926628 | Validation Accurancy:  0.9361972361803055\n",
      "Epoch:  9113 | Train Accurancy:  0.930044375360012 | Validation Accurancy:  0.9362009987235069\n",
      "Epoch:  9114 | Train Accurancy:  0.9300452023744583 | Validation Accurancy:  0.9362048432230949\n",
      "Epoch:  9115 | Train Accurancy:  0.9300461038947105 | Validation Accurancy:  0.9362086802721024\n",
      "Epoch:  9116 | Train Accurancy:  0.930046945810318 | Validation Accurancy:  0.9362125843763351\n",
      "Epoch:  9117 | Train Accurancy:  0.9300478026270866 | Validation Accurancy:  0.9362164363265038\n",
      "Epoch:  9118 | Train Accurancy:  0.9300486519932747 | Validation Accurancy:  0.9362203106284142\n",
      "Epoch:  9119 | Train Accurancy:  0.9300495088100433 | Validation Accurancy:  0.9362241253256798\n",
      "Epoch:  9120 | Train Accurancy:  0.9300503730773926 | Validation Accurancy:  0.936228021979332\n",
      "Epoch:  9121 | Train Accurancy:  0.930051214993 | Validation Accurancy:  0.9362318366765976\n",
      "Epoch:  9122 | Train Accurancy:  0.9300520792603493 | Validation Accurancy:  0.936235599219799\n",
      "Epoch:  9123 | Train Accurancy:  0.9300529509782791 | Validation Accurancy:  0.9362395256757736\n",
      "Epoch:  9124 | Train Accurancy:  0.930053785443306 | Validation Accurancy:  0.9362434893846512\n",
      "Epoch:  9125 | Train Accurancy:  0.930054634809494 | Validation Accurancy:  0.9362473040819168\n",
      "Epoch:  9126 | Train Accurancy:  0.9300554841756821 | Validation Accurancy:  0.9362510964274406\n",
      "Epoch:  9127 | Train Accurancy:  0.9300563409924507 | Validation Accurancy:  0.9362548962235451\n",
      "Epoch:  9128 | Train Accurancy:  0.9300571903586388 | Validation Accurancy:  0.9362588375806808\n",
      "Epoch:  9129 | Train Accurancy:  0.930058054625988 | Validation Accurancy:  0.9362626224756241\n",
      "Epoch:  9130 | Train Accurancy:  0.9300588816404343 | Validation Accurancy:  0.9362664669752121\n",
      "Epoch:  9131 | Train Accurancy:  0.9300597757101059 | Validation Accurancy:  0.9362703338265419\n",
      "Epoch:  9132 | Train Accurancy:  0.9300606176257133 | Validation Accurancy:  0.9362740963697433\n",
      "Epoch:  9133 | Train Accurancy:  0.9300614669919014 | Validation Accurancy:  0.9362780228257179\n",
      "Epoch:  9134 | Train Accurancy:  0.9300622865557671 | Validation Accurancy:  0.9362819343805313\n",
      "Epoch:  9135 | Train Accurancy:  0.9300631582736969 | Validation Accurancy:  0.9362856671214104\n",
      "Epoch:  9136 | Train Accurancy:  0.930064007639885 | Validation Accurancy:  0.9362895786762238\n",
      "Epoch:  9137 | Train Accurancy:  0.9300648644566536 | Validation Accurancy:  0.9362934082746506\n",
      "Epoch:  9138 | Train Accurancy:  0.9300657510757446 | Validation Accurancy:  0.936297208070755\n",
      "Epoch:  9139 | Train Accurancy:  0.9300665631890297 | Validation Accurancy:  0.936301089823246\n",
      "Epoch:  9140 | Train Accurancy:  0.9300673976540565 | Validation Accurancy:  0.936304934322834\n",
      "Epoch:  9141 | Train Accurancy:  0.9300682693719864 | Validation Accurancy:  0.936308778822422\n",
      "Epoch:  9142 | Train Accurancy:  0.9300690963864326 | Validation Accurancy:  0.9363126084208488\n",
      "Epoch:  9143 | Train Accurancy:  0.9300699383020401 | Validation Accurancy:  0.9363164454698563\n",
      "Epoch:  9144 | Train Accurancy:  0.9300708100199699 | Validation Accurancy:  0.9363203048706055\n",
      "Epoch:  9145 | Train Accurancy:  0.9300716444849968 | Validation Accurancy:  0.9363241046667099\n",
      "Epoch:  9146 | Train Accurancy:  0.930072508752346 | Validation Accurancy:  0.9363279491662979\n",
      "Epoch:  9147 | Train Accurancy:  0.9300733655691147 | Validation Accurancy:  0.9363318458199501\n",
      "Epoch:  9148 | Train Accurancy:  0.9300742372870445 | Validation Accurancy:  0.9363355785608292\n",
      "Epoch:  9149 | Train Accurancy:  0.9300750717520714 | Validation Accurancy:  0.9363394752144814\n",
      "Epoch:  9150 | Train Accurancy:  0.9300758838653564 | Validation Accurancy:  0.9363433197140694\n",
      "Epoch:  9151 | Train Accurancy:  0.9300767183303833 | Validation Accurancy:  0.9363471642136574\n",
      "Epoch:  9152 | Train Accurancy:  0.9300775676965714 | Validation Accurancy:  0.936350978910923\n",
      "Epoch:  9153 | Train Accurancy:  0.930078461766243 | Validation Accurancy:  0.9363547787070274\n",
      "Epoch:  9154 | Train Accurancy:  0.9300793036818504 | Validation Accurancy:  0.9363585934042931\n",
      "Epoch:  9155 | Train Accurancy:  0.9300801306962967 | Validation Accurancy:  0.9363624900579453\n",
      "Epoch:  9156 | Train Accurancy:  0.9300810024142265 | Validation Accurancy:  0.9363662898540497\n",
      "Epoch:  9157 | Train Accurancy:  0.9300819113850594 | Validation Accurancy:  0.9363701194524765\n",
      "Epoch:  9158 | Train Accurancy:  0.930082730948925 | Validation Accurancy:  0.9363740459084511\n",
      "Epoch:  9159 | Train Accurancy:  0.9300835430622101 | Validation Accurancy:  0.9363778084516525\n",
      "Epoch:  9160 | Train Accurancy:  0.9300844296813011 | Validation Accurancy:  0.9363815784454346\n",
      "Epoch:  9161 | Train Accurancy:  0.9300852492451668 | Validation Accurancy:  0.9363854229450226\n",
      "Epoch:  9162 | Train Accurancy:  0.9300860911607742 | Validation Accurancy:  0.9363892525434494\n",
      "Epoch:  9163 | Train Accurancy:  0.9300869256258011 | Validation Accurancy:  0.9363931193947792\n",
      "Epoch:  9164 | Train Accurancy:  0.9300878122448921 | Validation Accurancy:  0.9363969638943672\n",
      "Epoch:  9165 | Train Accurancy:  0.9300886392593384 | Validation Accurancy:  0.936400793492794\n",
      "Epoch:  9166 | Train Accurancy:  0.930089458823204 | Validation Accurancy:  0.936404675245285\n",
      "Epoch:  9167 | Train Accurancy:  0.9300902932882309 | Validation Accurancy:  0.9364084228873253\n",
      "Epoch:  9168 | Train Accurancy:  0.9300911277532578 | Validation Accurancy:  0.9364122077822685\n",
      "Epoch:  9169 | Train Accurancy:  0.9300919994711876 | Validation Accurancy:  0.9364160671830177\n",
      "Epoch:  9170 | Train Accurancy:  0.930092878639698 | Validation Accurancy:  0.9364198371767998\n",
      "Epoch:  9171 | Train Accurancy:  0.9300937205553055 | Validation Accurancy:  0.9364237114787102\n",
      "Epoch:  9172 | Train Accurancy:  0.9300945475697517 | Validation Accurancy:  0.9364274814724922\n",
      "Epoch:  9173 | Train Accurancy:  0.9300953894853592 | Validation Accurancy:  0.936431311070919\n",
      "Epoch:  9174 | Train Accurancy:  0.9300962537527084 | Validation Accurancy:  0.9364351108670235\n",
      "Epoch:  9175 | Train Accurancy:  0.9300971031188965 | Validation Accurancy:  0.9364390224218369\n",
      "Epoch:  9176 | Train Accurancy:  0.9300979599356651 | Validation Accurancy:  0.9364427700638771\n",
      "Epoch:  9177 | Train Accurancy:  0.9300988242030144 | Validation Accurancy:  0.9364466667175293\n",
      "Epoch:  9178 | Train Accurancy:  0.9300996512174606 | Validation Accurancy:  0.9364504665136337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9179 | Train Accurancy:  0.9301004782319069 | Validation Accurancy:  0.9364543110132217\n",
      "Epoch:  9180 | Train Accurancy:  0.9301013052463531 | Validation Accurancy:  0.936458095908165\n",
      "Epoch:  9181 | Train Accurancy:  0.9301021546125412 | Validation Accurancy:  0.9364619106054306\n",
      "Epoch:  9182 | Train Accurancy:  0.9301030188798904 | Validation Accurancy:  0.9364658072590828\n",
      "Epoch:  9183 | Train Accurancy:  0.9301038831472397 | Validation Accurancy:  0.9364695698022842\n",
      "Epoch:  9184 | Train Accurancy:  0.9301046803593636 | Validation Accurancy:  0.9364733695983887\n",
      "Epoch:  9185 | Train Accurancy:  0.9301055297255516 | Validation Accurancy:  0.9364771842956543\n",
      "Epoch:  9186 | Train Accurancy:  0.9301063567399979 | Validation Accurancy:  0.9364810436964035\n",
      "Epoch:  9187 | Train Accurancy:  0.9301072433590889 | Validation Accurancy:  0.9364849105477333\n",
      "Epoch:  9188 | Train Accurancy:  0.9301080778241158 | Validation Accurancy:  0.9364886283874512\n",
      "Epoch:  9189 | Train Accurancy:  0.9301088899374008 | Validation Accurancy:  0.9364924430847168\n",
      "Epoch:  9190 | Train Accurancy:  0.9301097318530083 | Validation Accurancy:  0.9364963248372078\n",
      "Epoch:  9191 | Train Accurancy:  0.9301105588674545 | Validation Accurancy:  0.9365000054240227\n",
      "Epoch:  9192 | Train Accurancy:  0.9301114305853844 | Validation Accurancy:  0.9365039020776749\n",
      "Epoch:  9193 | Train Accurancy:  0.9301122725009918 | Validation Accurancy:  0.9365076199173927\n",
      "Epoch:  9194 | Train Accurancy:  0.9301131442189217 | Validation Accurancy:  0.9365115016698837\n",
      "Epoch:  9195 | Train Accurancy:  0.9301139935851097 | Validation Accurancy:  0.9365154132246971\n",
      "Epoch:  9196 | Train Accurancy:  0.9301147982478142 | Validation Accurancy:  0.9365190640091896\n",
      "Epoch:  9197 | Train Accurancy:  0.9301156774163246 | Validation Accurancy:  0.9365229904651642\n",
      "Epoch:  9198 | Train Accurancy:  0.9301165044307709 | Validation Accurancy:  0.9365267902612686\n",
      "Epoch:  9199 | Train Accurancy:  0.9301173314452171 | Validation Accurancy:  0.9365305602550507\n",
      "Epoch:  9200 | Train Accurancy:  0.9301181584596634 | Validation Accurancy:  0.9365343227982521\n",
      "Epoch:  9201 | Train Accurancy:  0.9301189929246902 | Validation Accurancy:  0.9365380927920341\n",
      "Epoch:  9202 | Train Accurancy:  0.9301198646426201 | Validation Accurancy:  0.9365420043468475\n",
      "Epoch:  9203 | Train Accurancy:  0.9301207363605499 | Validation Accurancy:  0.9365458488464355\n",
      "Epoch:  9204 | Train Accurancy:  0.9301215335726738 | Validation Accurancy:  0.9365495666861534\n",
      "Epoch:  9205 | Train Accurancy:  0.9301223605871201 | Validation Accurancy:  0.936553381383419\n",
      "Epoch:  9206 | Train Accurancy:  0.9301232248544693 | Validation Accurancy:  0.9365571513772011\n",
      "Epoch:  9207 | Train Accurancy:  0.9301240667700768 | Validation Accurancy:  0.9365609809756279\n",
      "Epoch:  9208 | Train Accurancy:  0.9301249086856842 | Validation Accurancy:  0.9365648105740547\n",
      "Epoch:  9209 | Train Accurancy:  0.9301257357001305 | Validation Accurancy:  0.9365686103701591\n",
      "Epoch:  9210 | Train Accurancy:  0.9301265478134155 | Validation Accurancy:  0.936572439968586\n",
      "Epoch:  9211 | Train Accurancy:  0.9301273971796036 | Validation Accurancy:  0.936576284468174\n",
      "Epoch:  9212 | Train Accurancy:  0.9301282539963722 | Validation Accurancy:  0.9365799874067307\n",
      "Epoch:  9213 | Train Accurancy:  0.9301291406154633 | Validation Accurancy:  0.9365838393568993\n",
      "Epoch:  9214 | Train Accurancy:  0.9301299303770065 | Validation Accurancy:  0.9365876019001007\n",
      "Epoch:  9215 | Train Accurancy:  0.9301307871937752 | Validation Accurancy:  0.9365914314985275\n",
      "Epoch:  9216 | Train Accurancy:  0.930131621658802 | Validation Accurancy:  0.9365952014923096\n",
      "Epoch:  9217 | Train Accurancy:  0.9301324784755707 | Validation Accurancy:  0.9365989714860916\n",
      "Epoch:  9218 | Train Accurancy:  0.9301332980394363 | Validation Accurancy:  0.9366028010845184\n",
      "Epoch:  9219 | Train Accurancy:  0.930134154856205 | Validation Accurancy:  0.9366066306829453\n",
      "Epoch:  9220 | Train Accurancy:  0.9301349967718124 | Validation Accurancy:  0.9366104155778885\n",
      "Epoch:  9221 | Train Accurancy:  0.9301358535885811 | Validation Accurancy:  0.9366142079234123\n",
      "Epoch:  9222 | Train Accurancy:  0.9301366358995438 | Validation Accurancy:  0.9366180077195168\n",
      "Epoch:  9223 | Train Accurancy:  0.9301374778151512 | Validation Accurancy:  0.9366218075156212\n",
      "Epoch:  9224 | Train Accurancy:  0.9301383420825005 | Validation Accurancy:  0.9366256073117256\n",
      "Epoch:  9225 | Train Accurancy:  0.9301391839981079 | Validation Accurancy:  0.93662940710783\n",
      "Epoch:  9226 | Train Accurancy:  0.9301399886608124 | Validation Accurancy:  0.9366331920027733\n",
      "Epoch:  9227 | Train Accurancy:  0.9301408231258392 | Validation Accurancy:  0.9366370067000389\n",
      "Epoch:  9228 | Train Accurancy:  0.9301416799426079 | Validation Accurancy:  0.9366408362984657\n",
      "Epoch:  9229 | Train Accurancy:  0.9301425293087959 | Validation Accurancy:  0.9366446807980537\n",
      "Epoch:  9230 | Train Accurancy:  0.930143341422081 | Validation Accurancy:  0.9366483986377716\n",
      "Epoch:  9231 | Train Accurancy:  0.930144190788269 | Validation Accurancy:  0.9366521164774895\n",
      "Epoch:  9232 | Train Accurancy:  0.9301449880003929 | Validation Accurancy:  0.9366559684276581\n",
      "Epoch:  9233 | Train Accurancy:  0.9301458299160004 | Validation Accurancy:  0.9366597458720207\n",
      "Epoch:  9234 | Train Accurancy:  0.9301466420292854 | Validation Accurancy:  0.9366635605692863\n",
      "Epoch:  9235 | Train Accurancy:  0.9301475659012794 | Validation Accurancy:  0.9366673156619072\n",
      "Epoch:  9236 | Train Accurancy:  0.9301483482122421 | Validation Accurancy:  0.9366711601614952\n",
      "Epoch:  9237 | Train Accurancy:  0.930149219930172 | Validation Accurancy:  0.9366748631000519\n",
      "Epoch:  9238 | Train Accurancy:  0.9301500767469406 | Validation Accurancy:  0.9366786032915115\n",
      "Epoch:  9239 | Train Accurancy:  0.9301508590579033 | Validation Accurancy:  0.9366824626922607\n",
      "Epoch:  9240 | Train Accurancy:  0.9301517009735107 | Validation Accurancy:  0.9366861656308174\n",
      "Epoch:  9241 | Train Accurancy:  0.93015256524086 | Validation Accurancy:  0.9366899952292442\n",
      "Epoch:  9242 | Train Accurancy:  0.9301533922553062 | Validation Accurancy:  0.9366939887404442\n",
      "Epoch:  9243 | Train Accurancy:  0.9301542341709137 | Validation Accurancy:  0.936697706580162\n",
      "Epoch:  9244 | Train Accurancy:  0.9301550313830376 | Validation Accurancy:  0.9367014542222023\n",
      "Epoch:  9245 | Train Accurancy:  0.9301559180021286 | Validation Accurancy:  0.9367053359746933\n",
      "Epoch:  9246 | Train Accurancy:  0.9301567301154137 | Validation Accurancy:  0.9367090538144112\n",
      "Epoch:  9247 | Train Accurancy:  0.9301575794816017 | Validation Accurancy:  0.9367128387093544\n",
      "Epoch:  9248 | Train Accurancy:  0.9301583841443062 | Validation Accurancy:  0.9367166683077812\n",
      "Epoch:  9249 | Train Accurancy:  0.9301592484116554 | Validation Accurancy:  0.9367204159498215\n",
      "Epoch:  9250 | Train Accurancy:  0.9301600828766823 | Validation Accurancy:  0.9367242157459259\n",
      "Epoch:  9251 | Train Accurancy:  0.9301609247922897 | Validation Accurancy:  0.9367280006408691\n",
      "Epoch:  9252 | Train Accurancy:  0.9301617443561554 | Validation Accurancy:  0.9367317333817482\n",
      "Epoch:  9253 | Train Accurancy:  0.9301625862717628 | Validation Accurancy:  0.9367355853319168\n",
      "Epoch:  9254 | Train Accurancy:  0.9301634132862091 | Validation Accurancy:  0.9367393180727959\n",
      "Epoch:  9255 | Train Accurancy:  0.9301642626523972 | Validation Accurancy:  0.9367431029677391\n",
      "Epoch:  9256 | Train Accurancy:  0.9301651045680046 | Validation Accurancy:  0.9367468506097794\n",
      "Epoch:  9257 | Train Accurancy:  0.9301659166812897 | Validation Accurancy:  0.9367506206035614\n",
      "Epoch:  9258 | Train Accurancy:  0.9301667660474777 | Validation Accurancy:  0.9367543682456017\n",
      "Epoch:  9259 | Train Accurancy:  0.9301675856113434 | Validation Accurancy:  0.9367581978440285\n",
      "Epoch:  9260 | Train Accurancy:  0.9301683977246284 | Validation Accurancy:  0.9367619678378105\n",
      "Epoch:  9261 | Train Accurancy:  0.9301692545413971 | Validation Accurancy:  0.9367657005786896\n",
      "Epoch:  9262 | Train Accurancy:  0.9301700815558434 | Validation Accurancy:  0.9367694854736328\n",
      "Epoch:  9263 | Train Accurancy:  0.9301709160208702 | Validation Accurancy:  0.9367732331156731\n",
      "Epoch:  9264 | Train Accurancy:  0.9301717206835747 | Validation Accurancy:  0.9367771297693253\n",
      "Epoch:  9265 | Train Accurancy:  0.9301725924015045 | Validation Accurancy:  0.9367808327078819\n",
      "Epoch:  9266 | Train Accurancy:  0.9301734119653702 | Validation Accurancy:  0.9367846176028252\n",
      "Epoch:  9267 | Train Accurancy:  0.9301742538809776 | Validation Accurancy:  0.9367884173989296\n",
      "Epoch:  9268 | Train Accurancy:  0.9301750957965851 | Validation Accurancy:  0.9367922618985176\n",
      "Epoch:  9269 | Train Accurancy:  0.9301759079098701 | Validation Accurancy:  0.9367959350347519\n",
      "Epoch:  9270 | Train Accurancy:  0.9301767200231552 | Validation Accurancy:  0.9367997497320175\n",
      "Epoch:  9271 | Train Accurancy:  0.9301775619387627 | Validation Accurancy:  0.9368034675717354\n",
      "Epoch:  9272 | Train Accurancy:  0.9301784038543701 | Validation Accurancy:  0.9368071854114532\n",
      "Epoch:  9273 | Train Accurancy:  0.9301792457699776 | Validation Accurancy:  0.9368109554052353\n",
      "Epoch:  9274 | Train Accurancy:  0.9301800802350044 | Validation Accurancy:  0.9368148297071457\n",
      "Epoch:  9275 | Train Accurancy:  0.9301808774471283 | Validation Accurancy:  0.9368186965584755\n",
      "Epoch:  9276 | Train Accurancy:  0.9301817342638969 | Validation Accurancy:  0.9368223324418068\n",
      "Epoch:  9277 | Train Accurancy:  0.930182546377182 | Validation Accurancy:  0.9368260577321053\n",
      "Epoch:  9278 | Train Accurancy:  0.9301834031939507 | Validation Accurancy:  0.9368299022316933\n",
      "Epoch:  9279 | Train Accurancy:  0.9301842153072357 | Validation Accurancy:  0.9368335753679276\n",
      "Epoch:  9280 | Train Accurancy:  0.930185042321682 | Validation Accurancy:  0.9368373900651932\n",
      "Epoch:  9281 | Train Accurancy:  0.9301858842372894 | Validation Accurancy:  0.9368411526083946\n",
      "Epoch:  9282 | Train Accurancy:  0.9301866665482521 | Validation Accurancy:  0.9368449375033379\n",
      "Epoch:  9283 | Train Accurancy:  0.9301875084638596 | Validation Accurancy:  0.9368486553430557\n",
      "Epoch:  9284 | Train Accurancy:  0.9301883429288864 | Validation Accurancy:  0.9368524104356766\n",
      "Epoch:  9285 | Train Accurancy:  0.9301891773939133 | Validation Accurancy:  0.936856172978878\n",
      "Epoch:  9286 | Train Accurancy:  0.9301900118589401 | Validation Accurancy:  0.9368598908185959\n",
      "Epoch:  9287 | Train Accurancy:  0.930190809071064 | Validation Accurancy:  0.9368636757135391\n",
      "Epoch:  9288 | Train Accurancy:  0.9301916435360909 | Validation Accurancy:  0.93686743080616\n",
      "Epoch:  9289 | Train Accurancy:  0.9301925003528595 | Validation Accurancy:  0.9368711188435555\n",
      "Epoch:  9290 | Train Accurancy:  0.9301933124661446 | Validation Accurancy:  0.9368749931454659\n",
      "Epoch:  9291 | Train Accurancy:  0.9301941469311714 | Validation Accurancy:  0.9368787780404091\n",
      "Epoch:  9292 | Train Accurancy:  0.9301949515938759 | Validation Accurancy:  0.9368825256824493\n",
      "Epoch:  9293 | Train Accurancy:  0.9301958233118057 | Validation Accurancy:  0.9368863254785538\n",
      "Epoch:  9294 | Train Accurancy:  0.9301966354250908 | Validation Accurancy:  0.9368900433182716\n",
      "Epoch:  9295 | Train Accurancy:  0.9301974698901176 | Validation Accurancy:  0.9368937686085701\n",
      "Epoch:  9296 | Train Accurancy:  0.9301982894539833 | Validation Accurancy:  0.9368975162506104\n",
      "Epoch:  9297 | Train Accurancy:  0.9301991611719131 | Validation Accurancy:  0.936901219189167\n",
      "Epoch:  9298 | Train Accurancy:  0.9301999732851982 | Validation Accurancy:  0.936905100941658\n",
      "Epoch:  9299 | Train Accurancy:  0.9302008152008057 | Validation Accurancy:  0.9369088634848595\n",
      "Epoch:  9300 | Train Accurancy:  0.9302016273140907 | Validation Accurancy:  0.9369125813245773\n",
      "Epoch:  9301 | Train Accurancy:  0.9302024394273758 | Validation Accurancy:  0.936916396021843\n",
      "Epoch:  9302 | Train Accurancy:  0.9302032217383385 | Validation Accurancy:  0.9369201213121414\n",
      "Epoch:  9303 | Train Accurancy:  0.9302041083574295 | Validation Accurancy:  0.9369238838553429\n",
      "Epoch:  9304 | Train Accurancy:  0.9302049055695534 | Validation Accurancy:  0.9369275718927383\n",
      "Epoch:  9305 | Train Accurancy:  0.930205725133419 | Validation Accurancy:  0.936931386590004\n",
      "Epoch:  9306 | Train Accurancy:  0.9302065521478653 | Validation Accurancy:  0.9369350448250771\n",
      "Epoch:  9307 | Train Accurancy:  0.9302074015140533 | Validation Accurancy:  0.9369387924671173\n",
      "Epoch:  9308 | Train Accurancy:  0.9302082061767578 | Validation Accurancy:  0.9369426742196083\n",
      "Epoch:  9309 | Train Accurancy:  0.9302090704441071 | Validation Accurancy:  0.9369464367628098\n",
      "Epoch:  9310 | Train Accurancy:  0.9302098825573921 | Validation Accurancy:  0.9369501769542694\n",
      "Epoch:  9311 | Train Accurancy:  0.9302106946706772 | Validation Accurancy:  0.9369539096951485\n",
      "Epoch:  9312 | Train Accurancy:  0.9302115142345428 | Validation Accurancy:  0.936957597732544\n",
      "Epoch:  9313 | Train Accurancy:  0.9302123636007309 | Validation Accurancy:  0.9369613826274872\n",
      "Epoch:  9314 | Train Accurancy:  0.9302132353186607 | Validation Accurancy:  0.9369650334119797\n",
      "Epoch:  9315 | Train Accurancy:  0.9302139729261398 | Validation Accurancy:  0.9369688704609871\n",
      "Epoch:  9316 | Train Accurancy:  0.9302148148417473 | Validation Accurancy:  0.9369725361466408\n",
      "Epoch:  9317 | Train Accurancy:  0.9302156642079353 | Validation Accurancy:  0.9369763359427452\n",
      "Epoch:  9318 | Train Accurancy:  0.9302164688706398 | Validation Accurancy:  0.9369800910353661\n",
      "Epoch:  9319 | Train Accurancy:  0.9302172660827637 | Validation Accurancy:  0.9369838088750839\n",
      "Epoch:  9320 | Train Accurancy:  0.9302181303501129 | Validation Accurancy:  0.9369875118136406\n",
      "Epoch:  9321 | Train Accurancy:  0.9302189201116562 | Validation Accurancy:  0.936991311609745\n",
      "Epoch:  9322 | Train Accurancy:  0.9302197620272636 | Validation Accurancy:  0.9369950145483017\n",
      "Epoch:  9323 | Train Accurancy:  0.9302205964922905 | Validation Accurancy:  0.936998762190342\n",
      "Epoch:  9324 | Train Accurancy:  0.9302214160561562 | Validation Accurancy:  0.937002532184124\n",
      "Epoch:  9325 | Train Accurancy:  0.930222250521183 | Validation Accurancy:  0.9370062351226807\n",
      "Epoch:  9326 | Train Accurancy:  0.9302231147885323 | Validation Accurancy:  0.9370099678635597\n",
      "Epoch:  9327 | Train Accurancy:  0.9302239269018173 | Validation Accurancy:  0.9370136931538582\n",
      "Epoch:  9328 | Train Accurancy:  0.930224746465683 | Validation Accurancy:  0.9370174407958984\n",
      "Epoch:  9329 | Train Accurancy:  0.9302255213260651 | Validation Accurancy:  0.9370211437344551\n",
      "Epoch:  9330 | Train Accurancy:  0.9302264004945755 | Validation Accurancy:  0.9370249435305595\n",
      "Epoch:  9331 | Train Accurancy:  0.9302271604537964 | Validation Accurancy:  0.9370286166667938\n",
      "Epoch:  9332 | Train Accurancy:  0.9302279651165009 | Validation Accurancy:  0.9370323643088341\n",
      "Epoch:  9333 | Train Accurancy:  0.9302288144826889 | Validation Accurancy:  0.9370361641049385\n",
      "Epoch:  9334 | Train Accurancy:  0.930229663848877 | Validation Accurancy:  0.9370398074388504\n",
      "Epoch:  9335 | Train Accurancy:  0.9302304610610008 | Validation Accurancy:  0.9370435252785683\n",
      "Epoch:  9336 | Train Accurancy:  0.9302312880754471 | Validation Accurancy:  0.9370473697781563\n",
      "Epoch:  9337 | Train Accurancy:  0.9302321374416351 | Validation Accurancy:  0.937051072716713\n",
      "Epoch:  9338 | Train Accurancy:  0.9302329272031784 | Validation Accurancy:  0.9370548278093338\n",
      "Epoch:  9339 | Train Accurancy:  0.9302337542176247 | Validation Accurancy:  0.937058575451374\n",
      "Epoch:  9340 | Train Accurancy:  0.9302345737814903 | Validation Accurancy:  0.9370623081922531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9341 | Train Accurancy:  0.9302354082465172 | Validation Accurancy:  0.9370660334825516\n",
      "Epoch:  9342 | Train Accurancy:  0.930236242711544 | Validation Accurancy:  0.9370696693658829\n",
      "Epoch:  9343 | Train Accurancy:  0.9302370697259903 | Validation Accurancy:  0.9370735362172127\n",
      "Epoch:  9344 | Train Accurancy:  0.930237852036953 | Validation Accurancy:  0.9370772168040276\n",
      "Epoch:  9345 | Train Accurancy:  0.930238738656044 | Validation Accurancy:  0.9370809569954872\n",
      "Epoch:  9346 | Train Accurancy:  0.9302395060658455 | Validation Accurancy:  0.9370846301317215\n",
      "Epoch:  9347 | Train Accurancy:  0.9302403181791306 | Validation Accurancy:  0.9370883777737617\n",
      "Epoch:  9348 | Train Accurancy:  0.9302411377429962 | Validation Accurancy:  0.9370921924710274\n",
      "Epoch:  9349 | Train Accurancy:  0.9302419796586037 | Validation Accurancy:  0.9370958358049393\n",
      "Epoch:  9350 | Train Accurancy:  0.9302428066730499 | Validation Accurancy:  0.9370996505022049\n",
      "Epoch:  9351 | Train Accurancy:  0.9302436038851738 | Validation Accurancy:  0.9371033161878586\n",
      "Epoch:  9352 | Train Accurancy:  0.9302444308996201 | Validation Accurancy:  0.9371069893240929\n",
      "Epoch:  9353 | Train Accurancy:  0.9302452802658081 | Validation Accurancy:  0.9371107891201973\n",
      "Epoch:  9354 | Train Accurancy:  0.9302460700273514 | Validation Accurancy:  0.9371144622564316\n",
      "Epoch:  9355 | Train Accurancy:  0.9302469193935394 | Validation Accurancy:  0.9371182471513748\n",
      "Epoch:  9356 | Train Accurancy:  0.9302476942539215 | Validation Accurancy:  0.9371219947934151\n",
      "Epoch:  9357 | Train Accurancy:  0.9302485063672066 | Validation Accurancy:  0.9371257647871971\n",
      "Epoch:  9358 | Train Accurancy:  0.9302493557333946 | Validation Accurancy:  0.9371294528245926\n",
      "Epoch:  9359 | Train Accurancy:  0.9302501454949379 | Validation Accurancy:  0.9371331036090851\n",
      "Epoch:  9360 | Train Accurancy:  0.9302509874105453 | Validation Accurancy:  0.9371368736028671\n",
      "Epoch:  9361 | Train Accurancy:  0.9302518218755722 | Validation Accurancy:  0.9371405616402626\n",
      "Epoch:  9362 | Train Accurancy:  0.9302526712417603 | Validation Accurancy:  0.9371442943811417\n",
      "Epoch:  9363 | Train Accurancy:  0.9302534759044647 | Validation Accurancy:  0.9371480122208595\n",
      "Epoch:  9364 | Train Accurancy:  0.9302542507648468 | Validation Accurancy:  0.9371517673134804\n",
      "Epoch:  9365 | Train Accurancy:  0.9302550926804543 | Validation Accurancy:  0.9371554553508759\n",
      "Epoch:  9366 | Train Accurancy:  0.9302558973431587 | Validation Accurancy:  0.9371591284871101\n",
      "Epoch:  9367 | Train Accurancy:  0.9302567169070244 | Validation Accurancy:  0.9371629431843758\n",
      "Epoch:  9368 | Train Accurancy:  0.9302575141191483 | Validation Accurancy:  0.9371665343642235\n",
      "Epoch:  9369 | Train Accurancy:  0.9302583783864975 | Validation Accurancy:  0.9371703118085861\n",
      "Epoch:  9370 | Train Accurancy:  0.9302591979503632 | Validation Accurancy:  0.9371740520000458\n",
      "Epoch:  9371 | Train Accurancy:  0.9302599877119064 | Validation Accurancy:  0.9371777400374413\n",
      "Epoch:  9372 | Train Accurancy:  0.9302608072757721 | Validation Accurancy:  0.9371814876794815\n",
      "Epoch:  9373 | Train Accurancy:  0.9302616640925407 | Validation Accurancy:  0.9371852055191994\n",
      "Epoch:  9374 | Train Accurancy:  0.9302624464035034 | Validation Accurancy:  0.937188945710659\n",
      "Epoch:  9375 | Train Accurancy:  0.9302632287144661 | Validation Accurancy:  0.9371926337480545\n",
      "Epoch:  9376 | Train Accurancy:  0.9302640706300735 | Validation Accurancy:  0.9371964111924171\n",
      "Epoch:  9377 | Train Accurancy:  0.930264912545681 | Validation Accurancy:  0.9372000843286514\n",
      "Epoch:  9378 | Train Accurancy:  0.9302657023072243 | Validation Accurancy:  0.9372037723660469\n",
      "Epoch:  9379 | Train Accurancy:  0.9302664920687675 | Validation Accurancy:  0.9372074902057648\n",
      "Epoch:  9380 | Train Accurancy:  0.9302673786878586 | Validation Accurancy:  0.9372111931443214\n",
      "Epoch:  9381 | Train Accurancy:  0.9302681609988213 | Validation Accurancy:  0.9372149482369423\n",
      "Epoch:  9382 | Train Accurancy:  0.9302689731121063 | Validation Accurancy:  0.9372186660766602\n",
      "Epoch:  9383 | Train Accurancy:  0.9302697628736496 | Validation Accurancy:  0.9372223392128944\n",
      "Epoch:  9384 | Train Accurancy:  0.9302705675363541 | Validation Accurancy:  0.9372260570526123\n",
      "Epoch:  9385 | Train Accurancy:  0.9302714243531227 | Validation Accurancy:  0.9372297450900078\n",
      "Epoch:  9386 | Train Accurancy:  0.9302722290158272 | Validation Accurancy:  0.9372335150837898\n",
      "Epoch:  9387 | Train Accurancy:  0.9302730411291122 | Validation Accurancy:  0.9372371211647987\n",
      "Epoch:  9388 | Train Accurancy:  0.9302738830447197 | Validation Accurancy:  0.9372408092021942\n",
      "Epoch:  9389 | Train Accurancy:  0.9302746877074242 | Validation Accurancy:  0.9372445717453957\n",
      "Epoch:  9390 | Train Accurancy:  0.9302755147218704 | Validation Accurancy:  0.9372483864426613\n",
      "Epoch:  9391 | Train Accurancy:  0.9302763417363167 | Validation Accurancy:  0.9372520446777344\n",
      "Epoch:  9392 | Train Accurancy:  0.9302771836519241 | Validation Accurancy:  0.937255747616291\n",
      "Epoch:  9393 | Train Accurancy:  0.930277943611145 | Validation Accurancy:  0.9372594505548477\n",
      "Epoch:  9394 | Train Accurancy:  0.9302787557244301 | Validation Accurancy:  0.9372630789875984\n",
      "Epoch:  9395 | Train Accurancy:  0.9302795976400375 | Validation Accurancy:  0.9372668117284775\n",
      "Epoch:  9396 | Train Accurancy:  0.9302803948521614 | Validation Accurancy:  0.9372705146670341\n",
      "Epoch:  9397 | Train Accurancy:  0.9302812144160271 | Validation Accurancy:  0.9372742995619774\n",
      "Epoch:  9398 | Train Accurancy:  0.9302820116281509 | Validation Accurancy:  0.9372779354453087\n",
      "Epoch:  9399 | Train Accurancy:  0.9302828386425972 | Validation Accurancy:  0.9372816905379295\n",
      "Epoch:  9400 | Train Accurancy:  0.9302836582064629 | Validation Accurancy:  0.937285378575325\n",
      "Epoch:  9401 | Train Accurancy:  0.9302844628691673 | Validation Accurancy:  0.9372890815138817\n",
      "Epoch:  9402 | Train Accurancy:  0.9302852898836136 | Validation Accurancy:  0.9372927322983742\n",
      "Epoch:  9403 | Train Accurancy:  0.9302860870957375 | Validation Accurancy:  0.9372965320944786\n",
      "Epoch:  9404 | Train Accurancy:  0.9302869141101837 | Validation Accurancy:  0.9373001903295517\n",
      "Epoch:  9405 | Train Accurancy:  0.9302877336740494 | Validation Accurancy:  0.9373038485646248\n",
      "Epoch:  9406 | Train Accurancy:  0.9302885383367538 | Validation Accurancy:  0.937307596206665\n",
      "Epoch:  9407 | Train Accurancy:  0.9302893653512001 | Validation Accurancy:  0.9373112171888351\n",
      "Epoch:  9408 | Train Accurancy:  0.9302901476621628 | Validation Accurancy:  0.9373149573802948\n",
      "Epoch:  9409 | Train Accurancy:  0.9302909150719643 | Validation Accurancy:  0.9373186305165291\n",
      "Epoch:  9410 | Train Accurancy:  0.9302917718887329 | Validation Accurancy:  0.9373223781585693\n",
      "Epoch:  9411 | Train Accurancy:  0.9302925691008568 | Validation Accurancy:  0.9373260214924812\n",
      "Epoch:  9412 | Train Accurancy:  0.9302933886647224 | Validation Accurancy:  0.9373297244310379\n",
      "Epoch:  9413 | Train Accurancy:  0.9302942529320717 | Validation Accurancy:  0.9373334124684334\n",
      "Epoch:  9414 | Train Accurancy:  0.9302950352430344 | Validation Accurancy:  0.93733711540699\n",
      "Epoch:  9415 | Train Accurancy:  0.930295892059803 | Validation Accurancy:  0.9373407661914825\n",
      "Epoch:  9416 | Train Accurancy:  0.9302966818213463 | Validation Accurancy:  0.9373445063829422\n",
      "Epoch:  9417 | Train Accurancy:  0.9302974566817284 | Validation Accurancy:  0.9373482391238213\n",
      "Epoch:  9418 | Train Accurancy:  0.9302982985973358 | Validation Accurancy:  0.9373518452048302\n",
      "Epoch:  9419 | Train Accurancy:  0.9302990660071373 | Validation Accurancy:  0.937355563044548\n",
      "Epoch:  9420 | Train Accurancy:  0.9302998930215836 | Validation Accurancy:  0.9373593032360077\n",
      "Epoch:  9421 | Train Accurancy:  0.9303007200360298 | Validation Accurancy:  0.9373629093170166\n",
      "Epoch:  9422 | Train Accurancy:  0.9303015172481537 | Validation Accurancy:  0.9373665526509285\n",
      "Epoch:  9423 | Train Accurancy:  0.9303022921085358 | Validation Accurancy:  0.9373703822493553\n",
      "Epoch:  9424 | Train Accurancy:  0.9303031265735626 | Validation Accurancy:  0.9373740702867508\n",
      "Epoch:  9425 | Train Accurancy:  0.9303039014339447 | Validation Accurancy:  0.9373777881264687\n",
      "Epoch:  9426 | Train Accurancy:  0.9303047508001328 | Validation Accurancy:  0.9373814091086388\n",
      "Epoch:  9427 | Train Accurancy:  0.930305503308773 | Validation Accurancy:  0.9373850971460342\n",
      "Epoch:  9428 | Train Accurancy:  0.9303063601255417 | Validation Accurancy:  0.9373887404799461\n",
      "Epoch:  9429 | Train Accurancy:  0.930307187139988 | Validation Accurancy:  0.9373924434185028\n",
      "Epoch:  9430 | Train Accurancy:  0.9303080141544342 | Validation Accurancy:  0.9373961761593819\n",
      "Epoch:  9431 | Train Accurancy:  0.9303087815642357 | Validation Accurancy:  0.9373999089002609\n",
      "Epoch:  9432 | Train Accurancy:  0.9303095787763596 | Validation Accurancy:  0.9374035373330116\n",
      "Epoch:  9433 | Train Accurancy:  0.9303104355931282 | Validation Accurancy:  0.9374072253704071\n",
      "Epoch:  9434 | Train Accurancy:  0.9303112179040909 | Validation Accurancy:  0.9374109283089638\n",
      "Epoch:  9435 | Train Accurancy:  0.9303120151162148 | Validation Accurancy:  0.9374145492911339\n",
      "Epoch:  9436 | Train Accurancy:  0.9303128197789192 | Validation Accurancy:  0.9374183043837547\n",
      "Epoch:  9437 | Train Accurancy:  0.9303136095404625 | Validation Accurancy:  0.9374220818281174\n",
      "Epoch:  9438 | Train Accurancy:  0.9303145185112953 | Validation Accurancy:  0.9374256953597069\n",
      "Epoch:  9439 | Train Accurancy:  0.930315263569355 | Validation Accurancy:  0.9374294281005859\n",
      "Epoch:  9440 | Train Accurancy:  0.9303160458803177 | Validation Accurancy:  0.937433160841465\n",
      "Epoch:  9441 | Train Accurancy:  0.9303168505430222 | Validation Accurancy:  0.9374368861317635\n",
      "Epoch:  9442 | Train Accurancy:  0.9303176924586296 | Validation Accurancy:  0.9374404773116112\n",
      "Epoch:  9443 | Train Accurancy:  0.9303185045719147 | Validation Accurancy:  0.9374441131949425\n",
      "Epoch:  9444 | Train Accurancy:  0.9303192645311356 | Validation Accurancy:  0.9374477192759514\n",
      "Epoch:  9445 | Train Accurancy:  0.9303201213479042 | Validation Accurancy:  0.9374513924121857\n",
      "Epoch:  9446 | Train Accurancy:  0.9303209260106087 | Validation Accurancy:  0.9374551102519035\n",
      "Epoch:  9447 | Train Accurancy:  0.9303217306733131 | Validation Accurancy:  0.9374588206410408\n",
      "Epoch:  9448 | Train Accurancy:  0.930322527885437 | Validation Accurancy:  0.9374624863266945\n",
      "Epoch:  9449 | Train Accurancy:  0.9303233847022057 | Validation Accurancy:  0.93746617436409\n",
      "Epoch:  9450 | Train Accurancy:  0.9303241744637489 | Validation Accurancy:  0.9374698475003242\n",
      "Epoch:  9451 | Train Accurancy:  0.9303250014781952 | Validation Accurancy:  0.9374735355377197\n",
      "Epoch:  9452 | Train Accurancy:  0.9303257539868355 | Validation Accurancy:  0.937477208673954\n",
      "Epoch:  9453 | Train Accurancy:  0.93032655864954 | Validation Accurancy:  0.9374808147549629\n",
      "Epoch:  9454 | Train Accurancy:  0.930327333509922 | Validation Accurancy:  0.937484547495842\n",
      "Epoch:  9455 | Train Accurancy:  0.9303281977772713 | Validation Accurancy:  0.9374882057309151\n",
      "Epoch:  9456 | Train Accurancy:  0.9303289651870728 | Validation Accurancy:  0.9374918788671494\n",
      "Epoch:  9457 | Train Accurancy:  0.9303298071026802 | Validation Accurancy:  0.9374955967068672\n",
      "Epoch:  9458 | Train Accurancy:  0.9303305968642235 | Validation Accurancy:  0.9374992176890373\n",
      "Epoch:  9459 | Train Accurancy:  0.930331401526928 | Validation Accurancy:  0.9375029094517231\n",
      "Epoch:  9460 | Train Accurancy:  0.9303322210907936 | Validation Accurancy:  0.9375066421926022\n",
      "Epoch:  9461 | Train Accurancy:  0.9303330257534981 | Validation Accurancy:  0.937510285526514\n",
      "Epoch:  9462 | Train Accurancy:  0.9303338378667831 | Validation Accurancy:  0.9375139065086842\n",
      "Epoch:  9463 | Train Accurancy:  0.9303346127271652 | Validation Accurancy:  0.9375175796449184\n",
      "Epoch:  9464 | Train Accurancy:  0.9303354918956757 | Validation Accurancy:  0.9375212825834751\n",
      "Epoch:  9465 | Train Accurancy:  0.9303362518548965 | Validation Accurancy:  0.9375249221920967\n",
      "Epoch:  9466 | Train Accurancy:  0.9303370267152786 | Validation Accurancy:  0.9375286735594273\n",
      "Epoch:  9467 | Train Accurancy:  0.9303378313779831 | Validation Accurancy:  0.9375322982668877\n",
      "Epoch:  9468 | Train Accurancy:  0.9303385764360428 | Validation Accurancy:  0.9375359676778316\n",
      "Epoch:  9469 | Train Accurancy:  0.9303394481539726 | Validation Accurancy:  0.937539592385292\n",
      "Epoch:  9470 | Train Accurancy:  0.9303402602672577 | Validation Accurancy:  0.9375432655215263\n",
      "Epoch:  9471 | Train Accurancy:  0.930341050028801 | Validation Accurancy:  0.9375469200313091\n",
      "Epoch:  9472 | Train Accurancy:  0.9303418472409248 | Validation Accurancy:  0.9375505931675434\n",
      "Epoch:  9473 | Train Accurancy:  0.9303426593542099 | Validation Accurancy:  0.9375543110072613\n",
      "Epoch:  9474 | Train Accurancy:  0.9303434565663338 | Validation Accurancy:  0.937558013945818\n",
      "Epoch:  9475 | Train Accurancy:  0.9303442984819412 | Validation Accurancy:  0.9375615604221821\n",
      "Epoch:  9476 | Train Accurancy:  0.9303450807929039 | Validation Accurancy:  0.9375652633607388\n",
      "Epoch:  9477 | Train Accurancy:  0.9303458705544472 | Validation Accurancy:  0.9375689513981342\n",
      "Epoch:  9478 | Train Accurancy:  0.9303466826677322 | Validation Accurancy:  0.9375725574791431\n",
      "Epoch:  9479 | Train Accurancy:  0.9303474649786949 | Validation Accurancy:  0.9375762306153774\n",
      "Epoch:  9480 | Train Accurancy:  0.9303482994437218 | Validation Accurancy:  0.9375799335539341\n",
      "Epoch:  9481 | Train Accurancy:  0.9303490668535233 | Validation Accurancy:  0.9375835098326206\n",
      "Epoch:  9482 | Train Accurancy:  0.9303498491644859 | Validation Accurancy:  0.9375871643424034\n",
      "Epoch:  9483 | Train Accurancy:  0.9303506538271904 | Validation Accurancy:  0.9375908374786377\n",
      "Epoch:  9484 | Train Accurancy:  0.9303514659404755 | Validation Accurancy:  0.9375944919884205\n",
      "Epoch:  9485 | Train Accurancy:  0.9303523004055023 | Validation Accurancy:  0.937598180025816\n",
      "Epoch:  9486 | Train Accurancy:  0.9303530529141426 | Validation Accurancy:  0.9376018196344376\n",
      "Epoch:  9487 | Train Accurancy:  0.930353932082653 | Validation Accurancy:  0.9376053959131241\n",
      "Epoch:  9488 | Train Accurancy:  0.9303546622395515 | Validation Accurancy:  0.9376091472804546\n",
      "Epoch:  9489 | Train Accurancy:  0.9303555190563202 | Validation Accurancy:  0.9376128055155277\n",
      "Epoch:  9490 | Train Accurancy:  0.9303562939167023 | Validation Accurancy:  0.9376164898276329\n",
      "Epoch:  9491 | Train Accurancy:  0.9303571134805679 | Validation Accurancy:  0.9376200847327709\n",
      "Epoch:  9492 | Train Accurancy:  0.9303579181432724 | Validation Accurancy:  0.9376237541437149\n",
      "Epoch:  9493 | Train Accurancy:  0.9303587675094604 | Validation Accurancy:  0.9376273788511753\n",
      "Epoch:  9494 | Train Accurancy:  0.930359497666359 | Validation Accurancy:  0.9376311153173447\n",
      "Epoch:  9495 | Train Accurancy:  0.9303603023290634 | Validation Accurancy:  0.9376346729695797\n",
      "Epoch:  9496 | Train Accurancy:  0.9303610846400261 | Validation Accurancy:  0.9376383796334267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9497 | Train Accurancy:  0.9303619116544724 | Validation Accurancy:  0.9376419708132744\n",
      "Epoch:  9498 | Train Accurancy:  0.9303627014160156 | Validation Accurancy:  0.9376456402242184\n",
      "Epoch:  9499 | Train Accurancy:  0.9303634911775589 | Validation Accurancy:  0.9376493617892265\n",
      "Epoch:  9500 | Train Accurancy:  0.930364340543747 | Validation Accurancy:  0.9376530013978481\n",
      "Epoch:  9501 | Train Accurancy:  0.9303651079535484 | Validation Accurancy:  0.9376565292477608\n",
      "Epoch:  9502 | Train Accurancy:  0.9303659275174141 | Validation Accurancy:  0.9376602657139301\n",
      "Epoch:  9503 | Train Accurancy:  0.9303667098283768 | Validation Accurancy:  0.9376639984548092\n",
      "Epoch:  9504 | Train Accurancy:  0.9303675144910812 | Validation Accurancy:  0.9376674965023994\n",
      "Epoch:  9505 | Train Accurancy:  0.9303683191537857 | Validation Accurancy:  0.9376712627708912\n",
      "Epoch:  9506 | Train Accurancy:  0.930369108915329 | Validation Accurancy:  0.9376748725771904\n",
      "Epoch:  9507 | Train Accurancy:  0.930369921028614 | Validation Accurancy:  0.9376785270869732\n",
      "Epoch:  9508 | Train Accurancy:  0.9303707107901573 | Validation Accurancy:  0.9376822151243687\n",
      "Epoch:  9509 | Train Accurancy:  0.9303715005517006 | Validation Accurancy:  0.9376858063042164\n",
      "Epoch:  9510 | Train Accurancy:  0.9303723201155663 | Validation Accurancy:  0.9376894645392895\n",
      "Epoch:  9511 | Train Accurancy:  0.9303731024265289 | Validation Accurancy:  0.937693040817976\n",
      "Epoch:  9512 | Train Accurancy:  0.930373914539814 | Validation Accurancy:  0.9376967288553715\n",
      "Epoch:  9513 | Train Accurancy:  0.9303747266530991 | Validation Accurancy:  0.9377003684639931\n",
      "Epoch:  9514 | Train Accurancy:  0.9303755015134811 | Validation Accurancy:  0.9377039261162281\n",
      "Epoch:  9515 | Train Accurancy:  0.9303762838244438 | Validation Accurancy:  0.9377076476812363\n",
      "Epoch:  9516 | Train Accurancy:  0.9303770884871483 | Validation Accurancy:  0.9377112239599228\n",
      "Epoch:  9517 | Train Accurancy:  0.9303779229521751 | Validation Accurancy:  0.9377149119973183\n",
      "Epoch:  9518 | Train Accurancy:  0.9303787052631378 | Validation Accurancy:  0.9377185963094234\n",
      "Epoch:  9519 | Train Accurancy:  0.9303794726729393 | Validation Accurancy:  0.9377222545444965\n",
      "Epoch:  9520 | Train Accurancy:  0.9303802996873856 | Validation Accurancy:  0.9377257823944092\n",
      "Epoch:  9521 | Train Accurancy:  0.9303810447454453 | Validation Accurancy:  0.9377295188605785\n",
      "Epoch:  9522 | Train Accurancy:  0.9303818568587303 | Validation Accurancy:  0.937733206897974\n",
      "Epoch:  9523 | Train Accurancy:  0.930382676422596 | Validation Accurancy:  0.9377367980778217\n",
      "Epoch:  9524 | Train Accurancy:  0.9303834810853004 | Validation Accurancy:  0.9377404674887657\n",
      "Epoch:  9525 | Train Accurancy:  0.9303842410445213 | Validation Accurancy:  0.9377440921962261\n",
      "Epoch:  9526 | Train Accurancy:  0.9303851053118706 | Validation Accurancy:  0.9377477020025253\n",
      "Epoch:  9527 | Train Accurancy:  0.9303859025239944 | Validation Accurancy:  0.9377513565123081\n",
      "Epoch:  9528 | Train Accurancy:  0.9303866550326347 | Validation Accurancy:  0.9377549476921558\n",
      "Epoch:  9529 | Train Accurancy:  0.9303874224424362 | Validation Accurancy:  0.9377585090696812\n",
      "Epoch:  9530 | Train Accurancy:  0.9303882569074631 | Validation Accurancy:  0.9377622120082378\n",
      "Epoch:  9531 | Train Accurancy:  0.9303890615701675 | Validation Accurancy:  0.937765933573246\n",
      "Epoch:  9532 | Train Accurancy:  0.9303898438811302 | Validation Accurancy:  0.9377694465219975\n",
      "Epoch:  9533 | Train Accurancy:  0.9303906261920929 | Validation Accurancy:  0.9377731494605541\n",
      "Epoch:  9534 | Train Accurancy:  0.9303914159536362 | Validation Accurancy:  0.937776755541563\n",
      "Epoch:  9535 | Train Accurancy:  0.9303922355175018 | Validation Accurancy:  0.9377804137766361\n",
      "Epoch:  9536 | Train Accurancy:  0.9303929954767227 | Validation Accurancy:  0.9377840347588062\n",
      "Epoch:  9537 | Train Accurancy:  0.9303937926888466 | Validation Accurancy:  0.9377876743674278\n",
      "Epoch:  9538 | Train Accurancy:  0.9303945824503899 | Validation Accurancy:  0.9377913326025009\n",
      "Epoch:  9539 | Train Accurancy:  0.9303954318165779 | Validation Accurancy:  0.9377949386835098\n",
      "Epoch:  9540 | Train Accurancy:  0.9303962364792824 | Validation Accurancy:  0.937798548489809\n",
      "Epoch:  9541 | Train Accurancy:  0.9303970113396645 | Validation Accurancy:  0.9378021731972694\n",
      "Epoch:  9542 | Train Accurancy:  0.9303978160023689 | Validation Accurancy:  0.9378058277070522\n",
      "Epoch:  9543 | Train Accurancy:  0.9303986132144928 | Validation Accurancy:  0.9378094188869\n",
      "Epoch:  9544 | Train Accurancy:  0.9303993657231331 | Validation Accurancy:  0.9378131069242954\n",
      "Epoch:  9545 | Train Accurancy:  0.9304001331329346 | Validation Accurancy:  0.9378167614340782\n",
      "Epoch:  9546 | Train Accurancy:  0.9304010197520256 | Validation Accurancy:  0.9378203861415386\n",
      "Epoch:  9547 | Train Accurancy:  0.9304018169641495 | Validation Accurancy:  0.9378240443766117\n",
      "Epoch:  9548 | Train Accurancy:  0.9304025918245316 | Validation Accurancy:  0.9378276206552982\n",
      "Epoch:  9549 | Train Accurancy:  0.9304033517837524 | Validation Accurancy:  0.9378312267363071\n",
      "Epoch:  9550 | Train Accurancy:  0.9304041564464569 | Validation Accurancy:  0.9378348663449287\n",
      "Epoch:  9551 | Train Accurancy:  0.9304049387574196 | Validation Accurancy:  0.937838476151228\n",
      "Epoch:  9552 | Train Accurancy:  0.9304057285189629 | Validation Accurancy:  0.9378421157598495\n",
      "Epoch:  9553 | Train Accurancy:  0.9304065629839897 | Validation Accurancy:  0.9378457218408585\n",
      "Epoch:  9554 | Train Accurancy:  0.9304073676466942 | Validation Accurancy:  0.9378493465483189\n",
      "Epoch:  9555 | Train Accurancy:  0.9304081350564957 | Validation Accurancy:  0.9378529228270054\n",
      "Epoch:  9556 | Train Accurancy:  0.9304089471697807 | Validation Accurancy:  0.9378565475344658\n",
      "Epoch:  9557 | Train Accurancy:  0.930409699678421 | Validation Accurancy:  0.9378602504730225\n",
      "Epoch:  9558 | Train Accurancy:  0.9304104894399643 | Validation Accurancy:  0.9378638751804829\n",
      "Epoch:  9559 | Train Accurancy:  0.9304112493991852 | Validation Accurancy:  0.9378674998879433\n",
      "Epoch:  9560 | Train Accurancy:  0.9304120689630508 | Validation Accurancy:  0.9378712326288223\n",
      "Epoch:  9561 | Train Accurancy:  0.9304128736257553 | Validation Accurancy:  0.937874760478735\n",
      "Epoch:  9562 | Train Accurancy:  0.9304136708378792 | Validation Accurancy:  0.9378784038126469\n",
      "Epoch:  9563 | Train Accurancy:  0.9304144755005836 | Validation Accurancy:  0.9378821216523647\n",
      "Epoch:  9564 | Train Accurancy:  0.9304152727127075 | Validation Accurancy:  0.9378856010735035\n",
      "Epoch:  9565 | Train Accurancy:  0.9304160550236702 | Validation Accurancy:  0.9378892406821251\n",
      "Epoch:  9566 | Train Accurancy:  0.9304168298840523 | Validation Accurancy:  0.9378928169608116\n",
      "Epoch:  9567 | Train Accurancy:  0.9304176345467567 | Validation Accurancy:  0.937896441668272\n",
      "Epoch:  9568 | Train Accurancy:  0.9304184168577194 | Validation Accurancy:  0.9379000514745712\n",
      "Epoch:  9569 | Train Accurancy:  0.9304192811250687 | Validation Accurancy:  0.9379037544131279\n",
      "Epoch:  9570 | Train Accurancy:  0.9304200485348701 | Validation Accurancy:  0.9379073306918144\n",
      "Epoch:  9571 | Train Accurancy:  0.930420845746994 | Validation Accurancy:  0.9379108585417271\n",
      "Epoch:  9572 | Train Accurancy:  0.9304216131567955 | Validation Accurancy:  0.9379146099090576\n",
      "Epoch:  9573 | Train Accurancy:  0.9304224252700806 | Validation Accurancy:  0.9379181079566479\n",
      "Epoch:  9574 | Train Accurancy:  0.9304232150316238 | Validation Accurancy:  0.9379217959940434\n",
      "Epoch:  9575 | Train Accurancy:  0.9304239898920059 | Validation Accurancy:  0.9379253871738911\n",
      "Epoch:  9576 | Train Accurancy:  0.9304247871041298 | Validation Accurancy:  0.9379289783537388\n",
      "Epoch:  9577 | Train Accurancy:  0.9304255619645119 | Validation Accurancy:  0.937932588160038\n",
      "Epoch:  9578 | Train Accurancy:  0.9304263293743134 | Validation Accurancy:  0.9379362277686596\n",
      "Epoch:  9579 | Train Accurancy:  0.9304270967841148 | Validation Accurancy:  0.9379398040473461\n",
      "Epoch:  9580 | Train Accurancy:  0.9304279014468193 | Validation Accurancy:  0.937943521887064\n",
      "Epoch:  9581 | Train Accurancy:  0.9304286539554596 | Validation Accurancy:  0.9379470348358154\n",
      "Epoch:  9582 | Train Accurancy:  0.9304295033216476 | Validation Accurancy:  0.9379506595432758\n",
      "Epoch:  9583 | Train Accurancy:  0.9304302856326103 | Validation Accurancy:  0.9379543140530586\n",
      "Epoch:  9584 | Train Accurancy:  0.9304310232400894 | Validation Accurancy:  0.937957875430584\n",
      "Epoch:  9585 | Train Accurancy:  0.9304318502545357 | Validation Accurancy:  0.9379614517092705\n",
      "Epoch:  9586 | Train Accurancy:  0.9304326698184013 | Validation Accurancy:  0.9379651211202145\n",
      "Epoch:  9587 | Train Accurancy:  0.9304334297776222 | Validation Accurancy:  0.9379686824977398\n",
      "Epoch:  9588 | Train Accurancy:  0.9304342269897461 | Validation Accurancy:  0.9379723854362965\n",
      "Epoch:  9589 | Train Accurancy:  0.9304350540041924 | Validation Accurancy:  0.9379758834838867\n",
      "Epoch:  9590 | Train Accurancy:  0.9304358437657356 | Validation Accurancy:  0.9379795081913471\n",
      "Epoch:  9591 | Train Accurancy:  0.9304366037249565 | Validation Accurancy:  0.9379830993711948\n",
      "Epoch:  9592 | Train Accurancy:  0.9304373934864998 | Validation Accurancy:  0.9379867538809776\n",
      "Epoch:  9593 | Train Accurancy:  0.9304382055997849 | Validation Accurancy:  0.9379903301596642\n",
      "Epoch:  9594 | Train Accurancy:  0.9304389655590057 | Validation Accurancy:  0.9379939064383507\n",
      "Epoch:  9595 | Train Accurancy:  0.9304397404193878 | Validation Accurancy:  0.9379975162446499\n",
      "Epoch:  9596 | Train Accurancy:  0.9304404929280281 | Validation Accurancy:  0.9380011409521103\n",
      "Epoch:  9597 | Train Accurancy:  0.9304412826895714 | Validation Accurancy:  0.9380047805607319\n",
      "Epoch:  9598 | Train Accurancy:  0.930442102253437 | Validation Accurancy:  0.9380083233118057\n",
      "Epoch:  9599 | Train Accurancy:  0.9304428622126579 | Validation Accurancy:  0.9380119182169437\n",
      "Epoch:  9600 | Train Accurancy:  0.930443674325943 | Validation Accurancy:  0.9380155093967915\n",
      "Epoch:  9601 | Train Accurancy:  0.9304444566369057 | Validation Accurancy:  0.9380190707743168\n",
      "Epoch:  9602 | Train Accurancy:  0.9304452687501907 | Validation Accurancy:  0.9380226619541645\n",
      "Epoch:  9603 | Train Accurancy:  0.930446058511734 | Validation Accurancy:  0.93802634999156\n",
      "Epoch:  9604 | Train Accurancy:  0.9304468333721161 | Validation Accurancy:  0.9380299560725689\n",
      "Epoch:  9605 | Train Accurancy:  0.9304476454854012 | Validation Accurancy:  0.9380335174500942\n",
      "Epoch:  9606 | Train Accurancy:  0.9304483979940414 | Validation Accurancy:  0.9380371235311031\n",
      "Epoch:  9607 | Train Accurancy:  0.9304492026567459 | Validation Accurancy:  0.9380406998097897\n",
      "Epoch:  9608 | Train Accurancy:  0.930449977517128 | Validation Accurancy:  0.9380443096160889\n",
      "Epoch:  9609 | Train Accurancy:  0.9304507672786713 | Validation Accurancy:  0.9380478858947754\n",
      "Epoch:  9610 | Train Accurancy:  0.9304515570402145 | Validation Accurancy:  0.938051525503397\n",
      "Epoch:  9611 | Train Accurancy:  0.9304523393511772 | Validation Accurancy:  0.9380550384521484\n",
      "Epoch:  9612 | Train Accurancy:  0.9304530769586563 | Validation Accurancy:  0.9380587264895439\n",
      "Epoch:  9613 | Train Accurancy:  0.9304538890719414 | Validation Accurancy:  0.9380622692406178\n",
      "Epoch:  9614 | Train Accurancy:  0.9304547011852264 | Validation Accurancy:  0.9380658455193043\n",
      "Epoch:  9615 | Train Accurancy:  0.9304554611444473 | Validation Accurancy:  0.9380693584680557\n",
      "Epoch:  9616 | Train Accurancy:  0.9304562583565712 | Validation Accurancy:  0.9380729980766773\n",
      "Epoch:  9617 | Train Accurancy:  0.9304570406675339 | Validation Accurancy:  0.9380765929818153\n",
      "Epoch:  9618 | Train Accurancy:  0.9304578676819801 | Validation Accurancy:  0.9380802623927593\n",
      "Epoch:  9619 | Train Accurancy:  0.9304586350917816 | Validation Accurancy:  0.9380838088691235\n",
      "Epoch:  9620 | Train Accurancy:  0.9304594025015831 | Validation Accurancy:  0.9380874633789062\n",
      "Epoch:  9621 | Train Accurancy:  0.9304601848125458 | Validation Accurancy:  0.9380910396575928\n",
      "Epoch:  9622 | Train Accurancy:  0.9304610043764114 | Validation Accurancy:  0.9380945824086666\n",
      "Epoch:  9623 | Train Accurancy:  0.9304617419838905 | Validation Accurancy:  0.938098207116127\n",
      "Epoch:  9624 | Train Accurancy:  0.9304625540971756 | Validation Accurancy:  0.9381017535924911\n",
      "Epoch:  9625 | Train Accurancy:  0.9304633066058159 | Validation Accurancy:  0.9381053596735001\n",
      "Epoch:  9626 | Train Accurancy:  0.9304640963673592 | Validation Accurancy:  0.9381089843809605\n",
      "Epoch:  9627 | Train Accurancy:  0.9304649531841278 | Validation Accurancy:  0.938112560659647\n",
      "Epoch:  9628 | Train Accurancy:  0.9304656758904457 | Validation Accurancy:  0.9381162002682686\n",
      "Epoch:  9629 | Train Accurancy:  0.9304664582014084 | Validation Accurancy:  0.9381197281181812\n",
      "Epoch:  9630 | Train Accurancy:  0.9304672405123711 | Validation Accurancy:  0.9381233528256416\n",
      "Epoch:  9631 | Train Accurancy:  0.9304680675268173 | Validation Accurancy:  0.9381268657743931\n",
      "Epoch:  9632 | Train Accurancy:  0.9304687976837158 | Validation Accurancy:  0.9381305202841759\n",
      "Epoch:  9633 | Train Accurancy:  0.9304695874452591 | Validation Accurancy:  0.9381341151893139\n",
      "Epoch:  9634 | Train Accurancy:  0.9304703697562218 | Validation Accurancy:  0.9381377547979355\n",
      "Epoch:  9635 | Train Accurancy:  0.930471159517765 | Validation Accurancy:  0.9381412491202354\n",
      "Epoch:  9636 | Train Accurancy:  0.9304719194769859 | Validation Accurancy:  0.9381448589265347\n",
      "Epoch:  9637 | Train Accurancy:  0.9304727017879486 | Validation Accurancy:  0.93814842030406\n",
      "Epoch:  9638 | Train Accurancy:  0.9304734915494919 | Validation Accurancy:  0.9381519630551338\n",
      "Epoch:  9639 | Train Accurancy:  0.930474303662777 | Validation Accurancy:  0.9381554611027241\n",
      "Epoch:  9640 | Train Accurancy:  0.9304750338196754 | Validation Accurancy:  0.9381591640412807\n",
      "Epoch:  9641 | Train Accurancy:  0.9304758459329605 | Validation Accurancy:  0.9381627701222897\n",
      "Epoch:  9642 | Train Accurancy:  0.9304766356945038 | Validation Accurancy:  0.9381663799285889\n",
      "Epoch:  9643 | Train Accurancy:  0.9304774105548859 | Validation Accurancy:  0.9381699897348881\n",
      "Epoch:  9644 | Train Accurancy:  0.9304781779646873 | Validation Accurancy:  0.938173595815897\n",
      "Epoch:  9645 | Train Accurancy:  0.9304789453744888 | Validation Accurancy:  0.9381771422922611\n",
      "Epoch:  9646 | Train Accurancy:  0.9304797798395157 | Validation Accurancy:  0.9381807185709476\n",
      "Epoch:  9647 | Train Accurancy:  0.9304805621504784 | Validation Accurancy:  0.9381843246519566\n",
      "Epoch:  9648 | Train Accurancy:  0.9304812923073769 | Validation Accurancy:  0.9381879344582558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9649 | Train Accurancy:  0.9304820820689201 | Validation Accurancy:  0.9381914623081684\n",
      "Epoch:  9650 | Train Accurancy:  0.9304828569293022 | Validation Accurancy:  0.9381950683891773\n",
      "Epoch:  9651 | Train Accurancy:  0.9304836988449097 | Validation Accurancy:  0.9381985813379288\n",
      "Epoch:  9652 | Train Accurancy:  0.9304844066500664 | Validation Accurancy:  0.9382021427154541\n",
      "Epoch:  9653 | Train Accurancy:  0.9304852187633514 | Validation Accurancy:  0.9382056854665279\n",
      "Epoch:  9654 | Train Accurancy:  0.9304860010743141 | Validation Accurancy:  0.9382092617452145\n",
      "Epoch:  9655 | Train Accurancy:  0.9304867759346962 | Validation Accurancy:  0.9382127933204174\n",
      "Epoch:  9656 | Train Accurancy:  0.9304875805974007 | Validation Accurancy:  0.9382164627313614\n",
      "Epoch:  9657 | Train Accurancy:  0.9304883703589439 | Validation Accurancy:  0.9382199607789516\n",
      "Epoch:  9658 | Train Accurancy:  0.9304891377687454 | Validation Accurancy:  0.938223585486412\n",
      "Epoch:  9659 | Train Accurancy:  0.9304898828268051 | Validation Accurancy:  0.938227191567421\n",
      "Epoch:  9660 | Train Accurancy:  0.9304906576871872 | Validation Accurancy:  0.9382307194173336\n",
      "Epoch:  9661 | Train Accurancy:  0.9304914548993111 | Validation Accurancy:  0.9382342807948589\n",
      "Epoch:  9662 | Train Accurancy:  0.9304922595620155 | Validation Accurancy:  0.9382378272712231\n",
      "Epoch:  9663 | Train Accurancy:  0.9304930046200752 | Validation Accurancy:  0.9382414482533932\n",
      "Epoch:  9664 | Train Accurancy:  0.9304938018321991 | Validation Accurancy:  0.9382449612021446\n",
      "Epoch:  9665 | Train Accurancy:  0.9304945766925812 | Validation Accurancy:  0.9382485710084438\n",
      "Epoch:  9666 | Train Accurancy:  0.9304953888058662 | Validation Accurancy:  0.9382521323859692\n",
      "Epoch:  9667 | Train Accurancy:  0.9304961487650871 | Validation Accurancy:  0.9382557235658169\n",
      "Epoch:  9668 | Train Accurancy:  0.930496908724308 | Validation Accurancy:  0.9382592663168907\n",
      "Epoch:  9669 | Train Accurancy:  0.9304977133870125 | Validation Accurancy:  0.938262827694416\n",
      "Epoch:  9670 | Train Accurancy:  0.930498480796814 | Validation Accurancy:  0.9382664039731026\n",
      "Epoch:  9671 | Train Accurancy:  0.9304992482066154 | Validation Accurancy:  0.9382700137794018\n",
      "Epoch:  9672 | Train Accurancy:  0.9305000081658363 | Validation Accurancy:  0.9382736049592495\n",
      "Epoch:  9673 | Train Accurancy:  0.930500827729702 | Validation Accurancy:  0.9382770545780659\n",
      "Epoch:  9674 | Train Accurancy:  0.9305016025900841 | Validation Accurancy:  0.9382806941866875\n",
      "Epoch:  9675 | Train Accurancy:  0.9305023476481438 | Validation Accurancy:  0.9382842220366001\n",
      "Epoch:  9676 | Train Accurancy:  0.9305031672120094 | Validation Accurancy:  0.9382877834141254\n",
      "Epoch:  9677 | Train Accurancy:  0.9305039346218109 | Validation Accurancy:  0.9382913112640381\n",
      "Epoch:  9678 | Train Accurancy:  0.930504709482193 | Validation Accurancy:  0.9382948726415634\n",
      "Epoch:  9679 | Train Accurancy:  0.9305054768919945 | Validation Accurancy:  0.9382984638214111\n",
      "Epoch:  9680 | Train Accurancy:  0.9305062219500542 | Validation Accurancy:  0.9383020251989365\n",
      "Epoch:  9681 | Train Accurancy:  0.9305069744586945 | Validation Accurancy:  0.9383055381476879\n",
      "Epoch:  9682 | Train Accurancy:  0.9305077567696571 | Validation Accurancy:  0.9383090808987617\n",
      "Epoch:  9683 | Train Accurancy:  0.930508591234684 | Validation Accurancy:  0.938312690705061\n",
      "Epoch:  9684 | Train Accurancy:  0.9305093437433243 | Validation Accurancy:  0.9383163116872311\n",
      "Epoch:  9685 | Train Accurancy:  0.930510126054287 | Validation Accurancy:  0.9383198879659176\n",
      "Epoch:  9686 | Train Accurancy:  0.9305109083652496 | Validation Accurancy:  0.9383234195411205\n",
      "Epoch:  9687 | Train Accurancy:  0.9305117279291153 | Validation Accurancy:  0.9383270107209682\n",
      "Epoch:  9688 | Train Accurancy:  0.9305125176906586 | Validation Accurancy:  0.9383305720984936\n",
      "Epoch:  9689 | Train Accurancy:  0.9305132478475571 | Validation Accurancy:  0.9383340664207935\n",
      "Epoch:  9690 | Train Accurancy:  0.9305140450596809 | Validation Accurancy:  0.9383375979959965\n",
      "Epoch:  9691 | Train Accurancy:  0.9305147901177406 | Validation Accurancy:  0.9383411407470703\n",
      "Epoch:  9692 | Train Accurancy:  0.9305155351758003 | Validation Accurancy:  0.938344731926918\n",
      "Epoch:  9693 | Train Accurancy:  0.930516317486763 | Validation Accurancy:  0.9383481815457344\n",
      "Epoch:  9694 | Train Accurancy:  0.9305170923471451 | Validation Accurancy:  0.9383518844842911\n",
      "Epoch:  9695 | Train Accurancy:  0.9305179119110107 | Validation Accurancy:  0.9383553490042686\n",
      "Epoch:  9696 | Train Accurancy:  0.930518664419651 | Validation Accurancy:  0.938358910381794\n",
      "Epoch:  9697 | Train Accurancy:  0.9305194318294525 | Validation Accurancy:  0.9383624717593193\n",
      "Epoch:  9698 | Train Accurancy:  0.9305202141404152 | Validation Accurancy:  0.9383660964667797\n",
      "Epoch:  9699 | Train Accurancy:  0.9305210039019585 | Validation Accurancy:  0.9383695758879185\n",
      "Epoch:  9700 | Train Accurancy:  0.9305218160152435 | Validation Accurancy:  0.9383732005953789\n",
      "Epoch:  9701 | Train Accurancy:  0.9305225685238838 | Validation Accurancy:  0.9383767768740654\n",
      "Epoch:  9702 | Train Accurancy:  0.9305232986807823 | Validation Accurancy:  0.9383802749216557\n",
      "Epoch:  9703 | Train Accurancy:  0.9305240735411644 | Validation Accurancy:  0.9383838325738907\n",
      "Epoch:  9704 | Train Accurancy:  0.9305248484015465 | Validation Accurancy:  0.9383872970938683\n",
      "Epoch:  9705 | Train Accurancy:  0.9305256679654121 | Validation Accurancy:  0.9383909553289413\n",
      "Epoch:  9706 | Train Accurancy:  0.930526465177536 | Validation Accurancy:  0.9383944682776928\n",
      "Epoch:  9707 | Train Accurancy:  0.9305272027850151 | Validation Accurancy:  0.9383980594575405\n",
      "Epoch:  9708 | Train Accurancy:  0.9305279925465584 | Validation Accurancy:  0.9384016022086143\n",
      "Epoch:  9709 | Train Accurancy:  0.9305287227034569 | Validation Accurancy:  0.9384051635861397\n",
      "Epoch:  9710 | Train Accurancy:  0.9305295646190643 | Validation Accurancy:  0.9384086765348911\n",
      "Epoch:  9711 | Train Accurancy:  0.9305302873253822 | Validation Accurancy:  0.9384122230112553\n",
      "Epoch:  9712 | Train Accurancy:  0.9305310621857643 | Validation Accurancy:  0.9384157992899418\n",
      "Epoch:  9713 | Train Accurancy:  0.9305318295955658 | Validation Accurancy:  0.9384193755686283\n",
      "Epoch:  9714 | Train Accurancy:  0.9305326119065285 | Validation Accurancy:  0.9384228847920895\n",
      "Epoch:  9715 | Train Accurancy:  0.9305333942174911 | Validation Accurancy:  0.9384265094995499\n",
      "Epoch:  9716 | Train Accurancy:  0.9305341616272926 | Validation Accurancy:  0.9384299926459789\n",
      "Epoch:  9717 | Train Accurancy:  0.9305349439382553 | Validation Accurancy:  0.938433550298214\n",
      "Epoch:  9718 | Train Accurancy:  0.9305357038974762 | Validation Accurancy:  0.938437033444643\n",
      "Epoch:  9719 | Train Accurancy:  0.9305364564061165 | Validation Accurancy:  0.9384405761957169\n",
      "Epoch:  9720 | Train Accurancy:  0.9305372387170792 | Validation Accurancy:  0.938444122672081\n",
      "Epoch:  9721 | Train Accurancy:  0.9305380433797836 | Validation Accurancy:  0.9384477138519287\n",
      "Epoch:  9722 | Train Accurancy:  0.9305388182401657 | Validation Accurancy:  0.9384512417018414\n",
      "Epoch:  9723 | Train Accurancy:  0.9305395260453224 | Validation Accurancy:  0.9384548030793667\n",
      "Epoch:  9724 | Train Accurancy:  0.9305403083562851 | Validation Accurancy:  0.9384583011269569\n",
      "Epoch:  9725 | Train Accurancy:  0.9305411130189896 | Validation Accurancy:  0.9384618140757084\n",
      "Epoch:  9726 | Train Accurancy:  0.9305418878793716 | Validation Accurancy:  0.9384653717279434\n",
      "Epoch:  9727 | Train Accurancy:  0.9305426329374313 | Validation Accurancy:  0.9384688846766949\n",
      "Epoch:  9728 | Train Accurancy:  0.930543415248394 | Validation Accurancy:  0.9384724460542202\n",
      "Epoch:  9729 | Train Accurancy:  0.9305441603064537 | Validation Accurancy:  0.9384760223329067\n",
      "Epoch:  9730 | Train Accurancy:  0.930544950067997 | Validation Accurancy:  0.938479520380497\n",
      "Epoch:  9731 | Train Accurancy:  0.9305457398295403 | Validation Accurancy:  0.9384831264615059\n",
      "Epoch:  9732 | Train Accurancy:  0.9305464774370193 | Validation Accurancy:  0.93848667293787\n",
      "Epoch:  9733 | Train Accurancy:  0.930547334253788 | Validation Accurancy:  0.93849016726017\n",
      "Epoch:  9734 | Train Accurancy:  0.9305480644106865 | Validation Accurancy:  0.9384937137365341\n",
      "Epoch:  9735 | Train Accurancy:  0.930548794567585 | Validation Accurancy:  0.9384972900152206\n",
      "Epoch:  9736 | Train Accurancy:  0.9305496215820312 | Validation Accurancy:  0.938500739634037\n",
      "Epoch:  9737 | Train Accurancy:  0.9305503517389297 | Validation Accurancy:  0.9385043159127235\n",
      "Epoch:  9738 | Train Accurancy:  0.930551141500473 | Validation Accurancy:  0.9385078735649586\n",
      "Epoch:  9739 | Train Accurancy:  0.9305518716573715 | Validation Accurancy:  0.9385113380849361\n",
      "Epoch:  9740 | Train Accurancy:  0.9305527061223984 | Validation Accurancy:  0.9385148696601391\n",
      "Epoch:  9741 | Train Accurancy:  0.9305534660816193 | Validation Accurancy:  0.9385184608399868\n",
      "Epoch:  9742 | Train Accurancy:  0.9305542185902596 | Validation Accurancy:  0.9385219737887383\n",
      "Epoch:  9743 | Train Accurancy:  0.9305549636483192 | Validation Accurancy:  0.9385254867374897\n",
      "Epoch:  9744 | Train Accurancy:  0.9305557459592819 | Validation Accurancy:  0.9385289661586285\n",
      "Epoch:  9745 | Train Accurancy:  0.9305565059185028 | Validation Accurancy:  0.938532542437315\n",
      "Epoch:  9746 | Train Accurancy:  0.9305572807788849 | Validation Accurancy:  0.9385360404849052\n",
      "Epoch:  9747 | Train Accurancy:  0.9305580779910088 | Validation Accurancy:  0.9385395385324955\n",
      "Epoch:  9748 | Train Accurancy:  0.9305588155984879 | Validation Accurancy:  0.9385431930422783\n",
      "Epoch:  9749 | Train Accurancy:  0.9305595979094505 | Validation Accurancy:  0.9385467544198036\n",
      "Epoch:  9750 | Train Accurancy:  0.9305603578686714 | Validation Accurancy:  0.9385501705110073\n",
      "Epoch:  9751 | Train Accurancy:  0.9305611178278923 | Validation Accurancy:  0.9385537952184677\n",
      "Epoch:  9752 | Train Accurancy:  0.9305618926882744 | Validation Accurancy:  0.9385573528707027\n",
      "Epoch:  9753 | Train Accurancy:  0.93056271225214 | Validation Accurancy:  0.9385607875883579\n",
      "Epoch:  9754 | Train Accurancy:  0.930563434958458 | Validation Accurancy:  0.9385643489658833\n",
      "Epoch:  9755 | Train Accurancy:  0.93056420981884 | Validation Accurancy:  0.938567828387022\n",
      "Epoch:  9756 | Train Accurancy:  0.9305649995803833 | Validation Accurancy:  0.9385714046657085\n",
      "Epoch:  9757 | Train Accurancy:  0.9305657371878624 | Validation Accurancy:  0.93857491761446\n",
      "Epoch:  9758 | Train Accurancy:  0.9305665045976639 | Validation Accurancy:  0.9385784454643726\n",
      "Epoch:  9759 | Train Accurancy:  0.9305672943592072 | Validation Accurancy:  0.9385819286108017\n",
      "Epoch:  9760 | Train Accurancy:  0.930568091571331 | Validation Accurancy:  0.9385854713618755\n",
      "Epoch:  9761 | Train Accurancy:  0.9305688217282295 | Validation Accurancy:  0.9385890476405621\n",
      "Epoch:  9762 | Train Accurancy:  0.9305696189403534 | Validation Accurancy:  0.938592467457056\n",
      "Epoch:  9763 | Train Accurancy:  0.9305703490972519 | Validation Accurancy:  0.9385959766805172\n",
      "Epoch:  9764 | Train Accurancy:  0.930571123957634 | Validation Accurancy:  0.9385995380580425\n",
      "Epoch:  9765 | Train Accurancy:  0.9305718764662743 | Validation Accurancy:  0.9386029578745365\n",
      "Epoch:  9766 | Train Accurancy:  0.9305726960301399 | Validation Accurancy:  0.9386065006256104\n",
      "Epoch:  9767 | Train Accurancy:  0.9305734187364578 | Validation Accurancy:  0.9386100769042969\n",
      "Epoch:  9768 | Train Accurancy:  0.9305741861462593 | Validation Accurancy:  0.9386135563254356\n",
      "Epoch:  9769 | Train Accurancy:  0.930574931204319 | Validation Accurancy:  0.938617117702961\n",
      "Epoch:  9770 | Train Accurancy:  0.9305757284164429 | Validation Accurancy:  0.9386206306517124\n",
      "Epoch:  9771 | Train Accurancy:  0.9305764883756638 | Validation Accurancy:  0.9386241920292377\n",
      "Epoch:  9772 | Train Accurancy:  0.9305772706866264 | Validation Accurancy:  0.9386277049779892\n",
      "Epoch:  9773 | Train Accurancy:  0.9305779784917831 | Validation Accurancy:  0.938631247729063\n",
      "Epoch:  9774 | Train Accurancy:  0.9305787533521652 | Validation Accurancy:  0.9386347308754921\n",
      "Epoch:  9775 | Train Accurancy:  0.9305795356631279 | Validation Accurancy:  0.9386382102966309\n",
      "Epoch:  9776 | Train Accurancy:  0.93058031052351 | Validation Accurancy:  0.9386417381465435\n",
      "Epoch:  9777 | Train Accurancy:  0.9305810779333115 | Validation Accurancy:  0.9386452846229076\n",
      "Epoch:  9778 | Train Accurancy:  0.9305818229913712 | Validation Accurancy:  0.938648734241724\n",
      "Epoch:  9779 | Train Accurancy:  0.9305826276540756 | Validation Accurancy:  0.9386522434651852\n",
      "Epoch:  9780 | Train Accurancy:  0.9305833801627159 | Validation Accurancy:  0.9386556781828403\n",
      "Epoch:  9781 | Train Accurancy:  0.9305841773748398 | Validation Accurancy:  0.9386591762304306\n",
      "Epoch:  9782 | Train Accurancy:  0.9305849000811577 | Validation Accurancy:  0.9386627338826656\n",
      "Epoch:  9783 | Train Accurancy:  0.9305857047438622 | Validation Accurancy:  0.9386662654578686\n",
      "Epoch:  9784 | Train Accurancy:  0.9305864349007607 | Validation Accurancy:  0.9386697448790073\n",
      "Epoch:  9785 | Train Accurancy:  0.9305872246623039 | Validation Accurancy:  0.9386732093989849\n",
      "Epoch:  9786 | Train Accurancy:  0.9305879846215248 | Validation Accurancy:  0.9386768490076065\n",
      "Epoch:  9787 | Train Accurancy:  0.9305887445807457 | Validation Accurancy:  0.9386803470551968\n",
      "Epoch:  9788 | Train Accurancy:  0.9305895119905472 | Validation Accurancy:  0.9386837966740131\n",
      "Epoch:  9789 | Train Accurancy:  0.9305902719497681 | Validation Accurancy:  0.9386873878538609\n",
      "Epoch:  9790 | Train Accurancy:  0.9305910021066666 | Validation Accurancy:  0.9386908859014511\n",
      "Epoch:  9791 | Train Accurancy:  0.9305917993187904 | Validation Accurancy:  0.938694316893816\n",
      "Epoch:  9792 | Train Accurancy:  0.9305925294756889 | Validation Accurancy:  0.9386978633701801\n",
      "Epoch:  9793 | Train Accurancy:  0.9305933490395546 | Validation Accurancy:  0.9387014247477055\n",
      "Epoch:  9794 | Train Accurancy:  0.9305940717458725 | Validation Accurancy:  0.9387049525976181\n",
      "Epoch:  9795 | Train Accurancy:  0.9305948242545128 | Validation Accurancy:  0.9387083686888218\n",
      "Epoch:  9796 | Train Accurancy:  0.9305956065654755 | Validation Accurancy:  0.9387119300663471\n",
      "Epoch:  9797 | Train Accurancy:  0.9305963590741158 | Validation Accurancy:  0.938715361058712\n",
      "Epoch:  9798 | Train Accurancy:  0.930597111582756 | Validation Accurancy:  0.9387189075350761\n",
      "Epoch:  9799 | Train Accurancy:  0.9305978864431381 | Validation Accurancy:  0.9387224987149239\n",
      "Epoch:  9800 | Train Accurancy:  0.930598646402359 | Validation Accurancy:  0.9387259818613529\n",
      "Epoch:  9801 | Train Accurancy:  0.9305994138121605 | Validation Accurancy:  0.9387294612824917\n",
      "Epoch:  9802 | Train Accurancy:  0.9306001588702202 | Validation Accurancy:  0.9387330375611782\n",
      "Epoch:  9803 | Train Accurancy:  0.9306009784340858 | Validation Accurancy:  0.9387363605201244\n",
      "Epoch:  9804 | Train Accurancy:  0.9306016862392426 | Validation Accurancy:  0.9387399181723595\n",
      "Epoch:  9805 | Train Accurancy:  0.930602453649044 | Validation Accurancy:  0.9387434646487236\n",
      "Epoch:  9806 | Train Accurancy:  0.9306032359600067 | Validation Accurancy:  0.9387469626963139\n",
      "Epoch:  9807 | Train Accurancy:  0.9306040331721306 | Validation Accurancy:  0.938750471919775\n",
      "Epoch:  9808 | Train Accurancy:  0.9306047484278679 | Validation Accurancy:  0.9387540183961391\n",
      "Epoch:  9809 | Train Accurancy:  0.9306055009365082 | Validation Accurancy:  0.9387575164437294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9810 | Train Accurancy:  0.9306062608957291 | Validation Accurancy:  0.938760980963707\n",
      "Epoch:  9811 | Train Accurancy:  0.9306070059537888 | Validation Accurancy:  0.9387644119560719\n",
      "Epoch:  9812 | Train Accurancy:  0.9306077882647514 | Validation Accurancy:  0.9387679100036621\n",
      "Epoch:  9813 | Train Accurancy:  0.9306085407733917 | Validation Accurancy:  0.9387714080512524\n",
      "Epoch:  9814 | Train Accurancy:  0.9306093230843544 | Validation Accurancy:  0.938774935901165\n",
      "Epoch:  9815 | Train Accurancy:  0.9306100383400917 | Validation Accurancy:  0.9387785270810127\n",
      "Epoch:  9816 | Train Accurancy:  0.930610828101635 | Validation Accurancy:  0.9387820549309254\n",
      "Epoch:  9817 | Train Accurancy:  0.9306116178631783 | Validation Accurancy:  0.9387854412198067\n",
      "Epoch:  9818 | Train Accurancy:  0.9306123405694962 | Validation Accurancy:  0.9387889243662357\n",
      "Epoch:  9819 | Train Accurancy:  0.9306131154298782 | Validation Accurancy:  0.9387924820184708\n",
      "Epoch:  9820 | Train Accurancy:  0.9306138604879379 | Validation Accurancy:  0.9387959018349648\n",
      "Epoch:  9821 | Train Accurancy:  0.930614672601223 | Validation Accurancy:  0.9387993961572647\n",
      "Epoch:  9822 | Train Accurancy:  0.9306154474616051 | Validation Accurancy:  0.9388028793036938\n",
      "Epoch:  9823 | Train Accurancy:  0.930616170167923 | Validation Accurancy:  0.9388064071536064\n",
      "Epoch:  9824 | Train Accurancy:  0.930616945028305 | Validation Accurancy:  0.9388098381459713\n",
      "Epoch:  9825 | Train Accurancy:  0.9306177124381065 | Validation Accurancy:  0.9388133846223354\n",
      "Epoch:  9826 | Train Accurancy:  0.9306184574961662 | Validation Accurancy:  0.9388168975710869\n",
      "Epoch:  9827 | Train Accurancy:  0.9306191876530647 | Validation Accurancy:  0.9388203769922256\n",
      "Epoch:  9828 | Train Accurancy:  0.9306200072169304 | Validation Accurancy:  0.9388238117098808\n",
      "Epoch:  9829 | Train Accurancy:  0.9306207522749901 | Validation Accurancy:  0.9388272762298584\n",
      "Epoch:  9830 | Train Accurancy:  0.9306215047836304 | Validation Accurancy:  0.9388308860361576\n",
      "Epoch:  9831 | Train Accurancy:  0.9306222721934319 | Validation Accurancy:  0.9388342872262001\n",
      "Epoch:  9832 | Train Accurancy:  0.930623009800911 | Validation Accurancy:  0.9388378299772739\n",
      "Epoch:  9833 | Train Accurancy:  0.9306237548589706 | Validation Accurancy:  0.9388413093984127\n",
      "Epoch:  9834 | Train Accurancy:  0.9306245222687721 | Validation Accurancy:  0.9388447925448418\n",
      "Epoch:  9835 | Train Accurancy:  0.9306253120303154 | Validation Accurancy:  0.9388482235372066\n",
      "Epoch:  9836 | Train Accurancy:  0.9306260570883751 | Validation Accurancy:  0.938851784914732\n",
      "Epoch:  9837 | Train Accurancy:  0.9306267872452736 | Validation Accurancy:  0.9388552345335484\n",
      "Epoch:  9838 | Train Accurancy:  0.9306275844573975 | Validation Accurancy:  0.9388588108122349\n",
      "Epoch:  9839 | Train Accurancy:  0.930628314614296 | Validation Accurancy:  0.9388622269034386\n",
      "Epoch:  9840 | Train Accurancy:  0.9306290596723557 | Validation Accurancy:  0.9388657584786415\n",
      "Epoch:  9841 | Train Accurancy:  0.9306298196315765 | Validation Accurancy:  0.9388692378997803\n",
      "Epoch:  9842 | Train Accurancy:  0.9306306093931198 | Validation Accurancy:  0.938872717320919\n",
      "Epoch:  9843 | Train Accurancy:  0.9306313693523407 | Validation Accurancy:  0.9388762004673481\n",
      "Epoch:  9844 | Train Accurancy:  0.930632121860981 | Validation Accurancy:  0.9388796798884869\n",
      "Epoch:  9845 | Train Accurancy:  0.9306328594684601 | Validation Accurancy:  0.9388831779360771\n",
      "Epoch:  9846 | Train Accurancy:  0.9306335970759392 | Validation Accurancy:  0.9388866908848286\n",
      "Epoch:  9847 | Train Accurancy:  0.9306343644857407 | Validation Accurancy:  0.9388900771737099\n",
      "Epoch:  9848 | Train Accurancy:  0.9306351616978645 | Validation Accurancy:  0.9388936534523964\n",
      "Epoch:  9849 | Train Accurancy:  0.930635891854763 | Validation Accurancy:  0.9388970546424389\n",
      "Epoch:  9850 | Train Accurancy:  0.9306366145610809 | Validation Accurancy:  0.9389005042612553\n",
      "Epoch:  9851 | Train Accurancy:  0.9306373447179794 | Validation Accurancy:  0.9389040805399418\n",
      "Epoch:  9852 | Train Accurancy:  0.9306381121277809 | Validation Accurancy:  0.9389075264334679\n",
      "Epoch:  9853 | Train Accurancy:  0.9306389540433884 | Validation Accurancy:  0.9389109946787357\n",
      "Epoch:  9854 | Train Accurancy:  0.9306396991014481 | Validation Accurancy:  0.9389144591987133\n",
      "Epoch:  9855 | Train Accurancy:  0.9306404292583466 | Validation Accurancy:  0.9389179386198521\n",
      "Epoch:  9856 | Train Accurancy:  0.9306411519646645 | Validation Accurancy:  0.9389214515686035\n",
      "Epoch:  9857 | Train Accurancy:  0.9306419566273689 | Validation Accurancy:  0.9389249011874199\n",
      "Epoch:  9858 | Train Accurancy:  0.9306427165865898 | Validation Accurancy:  0.9389283657073975\n",
      "Epoch:  9859 | Train Accurancy:  0.9306434467434883 | Validation Accurancy:  0.9389318004250526\n",
      "Epoch:  9860 | Train Accurancy:  0.9306441619992256 | Validation Accurancy:  0.9389352947473526\n",
      "Epoch:  9861 | Train Accurancy:  0.9306449592113495 | Validation Accurancy:  0.9389388710260391\n",
      "Epoch:  9862 | Train Accurancy:  0.9306457340717316 | Validation Accurancy:  0.9389423690736294\n",
      "Epoch:  9863 | Train Accurancy:  0.9306464940309525 | Validation Accurancy:  0.9389457851648331\n",
      "Epoch:  9864 | Train Accurancy:  0.9306472390890121 | Validation Accurancy:  0.9389492049813271\n",
      "Epoch:  9865 | Train Accurancy:  0.9306480139493942 | Validation Accurancy:  0.9389527328312397\n",
      "Epoch:  9866 | Train Accurancy:  0.9306487962603569 | Validation Accurancy:  0.9389561824500561\n",
      "Epoch:  9867 | Train Accurancy:  0.9306495413184166 | Validation Accurancy:  0.9389596618711948\n",
      "Epoch:  9868 | Train Accurancy:  0.9306503087282181 | Validation Accurancy:  0.9389631263911724\n",
      "Epoch:  9869 | Train Accurancy:  0.9306510388851166 | Validation Accurancy:  0.9389665611088276\n",
      "Epoch:  9870 | Train Accurancy:  0.9306517690420151 | Validation Accurancy:  0.9389700889587402\n",
      "Epoch:  9871 | Train Accurancy:  0.9306525141000748 | Validation Accurancy:  0.9389735534787178\n",
      "Epoch:  9872 | Train Accurancy:  0.9306532964110374 | Validation Accurancy:  0.9389770179986954\n",
      "Epoch:  9873 | Train Accurancy:  0.9306540042161942 | Validation Accurancy:  0.9389804676175117\n",
      "Epoch:  9874 | Train Accurancy:  0.9306547865271568 | Validation Accurancy:  0.9389839023351669\n",
      "Epoch:  9875 | Train Accurancy:  0.9306555166840553 | Validation Accurancy:  0.9389873966574669\n",
      "Epoch:  9876 | Train Accurancy:  0.9306562915444374 | Validation Accurancy:  0.938990879803896\n",
      "Epoch:  9877 | Train Accurancy:  0.9306570366024971 | Validation Accurancy:  0.9389943443238735\n",
      "Epoch:  9878 | Train Accurancy:  0.9306578189134598 | Validation Accurancy:  0.938997745513916\n",
      "Epoch:  9879 | Train Accurancy:  0.9306585490703583 | Validation Accurancy:  0.9390012733638287\n",
      "Epoch:  9880 | Train Accurancy:  0.9306593239307404 | Validation Accurancy:  0.9390047714114189\n",
      "Epoch:  9881 | Train Accurancy:  0.9306600540876389 | Validation Accurancy:  0.9390083327889442\n",
      "Epoch:  9882 | Train Accurancy:  0.9306608363986015 | Validation Accurancy:  0.9390117637813091\n",
      "Epoch:  9883 | Train Accurancy:  0.9306615740060806 | Validation Accurancy:  0.9390152618288994\n",
      "Epoch:  9884 | Train Accurancy:  0.9306622818112373 | Validation Accurancy:  0.9390186779201031\n",
      "Epoch:  9885 | Train Accurancy:  0.9306630864739418 | Validation Accurancy:  0.9390221275389194\n",
      "Epoch:  9886 | Train Accurancy:  0.9306638315320015 | Validation Accurancy:  0.9390255138278008\n",
      "Epoch:  9887 | Train Accurancy:  0.9306645616889 | Validation Accurancy:  0.9390290565788746\n",
      "Epoch:  9888 | Train Accurancy:  0.9306653216481209 | Validation Accurancy:  0.9390324912965298\n",
      "Epoch:  9889 | Train Accurancy:  0.9306660592556 | Validation Accurancy:  0.9390360042452812\n",
      "Epoch:  9890 | Train Accurancy:  0.9306668415665627 | Validation Accurancy:  0.9390394538640976\n",
      "Epoch:  9891 | Train Accurancy:  0.9306676089763641 | Validation Accurancy:  0.939042903482914\n",
      "Epoch:  9892 | Train Accurancy:  0.930668368935585 | Validation Accurancy:  0.9390464313328266\n",
      "Epoch:  9893 | Train Accurancy:  0.9306690841913223 | Validation Accurancy:  0.9390498474240303\n",
      "Epoch:  9894 | Train Accurancy:  0.9306698516011238 | Validation Accurancy:  0.9390533454716206\n",
      "Epoch:  9895 | Train Accurancy:  0.9306706190109253 | Validation Accurancy:  0.9390567131340504\n",
      "Epoch:  9896 | Train Accurancy:  0.9306713566184044 | Validation Accurancy:  0.9390601329505444\n",
      "Epoch:  9897 | Train Accurancy:  0.9306721165776253 | Validation Accurancy:  0.9390635825693607\n",
      "Epoch:  9898 | Train Accurancy:  0.9306728541851044 | Validation Accurancy:  0.9390670917928219\n",
      "Epoch:  9899 | Train Accurancy:  0.9306736439466476 | Validation Accurancy:  0.9390705265104771\n",
      "Epoch:  9900 | Train Accurancy:  0.930674359202385 | Validation Accurancy:  0.9390739910304546\n",
      "Epoch:  9901 | Train Accurancy:  0.9306750744581223 | Validation Accurancy:  0.939077440649271\n",
      "Epoch:  9902 | Train Accurancy:  0.9306758269667625 | Validation Accurancy:  0.9390809200704098\n",
      "Epoch:  9903 | Train Accurancy:  0.9306766614317894 | Validation Accurancy:  0.939084354788065\n",
      "Epoch:  9904 | Train Accurancy:  0.9306773692369461 | Validation Accurancy:  0.9390878677368164\n",
      "Epoch:  9905 | Train Accurancy:  0.9306781440973282 | Validation Accurancy:  0.9390912689268589\n",
      "Epoch:  9906 | Train Accurancy:  0.9306788668036461 | Validation Accurancy:  0.939094815403223\n",
      "Epoch:  9907 | Train Accurancy:  0.9306795969605446 | Validation Accurancy:  0.939098309725523\n",
      "Epoch:  9908 | Train Accurancy:  0.9306803271174431 | Validation Accurancy:  0.939101729542017\n",
      "Epoch:  9909 | Train Accurancy:  0.930681124329567 | Validation Accurancy:  0.9391051754355431\n",
      "Epoch:  9910 | Train Accurancy:  0.9306818470358849 | Validation Accurancy:  0.9391086436808109\n",
      "Epoch:  9911 | Train Accurancy:  0.9306826144456863 | Validation Accurancy:  0.9391120448708534\n",
      "Epoch:  9912 | Train Accurancy:  0.930683359503746 | Validation Accurancy:  0.9391154758632183\n",
      "Epoch:  9913 | Train Accurancy:  0.9306841343641281 | Validation Accurancy:  0.9391189739108086\n",
      "Epoch:  9914 | Train Accurancy:  0.930684894323349 | Validation Accurancy:  0.9391224049031734\n",
      "Epoch:  9915 | Train Accurancy:  0.9306856095790863 | Validation Accurancy:  0.9391258396208286\n",
      "Epoch:  9916 | Train Accurancy:  0.930686391890049 | Validation Accurancy:  0.939129289239645\n",
      "Epoch:  9917 | Train Accurancy:  0.9306871443986893 | Validation Accurancy:  0.9391327686607838\n",
      "Epoch:  9918 | Train Accurancy:  0.930687889456749 | Validation Accurancy:  0.939136266708374\n",
      "Epoch:  9919 | Train Accurancy:  0.9306886270642281 | Validation Accurancy:  0.9391396678984165\n",
      "Epoch:  9920 | Train Accurancy:  0.9306893646717072 | Validation Accurancy:  0.9391431026160717\n",
      "Epoch:  9921 | Train Accurancy:  0.9306901171803474 | Validation Accurancy:  0.9391466304659843\n",
      "Epoch:  9922 | Train Accurancy:  0.9306908622384071 | Validation Accurancy:  0.939149983227253\n",
      "Epoch:  9923 | Train Accurancy:  0.9306916445493698 | Validation Accurancy:  0.9391534328460693\n",
      "Epoch:  9924 | Train Accurancy:  0.9306923523545265 | Validation Accurancy:  0.9391569308936596\n",
      "Epoch:  9925 | Train Accurancy:  0.9306930974125862 | Validation Accurancy:  0.939160380512476\n",
      "Epoch:  9926 | Train Accurancy:  0.9306938648223877 | Validation Accurancy:  0.9391638115048409\n",
      "Epoch:  9927 | Train Accurancy:  0.9306946471333504 | Validation Accurancy:  0.9391672760248184\n",
      "Epoch:  9928 | Train Accurancy:  0.9306954070925713 | Validation Accurancy:  0.9391707740724087\n",
      "Epoch:  9929 | Train Accurancy:  0.9306961074471474 | Validation Accurancy:  0.9391742087900639\n",
      "Epoch:  9930 | Train Accurancy:  0.9306968450546265 | Validation Accurancy:  0.9391776099801064\n",
      "Epoch:  9931 | Train Accurancy:  0.9306975826621056 | Validation Accurancy:  0.9391810558736324\n",
      "Epoch:  9932 | Train Accurancy:  0.9306983277201653 | Validation Accurancy:  0.9391845241189003\n",
      "Epoch:  9933 | Train Accurancy:  0.9306991249322891 | Validation Accurancy:  0.9391879551112652\n",
      "Epoch:  9934 | Train Accurancy:  0.9306998401880264 | Validation Accurancy:  0.9391914196312428\n",
      "Epoch:  9935 | Train Accurancy:  0.9307006150484085 | Validation Accurancy:  0.9391947761178017\n",
      "Epoch:  9936 | Train Accurancy:  0.9307012856006622 | Validation Accurancy:  0.9391983039677143\n",
      "Epoch:  9937 | Train Accurancy:  0.9307021424174309 | Validation Accurancy:  0.9392017535865307\n",
      "Epoch:  9938 | Train Accurancy:  0.93070288002491 | Validation Accurancy:  0.9392051212489605\n",
      "Epoch:  9939 | Train Accurancy:  0.9307036027312279 | Validation Accurancy:  0.9392085857689381\n",
      "Epoch:  9940 | Train Accurancy:  0.9307043105363846 | Validation Accurancy:  0.9392119869589806\n",
      "Epoch:  9941 | Train Accurancy:  0.9307050704956055 | Validation Accurancy:  0.9392154552042484\n",
      "Epoch:  9942 | Train Accurancy:  0.930705837905407 | Validation Accurancy:  0.9392188712954521\n",
      "Epoch:  9943 | Train Accurancy:  0.9307065978646278 | Validation Accurancy:  0.9392222575843334\n",
      "Epoch:  9944 | Train Accurancy:  0.9307073131203651 | Validation Accurancy:  0.9392257854342461\n",
      "Epoch:  9945 | Train Accurancy:  0.9307080954313278 | Validation Accurancy:  0.9392291232943535\n",
      "Epoch:  9946 | Train Accurancy:  0.9307088479399681 | Validation Accurancy:  0.9392325729131699\n",
      "Epoch:  9947 | Train Accurancy:  0.9307095631957054 | Validation Accurancy:  0.9392360523343086\n",
      "Epoch:  9948 | Train Accurancy:  0.9307102933526039 | Validation Accurancy:  0.9392394870519638\n",
      "Epoch:  9949 | Train Accurancy:  0.9307110533118248 | Validation Accurancy:  0.9392429180443287\n",
      "Epoch:  9950 | Train Accurancy:  0.9307117909193039 | Validation Accurancy:  0.9392463825643063\n",
      "Epoch:  9951 | Train Accurancy:  0.9307125583291054 | Validation Accurancy:  0.9392498023808002\n",
      "Epoch:  9952 | Train Accurancy:  0.9307132959365845 | Validation Accurancy:  0.9392532967031002\n",
      "Epoch:  9953 | Train Accurancy:  0.9307140335440636 | Validation Accurancy:  0.9392565563321114\n",
      "Epoch:  9954 | Train Accurancy:  0.930714800953865 | Validation Accurancy:  0.9392600543797016\n",
      "Epoch:  9955 | Train Accurancy:  0.930715523660183 | Validation Accurancy:  0.9392635188996792\n",
      "Epoch:  9956 | Train Accurancy:  0.930716261267662 | Validation Accurancy:  0.9392669051885605\n",
      "Epoch:  9957 | Train Accurancy:  0.9307170212268829 | Validation Accurancy:  0.9392703548073769\n",
      "Epoch:  9958 | Train Accurancy:  0.930717796087265 | Validation Accurancy:  0.9392738342285156\n",
      "Epoch:  9959 | Train Accurancy:  0.9307185560464859 | Validation Accurancy:  0.939277172088623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9960 | Train Accurancy:  0.9307192787528038 | Validation Accurancy:  0.9392806515097618\n",
      "Epoch:  9961 | Train Accurancy:  0.9307200089097023 | Validation Accurancy:  0.939284086227417\n",
      "Epoch:  9962 | Train Accurancy:  0.9307207241654396 | Validation Accurancy:  0.9392874725162983\n",
      "Epoch:  9963 | Train Accurancy:  0.9307214841246605 | Validation Accurancy:  0.939290888607502\n",
      "Epoch:  9964 | Train Accurancy:  0.9307222291827202 | Validation Accurancy:  0.9392943233251572\n",
      "Epoch:  9965 | Train Accurancy:  0.9307229965925217 | Validation Accurancy:  0.9392978027462959\n",
      "Epoch:  9966 | Train Accurancy:  0.9307237192988396 | Validation Accurancy:  0.9393011555075645\n",
      "Epoch:  9967 | Train Accurancy:  0.9307244792580605 | Validation Accurancy:  0.9393046386539936\n",
      "Epoch:  9968 | Train Accurancy:  0.9307251498103142 | Validation Accurancy:  0.93930808827281\n",
      "Epoch:  9969 | Train Accurancy:  0.9307259023189545 | Validation Accurancy:  0.9393113926053047\n",
      "Epoch:  9970 | Train Accurancy:  0.9307266771793365 | Validation Accurancy:  0.9393148757517338\n",
      "Epoch:  9971 | Train Accurancy:  0.930727444589138 | Validation Accurancy:  0.9393183067440987\n",
      "Epoch:  9972 | Train Accurancy:  0.9307281523942947 | Validation Accurancy:  0.9393217712640762\n",
      "Epoch:  9973 | Train Accurancy:  0.9307288900017738 | Validation Accurancy:  0.9393252059817314\n",
      "Epoch:  9974 | Train Accurancy:  0.9307296723127365 | Validation Accurancy:  0.9393285922706127\n",
      "Epoch:  9975 | Train Accurancy:  0.9307304248213768 | Validation Accurancy:  0.9393320232629776\n",
      "Epoch:  9976 | Train Accurancy:  0.9307311400771141 | Validation Accurancy:  0.9393355064094067\n",
      "Epoch:  9977 | Train Accurancy:  0.930731862783432 | Validation Accurancy:  0.9393388889729977\n",
      "Epoch:  9978 | Train Accurancy:  0.9307326003909111 | Validation Accurancy:  0.939342338591814\n",
      "Epoch:  9979 | Train Accurancy:  0.9307333454489708 | Validation Accurancy:  0.9393457099795341\n",
      "Epoch:  9980 | Train Accurancy:  0.9307341352105141 | Validation Accurancy:  0.939349140971899\n",
      "Epoch:  9981 | Train Accurancy:  0.9307348653674126 | Validation Accurancy:  0.9393526241183281\n",
      "Epoch:  9982 | Train Accurancy:  0.9307355731725693 | Validation Accurancy:  0.9393560104072094\n",
      "Epoch:  9983 | Train Accurancy:  0.9307363331317902 | Validation Accurancy:  0.9393593929708004\n",
      "Epoch:  9984 | Train Accurancy:  0.9307370632886887 | Validation Accurancy:  0.9393627978861332\n",
      "Epoch:  9985 | Train Accurancy:  0.930737815797329 | Validation Accurancy:  0.9393662139773369\n",
      "Epoch:  9986 | Train Accurancy:  0.9307385683059692 | Validation Accurancy:  0.9393696300685406\n",
      "Epoch:  9987 | Train Accurancy:  0.9307393133640289 | Validation Accurancy:  0.9393730945885181\n",
      "Epoch:  9988 | Train Accurancy:  0.9307400807738304 | Validation Accurancy:  0.9393764510750771\n",
      "Epoch:  9989 | Train Accurancy:  0.9307407960295677 | Validation Accurancy:  0.9393798671662807\n",
      "Epoch:  9990 | Train Accurancy:  0.9307415187358856 | Validation Accurancy:  0.9393833167850971\n",
      "Epoch:  9991 | Train Accurancy:  0.9307422712445259 | Validation Accurancy:  0.9393867328763008\n",
      "Epoch:  9992 | Train Accurancy:  0.9307430312037468 | Validation Accurancy:  0.9393900856375694\n",
      "Epoch:  9993 | Train Accurancy:  0.9307437613606453 | Validation Accurancy:  0.9393935836851597\n",
      "Epoch:  9994 | Train Accurancy:  0.9307445362210274 | Validation Accurancy:  0.9393969848752022\n",
      "Epoch:  9995 | Train Accurancy:  0.9307452514767647 | Validation Accurancy:  0.9394004493951797\n",
      "Epoch:  9996 | Train Accurancy:  0.9307459816336632 | Validation Accurancy:  0.9394038692116737\n",
      "Epoch:  9997 | Train Accurancy:  0.9307467266917229 | Validation Accurancy:  0.9394072368741035\n",
      "Epoch:  9998 | Train Accurancy:  0.9307474941015244 | Validation Accurancy:  0.9394107200205326\n",
      "Epoch:  9999 | Train Accurancy:  0.9307482168078423 | Validation Accurancy:  0.9394141025841236\n",
      "Epoch:  10000 | Train Accurancy:  0.9307489469647408 | Validation Accurancy:  0.9394174739718437\n"
     ]
    }
   ],
   "source": [
    "# 分类问题\n",
    "x_train_tr = torch.from_numpy(x_train).float()\n",
    "y_train_tr = torch.from_numpy(y_train).long()\n",
    "x_test_tr = torch.from_numpy(x_test).float()\n",
    "y_test_tr = torch.from_numpy(y_test).long()\n",
    "\n",
    "class Net(torch.nn.Module):     # 继承 torch 的 Module\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()     # 继承 __init__ 功能\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # 隐藏层线性输出\n",
    "        self.out = torch.nn.Linear(n_hidden, n_output)       # 输出层线性输出\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 正向传播输入值, 神经网络分析出输出值\n",
    "        x = F.relu(self.hidden(x))      # 激励函数(隐藏层的线性值)\n",
    "        x = self.out(x)                 # 输出值, 但是这个不是预测值, 预测值还需要再另外计算\n",
    "        return x\n",
    "\n",
    "net = Net(n_feature=4, n_hidden=15, n_output=4) # 几个类别就几个 output\n",
    "\n",
    "print(net)  # net 的结构\n",
    "\n",
    "# optimizer 是训练的工具\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)  # 传入 net 的所有参数, 学习率\n",
    "# 算误差的时候, 注意真实值!不是! one-hot 形式的, 而是1D Tensor, (batch,)\n",
    "# 但是预测值是2D tensor (batch, n_classes)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for t in range(10000):\n",
    "    out = net(x_train_tr)     # 喂给 net 训练数据 x, 输出分析值\n",
    "\n",
    "    loss = loss_func(out, y_train_tr)     # 计算两者的误差\n",
    "\n",
    "    optimizer.zero_grad()   # 清空上一步的残余更新参数值\n",
    "    loss.backward()         # 误差反向传播, 计算参数更新值\n",
    "    optimizer.step()        # 将参数更新值施加到 net 的 parameters 上\n",
    "    out_val = net(x_test_tr)\n",
    "    loss_val = loss_func(out_val, y_test_tr)\n",
    "    print('Epoch: ', t+1, '| Train Accurancy: ', 1-float(loss), '| Validation Accurancy: ', 1-float(loss_val))\n",
    "\n",
    "    loss_val_past = 9999\n",
    "    if float(loss_val) > float(loss_val_past):\n",
    "        break\n",
    "    else:\n",
    "        loss_val_past = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSELoss 均方差损失\n",
    "# CrossEntropyLoss 交叉熵损失\n",
    "# NLLLoss 负对数似然损失\n",
    "# PoissonNLLLoss 带泊松分布的负对数似然损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最简易前馈神经网络搭建\n",
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10, 4)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(net2.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for t in range(10000):\n",
    "    out = net2(x_train_tr)\n",
    "    loss = loss_func(out, y_train_tr)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net2, 'net.pkl')  # 保存整个网络\n",
    "torch.save(net2.state_dict(), 'net_params.pkl')   # 只保存网络中的参数 (速度快, 占内存少)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -2.1221,   7.0310,   3.1393,  -5.4343],\n",
       "        [ -9.7379,   6.7664,  11.9438,  -7.4964],\n",
       "        [  0.1073,   6.8864,   0.4989,  -4.6650],\n",
       "        [-10.6423,   5.2682,  12.7835,  -6.7442],\n",
       "        [-11.5119,   4.4165,  13.6463,  -6.4088],\n",
       "        [ 19.3665,  11.4694, -21.2350,  -2.1024],\n",
       "        [ -2.3516,   6.1375,   3.2368,  -4.8744],\n",
       "        [ 18.7465,  11.1107, -20.5812,  -2.0339],\n",
       "        [ -2.0120,   7.3417,   3.0346,  -5.6037],\n",
       "        [-10.0111,   5.6541,  12.1101,  -6.8232],\n",
       "        [ -8.3381,   6.2277,  10.2401,  -6.7168],\n",
       "        [ 18.3837,  10.8967, -20.1858,  -1.9972],\n",
       "        [ -7.3049,   5.4934,   8.9213,  -5.9060],\n",
       "        [ -9.0573,   5.6218,  11.0133,  -6.5274],\n",
       "        [ -0.3521,   7.8821,   1.1954,  -5.4879],\n",
       "        [-14.9823,   5.5006,  17.8748,  -8.1891],\n",
       "        [ 19.6815,  11.8400, -21.5412,  -2.2650],\n",
       "        [ 18.5584,  10.9974, -20.3687,  -2.0168],\n",
       "        [ 16.1809,   9.8957, -17.7834,  -1.9585],\n",
       "        [ -2.1395,   6.0213,   2.9876,  -4.7392],\n",
       "        [ 18.2519,  10.8173, -20.0369,  -1.9853],\n",
       "        [ 19.9851,  11.8406, -21.9293,  -2.1595],\n",
       "        [ -9.9803,   7.0619,  12.3347,  -7.8000],\n",
       "        [ -7.2345,   6.5989,   9.0089,  -6.6432],\n",
       "        [ -9.5962,   6.4924,  11.7766,  -7.2849],\n",
       "        [-11.1765,   5.1296,  13.3795,  -6.8051],\n",
       "        [ -5.5524,   6.2222,   6.9882,  -5.8852],\n",
       "        [ -1.8350,   7.1015,   2.8211,  -5.4001],\n",
       "        [-11.7816,   6.3333,  14.2894,  -7.8192],\n",
       "        [ -0.2236,   7.0895,   0.9412,  -4.9141],\n",
       "        [ 16.8389,  10.2206, -18.4700,  -2.0003],\n",
       "        [-10.0286,   4.6144,  11.9548,  -6.1079],\n",
       "        [ -6.0468,   6.1763,   7.5544,  -5.9989],\n",
       "        [ 17.1568,  10.1794, -18.8684,  -1.8678],\n",
       "        [ 17.1945,  10.2021, -18.9111,  -1.8712],\n",
       "        [-11.3222,   5.2775,  13.5857,  -6.9561],\n",
       "        [ 16.7197,   9.9727, -18.3771,  -1.8620],\n",
       "        [ -5.7950,   6.1528,   7.2754,  -5.9164],\n",
       "        [ -6.0954,   6.5114,   7.6761,  -6.2494],\n",
       "        [  1.0164,   8.3232,  -0.3385,  -5.3816],\n",
       "        [ -2.8680,   6.4259,   3.9186,  -5.2418],\n",
       "        [-10.9427,   5.5966,  13.1807,  -7.0570],\n",
       "        [ -5.5875,   6.0982,   7.0239,  -5.8168],\n",
       "        [ 18.7779,  11.1195, -20.5845,  -2.0453],\n",
       "        [  0.4868,   7.2658,   0.1009,  -4.8062],\n",
       "        [  0.5750,   7.8807,   0.1083,  -5.2091],\n",
       "        [ -7.6492,   6.1556,   9.4496,  -6.4739],\n",
       "        [  1.3126,   6.4958,  -0.9770,  -4.0347],\n",
       "        [-13.6971,   4.6223,  16.2628,  -7.2154],\n",
       "        [ -1.7777,   6.3387,   2.6074,  -4.8462],\n",
       "        [ 19.6458,  11.6338, -21.5383,  -2.1309],\n",
       "        [ 16.7946,  10.1895, -18.4425,  -1.9831],\n",
       "        [ 20.0971,  11.8934, -22.0093,  -2.1821],\n",
       "        [ -8.8059,   6.1509,  10.7967,  -6.8135],\n",
       "        [ 15.9859,   9.4933, -17.6067,  -1.7456],\n",
       "        [ -6.9162,   5.7497,   8.5280,  -5.9760],\n",
       "        [ -8.3247,   5.7686,  10.1541,  -6.3980],\n",
       "        [ -7.4283,   5.6117,   9.1085,  -6.0354],\n",
       "        [ 18.7166,  11.0895, -20.5374,  -2.0338],\n",
       "        [ 15.3509,  10.0842, -16.7808,  -2.3368],\n",
       "        [  0.8005,   7.3355,  -0.2234,  -4.7752],\n",
       "        [ 17.3288,  10.3281, -19.0385,  -1.9223],\n",
       "        [ -9.0887,   6.6317,  11.1866,  -7.2209],\n",
       "        [ -0.0341,   7.5554,   0.7733,  -5.1690],\n",
       "        [-11.5344,   6.3412,  14.0045,  -7.7523],\n",
       "        [ -8.1749,   6.1118,  10.0125,  -6.5799],\n",
       "        [ -1.9634,   7.0067,   2.9129,  -5.3532],\n",
       "        [ -9.5739,   5.4851,  11.5844,  -6.5822],\n",
       "        [-10.6072,   6.2796,  12.9103,  -7.4332],\n",
       "        [  1.7230,   7.3354,  -1.3199,  -4.4918],\n",
       "        [ 21.2433,  12.5667, -23.2499,  -2.3003],\n",
       "        [  0.7562,   7.2742,  -0.1995,  -4.7379],\n",
       "        [ 13.7705,   8.8117, -15.1672,  -1.9174],\n",
       "        [  0.0279,   6.7311,   0.5620,  -4.5795],\n",
       "        [ -1.4690,   7.9701,   2.5127,  -5.8803],\n",
       "        [ 16.3796,  10.2687, -17.9430,  -2.1622],\n",
       "        [ -1.5882,   7.7523,   2.6092,  -5.7621],\n",
       "        [ 15.5982,  10.0921, -17.0657,  -2.2699],\n",
       "        [ 15.3027,   9.8968, -16.7179,  -2.2389],\n",
       "        [-10.8276,   5.2933,  13.0160,  -6.8222],\n",
       "        [ -8.9601,   4.8614,  10.7593,  -5.9660],\n",
       "        [-10.8808,   5.7199,  13.1389,  -7.1285],\n",
       "        [ 18.0025,  10.6741, -19.7773,  -1.9568],\n",
       "        [ 18.0571,  10.8410, -19.8035,  -2.0605],\n",
       "        [ -5.3181,   6.1367,   6.7271,  -5.7686],\n",
       "        [ 15.8809,   9.7016, -17.4450,  -1.9229],\n",
       "        [ -9.1279,   5.0088,  10.9810,  -6.1185],\n",
       "        [ 15.9780,   9.9189, -17.5260,  -2.0426],\n",
       "        [ -7.1814,   6.2023,   8.8895,  -6.3571],\n",
       "        [ -8.3021,   4.2689,   9.9067,  -5.3670],\n",
       "        [ 16.6799,   9.9102, -18.3437,  -1.8293],\n",
       "        [ -9.0267,   5.7172,  10.9647,  -6.5710],\n",
       "        [ 16.4058,   9.7442, -18.0744,  -1.7853],\n",
       "        [ -0.5503,   6.8962,   1.2856,  -4.8754],\n",
       "        [ 15.2099,   9.2832, -16.7347,  -1.8314],\n",
       "        [  1.0741,   6.9777,  -0.6180,  -4.4391],\n",
       "        [ -0.5724,   5.9782,   1.1351,  -4.2360],\n",
       "        [ 18.6525,  11.0540, -20.4749,  -2.0253],\n",
       "        [ 17.0197,  10.1969, -18.7119,  -1.9177],\n",
       "        [  1.2950,   6.4338,  -0.9591,  -4.0005],\n",
       "        [ 18.3021,  10.8555, -20.1190,  -1.9830],\n",
       "        [ -1.2171,   6.9990,   2.0641,  -5.1369],\n",
       "        [ -2.9211,   6.8225,   4.0380,  -5.5279],\n",
       "        [ 17.9600,  10.6538, -19.7190,  -1.9609],\n",
       "        [ -1.0540,   7.8607,   2.0096,  -5.6810],\n",
       "        [ -1.0448,   6.8503,   1.8518,  -4.9891],\n",
       "        [ -4.1354,   6.3584,   5.3361,  -5.5485],\n",
       "        [  0.6808,   8.5877,   0.1014,  -5.6663],\n",
       "        [ -9.1279,   5.0088,  10.9810,  -6.1185],\n",
       "        [ 18.1541,  11.0884, -19.8810,  -2.2003],\n",
       "        [ 16.3001,  10.1436, -17.8763,  -2.0968],\n",
       "        [ -8.3906,   5.5492,  10.2384,  -6.2860],\n",
       "        [  0.9106,   7.6161,  -0.3316,  -4.9244],\n",
       "        [ -5.9851,   7.2472,   7.6822,  -6.7313],\n",
       "        [  3.2813,   7.7200,  -3.0804,  -4.2920],\n",
       "        [ -5.1814,   6.4767,   6.6198,  -5.9612],\n",
       "        [ -7.6668,   6.0936,   9.4675,  -6.4398],\n",
       "        [ -5.0182,   6.3909,   6.3957,  -5.8444],\n",
       "        [-10.4703,   5.6420,  12.6300,  -6.9448],\n",
       "        [ 18.5479,  10.9903, -20.3545,  -2.0165]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将保存的整个网络储存到 net2\n",
    "net2 = torch.load('net.pkl')\n",
    "prediction = net2(x_train_tr)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -2.1221,   7.0310,   3.1393,  -5.4343],\n",
       "        [ -9.7379,   6.7664,  11.9438,  -7.4964],\n",
       "        [  0.1073,   6.8864,   0.4989,  -4.6650],\n",
       "        [-10.6423,   5.2682,  12.7835,  -6.7442],\n",
       "        [-11.5119,   4.4165,  13.6463,  -6.4088],\n",
       "        [ 19.3665,  11.4694, -21.2350,  -2.1024],\n",
       "        [ -2.3516,   6.1375,   3.2368,  -4.8744],\n",
       "        [ 18.7465,  11.1107, -20.5812,  -2.0339],\n",
       "        [ -2.0120,   7.3417,   3.0346,  -5.6037],\n",
       "        [-10.0111,   5.6541,  12.1101,  -6.8232],\n",
       "        [ -8.3381,   6.2277,  10.2401,  -6.7168],\n",
       "        [ 18.3837,  10.8967, -20.1858,  -1.9972],\n",
       "        [ -7.3049,   5.4934,   8.9213,  -5.9060],\n",
       "        [ -9.0573,   5.6218,  11.0133,  -6.5274],\n",
       "        [ -0.3521,   7.8821,   1.1954,  -5.4879],\n",
       "        [-14.9823,   5.5006,  17.8748,  -8.1891],\n",
       "        [ 19.6815,  11.8400, -21.5412,  -2.2650],\n",
       "        [ 18.5584,  10.9974, -20.3687,  -2.0168],\n",
       "        [ 16.1809,   9.8957, -17.7834,  -1.9585],\n",
       "        [ -2.1395,   6.0213,   2.9876,  -4.7392],\n",
       "        [ 18.2519,  10.8173, -20.0369,  -1.9853],\n",
       "        [ 19.9851,  11.8406, -21.9293,  -2.1595],\n",
       "        [ -9.9803,   7.0619,  12.3347,  -7.8000],\n",
       "        [ -7.2345,   6.5989,   9.0089,  -6.6432],\n",
       "        [ -9.5962,   6.4924,  11.7766,  -7.2849],\n",
       "        [-11.1765,   5.1296,  13.3795,  -6.8051],\n",
       "        [ -5.5524,   6.2222,   6.9882,  -5.8852],\n",
       "        [ -1.8350,   7.1015,   2.8211,  -5.4001],\n",
       "        [-11.7816,   6.3333,  14.2894,  -7.8192],\n",
       "        [ -0.2236,   7.0895,   0.9412,  -4.9141],\n",
       "        [ 16.8389,  10.2206, -18.4700,  -2.0003],\n",
       "        [-10.0286,   4.6144,  11.9548,  -6.1079],\n",
       "        [ -6.0468,   6.1763,   7.5544,  -5.9989],\n",
       "        [ 17.1568,  10.1794, -18.8684,  -1.8678],\n",
       "        [ 17.1945,  10.2021, -18.9111,  -1.8712],\n",
       "        [-11.3222,   5.2775,  13.5857,  -6.9561],\n",
       "        [ 16.7197,   9.9727, -18.3771,  -1.8620],\n",
       "        [ -5.7950,   6.1528,   7.2754,  -5.9164],\n",
       "        [ -6.0954,   6.5114,   7.6761,  -6.2494],\n",
       "        [  1.0164,   8.3232,  -0.3385,  -5.3816],\n",
       "        [ -2.8680,   6.4259,   3.9186,  -5.2418],\n",
       "        [-10.9427,   5.5966,  13.1807,  -7.0570],\n",
       "        [ -5.5875,   6.0982,   7.0239,  -5.8168],\n",
       "        [ 18.7779,  11.1195, -20.5845,  -2.0453],\n",
       "        [  0.4868,   7.2658,   0.1009,  -4.8062],\n",
       "        [  0.5750,   7.8807,   0.1083,  -5.2091],\n",
       "        [ -7.6492,   6.1556,   9.4496,  -6.4739],\n",
       "        [  1.3126,   6.4958,  -0.9770,  -4.0347],\n",
       "        [-13.6971,   4.6223,  16.2628,  -7.2154],\n",
       "        [ -1.7777,   6.3387,   2.6074,  -4.8462],\n",
       "        [ 19.6458,  11.6338, -21.5383,  -2.1309],\n",
       "        [ 16.7946,  10.1895, -18.4425,  -1.9831],\n",
       "        [ 20.0971,  11.8934, -22.0093,  -2.1821],\n",
       "        [ -8.8059,   6.1509,  10.7967,  -6.8135],\n",
       "        [ 15.9859,   9.4933, -17.6067,  -1.7456],\n",
       "        [ -6.9162,   5.7497,   8.5280,  -5.9760],\n",
       "        [ -8.3247,   5.7686,  10.1541,  -6.3980],\n",
       "        [ -7.4283,   5.6117,   9.1085,  -6.0354],\n",
       "        [ 18.7166,  11.0895, -20.5374,  -2.0338],\n",
       "        [ 15.3509,  10.0842, -16.7808,  -2.3368],\n",
       "        [  0.8005,   7.3355,  -0.2234,  -4.7752],\n",
       "        [ 17.3288,  10.3281, -19.0385,  -1.9223],\n",
       "        [ -9.0887,   6.6317,  11.1866,  -7.2209],\n",
       "        [ -0.0341,   7.5554,   0.7733,  -5.1690],\n",
       "        [-11.5344,   6.3412,  14.0045,  -7.7523],\n",
       "        [ -8.1749,   6.1118,  10.0125,  -6.5799],\n",
       "        [ -1.9634,   7.0067,   2.9129,  -5.3532],\n",
       "        [ -9.5739,   5.4851,  11.5844,  -6.5822],\n",
       "        [-10.6072,   6.2796,  12.9103,  -7.4332],\n",
       "        [  1.7230,   7.3354,  -1.3199,  -4.4918],\n",
       "        [ 21.2433,  12.5667, -23.2499,  -2.3003],\n",
       "        [  0.7562,   7.2742,  -0.1995,  -4.7379],\n",
       "        [ 13.7705,   8.8117, -15.1672,  -1.9174],\n",
       "        [  0.0279,   6.7311,   0.5620,  -4.5795],\n",
       "        [ -1.4690,   7.9701,   2.5127,  -5.8803],\n",
       "        [ 16.3796,  10.2687, -17.9430,  -2.1622],\n",
       "        [ -1.5882,   7.7523,   2.6092,  -5.7621],\n",
       "        [ 15.5982,  10.0921, -17.0657,  -2.2699],\n",
       "        [ 15.3027,   9.8968, -16.7179,  -2.2389],\n",
       "        [-10.8276,   5.2933,  13.0160,  -6.8222],\n",
       "        [ -8.9601,   4.8614,  10.7593,  -5.9660],\n",
       "        [-10.8808,   5.7199,  13.1389,  -7.1285],\n",
       "        [ 18.0025,  10.6741, -19.7773,  -1.9568],\n",
       "        [ 18.0571,  10.8410, -19.8035,  -2.0605],\n",
       "        [ -5.3181,   6.1367,   6.7271,  -5.7686],\n",
       "        [ 15.8809,   9.7016, -17.4450,  -1.9229],\n",
       "        [ -9.1279,   5.0088,  10.9810,  -6.1185],\n",
       "        [ 15.9780,   9.9189, -17.5260,  -2.0426],\n",
       "        [ -7.1814,   6.2023,   8.8895,  -6.3571],\n",
       "        [ -8.3021,   4.2689,   9.9067,  -5.3670],\n",
       "        [ 16.6799,   9.9102, -18.3437,  -1.8293],\n",
       "        [ -9.0267,   5.7172,  10.9647,  -6.5710],\n",
       "        [ 16.4058,   9.7442, -18.0744,  -1.7853],\n",
       "        [ -0.5503,   6.8962,   1.2856,  -4.8754],\n",
       "        [ 15.2099,   9.2832, -16.7347,  -1.8314],\n",
       "        [  1.0741,   6.9777,  -0.6180,  -4.4391],\n",
       "        [ -0.5724,   5.9782,   1.1351,  -4.2360],\n",
       "        [ 18.6525,  11.0540, -20.4749,  -2.0253],\n",
       "        [ 17.0197,  10.1969, -18.7119,  -1.9177],\n",
       "        [  1.2950,   6.4338,  -0.9591,  -4.0005],\n",
       "        [ 18.3021,  10.8555, -20.1190,  -1.9830],\n",
       "        [ -1.2171,   6.9990,   2.0641,  -5.1369],\n",
       "        [ -2.9211,   6.8225,   4.0380,  -5.5279],\n",
       "        [ 17.9600,  10.6538, -19.7190,  -1.9609],\n",
       "        [ -1.0540,   7.8607,   2.0096,  -5.6810],\n",
       "        [ -1.0448,   6.8503,   1.8518,  -4.9891],\n",
       "        [ -4.1354,   6.3584,   5.3361,  -5.5485],\n",
       "        [  0.6808,   8.5877,   0.1014,  -5.6663],\n",
       "        [ -9.1279,   5.0088,  10.9810,  -6.1185],\n",
       "        [ 18.1541,  11.0884, -19.8810,  -2.2003],\n",
       "        [ 16.3001,  10.1436, -17.8763,  -2.0968],\n",
       "        [ -8.3906,   5.5492,  10.2384,  -6.2860],\n",
       "        [  0.9106,   7.6161,  -0.3316,  -4.9244],\n",
       "        [ -5.9851,   7.2472,   7.6822,  -6.7313],\n",
       "        [  3.2813,   7.7200,  -3.0804,  -4.2920],\n",
       "        [ -5.1814,   6.4767,   6.6198,  -5.9612],\n",
       "        [ -7.6668,   6.0936,   9.4675,  -6.4398],\n",
       "        [ -5.0182,   6.3909,   6.3957,  -5.8444],\n",
       "        [-10.4703,   5.6420,  12.6300,  -6.9448],\n",
       "        [ 18.5479,  10.9903, -20.3545,  -2.0165]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 新建net3\n",
    "net3 = torch.nn.Sequential(\n",
    "        torch.nn.Linear(4, 10),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(10, 4)\n",
    "    )\n",
    "\n",
    "# 将保存的参数复制到 net3\n",
    "net3.load_state_dict(torch.load('net_params.pkl'))\n",
    "prediction = net3(x_train_tr)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Train Accurancy:  -0.33612775802612305 | Validation Accurancy:  -0.3739662170410156\n",
      "Epoch:  1 | Train Accurancy:  -0.2621345520019531 | Validation Accurancy:  -0.31677234172821045\n",
      "Epoch:  2 | Train Accurancy:  -0.21182000637054443 | Validation Accurancy:  -0.27175796031951904\n",
      "Epoch:  3 | Train Accurancy:  -0.17916607856750488 | Validation Accurancy:  -0.23815155029296875\n",
      "Epoch:  4 | Train Accurancy:  -0.15346205234527588 | Validation Accurancy:  -0.2065129280090332\n",
      "Epoch:  5 | Train Accurancy:  -0.12885308265686035 | Validation Accurancy:  -0.17591655254364014\n",
      "Epoch:  6 | Train Accurancy:  -0.1046220064163208 | Validation Accurancy:  -0.1483229398727417\n",
      "Epoch:  7 | Train Accurancy:  -0.08197665214538574 | Validation Accurancy:  -0.1252363920211792\n",
      "Epoch:  8 | Train Accurancy:  -0.06204092502593994 | Validation Accurancy:  -0.10729265213012695\n",
      "Epoch:  9 | Train Accurancy:  -0.0451582670211792 | Validation Accurancy:  -0.09426069259643555\n",
      "Epoch:  10 | Train Accurancy:  -0.03043234348297119 | Validation Accurancy:  -0.08466899394989014\n",
      "Epoch:  11 | Train Accurancy:  -0.016655564308166504 | Validation Accurancy:  -0.0762481689453125\n",
      "Epoch:  12 | Train Accurancy:  -0.0029278993606567383 | Validation Accurancy:  -0.06675279140472412\n",
      "Epoch:  13 | Train Accurancy:  0.011224091053009033 | Validation Accurancy:  -0.05449080467224121\n",
      "Epoch:  14 | Train Accurancy:  0.025870978832244873 | Validation Accurancy:  -0.03847956657409668\n",
      "Epoch:  15 | Train Accurancy:  0.04120361804962158 | Validation Accurancy:  -0.01862466335296631\n",
      "Epoch:  16 | Train Accurancy:  0.05717819929122925 | Validation Accurancy:  0.004248619079589844\n",
      "Epoch:  17 | Train Accurancy:  0.0736093521118164 | Validation Accurancy:  0.028754472732543945\n",
      "Epoch:  18 | Train Accurancy:  0.0902218222618103 | Validation Accurancy:  0.05350327491760254\n",
      "Epoch:  19 | Train Accurancy:  0.10695391893386841 | Validation Accurancy:  0.0774374008178711\n",
      "Epoch:  20 | Train Accurancy:  0.12403011322021484 | Validation Accurancy:  0.09996163845062256\n",
      "Epoch:  21 | Train Accurancy:  0.14181190729141235 | Validation Accurancy:  0.12068825960159302\n",
      "Epoch:  22 | Train Accurancy:  0.16051048040390015 | Validation Accurancy:  0.1397334337234497\n",
      "Epoch:  23 | Train Accurancy:  0.18004554510116577 | Validation Accurancy:  0.15770608186721802\n",
      "Epoch:  24 | Train Accurancy:  0.20002537965774536 | Validation Accurancy:  0.17556768655776978\n",
      "Epoch:  25 | Train Accurancy:  0.22012925148010254 | Validation Accurancy:  0.1943393349647522\n",
      "Epoch:  26 | Train Accurancy:  0.24027103185653687 | Validation Accurancy:  0.21481096744537354\n",
      "Epoch:  27 | Train Accurancy:  0.26050055027008057 | Validation Accurancy:  0.237143874168396\n",
      "Epoch:  28 | Train Accurancy:  0.28084635734558105 | Validation Accurancy:  0.26077020168304443\n",
      "Epoch:  29 | Train Accurancy:  0.30117541551589966 | Validation Accurancy:  0.2846115231513977\n",
      "Epoch:  30 | Train Accurancy:  0.3212229013442993 | Validation Accurancy:  0.30751490592956543\n",
      "Epoch:  31 | Train Accurancy:  0.3407711386680603 | Validation Accurancy:  0.3286266326904297\n",
      "Epoch:  32 | Train Accurancy:  0.35969072580337524 | Validation Accurancy:  0.3476353883743286\n",
      "Epoch:  33 | Train Accurancy:  0.3779493570327759 | Validation Accurancy:  0.3647642731666565\n",
      "Epoch:  34 | Train Accurancy:  0.39554840326309204 | Validation Accurancy:  0.3806827664375305\n",
      "Epoch:  35 | Train Accurancy:  0.41245758533477783 | Validation Accurancy:  0.3961440920829773\n",
      "Epoch:  36 | Train Accurancy:  0.42863303422927856 | Validation Accurancy:  0.4116867184638977\n",
      "Epoch:  37 | Train Accurancy:  0.4440425634384155 | Validation Accurancy:  0.4275205731391907\n",
      "Epoch:  38 | Train Accurancy:  0.45869332551956177 | Validation Accurancy:  0.4434192180633545\n",
      "Epoch:  39 | Train Accurancy:  0.47260934114456177 | Validation Accurancy:  0.45886117219924927\n",
      "Epoch:  40 | Train Accurancy:  0.48583585023880005 | Validation Accurancy:  0.47328490018844604\n",
      "Epoch:  41 | Train Accurancy:  0.49843859672546387 | Validation Accurancy:  0.48633408546447754\n",
      "Epoch:  42 | Train Accurancy:  0.5104935765266418 | Validation Accurancy:  0.4979972243309021\n",
      "Epoch:  43 | Train Accurancy:  0.5220551192760468 | Validation Accurancy:  0.5085985064506531\n",
      "Epoch:  44 | Train Accurancy:  0.5331474244594574 | Validation Accurancy:  0.5186791121959686\n",
      "Epoch:  45 | Train Accurancy:  0.5438102781772614 | Validation Accurancy:  0.5287454724311829\n",
      "Epoch:  46 | Train Accurancy:  0.554098516702652 | Validation Accurancy:  0.539109617471695\n",
      "Epoch:  47 | Train Accurancy:  0.5640774965286255 | Validation Accurancy:  0.5497346222400665\n",
      "Epoch:  48 | Train Accurancy:  0.573792040348053 | Validation Accurancy:  0.5603291690349579\n",
      "Epoch:  49 | Train Accurancy:  0.5832673907279968 | Validation Accurancy:  0.570539265871048\n",
      "Epoch:  50 | Train Accurancy:  0.5925268530845642 | Validation Accurancy:  0.5801302492618561\n",
      "Epoch:  51 | Train Accurancy:  0.6015949845314026 | Validation Accurancy:  0.5891040861606598\n",
      "Epoch:  52 | Train Accurancy:  0.6104895174503326 | Validation Accurancy:  0.5976865589618683\n",
      "Epoch:  53 | Train Accurancy:  0.6192214787006378 | Validation Accurancy:  0.6062038242816925\n",
      "Epoch:  54 | Train Accurancy:  0.6278046369552612 | Validation Accurancy:  0.6149035096168518\n",
      "Epoch:  55 | Train Accurancy:  0.6362521052360535 | Validation Accurancy:  0.6238005459308624\n",
      "Epoch:  56 | Train Accurancy:  0.6445727348327637 | Validation Accurancy:  0.6327225267887115\n",
      "Epoch:  57 | Train Accurancy:  0.652766764163971 | Validation Accurancy:  0.6414039731025696\n",
      "Epoch:  58 | Train Accurancy:  0.6608313024044037 | Validation Accurancy:  0.6496381163597107\n",
      "Epoch:  59 | Train Accurancy:  0.6687643826007843 | Validation Accurancy:  0.6574061512947083\n",
      "Epoch:  60 | Train Accurancy:  0.676565945148468 | Validation Accurancy:  0.6648892760276794\n",
      "Epoch:  61 | Train Accurancy:  0.6842309832572937 | Validation Accurancy:  0.6723436415195465\n",
      "Epoch:  62 | Train Accurancy:  0.6917549669742584 | Validation Accurancy:  0.6799351871013641\n",
      "Epoch:  63 | Train Accurancy:  0.6991327404975891 | Validation Accurancy:  0.6876117885112762\n",
      "Epoch:  64 | Train Accurancy:  0.7063631117343903 | Validation Accurancy:  0.6952034533023834\n",
      "Epoch:  65 | Train Accurancy:  0.7134411036968231 | Validation Accurancy:  0.7025242447853088\n",
      "Epoch:  66 | Train Accurancy:  0.7203632891178131 | Validation Accurancy:  0.7094912230968475\n",
      "Epoch:  67 | Train Accurancy:  0.7271266579627991 | Validation Accurancy:  0.7161742448806763\n",
      "Epoch:  68 | Train Accurancy:  0.73372682929039 | Validation Accurancy:  0.7227142155170441\n",
      "Epoch:  69 | Train Accurancy:  0.7401563227176666 | Validation Accurancy:  0.729253739118576\n",
      "Epoch:  70 | Train Accurancy:  0.7464196085929871 | Validation Accurancy:  0.735794872045517\n",
      "Epoch:  71 | Train Accurancy:  0.75251604616642 | Validation Accurancy:  0.7422425448894501\n",
      "Epoch:  72 | Train Accurancy:  0.7584433406591415 | Validation Accurancy:  0.7484209835529327\n",
      "Epoch:  73 | Train Accurancy:  0.7641972601413727 | Validation Accurancy:  0.7542585730552673\n",
      "Epoch:  74 | Train Accurancy:  0.7697846442461014 | Validation Accurancy:  0.7598191201686859\n",
      "Epoch:  75 | Train Accurancy:  0.7752058058977127 | Validation Accurancy:  0.765234500169754\n",
      "Epoch:  76 | Train Accurancy:  0.7804612815380096 | Validation Accurancy:  0.7706072628498077\n",
      "Epoch:  77 | Train Accurancy:  0.7855471670627594 | Validation Accurancy:  0.7759315818548203\n",
      "Epoch:  78 | Train Accurancy:  0.7904698401689529 | Validation Accurancy:  0.7811204046010971\n",
      "Epoch:  79 | Train Accurancy:  0.7952345460653305 | Validation Accurancy:  0.7860822826623917\n",
      "Epoch:  80 | Train Accurancy:  0.7998431771993637 | Validation Accurancy:  0.7907978147268295\n",
      "Epoch:  81 | Train Accurancy:  0.8042903989553452 | Validation Accurancy:  0.7953081876039505\n",
      "Epoch:  82 | Train Accurancy:  0.8085831105709076 | Validation Accurancy:  0.7997095882892609\n",
      "Epoch:  83 | Train Accurancy:  0.8127220422029495 | Validation Accurancy:  0.8040670901536942\n",
      "Epoch:  84 | Train Accurancy:  0.8167177587747574 | Validation Accurancy:  0.8083773702383041\n",
      "Epoch:  85 | Train Accurancy:  0.8205733597278595 | Validation Accurancy:  0.812552735209465\n",
      "Epoch:  86 | Train Accurancy:  0.824291542172432 | Validation Accurancy:  0.816507562994957\n",
      "Epoch:  87 | Train Accurancy:  0.8278758078813553 | Validation Accurancy:  0.8202478289604187\n",
      "Epoch:  88 | Train Accurancy:  0.8313359171152115 | Validation Accurancy:  0.8238802403211594\n",
      "Epoch:  89 | Train Accurancy:  0.8346764296293259 | Validation Accurancy:  0.8274910300970078\n",
      "Epoch:  90 | Train Accurancy:  0.8379014283418655 | Validation Accurancy:  0.8310627490282059\n",
      "Epoch:  91 | Train Accurancy:  0.8410132676362991 | Validation Accurancy:  0.8345106691122055\n",
      "Epoch:  92 | Train Accurancy:  0.8440155535936356 | Validation Accurancy:  0.8377646058797836\n",
      "Epoch:  93 | Train Accurancy:  0.8469119369983673 | Validation Accurancy:  0.8408329486846924\n",
      "Epoch:  94 | Train Accurancy:  0.849705308675766 | Validation Accurancy:  0.8437904864549637\n",
      "Epoch:  95 | Train Accurancy:  0.852398470044136 | Validation Accurancy:  0.8467104285955429\n",
      "Epoch:  96 | Train Accurancy:  0.8549946993589401 | Validation Accurancy:  0.8496030122041702\n",
      "Epoch:  97 | Train Accurancy:  0.8574971556663513 | Validation Accurancy:  0.8524169474840164\n",
      "Epoch:  98 | Train Accurancy:  0.8599088042974472 | Validation Accurancy:  0.8550956845283508\n",
      "Epoch:  99 | Train Accurancy:  0.8622327595949173 | Validation Accurancy:  0.8576314151287079\n",
      "Epoch:  100 | Train Accurancy:  0.8644722402095795 | Validation Accurancy:  0.8600694239139557\n",
      "Epoch:  101 | Train Accurancy:  0.8666299879550934 | Validation Accurancy:  0.8624642789363861\n",
      "Epoch:  102 | Train Accurancy:  0.8687091320753098 | Validation Accurancy:  0.864832192659378\n",
      "Epoch:  103 | Train Accurancy:  0.870712623000145 | Validation Accurancy:  0.8671422302722931\n",
      "Epoch:  104 | Train Accurancy:  0.8726431429386139 | Validation Accurancy:  0.8693510442972183\n",
      "Epoch:  105 | Train Accurancy:  0.8745032995939255 | Validation Accurancy:  0.8714423477649689\n",
      "Epoch:  106 | Train Accurancy:  0.8762960284948349 | Validation Accurancy:  0.8734476715326309\n",
      "Epoch:  107 | Train Accurancy:  0.8780239298939705 | Validation Accurancy:  0.8754112422466278\n",
      "Epoch:  108 | Train Accurancy:  0.8796896263957024 | Validation Accurancy:  0.8773502558469772\n",
      "Epoch:  109 | Train Accurancy:  0.8812956735491753 | Validation Accurancy:  0.8792439848184586\n",
      "Epoch:  110 | Train Accurancy:  0.8828444629907608 | Validation Accurancy:  0.8810591250658035\n",
      "Epoch:  111 | Train Accurancy:  0.8843381702899933 | Validation Accurancy:  0.8827820643782616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  112 | Train Accurancy:  0.8857791274785995 | Validation Accurancy:  0.8844351097941399\n",
      "Epoch:  113 | Train Accurancy:  0.8871695250272751 | Validation Accurancy:  0.8860489055514336\n",
      "Epoch:  114 | Train Accurancy:  0.8885115310549736 | Validation Accurancy:  0.8876438438892365\n",
      "Epoch:  115 | Train Accurancy:  0.889807254076004 | Validation Accurancy:  0.8892101272940636\n",
      "Epoch:  116 | Train Accurancy:  0.8910585790872574 | Validation Accurancy:  0.8907221108675003\n",
      "Epoch:  117 | Train Accurancy:  0.8922673314809799 | Validation Accurancy:  0.8921654149889946\n",
      "Epoch:  118 | Train Accurancy:  0.8934353515505791 | Validation Accurancy:  0.8935507088899612\n",
      "Epoch:  119 | Train Accurancy:  0.8945642858743668 | Validation Accurancy:  0.8949025869369507\n",
      "Epoch:  120 | Train Accurancy:  0.8956557810306549 | Validation Accurancy:  0.8962372317910194\n",
      "Epoch:  121 | Train Accurancy:  0.8967113122344017 | Validation Accurancy:  0.8975522369146347\n",
      "Epoch:  122 | Train Accurancy:  0.8977324813604355 | Validation Accurancy:  0.8988264128565788\n",
      "Epoch:  123 | Train Accurancy:  0.8987206071615219 | Validation Accurancy:  0.9000455811619759\n",
      "Epoch:  124 | Train Accurancy:  0.8996770530939102 | Validation Accurancy:  0.9012164026498795\n",
      "Epoch:  125 | Train Accurancy:  0.9006031304597855 | Validation Accurancy:  0.9023609086871147\n",
      "Epoch:  126 | Train Accurancy:  0.9015000909566879 | Validation Accurancy:  0.9034924283623695\n",
      "Epoch:  127 | Train Accurancy:  0.9023691415786743 | Validation Accurancy:  0.9046070277690887\n",
      "Epoch:  128 | Train Accurancy:  0.9032113775610924 | Validation Accurancy:  0.9056898728013039\n",
      "Epoch:  129 | Train Accurancy:  0.9040278345346451 | Validation Accurancy:  0.9067317023873329\n",
      "Epoch:  130 | Train Accurancy:  0.904819630086422 | Validation Accurancy:  0.9077374115586281\n",
      "Epoch:  131 | Train Accurancy:  0.90558772534132 | Validation Accurancy:  0.9087215587496758\n",
      "Epoch:  132 | Train Accurancy:  0.9063329473137856 | Validation Accurancy:  0.9096941128373146\n",
      "Epoch:  133 | Train Accurancy:  0.9070562869310379 | Validation Accurancy:  0.9106506332755089\n",
      "Epoch:  134 | Train Accurancy:  0.9077585712075233 | Validation Accurancy:  0.9115828946232796\n",
      "Epoch:  135 | Train Accurancy:  0.908440612256527 | Validation Accurancy:  0.9124857187271118\n",
      "Epoch:  136 | Train Accurancy:  0.9091031327843666 | Validation Accurancy:  0.9133622497320175\n",
      "Epoch:  137 | Train Accurancy:  0.9097468927502632 | Validation Accurancy:  0.9142206534743309\n",
      "Epoch:  138 | Train Accurancy:  0.9103726446628571 | Validation Accurancy:  0.9150663688778877\n",
      "Epoch:  139 | Train Accurancy:  0.9109811261296272 | Validation Accurancy:  0.9158994480967522\n",
      "Epoch:  140 | Train Accurancy:  0.9115728214383125 | Validation Accurancy:  0.9167139530181885\n",
      "Epoch:  141 | Train Accurancy:  0.9121483042836189 | Validation Accurancy:  0.9175031632184982\n",
      "Epoch:  142 | Train Accurancy:  0.9127083346247673 | Validation Accurancy:  0.9182658493518829\n",
      "Epoch:  143 | Train Accurancy:  0.9132534563541412 | Validation Accurancy:  0.9190118461847305\n",
      "Epoch:  144 | Train Accurancy:  0.9137841537594795 | Validation Accurancy:  0.91974987834692\n",
      "Epoch:  145 | Train Accurancy:  0.9143009707331657 | Validation Accurancy:  0.9204800948500633\n",
      "Epoch:  146 | Train Accurancy:  0.9148043617606163 | Validation Accurancy:  0.9211952015757561\n",
      "Epoch:  147 | Train Accurancy:  0.9152947887778282 | Validation Accurancy:  0.9218889698386192\n",
      "Epoch:  148 | Train Accurancy:  0.9157727956771851 | Validation Accurancy:  0.9225621372461319\n",
      "Epoch:  149 | Train Accurancy:  0.9162387624382973 | Validation Accurancy:  0.9232220500707626\n",
      "Epoch:  150 | Train Accurancy:  0.9166930243372917 | Validation Accurancy:  0.9238749966025352\n",
      "Epoch:  151 | Train Accurancy:  0.917136050760746 | Validation Accurancy:  0.9245205372571945\n",
      "Epoch:  152 | Train Accurancy:  0.9175682589411736 | Validation Accurancy:  0.9251537621021271\n",
      "Epoch:  153 | Train Accurancy:  0.9179899170994759 | Validation Accurancy:  0.9257697388529778\n",
      "Epoch:  154 | Train Accurancy:  0.9184015244245529 | Validation Accurancy:  0.9263697639107704\n",
      "Epoch:  155 | Train Accurancy:  0.9188032150268555 | Validation Accurancy:  0.9269593432545662\n",
      "Epoch:  156 | Train Accurancy:  0.9191954433917999 | Validation Accurancy:  0.9275425300002098\n",
      "Epoch:  157 | Train Accurancy:  0.9195785000920296 | Validation Accurancy:  0.9281191155314445\n",
      "Epoch:  158 | Train Accurancy:  0.9199526160955429 | Validation Accurancy:  0.9286847934126854\n",
      "Epoch:  159 | Train Accurancy:  0.920318141579628 | Validation Accurancy:  0.9292367622256279\n",
      "Epoch:  160 | Train Accurancy:  0.9206753000617027 | Validation Accurancy:  0.9297760799527168\n",
      "Epoch:  161 | Train Accurancy:  0.9210244566202164 | Validation Accurancy:  0.9303067550063133\n",
      "Epoch:  162 | Train Accurancy:  0.9213657677173615 | Validation Accurancy:  0.9308330565690994\n",
      "Epoch:  163 | Train Accurancy:  0.9216994419693947 | Validation Accurancy:  0.9313513934612274\n",
      "Epoch:  164 | Train Accurancy:  0.9220258221030235 | Validation Accurancy:  0.931859128177166\n",
      "Epoch:  165 | Train Accurancy:  0.9223450422286987 | Validation Accurancy:  0.9323557540774345\n",
      "Epoch:  166 | Train Accurancy:  0.9226573780179024 | Validation Accurancy:  0.9328436702489853\n",
      "Epoch:  167 | Train Accurancy:  0.9229629412293434 | Validation Accurancy:  0.9333257377147675\n",
      "Epoch:  168 | Train Accurancy:  0.9232620745897293 | Validation Accurancy:  0.9338024109601974\n",
      "Epoch:  169 | Train Accurancy:  0.9235549047589302 | Validation Accurancy:  0.934271827340126\n",
      "Epoch:  170 | Train Accurancy:  0.9238415211439133 | Validation Accurancy:  0.9347322955727577\n",
      "Epoch:  171 | Train Accurancy:  0.9241222143173218 | Validation Accurancy:  0.9351838082075119\n",
      "Epoch:  172 | Train Accurancy:  0.9243971258401871 | Validation Accurancy:  0.9356283023953438\n",
      "Epoch:  173 | Train Accurancy:  0.9246664792299271 | Validation Accurancy:  0.936067707836628\n",
      "Epoch:  174 | Train Accurancy:  0.9249302819371223 | Validation Accurancy:  0.9365021213889122\n",
      "Epoch:  175 | Train Accurancy:  0.9251888021826744 | Validation Accurancy:  0.9369299858808517\n",
      "Epoch:  176 | Train Accurancy:  0.9254421517252922 | Validation Accurancy:  0.9373503178358078\n",
      "Epoch:  177 | Train Accurancy:  0.9256904795765877 | Validation Accurancy:  0.9377643428742886\n",
      "Epoch:  178 | Train Accurancy:  0.9259339794516563 | Validation Accurancy:  0.9381721168756485\n",
      "Epoch:  179 | Train Accurancy:  0.926172599196434 | Validation Accurancy:  0.9385744743049145\n",
      "Epoch:  180 | Train Accurancy:  0.9264067187905312 | Validation Accurancy:  0.9389716945588589\n",
      "Epoch:  181 | Train Accurancy:  0.9266363307833672 | Validation Accurancy:  0.9393635131418705\n",
      "Epoch:  182 | Train Accurancy:  0.926861509680748 | Validation Accurancy:  0.9397496208548546\n",
      "Epoch:  183 | Train Accurancy:  0.9270825311541557 | Validation Accurancy:  0.9401301704347134\n",
      "Epoch:  184 | Train Accurancy:  0.9272993430495262 | Validation Accurancy:  0.9405057914555073\n",
      "Epoch:  185 | Train Accurancy:  0.9275121688842773 | Validation Accurancy:  0.9408768005669117\n",
      "Epoch:  186 | Train Accurancy:  0.9277210682630539 | Validation Accurancy:  0.9412433616816998\n",
      "Epoch:  187 | Train Accurancy:  0.927926167845726 | Validation Accurancy:  0.9416049942374229\n",
      "Epoch:  188 | Train Accurancy:  0.9281275197863579 | Validation Accurancy:  0.9419617801904678\n",
      "Epoch:  189 | Train Accurancy:  0.928325243294239 | Validation Accurancy:  0.942314051091671\n",
      "Epoch:  190 | Train Accurancy:  0.9285194128751755 | Validation Accurancy:  0.9426618404686451\n",
      "Epoch:  191 | Train Accurancy:  0.9287101849913597 | Validation Accurancy:  0.9430057853460312\n",
      "Epoch:  192 | Train Accurancy:  0.9288975894451141 | Validation Accurancy:  0.94334577023983\n",
      "Epoch:  193 | Train Accurancy:  0.9290816932916641 | Validation Accurancy:  0.9436815269291401\n",
      "Epoch:  194 | Train Accurancy:  0.9292626529932022 | Validation Accurancy:  0.9440129771828651\n",
      "Epoch:  195 | Train Accurancy:  0.9294404983520508 | Validation Accurancy:  0.9443403705954552\n",
      "Epoch:  196 | Train Accurancy:  0.9296152964234352 | Validation Accurancy:  0.9446642249822617\n",
      "Epoch:  197 | Train Accurancy:  0.9297871589660645 | Validation Accurancy:  0.9449843242764473\n",
      "Epoch:  198 | Train Accurancy:  0.9299560636281967 | Validation Accurancy:  0.9453008957207203\n",
      "Epoch:  199 | Train Accurancy:  0.9301222264766693 | Validation Accurancy:  0.9456137493252754\n",
      "Epoch:  200 | Train Accurancy:  0.9302855655550957 | Validation Accurancy:  0.9459229484200478\n",
      "Epoch:  201 | Train Accurancy:  0.9304462820291519 | Validation Accurancy:  0.9462287910282612\n",
      "Epoch:  202 | Train Accurancy:  0.9306043460965157 | Validation Accurancy:  0.9465306922793388\n",
      "Epoch:  203 | Train Accurancy:  0.930759884417057 | Validation Accurancy:  0.9468295238912106\n",
      "Epoch:  204 | Train Accurancy:  0.9309128895401955 | Validation Accurancy:  0.9471258781850338\n",
      "Epoch:  205 | Train Accurancy:  0.9310634806752205 | Validation Accurancy:  0.9474193267524242\n",
      "Epoch:  206 | Train Accurancy:  0.9312116801738739 | Validation Accurancy:  0.9477093070745468\n",
      "Epoch:  207 | Train Accurancy:  0.9313575774431229 | Validation Accurancy:  0.9479957111179829\n",
      "Epoch:  208 | Train Accurancy:  0.9315011277794838 | Validation Accurancy:  0.9482790008187294\n",
      "Epoch:  209 | Train Accurancy:  0.9316425547003746 | Validation Accurancy:  0.9485589191317558\n",
      "Epoch:  210 | Train Accurancy:  0.9317817464470863 | Validation Accurancy:  0.9488363899290562\n",
      "Epoch:  211 | Train Accurancy:  0.9319188594818115 | Validation Accurancy:  0.9491122253239155\n",
      "Epoch:  212 | Train Accurancy:  0.9320538267493248 | Validation Accurancy:  0.9493856765329838\n",
      "Epoch:  213 | Train Accurancy:  0.9321868047118187 | Validation Accurancy:  0.9496556743979454\n",
      "Epoch:  214 | Train Accurancy:  0.9323178082704544 | Validation Accurancy:  0.9499221183359623\n",
      "Epoch:  215 | Train Accurancy:  0.9324469268321991 | Validation Accurancy:  0.9501857124269009\n",
      "Epoch:  216 | Train Accurancy:  0.932574100792408 | Validation Accurancy:  0.950447354465723\n",
      "Epoch:  217 | Train Accurancy:  0.9326994344592094 | Validation Accurancy:  0.9507070854306221\n",
      "Epoch:  218 | Train Accurancy:  0.9328229203820229 | Validation Accurancy:  0.9509642273187637\n",
      "Epoch:  219 | Train Accurancy:  0.9329447001218796 | Validation Accurancy:  0.9512179680168629\n",
      "Epoch:  220 | Train Accurancy:  0.9330646991729736 | Validation Accurancy:  0.9514689296483994\n",
      "Epoch:  221 | Train Accurancy:  0.9331830814480782 | Validation Accurancy:  0.9517177753150463\n",
      "Epoch:  222 | Train Accurancy:  0.9332997426390648 | Validation Accurancy:  0.9519645050168037\n",
      "Epoch:  223 | Train Accurancy:  0.9334148019552231 | Validation Accurancy:  0.9522093459963799\n",
      "Epoch:  224 | Train Accurancy:  0.933528296649456 | Validation Accurancy:  0.9524514190852642\n",
      "Epoch:  225 | Train Accurancy:  0.9336402416229248 | Validation Accurancy:  0.9526914767920971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  226 | Train Accurancy:  0.9337505772709846 | Validation Accurancy:  0.9529287964105606\n",
      "Epoch:  227 | Train Accurancy:  0.9338594898581505 | Validation Accurancy:  0.9531637988984585\n",
      "Epoch:  228 | Train Accurancy:  0.9339669868350029 | Validation Accurancy:  0.9533965922892094\n",
      "Epoch:  229 | Train Accurancy:  0.9340729936957359 | Validation Accurancy:  0.9536274895071983\n",
      "Epoch:  230 | Train Accurancy:  0.9341776296496391 | Validation Accurancy:  0.9538567215204239\n",
      "Epoch:  231 | Train Accurancy:  0.9342809468507767 | Validation Accurancy:  0.9540837779641151\n",
      "Epoch:  232 | Train Accurancy:  0.934382863342762 | Validation Accurancy:  0.9543087147176266\n",
      "Epoch:  233 | Train Accurancy:  0.9344835057854652 | Validation Accurancy:  0.9545314162969589\n",
      "Epoch:  234 | Train Accurancy:  0.9345828965306282 | Validation Accurancy:  0.9547526054084301\n",
      "Epoch:  235 | Train Accurancy:  0.9346809014678001 | Validation Accurancy:  0.9549723453819752\n",
      "Epoch:  236 | Train Accurancy:  0.9347777888178825 | Validation Accurancy:  0.9551902450621128\n",
      "Epoch:  237 | Train Accurancy:  0.9348733872175217 | Validation Accurancy:  0.9554062038660049\n",
      "Epoch:  238 | Train Accurancy:  0.9349679127335548 | Validation Accurancy:  0.955620288848877\n",
      "Epoch:  239 | Train Accurancy:  0.9350611940026283 | Validation Accurancy:  0.9558328315615654\n",
      "Epoch:  240 | Train Accurancy:  0.9351534247398376 | Validation Accurancy:  0.9560438618063927\n",
      "Epoch:  241 | Train Accurancy:  0.9352445006370544 | Validation Accurancy:  0.9562533684074879\n",
      "Epoch:  242 | Train Accurancy:  0.9353344887495041 | Validation Accurancy:  0.9564612060785294\n",
      "Epoch:  243 | Train Accurancy:  0.9354233890771866 | Validation Accurancy:  0.9566670879721642\n",
      "Epoch:  244 | Train Accurancy:  0.9355112835764885 | Validation Accurancy:  0.9568714462220669\n",
      "Epoch:  245 | Train Accurancy:  0.9355981349945068 | Validation Accurancy:  0.9570744186639786\n",
      "Epoch:  246 | Train Accurancy:  0.9356840178370476 | Validation Accurancy:  0.9572759009897709\n",
      "Epoch:  247 | Train Accurancy:  0.9357688575983047 | Validation Accurancy:  0.9574759341776371\n",
      "Epoch:  248 | Train Accurancy:  0.9358527436852455 | Validation Accurancy:  0.9576741382479668\n",
      "Epoch:  249 | Train Accurancy:  0.9359357133507729 | Validation Accurancy:  0.9578702934086323\n",
      "Epoch:  250 | Train Accurancy:  0.9360177367925644 | Validation Accurancy:  0.9580650664865971\n",
      "Epoch:  251 | Train Accurancy:  0.9360988438129425 | Validation Accurancy:  0.9582592025399208\n",
      "Epoch:  252 | Train Accurancy:  0.9361791387200356 | Validation Accurancy:  0.9584522396326065\n",
      "Epoch:  253 | Train Accurancy:  0.9362584725022316 | Validation Accurancy:  0.9586426429450512\n",
      "Epoch:  254 | Train Accurancy:  0.9363368973135948 | Validation Accurancy:  0.9588312469422817\n",
      "Epoch:  255 | Train Accurancy:  0.9364145696163177 | Validation Accurancy:  0.95901919901371\n",
      "Epoch:  256 | Train Accurancy:  0.9364914000034332 | Validation Accurancy:  0.9592073112726212\n",
      "Epoch:  257 | Train Accurancy:  0.9365673512220383 | Validation Accurancy:  0.9593935795128345\n",
      "Epoch:  258 | Train Accurancy:  0.9366425722837448 | Validation Accurancy:  0.9595770984888077\n",
      "Epoch:  259 | Train Accurancy:  0.9367169961333275 | Validation Accurancy:  0.9597582817077637\n",
      "Epoch:  260 | Train Accurancy:  0.9367906600236893 | Validation Accurancy:  0.9599386043846607\n",
      "Epoch:  261 | Train Accurancy:  0.9368635192513466 | Validation Accurancy:  0.9601188339293003\n",
      "Epoch:  262 | Train Accurancy:  0.9369357079267502 | Validation Accurancy:  0.9602979831397533\n",
      "Epoch:  263 | Train Accurancy:  0.9370071440935135 | Validation Accurancy:  0.9604752063751221\n",
      "Epoch:  264 | Train Accurancy:  0.9370778128504753 | Validation Accurancy:  0.9606500938534737\n",
      "Epoch:  265 | Train Accurancy:  0.9371478855609894 | Validation Accurancy:  0.9608231373131275\n",
      "Epoch:  266 | Train Accurancy:  0.9372172206640244 | Validation Accurancy:  0.9609954841434956\n",
      "Epoch:  267 | Train Accurancy:  0.9372858330607414 | Validation Accurancy:  0.9611675105988979\n",
      "Epoch:  268 | Train Accurancy:  0.9373538196086884 | Validation Accurancy:  0.9613381400704384\n",
      "Epoch:  269 | Train Accurancy:  0.9374211505055428 | Validation Accurancy:  0.9615067653357983\n",
      "Epoch:  270 | Train Accurancy:  0.9374878779053688 | Validation Accurancy:  0.9616735316812992\n",
      "Epoch:  271 | Train Accurancy:  0.9375539310276508 | Validation Accurancy:  0.9618394710123539\n",
      "Epoch:  272 | Train Accurancy:  0.937619399279356 | Validation Accurancy:  0.9620049484074116\n",
      "Epoch:  273 | Train Accurancy:  0.9376842565834522 | Validation Accurancy:  0.9621694721281528\n",
      "Epoch:  274 | Train Accurancy:  0.9377485178411007 | Validation Accurancy:  0.9623324237763882\n",
      "Epoch:  275 | Train Accurancy:  0.9378121979534626 | Validation Accurancy:  0.9624935314059258\n",
      "Epoch:  276 | Train Accurancy:  0.9378753080964088 | Validation Accurancy:  0.9626535400748253\n",
      "Epoch:  277 | Train Accurancy:  0.9379378370940685 | Validation Accurancy:  0.9628132991492748\n",
      "Epoch:  278 | Train Accurancy:  0.9379998221993446 | Validation Accurancy:  0.9629721157252789\n",
      "Epoch:  279 | Train Accurancy:  0.9380612447857857 | Validation Accurancy:  0.9631295539438725\n",
      "Epoch:  280 | Train Accurancy:  0.9381221644580364 | Validation Accurancy:  0.9632855877280235\n",
      "Epoch:  281 | Train Accurancy:  0.9381826110184193 | Validation Accurancy:  0.9634405300021172\n",
      "Epoch:  282 | Train Accurancy:  0.9382424242794514 | Validation Accurancy:  0.9635946415364742\n",
      "Epoch:  283 | Train Accurancy:  0.9383018277585506 | Validation Accurancy:  0.9637482017278671\n",
      "Epoch:  284 | Train Accurancy:  0.9383606277406216 | Validation Accurancy:  0.963900551199913\n",
      "Epoch:  285 | Train Accurancy:  0.9384189806878567 | Validation Accurancy:  0.9640515185892582\n",
      "Epoch:  286 | Train Accurancy:  0.9384768977761269 | Validation Accurancy:  0.9642013721168041\n",
      "Epoch:  287 | Train Accurancy:  0.9385343194007874 | Validation Accurancy:  0.9643503651022911\n",
      "Epoch:  288 | Train Accurancy:  0.9385912753641605 | Validation Accurancy:  0.9644992351531982\n",
      "Epoch:  289 | Train Accurancy:  0.9386476911604404 | Validation Accurancy:  0.9646467678248882\n",
      "Epoch:  290 | Train Accurancy:  0.9387037605047226 | Validation Accurancy:  0.9647926017642021\n",
      "Epoch:  291 | Train Accurancy:  0.9387592747807503 | Validation Accurancy:  0.9649372883141041\n",
      "Epoch:  292 | Train Accurancy:  0.9388144351541996 | Validation Accurancy:  0.9650813564658165\n",
      "Epoch:  293 | Train Accurancy:  0.9388691559433937 | Validation Accurancy:  0.9652251228690147\n",
      "Epoch:  294 | Train Accurancy:  0.9389234818518162 | Validation Accurancy:  0.9653676673769951\n",
      "Epoch:  295 | Train Accurancy:  0.9389773495495319 | Validation Accurancy:  0.9655088409781456\n",
      "Epoch:  296 | Train Accurancy:  0.9390308074653149 | Validation Accurancy:  0.965648952871561\n",
      "Epoch:  297 | Train Accurancy:  0.9390839114785194 | Validation Accurancy:  0.9657880626618862\n",
      "Epoch:  298 | Train Accurancy:  0.9391365274786949 | Validation Accurancy:  0.9659270904958248\n",
      "Epoch:  299 | Train Accurancy:  0.9391888156533241 | Validation Accurancy:  0.9660648964345455\n",
      "Epoch:  300 | Train Accurancy:  0.9392407536506653 | Validation Accurancy:  0.9662014320492744\n",
      "Epoch:  301 | Train Accurancy:  0.93929223716259 | Validation Accurancy:  0.966336902230978\n",
      "Epoch:  302 | Train Accurancy:  0.9393433891236782 | Validation Accurancy:  0.9664715118706226\n",
      "Epoch:  303 | Train Accurancy:  0.9393941313028336 | Validation Accurancy:  0.9666056632995605\n",
      "Epoch:  304 | Train Accurancy:  0.9394445791840553 | Validation Accurancy:  0.9667389877140522\n",
      "Epoch:  305 | Train Accurancy:  0.9394945912063122 | Validation Accurancy:  0.9668712615966797\n",
      "Epoch:  306 | Train Accurancy:  0.9395443685352802 | Validation Accurancy:  0.9670021049678326\n",
      "Epoch:  307 | Train Accurancy:  0.9395936764776707 | Validation Accurancy:  0.9671324267983437\n",
      "Epoch:  308 | Train Accurancy:  0.9396427236497402 | Validation Accurancy:  0.9672620631754398\n",
      "Epoch:  309 | Train Accurancy:  0.9396914504468441 | Validation Accurancy:  0.9673910774290562\n",
      "Epoch:  310 | Train Accurancy:  0.9397397600114346 | Validation Accurancy:  0.9675190784037113\n",
      "Epoch:  311 | Train Accurancy:  0.9397878386080265 | Validation Accurancy:  0.9676456302404404\n",
      "Epoch:  312 | Train Accurancy:  0.939835537225008 | Validation Accurancy:  0.967771865427494\n",
      "Epoch:  313 | Train Accurancy:  0.9398829378187656 | Validation Accurancy:  0.9678972400724888\n",
      "Epoch:  314 | Train Accurancy:  0.9399300590157509 | Validation Accurancy:  0.9680218063294888\n",
      "Epoch:  315 | Train Accurancy:  0.9399768337607384 | Validation Accurancy:  0.9681454487144947\n",
      "Epoch:  316 | Train Accurancy:  0.9400233030319214 | Validation Accurancy:  0.9682682529091835\n",
      "Epoch:  317 | Train Accurancy:  0.9400694742798805 | Validation Accurancy:  0.9683902598917484\n",
      "Epoch:  318 | Train Accurancy:  0.9401153773069382 | Validation Accurancy:  0.9685117416083813\n",
      "Epoch:  319 | Train Accurancy:  0.9401610121130943 | Validation Accurancy:  0.9686322547495365\n",
      "Epoch:  320 | Train Accurancy:  0.9402063526213169 | Validation Accurancy:  0.9687519073486328\n",
      "Epoch:  321 | Train Accurancy:  0.9402513727545738 | Validation Accurancy:  0.9688711799681187\n",
      "Epoch:  322 | Train Accurancy:  0.9402961134910583 | Validation Accurancy:  0.968989547342062\n",
      "Epoch:  323 | Train Accurancy:  0.9403406567871571 | Validation Accurancy:  0.9691067859530449\n",
      "Epoch:  324 | Train Accurancy:  0.940384890884161 | Validation Accurancy:  0.9692233093082905\n",
      "Epoch:  325 | Train Accurancy:  0.9404288306832314 | Validation Accurancy:  0.9693390056490898\n",
      "Epoch:  326 | Train Accurancy:  0.9404725544154644 | Validation Accurancy:  0.9694540817290545\n",
      "Epoch:  327 | Train Accurancy:  0.9405160285532475 | Validation Accurancy:  0.9695684593170881\n",
      "Epoch:  328 | Train Accurancy:  0.9405591674149036 | Validation Accurancy:  0.9696821365505457\n",
      "Epoch:  329 | Train Accurancy:  0.9406020902097225 | Validation Accurancy:  0.9697950202971697\n",
      "Epoch:  330 | Train Accurancy:  0.9406447820365429 | Validation Accurancy:  0.9699073154479265\n",
      "Epoch:  331 | Train Accurancy:  0.940687283873558 | Validation Accurancy:  0.9700189903378487\n",
      "Epoch:  332 | Train Accurancy:  0.9407294578850269 | Validation Accurancy:  0.9701294265687466\n",
      "Epoch:  333 | Train Accurancy:  0.9407714232802391 | Validation Accurancy:  0.9702391140162945\n",
      "Epoch:  334 | Train Accurancy:  0.9408132210373878 | Validation Accurancy:  0.9703482948243618\n",
      "Epoch:  335 | Train Accurancy:  0.9408546909689903 | Validation Accurancy:  0.9704569019377232\n",
      "Epoch:  336 | Train Accurancy:  0.9408959597349167 | Validation Accurancy:  0.9705645404756069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  337 | Train Accurancy:  0.9409370459616184 | Validation Accurancy:  0.9706713985651731\n",
      "Epoch:  338 | Train Accurancy:  0.9409778043627739 | Validation Accurancy:  0.9707778301090002\n",
      "Epoch:  339 | Train Accurancy:  0.9410184361040592 | Validation Accurancy:  0.9708839263767004\n",
      "Epoch:  340 | Train Accurancy:  0.9410588182508945 | Validation Accurancy:  0.9709891323000193\n",
      "Epoch:  341 | Train Accurancy:  0.9410990513861179 | Validation Accurancy:  0.9710932895541191\n",
      "Epoch:  342 | Train Accurancy:  0.9411390163004398 | Validation Accurancy:  0.9711969066411257\n",
      "Epoch:  343 | Train Accurancy:  0.9411787949502468 | Validation Accurancy:  0.9713001251220703\n",
      "Epoch:  344 | Train Accurancy:  0.9412183649837971 | Validation Accurancy:  0.9714027084410191\n",
      "Epoch:  345 | Train Accurancy:  0.9412577040493488 | Validation Accurancy:  0.9715045932680368\n",
      "Epoch:  346 | Train Accurancy:  0.9412968941032887 | Validation Accurancy:  0.9716053809970617\n",
      "Epoch:  347 | Train Accurancy:  0.9413357973098755 | Validation Accurancy:  0.971705786883831\n",
      "Epoch:  348 | Train Accurancy:  0.9413745775818825 | Validation Accurancy:  0.971805589273572\n",
      "Epoch:  349 | Train Accurancy:  0.941413227468729 | Validation Accurancy:  0.9719047378748655\n",
      "Epoch:  350 | Train Accurancy:  0.9414515048265457 | Validation Accurancy:  0.9720031898468733\n",
      "Epoch:  351 | Train Accurancy:  0.9414898157119751 | Validation Accurancy:  0.9721009414643049\n",
      "Epoch:  352 | Train Accurancy:  0.9415277801454067 | Validation Accurancy:  0.9721978828310966\n",
      "Epoch:  353 | Train Accurancy:  0.9415655732154846 | Validation Accurancy:  0.9722943790256977\n",
      "Epoch:  354 | Train Accurancy:  0.9416032880544662 | Validation Accurancy:  0.9723904766142368\n",
      "Epoch:  355 | Train Accurancy:  0.9416407756507397 | Validation Accurancy:  0.9724856056272984\n",
      "Epoch:  356 | Train Accurancy:  0.9416780583560467 | Validation Accurancy:  0.972579987719655\n",
      "Epoch:  357 | Train Accurancy:  0.9417152218520641 | Validation Accurancy:  0.9726740196347237\n",
      "Epoch:  358 | Train Accurancy:  0.9417521171271801 | Validation Accurancy:  0.9727673698216677\n",
      "Epoch:  359 | Train Accurancy:  0.9417889453470707 | Validation Accurancy:  0.9728602562099695\n",
      "Epoch:  360 | Train Accurancy:  0.9418255686759949 | Validation Accurancy:  0.9729523658752441\n",
      "Epoch:  361 | Train Accurancy:  0.9418620020151138 | Validation Accurancy:  0.9730435367673635\n",
      "Epoch:  362 | Train Accurancy:  0.9418982639908791 | Validation Accurancy:  0.9731341674923897\n",
      "Epoch:  363 | Train Accurancy:  0.9419344924390316 | Validation Accurancy:  0.973224576562643\n",
      "Epoch:  364 | Train Accurancy:  0.941970307379961 | Validation Accurancy:  0.9733143970370293\n",
      "Epoch:  365 | Train Accurancy:  0.9420062303543091 | Validation Accurancy:  0.9734033420681953\n",
      "Epoch:  366 | Train Accurancy:  0.9420419260859489 | Validation Accurancy:  0.9734918437898159\n",
      "Epoch:  367 | Train Accurancy:  0.9420774020254612 | Validation Accurancy:  0.9735796619206667\n",
      "Epoch:  368 | Train Accurancy:  0.9421127252280712 | Validation Accurancy:  0.9736672397702932\n",
      "Epoch:  369 | Train Accurancy:  0.9421479552984238 | Validation Accurancy:  0.9737539924681187\n",
      "Epoch:  370 | Train Accurancy:  0.942183006554842 | Validation Accurancy:  0.973840219900012\n",
      "Epoch:  371 | Train Accurancy:  0.9422178864479065 | Validation Accurancy:  0.9739258605986834\n",
      "Epoch:  372 | Train Accurancy:  0.9422527216374874 | Validation Accurancy:  0.974010992795229\n",
      "Epoch:  373 | Train Accurancy:  0.9422872811555862 | Validation Accurancy:  0.9740955661982298\n",
      "Epoch:  374 | Train Accurancy:  0.9423217996954918 | Validation Accurancy:  0.9741796646267176\n",
      "Epoch:  375 | Train Accurancy:  0.9423560984432697 | Validation Accurancy:  0.9742630328983068\n",
      "Epoch:  376 | Train Accurancy:  0.942390251904726 | Validation Accurancy:  0.9743460174649954\n",
      "Epoch:  377 | Train Accurancy:  0.942424364387989 | Validation Accurancy:  0.9744283203035593\n",
      "Epoch:  378 | Train Accurancy:  0.9424582533538342 | Validation Accurancy:  0.9745101928710938\n",
      "Epoch:  379 | Train Accurancy:  0.942492064088583 | Validation Accurancy:  0.9745914451777935\n",
      "Epoch:  380 | Train Accurancy:  0.9425257295370102 | Validation Accurancy:  0.9746720790863037\n",
      "Epoch:  381 | Train Accurancy:  0.9425592683255672 | Validation Accurancy:  0.9747522193938494\n",
      "Epoch:  382 | Train Accurancy:  0.9425925835967064 | Validation Accurancy:  0.974832009524107\n",
      "Epoch:  383 | Train Accurancy:  0.9426259212195873 | Validation Accurancy:  0.9749111644923687\n",
      "Epoch:  384 | Train Accurancy:  0.9426590614020824 | Validation Accurancy:  0.9749895725399256\n",
      "Epoch:  385 | Train Accurancy:  0.9426920935511589 | Validation Accurancy:  0.9750675987452269\n",
      "Epoch:  386 | Train Accurancy:  0.9427249655127525 | Validation Accurancy:  0.9751452766358852\n",
      "Epoch:  387 | Train Accurancy:  0.9427577704191208 | Validation Accurancy:  0.9752221424132586\n",
      "Epoch:  388 | Train Accurancy:  0.9427903033792973 | Validation Accurancy:  0.9752986915409565\n",
      "Epoch:  389 | Train Accurancy:  0.9428228475153446 | Validation Accurancy:  0.9753745868802071\n",
      "Epoch:  390 | Train Accurancy:  0.9428552500903606 | Validation Accurancy:  0.9754501655697823\n",
      "Epoch:  391 | Train Accurancy:  0.9428874962031841 | Validation Accurancy:  0.975525189191103\n",
      "Epoch:  392 | Train Accurancy:  0.9429195933043957 | Validation Accurancy:  0.9755998458713293\n",
      "Epoch:  393 | Train Accurancy:  0.9429516904056072 | Validation Accurancy:  0.9756737388670444\n",
      "Epoch:  394 | Train Accurancy:  0.9429836086928844 | Validation Accurancy:  0.9757471401244402\n",
      "Epoch:  395 | Train Accurancy:  0.9430155530571938 | Validation Accurancy:  0.9758200161159039\n",
      "Epoch:  396 | Train Accurancy:  0.9430472366511822 | Validation Accurancy:  0.9758927654474974\n",
      "Epoch:  397 | Train Accurancy:  0.9430787898600101 | Validation Accurancy:  0.975964767858386\n",
      "Epoch:  398 | Train Accurancy:  0.9431102499365807 | Validation Accurancy:  0.9760363418608904\n",
      "Epoch:  399 | Train Accurancy:  0.9431416764855385 | Validation Accurancy:  0.9761071689426899\n",
      "Epoch:  400 | Train Accurancy:  0.9431729540228844 | Validation Accurancy:  0.9761778507381678\n",
      "Epoch:  401 | Train Accurancy:  0.9432040527462959 | Validation Accurancy:  0.9762481208890676\n",
      "Epoch:  402 | Train Accurancy:  0.9432351253926754 | Validation Accurancy:  0.9763177875429392\n",
      "Epoch:  403 | Train Accurancy:  0.9432660974562168 | Validation Accurancy:  0.976386833935976\n",
      "Epoch:  404 | Train Accurancy:  0.943296916782856 | Validation Accurancy:  0.9764554500579834\n",
      "Epoch:  405 | Train Accurancy:  0.9433276504278183 | Validation Accurancy:  0.9765239078551531\n",
      "Epoch:  406 | Train Accurancy:  0.9433583430945873 | Validation Accurancy:  0.9765917304903269\n",
      "Epoch:  407 | Train Accurancy:  0.9433888830244541 | Validation Accurancy:  0.9766591396182775\n",
      "Epoch:  408 | Train Accurancy:  0.9434193298220634 | Validation Accurancy:  0.9767259750515223\n",
      "Epoch:  409 | Train Accurancy:  0.9434496611356735 | Validation Accurancy:  0.9767925255000591\n",
      "Epoch:  410 | Train Accurancy:  0.9434799030423164 | Validation Accurancy:  0.9768586158752441\n",
      "Epoch:  411 | Train Accurancy:  0.9435100927948952 | Validation Accurancy:  0.9769242759793997\n",
      "Epoch:  412 | Train Accurancy:  0.9435401223599911 | Validation Accurancy:  0.9769893642514944\n",
      "Epoch:  413 | Train Accurancy:  0.9435700625181198 | Validation Accurancy:  0.9770539291203022\n",
      "Epoch:  414 | Train Accurancy:  0.9435999505221844 | Validation Accurancy:  0.9771182537078857\n",
      "Epoch:  415 | Train Accurancy:  0.9436296932399273 | Validation Accurancy:  0.9771821666508913\n",
      "Epoch:  416 | Train Accurancy:  0.9436594061553478 | Validation Accurancy:  0.977245569229126\n",
      "Epoch:  417 | Train Accurancy:  0.9436889663338661 | Validation Accurancy:  0.9773086067289114\n",
      "Epoch:  418 | Train Accurancy:  0.9437184818089008 | Validation Accurancy:  0.9773711990565062\n",
      "Epoch:  419 | Train Accurancy:  0.9437479302287102 | Validation Accurancy:  0.9774333797395229\n",
      "Epoch:  420 | Train Accurancy:  0.9437771327793598 | Validation Accurancy:  0.9774950500577688\n",
      "Epoch:  421 | Train Accurancy:  0.9438064806163311 | Validation Accurancy:  0.9775563236325979\n",
      "Epoch:  422 | Train Accurancy:  0.9438355639576912 | Validation Accurancy:  0.977617247030139\n",
      "Epoch:  423 | Train Accurancy:  0.943864643573761 | Validation Accurancy:  0.9776777420192957\n",
      "Epoch:  424 | Train Accurancy:  0.9438936226069927 | Validation Accurancy:  0.9777379035949707\n",
      "Epoch:  425 | Train Accurancy:  0.9439224675297737 | Validation Accurancy:  0.9777977149933577\n",
      "Epoch:  426 | Train Accurancy:  0.9439513050019741 | Validation Accurancy:  0.9778567161411047\n",
      "Epoch:  427 | Train Accurancy:  0.9439799822866917 | Validation Accurancy:  0.9779155254364014\n",
      "Epoch:  428 | Train Accurancy:  0.9440086707472801 | Validation Accurancy:  0.9779740814119577\n",
      "Epoch:  429 | Train Accurancy:  0.9440372250974178 | Validation Accurancy:  0.978032048791647\n",
      "Epoch:  430 | Train Accurancy:  0.9440656825900078 | Validation Accurancy:  0.9780898094177246\n",
      "Epoch:  431 | Train Accurancy:  0.9440941102802753 | Validation Accurancy:  0.9781471565365791\n",
      "Epoch:  432 | Train Accurancy:  0.9441224746406078 | Validation Accurancy:  0.978203821927309\n",
      "Epoch:  433 | Train Accurancy:  0.9441506080329418 | Validation Accurancy:  0.9782603420317173\n",
      "Epoch:  434 | Train Accurancy:  0.944178681820631 | Validation Accurancy:  0.9783165622502565\n",
      "Epoch:  435 | Train Accurancy:  0.9442068301141262 | Validation Accurancy:  0.9783721920102835\n",
      "Epoch:  436 | Train Accurancy:  0.9442348517477512 | Validation Accurancy:  0.9784272350370884\n",
      "Epoch:  437 | Train Accurancy:  0.9442627653479576 | Validation Accurancy:  0.9784826599061489\n",
      "Epoch:  438 | Train Accurancy:  0.9442906826734543 | Validation Accurancy:  0.9785374328494072\n",
      "Epoch:  439 | Train Accurancy:  0.9443184174597263 | Validation Accurancy:  0.978591077029705\n",
      "Epoch:  440 | Train Accurancy:  0.944346085190773 | Validation Accurancy:  0.9786447044461966\n",
      "Epoch:  441 | Train Accurancy:  0.9443737268447876 | Validation Accurancy:  0.9786983337253332\n",
      "Epoch:  442 | Train Accurancy:  0.9444012977182865 | Validation Accurancy:  0.9787514377385378\n",
      "Epoch:  443 | Train Accurancy:  0.9444287493824959 | Validation Accurancy:  0.9788042549043894\n",
      "Epoch:  444 | Train Accurancy:  0.9444561563432217 | Validation Accurancy:  0.9788562618196011\n",
      "Epoch:  445 | Train Accurancy:  0.9444834478199482 | Validation Accurancy:  0.978908110409975\n",
      "Epoch:  446 | Train Accurancy:  0.9445107206702232 | Validation Accurancy:  0.9789597503840923\n",
      "Epoch:  447 | Train Accurancy:  0.9445378743112087 | Validation Accurancy:  0.9790114238858223\n",
      "Epoch:  448 | Train Accurancy:  0.9445650354027748 | Validation Accurancy:  0.9790620803833008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  449 | Train Accurancy:  0.9445921070873737 | Validation Accurancy:  0.979112196713686\n",
      "Epoch:  450 | Train Accurancy:  0.9446190074086189 | Validation Accurancy:  0.979162534698844\n",
      "Epoch:  451 | Train Accurancy:  0.9446459747850895 | Validation Accurancy:  0.9792126026004553\n",
      "Epoch:  452 | Train Accurancy:  0.9446727186441422 | Validation Accurancy:  0.979261826723814\n",
      "Epoch:  453 | Train Accurancy:  0.9446995630860329 | Validation Accurancy:  0.9793105442076921\n",
      "Epoch:  454 | Train Accurancy:  0.944726325571537 | Validation Accurancy:  0.9793592765927315\n",
      "Epoch:  455 | Train Accurancy:  0.9447529092431068 | Validation Accurancy:  0.9794080257415771\n",
      "Epoch:  456 | Train Accurancy:  0.9447794519364834 | Validation Accurancy:  0.9794560745358467\n",
      "Epoch:  457 | Train Accurancy:  0.9448059909045696 | Validation Accurancy:  0.9795036315917969\n",
      "Epoch:  458 | Train Accurancy:  0.9448324218392372 | Validation Accurancy:  0.9795509018003941\n",
      "Epoch:  459 | Train Accurancy:  0.9448587521910667 | Validation Accurancy:  0.9795980285853148\n",
      "Epoch:  460 | Train Accurancy:  0.9448850937187672 | Validation Accurancy:  0.979644950479269\n",
      "Epoch:  461 | Train Accurancy:  0.9449113681912422 | Validation Accurancy:  0.9796911869198084\n",
      "Epoch:  462 | Train Accurancy:  0.944937564432621 | Validation Accurancy:  0.9797367732971907\n",
      "Epoch:  463 | Train Accurancy:  0.9449636600911617 | Validation Accurancy:  0.9797826763242483\n",
      "Epoch:  464 | Train Accurancy:  0.9449897222220898 | Validation Accurancy:  0.9798282142728567\n",
      "Epoch:  465 | Train Accurancy:  0.9450156576931477 | Validation Accurancy:  0.979873163625598\n",
      "Epoch:  466 | Train Accurancy:  0.9450416043400764 | Validation Accurancy:  0.9799177646636963\n",
      "Epoch:  467 | Train Accurancy:  0.9450675249099731 | Validation Accurancy:  0.9799619987607002\n",
      "Epoch:  468 | Train Accurancy:  0.9450932368636131 | Validation Accurancy:  0.9800062347203493\n",
      "Epoch:  469 | Train Accurancy:  0.945119109004736 | Validation Accurancy:  0.9800501670688391\n",
      "Epoch:  470 | Train Accurancy:  0.9451447874307632 | Validation Accurancy:  0.9800933673977852\n",
      "Epoch:  471 | Train Accurancy:  0.9451704360544682 | Validation Accurancy:  0.9801363628357649\n",
      "Epoch:  472 | Train Accurancy:  0.9451958760619164 | Validation Accurancy:  0.9801792614161968\n",
      "Epoch:  473 | Train Accurancy:  0.9452214948832989 | Validation Accurancy:  0.9802218750119209\n",
      "Epoch:  474 | Train Accurancy:  0.9452469013631344 | Validation Accurancy:  0.980263726785779\n",
      "Epoch:  475 | Train Accurancy:  0.9452723003923893 | Validation Accurancy:  0.9803056083619595\n",
      "Epoch:  476 | Train Accurancy:  0.945297684520483 | Validation Accurancy:  0.9803473632782698\n",
      "Epoch:  477 | Train Accurancy:  0.9453229755163193 | Validation Accurancy:  0.9803886245936155\n",
      "Epoch:  478 | Train Accurancy:  0.9453481175005436 | Validation Accurancy:  0.9804294276982546\n",
      "Epoch:  479 | Train Accurancy:  0.9453733563423157 | Validation Accurancy:  0.9804698619991541\n",
      "Epoch:  480 | Train Accurancy:  0.945398423820734 | Validation Accurancy:  0.9805104248225689\n",
      "Epoch:  481 | Train Accurancy:  0.9454234801232815 | Validation Accurancy:  0.9805504009127617\n",
      "Epoch:  482 | Train Accurancy:  0.9454485327005386 | Validation Accurancy:  0.9805900733917952\n",
      "Epoch:  483 | Train Accurancy:  0.945473488420248 | Validation Accurancy:  0.9806292541325092\n",
      "Epoch:  484 | Train Accurancy:  0.9454983212053776 | Validation Accurancy:  0.9806685764342546\n",
      "Epoch:  485 | Train Accurancy:  0.9455231092870235 | Validation Accurancy:  0.9807075653225183\n",
      "Epoch:  486 | Train Accurancy:  0.9455479197204113 | Validation Accurancy:  0.980745904147625\n",
      "Epoch:  487 | Train Accurancy:  0.9455726891756058 | Validation Accurancy:  0.9807840827852488\n",
      "Epoch:  488 | Train Accurancy:  0.9455973580479622 | Validation Accurancy:  0.9808219112455845\n",
      "Epoch:  489 | Train Accurancy:  0.9456219486892223 | Validation Accurancy:  0.980859836563468\n",
      "Epoch:  490 | Train Accurancy:  0.945646446198225 | Validation Accurancy:  0.9808971080929041\n",
      "Epoch:  491 | Train Accurancy:  0.9456709697842598 | Validation Accurancy:  0.9809341598302126\n",
      "Epoch:  492 | Train Accurancy:  0.9456954561173916 | Validation Accurancy:  0.9809708911925554\n",
      "Epoch:  493 | Train Accurancy:  0.9457198716700077 | Validation Accurancy:  0.9810075126588345\n",
      "Epoch:  494 | Train Accurancy:  0.9457443095743656 | Validation Accurancy:  0.9810436889529228\n",
      "Epoch:  495 | Train Accurancy:  0.9457685798406601 | Validation Accurancy:  0.9810794834047556\n",
      "Epoch:  496 | Train Accurancy:  0.945792768150568 | Validation Accurancy:  0.981115372851491\n",
      "Epoch:  497 | Train Accurancy:  0.9458170384168625 | Validation Accurancy:  0.9811509139835835\n",
      "Epoch:  498 | Train Accurancy:  0.9458412043750286 | Validation Accurancy:  0.9811856746673584\n",
      "Epoch:  499 | Train Accurancy:  0.9458652101457119 | Validation Accurancy:  0.9812205154448748\n",
      "Epoch:  500 | Train Accurancy:  0.9458892308175564 | Validation Accurancy:  0.981255229562521\n",
      "Epoch:  501 | Train Accurancy:  0.9459132552146912 | Validation Accurancy:  0.9812895935028791\n",
      "Epoch:  502 | Train Accurancy:  0.9459372535347939 | Validation Accurancy:  0.9813233222812414\n",
      "Epoch:  503 | Train Accurancy:  0.9459610916674137 | Validation Accurancy:  0.9813570342957973\n",
      "Epoch:  504 | Train Accurancy:  0.9459850192070007 | Validation Accurancy:  0.9813906513154507\n",
      "Epoch:  505 | Train Accurancy:  0.9460087455809116 | Validation Accurancy:  0.9814239982515574\n",
      "Epoch:  506 | Train Accurancy:  0.9460324868559837 | Validation Accurancy:  0.9814567565917969\n",
      "Epoch:  507 | Train Accurancy:  0.9460562244057655 | Validation Accurancy:  0.9814894367009401\n",
      "Epoch:  508 | Train Accurancy:  0.9460798874497414 | Validation Accurancy:  0.9815218281000853\n",
      "Epoch:  509 | Train Accurancy:  0.9461035281419754 | Validation Accurancy:  0.9815539680421352\n",
      "Epoch:  510 | Train Accurancy:  0.9461270533502102 | Validation Accurancy:  0.9815858844667673\n",
      "Epoch:  511 | Train Accurancy:  0.9461506009101868 | Validation Accurancy:  0.9816175308078527\n",
      "Epoch:  512 | Train Accurancy:  0.9461740143597126 | Validation Accurancy:  0.9816489387303591\n",
      "Epoch:  513 | Train Accurancy:  0.9461974911391735 | Validation Accurancy:  0.9816799964755774\n",
      "Epoch:  514 | Train Accurancy:  0.9462208189070225 | Validation Accurancy:  0.9817108158022165\n",
      "Epoch:  515 | Train Accurancy:  0.9462441466748714 | Validation Accurancy:  0.9817415084689856\n",
      "Epoch:  516 | Train Accurancy:  0.9462674707174301 | Validation Accurancy:  0.9817717559635639\n",
      "Epoch:  517 | Train Accurancy:  0.9462906569242477 | Validation Accurancy:  0.9818017650395632\n",
      "Epoch:  518 | Train Accurancy:  0.9463137611746788 | Validation Accurancy:  0.9818317405879498\n",
      "Epoch:  519 | Train Accurancy:  0.9463369585573673 | Validation Accurancy:  0.9818614646792412\n",
      "Epoch:  520 | Train Accurancy:  0.9463600590825081 | Validation Accurancy:  0.9818906150758266\n",
      "Epoch:  521 | Train Accurancy:  0.9463830962777138 | Validation Accurancy:  0.9819198288023472\n",
      "Epoch:  522 | Train Accurancy:  0.9464060552418232 | Validation Accurancy:  0.9819486942142248\n",
      "Epoch:  523 | Train Accurancy:  0.9464290179312229 | Validation Accurancy:  0.9819773510098457\n",
      "Epoch:  524 | Train Accurancy:  0.9464520141482353 | Validation Accurancy:  0.982005612924695\n",
      "Epoch:  525 | Train Accurancy:  0.9464748278260231 | Validation Accurancy:  0.9820337127894163\n",
      "Epoch:  526 | Train Accurancy:  0.9464975632727146 | Validation Accurancy:  0.9820615444332361\n",
      "Epoch:  527 | Train Accurancy:  0.9465203061699867 | Validation Accurancy:  0.9820891860872507\n",
      "Epoch:  528 | Train Accurancy:  0.9465431421995163 | Validation Accurancy:  0.9821166042238474\n",
      "Epoch:  529 | Train Accurancy:  0.946565791964531 | Validation Accurancy:  0.982143783941865\n",
      "Epoch:  530 | Train Accurancy:  0.9465883113443851 | Validation Accurancy:  0.9821709152311087\n",
      "Epoch:  531 | Train Accurancy:  0.946611050516367 | Validation Accurancy:  0.982197554782033\n",
      "Epoch:  532 | Train Accurancy:  0.9466335251927376 | Validation Accurancy:  0.982224004343152\n",
      "Epoch:  533 | Train Accurancy:  0.9466560520231724 | Validation Accurancy:  0.9822504688054323\n",
      "Epoch:  534 | Train Accurancy:  0.9466784819960594 | Validation Accurancy:  0.9822766147553921\n",
      "Epoch:  535 | Train Accurancy:  0.9467008449137211 | Validation Accurancy:  0.982302363961935\n",
      "Epoch:  536 | Train Accurancy:  0.9467232376337051 | Validation Accurancy:  0.9823279697448015\n",
      "Epoch:  537 | Train Accurancy:  0.9467455185949802 | Validation Accurancy:  0.9823531936854124\n",
      "Epoch:  538 | Train Accurancy:  0.9467678405344486 | Validation Accurancy:  0.9823783561587334\n",
      "Epoch:  539 | Train Accurancy:  0.9467900805175304 | Validation Accurancy:  0.9824034217745066\n",
      "Epoch:  540 | Train Accurancy:  0.9468123316764832 | Validation Accurancy:  0.982428090646863\n",
      "Epoch:  541 | Train Accurancy:  0.9468344487249851 | Validation Accurancy:  0.9824524726718664\n",
      "Epoch:  542 | Train Accurancy:  0.9468565173447132 | Validation Accurancy:  0.9824765678495169\n",
      "Epoch:  543 | Train Accurancy:  0.9468785896897316 | Validation Accurancy:  0.9825007598847151\n",
      "Epoch:  544 | Train Accurancy:  0.9469006210565567 | Validation Accurancy:  0.9825246650725603\n",
      "Epoch:  545 | Train Accurancy:  0.9469226151704788 | Validation Accurancy:  0.9825481735169888\n",
      "Epoch:  546 | Train Accurancy:  0.9469445459544659 | Validation Accurancy:  0.9825713150203228\n",
      "Epoch:  547 | Train Accurancy:  0.9469664096832275 | Validation Accurancy:  0.9825947117060423\n",
      "Epoch:  548 | Train Accurancy:  0.9469882473349571 | Validation Accurancy:  0.9826173782348633\n",
      "Epoch:  549 | Train Accurancy:  0.9470100663602352 | Validation Accurancy:  0.9826398380100727\n",
      "Epoch:  550 | Train Accurancy:  0.9470317475497723 | Validation Accurancy:  0.9826625343412161\n",
      "Epoch:  551 | Train Accurancy:  0.9470535516738892 | Validation Accurancy:  0.9826848823577166\n",
      "Epoch:  552 | Train Accurancy:  0.9470751956105232 | Validation Accurancy:  0.9827067852020264\n",
      "Epoch:  553 | Train Accurancy:  0.9470969960093498 | Validation Accurancy:  0.9827286396175623\n",
      "Epoch:  554 | Train Accurancy:  0.9471185132861137 | Validation Accurancy:  0.9827502258121967\n",
      "Epoch:  555 | Train Accurancy:  0.9471400454640388 | Validation Accurancy:  0.9827716033905745\n",
      "Epoch:  556 | Train Accurancy:  0.9471614956855774 | Validation Accurancy:  0.9827926959842443\n",
      "Epoch:  557 | Train Accurancy:  0.9471829459071159 | Validation Accurancy:  0.9828135650604963\n",
      "Epoch:  558 | Train Accurancy:  0.9472044073045254 | Validation Accurancy:  0.9828343391418457\n",
      "Epoch:  559 | Train Accurancy:  0.9472258426249027 | Validation Accurancy:  0.9828548915684223\n",
      "Epoch:  560 | Train Accurancy:  0.9472471624612808 | Validation Accurancy:  0.9828752670437098\n",
      "Epoch:  561 | Train Accurancy:  0.9472685046494007 | Validation Accurancy:  0.9828951042145491\n",
      "Epoch:  562 | Train Accurancy:  0.947289727628231 | Validation Accurancy:  0.982914861291647\n",
      "Epoch:  563 | Train Accurancy:  0.9473108984529972 | Validation Accurancy:  0.9829346016049385\n",
      "Epoch:  564 | Train Accurancy:  0.9473321549594402 | Validation Accurancy:  0.9829540085047483\n",
      "Epoch:  565 | Train Accurancy:  0.9473533220589161 | Validation Accurancy:  0.9829730037599802\n",
      "Epoch:  566 | Train Accurancy:  0.9473743475973606 | Validation Accurancy:  0.9829922206699848\n",
      "Epoch:  567 | Train Accurancy:  0.9473954848945141 | Validation Accurancy:  0.9830110389739275\n",
      "Epoch:  568 | Train Accurancy:  0.9474164247512817 | Validation Accurancy:  0.9830295238643885\n",
      "Epoch:  569 | Train Accurancy:  0.9474375955760479 | Validation Accurancy:  0.983047740533948\n",
      "Epoch:  570 | Train Accurancy:  0.9474584385752678 | Validation Accurancy:  0.9830659069120884\n",
      "Epoch:  571 | Train Accurancy:  0.9474793151021004 | Validation Accurancy:  0.9830840583890676\n",
      "Epoch:  572 | Train Accurancy:  0.9475001208484173 | Validation Accurancy:  0.9831016696989536\n",
      "Epoch:  573 | Train Accurancy:  0.9475210160017014 | Validation Accurancy:  0.9831191059201956\n",
      "Epoch:  574 | Train Accurancy:  0.9475418142974377 | Validation Accurancy:  0.9831366706639528\n",
      "Epoch:  575 | Train Accurancy:  0.9475625045597553 | Validation Accurancy:  0.9831537883728743\n",
      "Epoch:  576 | Train Accurancy:  0.947583232074976 | Validation Accurancy:  0.9831708278506994\n",
      "Epoch:  577 | Train Accurancy:  0.9476039446890354 | Validation Accurancy:  0.9831874687224627\n",
      "Epoch:  578 | Train Accurancy:  0.9476245418190956 | Validation Accurancy:  0.9832042213529348\n",
      "Epoch:  579 | Train Accurancy:  0.947645116597414 | Validation Accurancy:  0.9832206405699253\n",
      "Epoch:  580 | Train Accurancy:  0.9476656503975391 | Validation Accurancy:  0.9832367263734341\n",
      "Epoch:  581 | Train Accurancy:  0.9476862624287605 | Validation Accurancy:  0.9832526687532663\n",
      "Epoch:  582 | Train Accurancy:  0.9477065950632095 | Validation Accurancy:  0.9832686260342598\n",
      "Epoch:  583 | Train Accurancy:  0.9477270804345608 | Validation Accurancy:  0.9832845218479633\n",
      "Epoch:  584 | Train Accurancy:  0.947747528553009 | Validation Accurancy:  0.983299732208252\n",
      "Epoch:  585 | Train Accurancy:  0.9477678947150707 | Validation Accurancy:  0.9833149425685406\n",
      "Epoch:  586 | Train Accurancy:  0.9477881342172623 | Validation Accurancy:  0.9833304081112146\n",
      "Epoch:  587 | Train Accurancy:  0.9478084035217762 | Validation Accurancy:  0.9833454452455044\n",
      "Epoch:  588 | Train Accurancy:  0.947828646749258 | Validation Accurancy:  0.9833601154386997\n",
      "Epoch:  589 | Train Accurancy:  0.9478488303720951 | Validation Accurancy:  0.983374547213316\n",
      "Epoch:  590 | Train Accurancy:  0.9478689767420292 | Validation Accurancy:  0.9833893608301878\n",
      "Epoch:  591 | Train Accurancy:  0.9478891417384148 | Validation Accurancy:  0.9834038261324167\n",
      "Epoch:  592 | Train Accurancy:  0.9479091763496399 | Validation Accurancy:  0.9834174625575542\n",
      "Epoch:  593 | Train Accurancy:  0.9479292519390583 | Validation Accurancy:  0.9834314975887537\n",
      "Epoch:  594 | Train Accurancy:  0.947949193418026 | Validation Accurancy:  0.983445581048727\n",
      "Epoch:  595 | Train Accurancy:  0.9479692205786705 | Validation Accurancy:  0.9834590759128332\n",
      "Epoch:  596 | Train Accurancy:  0.9479890912771225 | Validation Accurancy:  0.9834721721708775\n",
      "Epoch:  597 | Train Accurancy:  0.9480090364813805 | Validation Accurancy:  0.9834856037050486\n",
      "Epoch:  598 | Train Accurancy:  0.948028851300478 | Validation Accurancy:  0.9834991618990898\n",
      "Epoch:  599 | Train Accurancy:  0.9480486959218979 | Validation Accurancy:  0.9835117664188147\n",
      "Epoch:  600 | Train Accurancy:  0.9480684138834476 | Validation Accurancy:  0.9835243541747332\n",
      "Epoch:  601 | Train Accurancy:  0.9480881355702877 | Validation Accurancy:  0.9835370853543282\n",
      "Epoch:  602 | Train Accurancy:  0.9481077678501606 | Validation Accurancy:  0.9835497383028269\n",
      "Epoch:  603 | Train Accurancy:  0.9481274969875813 | Validation Accurancy:  0.9835617858916521\n",
      "Epoch:  604 | Train Accurancy:  0.9481470957398415 | Validation Accurancy:  0.9835735950618982\n",
      "Epoch:  605 | Train Accurancy:  0.9481666423380375 | Validation Accurancy:  0.983585961163044\n",
      "Epoch:  606 | Train Accurancy:  0.948186207562685 | Validation Accurancy:  0.983597818762064\n",
      "Epoch:  607 | Train Accurancy:  0.9482057839632034 | Validation Accurancy:  0.9836089927703142\n",
      "Epoch:  608 | Train Accurancy:  0.9482251852750778 | Validation Accurancy:  0.9836203884333372\n",
      "Epoch:  609 | Train Accurancy:  0.948244534432888 | Validation Accurancy:  0.9836319759488106\n",
      "Epoch:  610 | Train Accurancy:  0.9482640027999878 | Validation Accurancy:  0.9836431667208672\n",
      "Epoch:  611 | Train Accurancy:  0.9482833743095398 | Validation Accurancy:  0.9836538322269917\n",
      "Epoch:  612 | Train Accurancy:  0.9483026303350925 | Validation Accurancy:  0.9836646877229214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  613 | Train Accurancy:  0.948321882635355 | Validation Accurancy:  0.9836756866425276\n",
      "Epoch:  614 | Train Accurancy:  0.9483411647379398 | Validation Accurancy:  0.9836861602962017\n",
      "Epoch:  615 | Train Accurancy:  0.9483603835105896 | Validation Accurancy:  0.9836962539702654\n",
      "Epoch:  616 | Train Accurancy:  0.9483795575797558 | Validation Accurancy:  0.9837064743041992\n",
      "Epoch:  617 | Train Accurancy:  0.9483986124396324 | Validation Accurancy:  0.983716631308198\n",
      "Epoch:  618 | Train Accurancy:  0.9484177492558956 | Validation Accurancy:  0.9837263897061348\n",
      "Epoch:  619 | Train Accurancy:  0.948436688631773 | Validation Accurancy:  0.9837359581142664\n",
      "Epoch:  620 | Train Accurancy:  0.9484557434916496 | Validation Accurancy:  0.9837457649409771\n",
      "Epoch:  621 | Train Accurancy:  0.9484747052192688 | Validation Accurancy:  0.9837550949305296\n",
      "Epoch:  622 | Train Accurancy:  0.9484936520457268 | Validation Accurancy:  0.9837641716003418\n",
      "Epoch:  623 | Train Accurancy:  0.9485125094652176 | Validation Accurancy:  0.9837733581662178\n",
      "Epoch:  624 | Train Accurancy:  0.9485313668847084 | Validation Accurancy:  0.9837824497371912\n",
      "Epoch:  625 | Train Accurancy:  0.9485501609742641 | Validation Accurancy:  0.9837912246584892\n",
      "Epoch:  626 | Train Accurancy:  0.948568943887949 | Validation Accurancy:  0.9837997909635305\n",
      "Epoch:  627 | Train Accurancy:  0.9485877193510532 | Validation Accurancy:  0.9838082622736692\n",
      "Epoch:  628 | Train Accurancy:  0.9486064128577709 | Validation Accurancy:  0.9838166404515505\n",
      "Epoch:  629 | Train Accurancy:  0.9486250020563602 | Validation Accurancy:  0.9838248882442713\n",
      "Epoch:  630 | Train Accurancy:  0.9486436359584332 | Validation Accurancy:  0.9838328044861555\n",
      "Epoch:  631 | Train Accurancy:  0.948662243783474 | Validation Accurancy:  0.983840798959136\n",
      "Epoch:  632 | Train Accurancy:  0.9486808627843857 | Validation Accurancy:  0.9838484600186348\n",
      "Epoch:  633 | Train Accurancy:  0.948699314147234 | Validation Accurancy:  0.9838560428470373\n",
      "Epoch:  634 | Train Accurancy:  0.9487178102135658 | Validation Accurancy:  0.983863640576601\n",
      "Epoch:  635 | Train Accurancy:  0.9487362615764141 | Validation Accurancy:  0.9838709197938442\n",
      "Epoch:  636 | Train Accurancy:  0.9487546645104885 | Validation Accurancy:  0.9838780555874109\n",
      "Epoch:  637 | Train Accurancy:  0.9487730264663696 | Validation Accurancy:  0.9838849063962698\n",
      "Epoch:  638 | Train Accurancy:  0.9487913325428963 | Validation Accurancy:  0.9838919006288052\n",
      "Epoch:  639 | Train Accurancy:  0.948809627443552 | Validation Accurancy:  0.983898688107729\n",
      "Epoch:  640 | Train Accurancy:  0.948827862739563 | Validation Accurancy:  0.9839051887392998\n",
      "Epoch:  641 | Train Accurancy:  0.9488459825515747 | Validation Accurancy:  0.9839115310460329\n",
      "Epoch:  642 | Train Accurancy:  0.9488642141222954 | Validation Accurancy:  0.9839180316776037\n",
      "Epoch:  643 | Train Accurancy:  0.9488824009895325 | Validation Accurancy:  0.9839240871369839\n",
      "Epoch:  644 | Train Accurancy:  0.9489004015922546 | Validation Accurancy:  0.9839301593601704\n",
      "Epoch:  645 | Train Accurancy:  0.9489185698330402 | Validation Accurancy:  0.9839359596371651\n",
      "Epoch:  646 | Train Accurancy:  0.9489364549517632 | Validation Accurancy:  0.9839416667819023\n",
      "Epoch:  647 | Train Accurancy:  0.948954377323389 | Validation Accurancy:  0.983947403728962\n",
      "Epoch:  648 | Train Accurancy:  0.9489724412560463 | Validation Accurancy:  0.9839526806026697\n",
      "Epoch:  649 | Train Accurancy:  0.9489902853965759 | Validation Accurancy:  0.9839580059051514\n",
      "Epoch:  650 | Train Accurancy:  0.9490081146359444 | Validation Accurancy:  0.9839633144438267\n",
      "Epoch:  651 | Train Accurancy:  0.9490260407328606 | Validation Accurancy:  0.9839683212339878\n",
      "Epoch:  652 | Train Accurancy:  0.9490438289940357 | Validation Accurancy:  0.9839732330292463\n",
      "Epoch:  653 | Train Accurancy:  0.9490614607930183 | Validation Accurancy:  0.983977921307087\n",
      "Epoch:  654 | Train Accurancy:  0.9490792155265808 | Validation Accurancy:  0.9839826114475727\n",
      "Epoch:  655 | Train Accurancy:  0.9490968696773052 | Validation Accurancy:  0.9839873947203159\n",
      "Epoch:  656 | Train Accurancy:  0.9491145424544811 | Validation Accurancy:  0.9839916862547398\n",
      "Epoch:  657 | Train Accurancy:  0.9491321593523026 | Validation Accurancy:  0.9839958027005196\n",
      "Epoch:  658 | Train Accurancy:  0.9491497464478016 | Validation Accurancy:  0.9840000793337822\n",
      "Epoch:  659 | Train Accurancy:  0.9491672478616238 | Validation Accurancy:  0.9840040374547243\n",
      "Epoch:  660 | Train Accurancy:  0.9491847530007362 | Validation Accurancy:  0.9840076919645071\n",
      "Epoch:  661 | Train Accurancy:  0.949202224612236 | Validation Accurancy:  0.9840116016566753\n",
      "Epoch:  662 | Train Accurancy:  0.9492194913327694 | Validation Accurancy:  0.9840151779353619\n",
      "Epoch:  663 | Train Accurancy:  0.9492368958890438 | Validation Accurancy:  0.9840185809880495\n",
      "Epoch:  664 | Train Accurancy:  0.9492542631924152 | Validation Accurancy:  0.9840220138430595\n",
      "Epoch:  665 | Train Accurancy:  0.9492716006934643 | Validation Accurancy:  0.9840252883732319\n",
      "Epoch:  666 | Train Accurancy:  0.9492888450622559 | Validation Accurancy:  0.9840283710509539\n",
      "Epoch:  667 | Train Accurancy:  0.9493060447275639 | Validation Accurancy:  0.9840312954038382\n",
      "Epoch:  668 | Train Accurancy:  0.9493232257664204 | Validation Accurancy:  0.9840339813381433\n",
      "Epoch:  669 | Train Accurancy:  0.9493403807282448 | Validation Accurancy:  0.9840367790311575\n",
      "Epoch:  670 | Train Accurancy:  0.9493574872612953 | Validation Accurancy:  0.9840395618230104\n",
      "Epoch:  671 | Train Accurancy:  0.9493745118379593 | Validation Accurancy:  0.9840417858213186\n",
      "Epoch:  672 | Train Accurancy:  0.949391596019268 | Validation Accurancy:  0.9840441234409809\n",
      "Epoch:  673 | Train Accurancy:  0.9494085572659969 | Validation Accurancy:  0.9840465392917395\n",
      "Epoch:  674 | Train Accurancy:  0.9494254924356937 | Validation Accurancy:  0.9840486217290163\n",
      "Epoch:  675 | Train Accurancy:  0.9494423344731331 | Validation Accurancy:  0.9840504638850689\n",
      "Epoch:  676 | Train Accurancy:  0.9494593217968941 | Validation Accurancy:  0.9840524513274431\n",
      "Epoch:  677 | Train Accurancy:  0.9494761079549789 | Validation Accurancy:  0.9840542003512383\n",
      "Epoch:  678 | Train Accurancy:  0.9494928307831287 | Validation Accurancy:  0.9840556308627129\n",
      "Epoch:  679 | Train Accurancy:  0.9495096132159233 | Validation Accurancy:  0.9840571712702513\n",
      "Epoch:  680 | Train Accurancy:  0.9495263174176216 | Validation Accurancy:  0.9840586502104998\n",
      "Epoch:  681 | Train Accurancy:  0.9495429880917072 | Validation Accurancy:  0.984060000628233\n",
      "Epoch:  682 | Train Accurancy:  0.9495597369968891 | Validation Accurancy:  0.9840609394013882\n",
      "Epoch:  683 | Train Accurancy:  0.9495762921869755 | Validation Accurancy:  0.9840620830655098\n",
      "Epoch:  684 | Train Accurancy:  0.9495927691459656 | Validation Accurancy:  0.9840631000697613\n",
      "Epoch:  685 | Train Accurancy:  0.9496093802154064 | Validation Accurancy:  0.9840636253356934\n",
      "Epoch:  686 | Train Accurancy:  0.9496258422732353 | Validation Accurancy:  0.9840644206851721\n",
      "Epoch:  687 | Train Accurancy:  0.9496423713862896 | Validation Accurancy:  0.9840650875121355\n",
      "Epoch:  688 | Train Accurancy:  0.949658703058958 | Validation Accurancy:  0.984065406024456\n",
      "Epoch:  689 | Train Accurancy:  0.9496751055121422 | Validation Accurancy:  0.9840658977627754\n",
      "Epoch:  690 | Train Accurancy:  0.9496914111077785 | Validation Accurancy:  0.9840661361813545\n",
      "Epoch:  691 | Train Accurancy:  0.9497076347470284 | Validation Accurancy:  0.9840661361813545\n",
      "Epoch:  692 | Train Accurancy:  0.9497239217162132 | Validation Accurancy:  0.9840661678463221\n",
      "Epoch:  693 | Train Accurancy:  0.9497401602566242 | Validation Accurancy:  0.9840661846101284\n",
      "Epoch:  694 | Train Accurancy:  0.9497562497854233 | Validation Accurancy:  0.9840659610927105\n"
     ]
    }
   ],
   "source": [
    "# 批训练epoch\n",
    "import torch.utils.data as Data\n",
    "\n",
    "BATCH_SIZE = 5      # 批训练的数据个数\n",
    "\n",
    "# 先转换成 torch 能识别的 Dataset\n",
    "torch_dataset = Data.TensorDataset(x_train_tr, y_train_tr)\n",
    "\n",
    "# 把 dataset 放入 DataLoader\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # 要不要打乱数据 (打乱比较好)\n",
    "    num_workers=2,              # 多线程来读数据\n",
    ")\n",
    "\n",
    "class Net(torch.nn.Module):     # 继承 torch 的 Module\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()     # 继承 __init__ 功能\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # 隐藏层线性输出\n",
    "        self.out = torch.nn.Linear(n_hidden, n_output)       # 输出层线性输出\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 正向传播输入值, 神经网络分析出输出值\n",
    "        x = F.relu(self.hidden(x))      # 激励函数(隐藏层的线性值)\n",
    "        x = self.out(x)                 # 输出值, 但是这个不是预测值, 预测值还需要再另外计算\n",
    "        return x\n",
    "\n",
    "net = Net(n_feature=4, n_hidden=15, n_output=4)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)  # 传入 net 的所有参数, 学习率\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# for epoch in range(100):   # 训练所有!整套!数据 100 次\n",
    "#     for step, (batch_x, batch_y) in enumerate(loader):  # 每一步 loader 释放一小批数据用来学习\n",
    "#         out = net(x_train_tr)\n",
    "#         loss = loss_func(out, y_train_tr)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     out_val = net(x_test_tr)\n",
    "#     loss_val = loss_func(out_val, y_test_tr)\n",
    "#     print('Epoch: ', epoch, '| Train Accurancy: ', 1-float(loss), '| Validation Accurancy: ', 1-float(loss_val))\n",
    "\n",
    "del loss_val_past\n",
    "for epoch in range(100000):   # 训练所有!整套!数据 N 次\n",
    "    out = net(x_train_tr)\n",
    "    loss = loss_func(out, y_train_tr)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    out_val = net(x_test_tr)\n",
    "    loss_val = loss_func(out_val, y_test_tr)\n",
    "    print('Epoch: ', epoch, '| Train Accurancy: ', 1-float(loss), '| Validation Accurancy: ', 1-float(loss_val))\n",
    "    try:\n",
    "        if float(loss_val) > float(loss_val_past):\n",
    "            break\n",
    "        else:\n",
    "            loss_val_past = loss_val\n",
    "    except:\n",
    "        loss_val_past = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器：SGD Momentum RMSprop Adam\n",
    "# SGD(params, lr=0.1, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "# 随机梯度下降法\n",
    "\n",
    "# Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# Adam\n",
    "\n",
    "# RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "# RMSprop\n",
    "\n",
    "# Adadelta(params, lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "# Adadelta\n",
    "\n",
    "# Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "# Adagrad\n",
    "\n",
    "# lr_scheduler.ReduceLROnPlateau(optimizer, mode=’min’, factor=0.1, patience=10, verbose=False, threshold=0.0001, threshold_mode=’rel’, cooldown=0, min_lr=0, eps=1e-08)\n",
    "# 学习率的控制"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \"\"\" 初始化层类型\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" 定义前向传播\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320) # 类似于np.reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \"\"\"\n",
    "\n",
    "# Example of using Sequential\n",
    "model = torch.nn.Sequential(\n",
    "          nn.Conv2d(1,20,5),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(20,64,5),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "\n",
    "# Example of using Sequential with OrderedDict\n",
    "model = torch.nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv2d(1,20,5)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "        ]))\n",
    "        \n",
    "def train(args, model, device, train_loader, optimizer, epoch): # 还可添加loss_func等参数\n",
    "    model.train() # 必备，将模型设置为训练模式\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): # 从数据加载器迭代一个batch的数据\n",
    "        data, target = data.to(device), target.to(device) # 将数据存储CPU或者GPU\n",
    "        optimizer.zero_grad() # 清除所有优化的梯度\n",
    "        output = model(data)  # 喂入数据并前向传播获取输出\n",
    "        loss = F.nll_loss(output, target) # 调用损失函数计算损失\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新参数\n",
    "        if batch_idx % args.log_interval == 0: # 根据设置的显式间隔输出训练日志\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
