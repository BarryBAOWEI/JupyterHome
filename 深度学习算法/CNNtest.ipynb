{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import torch.nn as nn  \n",
    "from torch.autograd import Variable  \n",
    "import torch.utils.data as Data  \n",
    "import torchvision  \n",
    "import time\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)  \n",
    "  \n",
    "EPOCH = 1  \n",
    "BATCH_SIZE = 50  \n",
    "LR = 0.001  \n",
    "DOWNLOAD_MNIST = True\n",
    "if_use_gpu = 1\n",
    "  \n",
    "# 获取训练集dataset  \n",
    "training_data = torchvision.datasets.MNIST(  \n",
    "             root='./mnist/', # dataset存储路径  \n",
    "             train=True, # True表示是train训练集，False表示test测试集  \n",
    "             transform=torchvision.transforms.ToTensor(), # 将原数据规范化到（0,1）区间  \n",
    "             download=DOWNLOAD_MNIST,  \n",
    "             )\n",
    "  \n",
    "# 打印MNIST数据集的训练集及测试集的尺寸  \n",
    "print(training_data.train_data.size())  \n",
    "print(training_data.train_labels.size())  \n",
    "# torch.Size([60000, 28, 28])  \n",
    "# torch.Size([60000])  \n",
    "\n",
    "#plt.imshow(training_data.train_data[0].numpy(), cmap='gray')  \n",
    "#plt.title('%i' % training_data.train_labels[0])  \n",
    "#plt.show()  \n",
    "  \n",
    "# 通过torchvision.datasets获取的dataset格式可直接可置于DataLoader  \n",
    "train_loader = Data.DataLoader(dataset=training_data, batch_size=BATCH_SIZE,  \n",
    "                               shuffle=True)  \n",
    "  \n",
    "# 获取测试集dataset  \n",
    " \n",
    "test_data = torchvision.datasets.MNIST(  \n",
    "             root='./mnist/', # dataset存储路径  \n",
    "             train=False, # True表示是train训练集，False表示test测试集  \n",
    "             transform=torchvision.transforms.ToTensor(), # 将原数据规范化到（0,1）区间  \n",
    "             download=DOWNLOAD_MNIST,  \n",
    "             )  \n",
    "# 取前全部10000个测试集样本  \n",
    "test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1).float(), requires_grad=False)\n",
    "#test_x = test_x.cuda()\n",
    "## (~, 28, 28) to (~, 1, 28, 28), in range(0,1)  \n",
    "test_y = test_data.test_labels\n",
    "#test_y = test_y.cuda()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接抄来的cnn\n",
    "class CNN(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(CNN, self).__init__()  \n",
    "        self.conv1 = nn.Sequential( # (1,28,28)  \n",
    "                     nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5,  \n",
    "                               stride=1, padding=2), # (16,28,28)  \n",
    "        # 想要con2d卷积出来的图片尺寸没有变化, padding=(kernel_size-1)/2  \n",
    "                     nn.ReLU(),  \n",
    "                     nn.MaxPool2d(kernel_size=2) # (16,14,14)  \n",
    "                     )  \n",
    "        self.conv2 = nn.Sequential( # (16,14,14)  \n",
    "                     nn.Conv2d(16, 32, 5, 1, 2), # (32,14,14)  \n",
    "                     nn.ReLU(),  \n",
    "                     nn.MaxPool2d(2) # (32,7,7)  \n",
    "                     )  \n",
    "        self.out = nn.Linear(32*7*7, 10)  \n",
    "  \n",
    "    def forward(self, x):  \n",
    "        x = self.conv1(x)  \n",
    "        x = self.conv2(x)  \n",
    "        x = x.view(x.size(0), -1) # 将（batch，32,7,7）展平为（batch，32*7*7），一个向量\n",
    "        output = self.out(x)  \n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 |Step: 0 |train loss:2.3099\n",
      "Epoch: 0 |Step: 100 |train loss:0.5186\n",
      "Epoch: 0 |Step: 200 |train loss:0.1705\n",
      "Epoch: 0 |Step: 300 |train loss:0.0541\n",
      "Epoch: 0 |Step: 400 |train loss:0.0901\n",
      "Epoch: 0 |Step: 500 |train loss:0.0945\n",
      "Epoch: 0 |Step: 600 |train loss:0.1182\n",
      "Epoch: 0 |Step: 700 |train loss:0.0937\n",
      "Epoch: 0 |Step: 800 |train loss:0.1940\n",
      "Epoch: 0 |Step: 900 |train loss:0.0278\n",
      "Epoch: 0 |Step: 1000 |train loss:0.0342\n",
      "Epoch: 0 |Step: 1100 |train loss:0.1762\n",
      "Training duation: 9.2809\n"
     ]
    }
   ],
   "source": [
    "# 直接抄来的cnn\n",
    "cnn = CNN()  \n",
    "if if_use_gpu:\n",
    "    cnn = cnn.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)  \n",
    "loss_function = nn.CrossEntropyLoss()  \n",
    " \n",
    " \n",
    " \n",
    "for epoch in range(EPOCH):  \n",
    "    start = time.time() \n",
    "    for step, (x, y) in enumerate(train_loader):  \n",
    "        b_x = Variable(x, requires_grad=False) \n",
    "        b_y = Variable(y, requires_grad=False)  \n",
    "        if if_use_gpu:\n",
    "            b_x = b_x.cuda()\n",
    "            b_y = b_y.cuda()\n",
    "  \n",
    "        output = cnn(b_x)  \n",
    "        loss = loss_function(output, b_y)  \n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "  \n",
    "        if step % 100 == 0:  \n",
    "            print('Epoch:', epoch, '|Step:', step,  \n",
    "                  '|train loss:%.4f'%loss)  \n",
    "    duration = time.time() - start \n",
    "    print('Training duation: %.4f'%duration)\n",
    "    \n",
    "cnn = cnn.cpu()\n",
    "test_output = cnn(test_x)  \n",
    "pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "accuracy = sum(pred_y.numpy()==test_y.numpy())/len(test_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自己修改成LeNet-CNN\n",
    "class CNN(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(CNN, self).__init__()  \n",
    "        self.conv1 = nn.Sequential( # (1,28,28)  \n",
    "                      nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2), # (6,28,28)  \n",
    "                      nn.ReLU(),  \n",
    "                      nn.MaxPool2d(kernel_size=2) # (6,14,14)  \n",
    "                      )  \n",
    "        self.conv2 = nn.Sequential( # (6,14,14)  \n",
    "                      nn.Conv2d(6, 16, 5, 1, 0), # (16,10,10)  \n",
    "                      nn.ReLU(),  \n",
    "                      nn.MaxPool2d(2) # (16,5,5)  \n",
    "                     )\n",
    "        self.conv3 = nn.Sequential( # (16,5,5)   \n",
    "                      nn.Conv2d(16, 120, 5, 1, 0), # (120,1,1)  \n",
    "                      nn.ReLU()\n",
    "                     )\n",
    "        \n",
    "        self.fc   = nn.Sequential( # (120,1,1)\n",
    "                      nn.Linear(120*1*1, 84),  # (84,1,1)\n",
    "                      nn.ReLU()\n",
    "                     )\n",
    "        self.out   = nn.Linear(84*1*1, 10)\n",
    "  \n",
    "    def forward(self, x):  \n",
    "        x = self.conv1(x)  \n",
    "        x = self.conv2(x) \n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1) # 将（batch，32,7,7）展平为（batch，32*7*7），一个向量\n",
    "        x = self.fc(x)\n",
    "        output = self.out(x)  \n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 |Step: 0 |train loss:2.3225\n",
      "Epoch: 0 |Step: 100 |train loss:0.4402\n",
      "Epoch: 0 |Step: 200 |train loss:0.2708\n",
      "Epoch: 0 |Step: 300 |train loss:0.1160\n",
      "Epoch: 0 |Step: 400 |train loss:0.2075\n",
      "Epoch: 0 |Step: 500 |train loss:0.1879\n",
      "Epoch: 0 |Step: 600 |train loss:0.1099\n",
      "Epoch: 0 |Step: 700 |train loss:0.1298\n",
      "Epoch: 0 |Step: 800 |train loss:0.0946\n",
      "Epoch: 0 |Step: 900 |train loss:0.1945\n",
      "Epoch: 0 |Step: 1000 |train loss:0.1123\n",
      "Epoch: 0 |Step: 1100 |train loss:0.3685\n",
      "Training duation: 11.3302\n"
     ]
    }
   ],
   "source": [
    "# 自己修改成LeNet-CNN\n",
    "cnn = CNN()  \n",
    "if if_use_gpu:\n",
    "    cnn = cnn.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)  \n",
    "loss_function = nn.CrossEntropyLoss()  \n",
    "\n",
    "for epoch in range(EPOCH):  \n",
    "    start = time.time() \n",
    "    for step, (x, y) in enumerate(train_loader):  \n",
    "        b_x = Variable(x, requires_grad=False) \n",
    "        b_y = Variable(y, requires_grad=False)  \n",
    "        if if_use_gpu:\n",
    "            b_x = b_x.cuda()\n",
    "            b_y = b_y.cuda()\n",
    "  \n",
    "        output = cnn(b_x)  \n",
    "        loss = loss_function(output, b_y)  \n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "  \n",
    "        if step % 100 == 0:  \n",
    "            print('Epoch:', epoch, '|Step:', step,  \n",
    "                  '|train loss:%.4f'%loss)\n",
    "    duration = time.time() - start \n",
    "    print('Training duation: %.4f'%duration)\n",
    "    \n",
    "cnn = cnn.cpu()\n",
    "test_output = cnn(test_x)  \n",
    "pred_y = torch.max(test_output, 1)[1].data.squeeze() \n",
    "# torch.max(D, 0or1) axis=0，返回D中每列的最大值及其行索引；axis=1，返回D中每行的最大值及其列索引\n",
    "accuracy = sum(pred_y.numpy()==test_y.numpy())/len(test_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set : torch.Size([60000, 28, 28])\n",
      "test set : torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "import torchvision.datasets.mnist as mnist\n",
    "\n",
    "root=\"C:/Users/jxjsj/Desktop/JupyterHome/Data/fashion/\"\n",
    "train_set = (\n",
    "    mnist.read_image_file(os.path.join(root, 'train-images-idx3-ubyte')),\n",
    "    mnist.read_label_file(os.path.join(root, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "test_set = (\n",
    "    mnist.read_image_file(os.path.join(root, 't10k-images-idx3-ubyte')),\n",
    "    mnist.read_label_file(os.path.join(root, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "print(\"training set :\",train_set[0].size())\n",
    "print(\"test set :\",test_set[0].size())\n",
    "\n",
    "def convert_to_img(train=True):\n",
    "    if(train):\n",
    "        f=open(root+'train.txt','w')\n",
    "        data_path=root+'/train/'\n",
    "        if(not os.path.exists(data_path)):\n",
    "            os.makedirs(data_path)\n",
    "        for i, (img,label) in enumerate(zip(train_set[0],train_set[1])):\n",
    "            img_path=data_path+str(i)+'.jpg'\n",
    "            io.imsave(img_path,img.numpy())\n",
    "            f.write(img_path+' '+str(label)+'\\n')\n",
    "        f.close()\n",
    "    else:\n",
    "        f = open(root + 'test.txt', 'w')\n",
    "        data_path = root + '/test/'\n",
    "        if (not os.path.exists(data_path)):\n",
    "            os.makedirs(data_path)\n",
    "        for i, (img,label) in enumerate(zip(test_set[0],test_set[1])):\n",
    "            img_path = data_path+ str(i) + '.jpg'\n",
    "            io.imsave(img_path, img.numpy())\n",
    "            f.write(img_path + ' ' + str(label) + '\\n')\n",
    "        f.close()\n",
    "\n",
    "convert_to_img(True)\n",
    "convert_to_img(False)\n",
    "\n",
    "# 这样就会在e:/fashion_mnist/目录下分别生成train和test文件夹，用于存放图片。还在该目录下生成了标签文件train.txt和test.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二、进行CNN分类训练和测试\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, transform=None, target_transform=None, loader=default_loader):\n",
    "        fh = open(txt, 'r')\n",
    "        imgs = []\n",
    "        for line in fh:\n",
    "            line = line.strip('\\n')\n",
    "            line = line.rstrip()\n",
    "            words = line.split()\n",
    "            imgs.append((words[0],int(words[1][7]))) # 看情况修改\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        img = self.loader(fn)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'C:/Users/jxjsj/Desktop/JupyterHome/Data/fashion/'\n",
    "train_data = MyDataset(txt=root+'train.txt', transform=transforms.ToTensor())\n",
    "train_data_loader = DataLoader(train_data, batch_size=200,shuffle=True)\n",
    "test_data = MyDataset(txt=root+'test.txt', transform=transforms.ToTensor())\n",
    "test_data_loader = DataLoader(test_data, batch_size=test_data.__len__(),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------create the Net and training------------------------\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, 3, 1, 1), #32 28 28\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2)) #32 14 14\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, 3, 1, 1), #64 14 14\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2) #64 7 7\n",
    "        )\n",
    "        self.conv3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 64, 3, 1, 1), #64 7 7\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2) #64 3 3 除法是floor除，取整数部分\n",
    "        )\n",
    "        self.dense = torch.nn.Sequential(\n",
    "            torch.nn.Linear(64 * 3 * 3, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv2_out = self.conv2(conv1_out)\n",
    "        conv3_out = self.conv3(conv2_out)\n",
    "        res = conv3_out.view(conv3_out.size(0), -1)\n",
    "        out = self.dense(res)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Step: 0 Finished!\n",
      "Step: 1 Finished!\n",
      "Step: 2 Finished!\n",
      "Step: 3 Finished!\n",
      "Step: 4 Finished!\n",
      "Step: 5 Finished!\n",
      "Step: 6 Finished!\n",
      "Step: 7 Finished!\n",
      "Step: 8 Finished!\n",
      "Step: 9 Finished!\n",
      "Step: 10 Finished!\n",
      "Step: 11 Finished!\n",
      "Step: 12 Finished!\n",
      "Step: 13 Finished!\n",
      "Step: 14 Finished!\n",
      "Step: 15 Finished!\n",
      "Step: 16 Finished!\n",
      "Step: 17 Finished!\n",
      "Step: 18 Finished!\n",
      "Step: 19 Finished!\n",
      "Step: 20 Finished!\n",
      "Step: 21 Finished!\n",
      "Step: 22 Finished!\n",
      "Step: 23 Finished!\n",
      "Step: 24 Finished!\n",
      "Step: 25 Finished!\n",
      "Step: 26 Finished!\n",
      "Step: 27 Finished!\n",
      "Step: 28 Finished!\n",
      "Step: 29 Finished!\n",
      "Step: 30 Finished!\n",
      "Step: 31 Finished!\n",
      "Step: 32 Finished!\n",
      "Step: 33 Finished!\n",
      "Step: 34 Finished!\n",
      "Step: 35 Finished!\n",
      "Step: 36 Finished!\n",
      "Step: 37 Finished!\n",
      "Step: 38 Finished!\n",
      "Step: 39 Finished!\n",
      "Step: 40 Finished!\n",
      "Step: 41 Finished!\n",
      "Step: 42 Finished!\n",
      "Step: 43 Finished!\n",
      "Step: 44 Finished!\n",
      "Step: 45 Finished!\n",
      "Step: 46 Finished!\n",
      "Step: 47 Finished!\n",
      "Step: 48 Finished!\n",
      "Step: 49 Finished!\n",
      "Step: 50 Finished!\n",
      "Step: 51 Finished!\n",
      "Step: 52 Finished!\n",
      "Step: 53 Finished!\n",
      "Step: 54 Finished!\n",
      "Step: 55 Finished!\n",
      "Step: 56 Finished!\n",
      "Step: 57 Finished!\n",
      "Step: 58 Finished!\n",
      "Step: 59 Finished!\n",
      "Step: 60 Finished!\n",
      "Step: 61 Finished!\n",
      "Step: 62 Finished!\n",
      "Step: 63 Finished!\n",
      "Step: 64 Finished!\n",
      "Step: 65 Finished!\n",
      "Step: 66 Finished!\n",
      "Step: 67 Finished!\n",
      "Step: 68 Finished!\n",
      "Step: 69 Finished!\n",
      "Step: 70 Finished!\n",
      "Step: 71 Finished!\n",
      "Step: 72 Finished!\n",
      "Step: 73 Finished!\n",
      "Step: 74 Finished!\n",
      "Step: 75 Finished!\n",
      "Step: 76 Finished!\n",
      "Step: 77 Finished!\n",
      "Step: 78 Finished!\n",
      "Step: 79 Finished!\n",
      "Step: 80 Finished!\n",
      "Step: 81 Finished!\n",
      "Step: 82 Finished!\n",
      "Step: 83 Finished!\n",
      "Step: 84 Finished!\n",
      "Step: 85 Finished!\n",
      "Step: 86 Finished!\n",
      "Step: 87 Finished!\n",
      "Step: 88 Finished!\n",
      "Step: 89 Finished!\n",
      "Step: 90 Finished!\n",
      "Step: 91 Finished!\n",
      "Step: 92 Finished!\n",
      "Step: 93 Finished!\n",
      "Step: 94 Finished!\n",
      "Step: 95 Finished!\n",
      "Step: 96 Finished!\n",
      "Step: 97 Finished!\n",
      "Step: 98 Finished!\n",
      "Step: 99 Finished!\n",
      "Step: 100 Finished!\n",
      "Step: 101 Finished!\n",
      "Step: 102 Finished!\n",
      "Step: 103 Finished!\n",
      "Step: 104 Finished!\n",
      "Step: 105 Finished!\n",
      "Step: 106 Finished!\n",
      "Step: 107 Finished!\n",
      "Step: 108 Finished!\n",
      "Step: 109 Finished!\n",
      "Step: 110 Finished!\n",
      "Step: 111 Finished!\n",
      "Step: 112 Finished!\n",
      "Step: 113 Finished!\n",
      "Step: 114 Finished!\n",
      "Step: 115 Finished!\n",
      "Step: 116 Finished!\n",
      "Step: 117 Finished!\n",
      "Step: 118 Finished!\n",
      "Step: 119 Finished!\n",
      "Step: 120 Finished!\n",
      "Step: 121 Finished!\n",
      "Step: 122 Finished!\n",
      "Step: 123 Finished!\n",
      "Step: 124 Finished!\n",
      "Step: 125 Finished!\n",
      "Step: 126 Finished!\n",
      "Step: 127 Finished!\n",
      "Step: 128 Finished!\n",
      "Step: 129 Finished!\n",
      "Step: 130 Finished!\n",
      "Step: 131 Finished!\n",
      "Step: 132 Finished!\n",
      "Step: 133 Finished!\n",
      "Step: 134 Finished!\n",
      "Step: 135 Finished!\n",
      "Step: 136 Finished!\n",
      "Step: 137 Finished!\n",
      "Step: 138 Finished!\n",
      "Step: 139 Finished!\n",
      "Step: 140 Finished!\n",
      "Step: 141 Finished!\n",
      "Step: 142 Finished!\n",
      "Step: 143 Finished!\n",
      "Step: 144 Finished!\n",
      "Step: 145 Finished!\n",
      "Step: 146 Finished!\n",
      "Step: 147 Finished!\n",
      "Step: 148 Finished!\n",
      "Step: 149 Finished!\n",
      "Step: 150 Finished!\n",
      "Step: 151 Finished!\n",
      "Step: 152 Finished!\n",
      "Step: 153 Finished!\n",
      "Step: 154 Finished!\n",
      "Step: 155 Finished!\n",
      "Step: 156 Finished!\n",
      "Step: 157 Finished!\n",
      "Step: 158 Finished!\n",
      "Step: 159 Finished!\n",
      "Step: 160 Finished!\n",
      "Step: 161 Finished!\n",
      "Step: 162 Finished!\n",
      "Step: 163 Finished!\n",
      "Step: 164 Finished!\n",
      "Step: 165 Finished!\n",
      "Step: 166 Finished!\n",
      "Step: 167 Finished!\n",
      "Step: 168 Finished!\n",
      "Step: 169 Finished!\n",
      "Step: 170 Finished!\n",
      "Step: 171 Finished!\n",
      "Step: 172 Finished!\n",
      "Step: 173 Finished!\n",
      "Step: 174 Finished!\n",
      "Step: 175 Finished!\n",
      "Step: 176 Finished!\n",
      "Step: 177 Finished!\n",
      "Step: 178 Finished!\n",
      "Step: 179 Finished!\n",
      "Step: 180 Finished!\n",
      "Step: 181 Finished!\n",
      "Step: 182 Finished!\n",
      "Step: 183 Finished!\n",
      "Step: 184 Finished!\n",
      "Step: 185 Finished!\n",
      "Step: 186 Finished!\n",
      "Step: 187 Finished!\n",
      "Step: 188 Finished!\n",
      "Step: 189 Finished!\n",
      "Step: 190 Finished!\n",
      "Step: 191 Finished!\n",
      "Step: 192 Finished!\n",
      "Step: 193 Finished!\n",
      "Step: 194 Finished!\n",
      "Step: 195 Finished!\n",
      "Step: 196 Finished!\n",
      "Step: 197 Finished!\n",
      "Step: 198 Finished!\n",
      "Step: 199 Finished!\n",
      "Step: 200 Finished!\n",
      "Step: 201 Finished!\n",
      "Step: 202 Finished!\n",
      "Step: 203 Finished!\n",
      "Step: 204 Finished!\n",
      "Step: 205 Finished!\n",
      "Step: 206 Finished!\n",
      "Step: 207 Finished!\n",
      "Step: 208 Finished!\n",
      "Step: 209 Finished!\n",
      "Step: 210 Finished!\n",
      "Step: 211 Finished!\n",
      "Step: 212 Finished!\n",
      "Step: 213 Finished!\n",
      "Step: 214 Finished!\n",
      "Step: 215 Finished!\n",
      "Step: 216 Finished!\n",
      "Step: 217 Finished!\n",
      "Step: 218 Finished!\n",
      "Step: 219 Finished!\n",
      "Step: 220 Finished!\n",
      "Step: 221 Finished!\n",
      "Step: 222 Finished!\n",
      "Step: 223 Finished!\n",
      "Step: 224 Finished!\n",
      "Step: 225 Finished!\n",
      "Step: 226 Finished!\n",
      "Step: 227 Finished!\n",
      "Step: 228 Finished!\n",
      "Step: 229 Finished!\n",
      "Step: 230 Finished!\n",
      "Step: 231 Finished!\n",
      "Step: 232 Finished!\n",
      "Step: 233 Finished!\n",
      "Step: 234 Finished!\n",
      "Step: 235 Finished!\n",
      "Step: 236 Finished!\n",
      "Step: 237 Finished!\n",
      "Step: 238 Finished!\n",
      "Step: 239 Finished!\n",
      "Step: 240 Finished!\n",
      "Step: 241 Finished!\n",
      "Step: 242 Finished!\n",
      "Step: 243 Finished!\n",
      "Step: 244 Finished!\n",
      "Step: 245 Finished!\n",
      "Step: 246 Finished!\n",
      "Step: 247 Finished!\n",
      "Step: 248 Finished!\n",
      "Step: 249 Finished!\n",
      "Step: 250 Finished!\n",
      "Step: 251 Finished!\n",
      "Step: 252 Finished!\n",
      "Step: 253 Finished!\n",
      "Step: 254 Finished!\n",
      "Step: 255 Finished!\n",
      "Step: 256 Finished!\n",
      "Step: 257 Finished!\n",
      "Step: 258 Finished!\n",
      "Step: 259 Finished!\n",
      "Step: 260 Finished!\n",
      "Step: 261 Finished!\n",
      "Step: 262 Finished!\n",
      "Step: 263 Finished!\n",
      "Step: 264 Finished!\n",
      "Step: 265 Finished!\n",
      "Step: 266 Finished!\n",
      "Step: 267 Finished!\n",
      "Step: 268 Finished!\n",
      "Step: 269 Finished!\n",
      "Step: 270 Finished!\n",
      "Step: 271 Finished!\n",
      "Step: 272 Finished!\n",
      "Step: 273 Finished!\n",
      "Step: 274 Finished!\n",
      "Step: 275 Finished!\n",
      "Step: 276 Finished!\n",
      "Step: 277 Finished!\n",
      "Step: 278 Finished!\n",
      "Step: 279 Finished!\n",
      "Step: 280 Finished!\n",
      "Step: 281 Finished!\n",
      "Step: 282 Finished!\n",
      "Step: 283 Finished!\n",
      "Step: 284 Finished!\n",
      "Step: 285 Finished!\n",
      "Step: 286 Finished!\n",
      "Step: 287 Finished!\n",
      "Step: 288 Finished!\n",
      "Step: 289 Finished!\n",
      "Step: 290 Finished!\n",
      "Step: 291 Finished!\n",
      "Step: 292 Finished!\n",
      "Step: 293 Finished!\n",
      "Step: 294 Finished!\n",
      "Step: 295 Finished!\n",
      "Step: 296 Finished!\n",
      "Step: 297 Finished!\n",
      "Step: 298 Finished!\n",
      "Step: 299 Finished!\n",
      "Acc: 0.760583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-eba8cb4f6d48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-115-66ad810b1c7e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mconv1_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mconv2_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mconv3_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv2_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mthreshold\u001b[1;34m(input, threshold, value, inplace)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(2):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    # training-----------------------------\n",
    "    train_acc = 0.\n",
    "    for step, (batch_x, batch_y) in enumerate(train_data_loader):\n",
    "        batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        num_correct = (pred == batch_y).sum()\n",
    "        train_acc += num_correct.data.item()\n",
    "        print('Step:',step+1,'Finished!')\n",
    "    print('Acc: {:.6f}'.format(train_acc / (len(train_data))))\n",
    "\n",
    "    # evaluation--------------------------------\n",
    "    model.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    for batch_x, batch_y in test_data_loader:\n",
    "        batch_x, batch_y = Variable(batch_x, volatile=True), Variable(batch_y, volatile=True)\n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        num_correct = (pred == batch_y).sum()\n",
    "        eval_acc += num_correct.data.item()\n",
    "    print('Acc: {:.6f}'.format(eval_acc / (len(test_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
