{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB,ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 自行构造的聚类数据\n",
    "X, y = make_blobs(n_samples=20000, n_features=10, centers=100,\n",
    "    random_state=0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=1, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据wine_quality\n",
    "path = u'C:/Users/jxjsj/Desktop/JupyterHome/Data/winequality-white-test.csv'\n",
    "dataSet = pd.read_csv(path, header = 0)\n",
    "x_temp, y_temp = np.split(dataSet, (11,), axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_temp, y_temp, random_state=1, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据iris数据集\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=1, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据carEvaluation数据集\n",
    "path = u'C:/Users/jxjsj/Desktop/JupyterHome/Data/carEvaluation.txt'\n",
    "dataSet = pd.read_csv(path, header = None)\n",
    "x_temp, y_temp = np.split(dataSet, (6,), axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_temp, y_temp, random_state=1, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0=high',\n",
       " '0=low',\n",
       " '0=med',\n",
       " '0=vhigh',\n",
       " '1=high',\n",
       " '1=low',\n",
       " '1=med',\n",
       " '1=vhigh',\n",
       " '2=2',\n",
       " '2=3',\n",
       " '2=4',\n",
       " '2=5more',\n",
       " '3=2',\n",
       " '3=4',\n",
       " '3=more',\n",
       " '4=big',\n",
       " '4=med',\n",
       " '4=small',\n",
       " '5=high',\n",
       " '5=low',\n",
       " '5=med']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 属性变量编码\n",
    "vec = DictVectorizer(sparse=False)\n",
    "x_train = vec.fit_transform(x_train.to_dict(orient='record'))   #对训练数据的特征进行提取\n",
    "x_test = vec.transform(x_test.to_dict(orient='record'))         #对测试数据的特征进行提取\n",
    "vec.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       1.00      1.00      1.00        18\n",
      "         4.0       1.00      1.00      1.00       134\n",
      "         5.0       1.00      1.00      1.00      1164\n",
      "         6.0       1.00      1.00      1.00      1763\n",
      "         7.0       1.00      1.00      1.00       696\n",
      "         8.0       1.00      1.00      1.00       138\n",
      "         9.0       1.00      1.00      1.00         5\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      3918\n",
      "   macro avg       1.00      1.00      1.00      3918\n",
      "weighted avg       1.00      1.00      1.00      3918\n",
      "\n",
      "testAccracy: 0.5979591836734693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         4.0       0.07      0.07      0.07        29\n",
      "         5.0       0.63      0.57      0.60       293\n",
      "         6.0       0.64      0.67      0.66       435\n",
      "         7.0       0.56      0.59      0.58       184\n",
      "         8.0       0.47      0.46      0.47        37\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       980\n",
      "   macro avg       0.34      0.34      0.34       980\n",
      "weighted avg       0.60      0.60      0.60       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# 训练决策树\n",
    "blobEvaluation = DecisionTreeClassifier(class_weight = \"balanced\",\n",
    "                                        criterion='entropy')\n",
    "blobEvaluation = blobEvaluation.fit(x_train, y_train)\n",
    "y_train_predict = blobEvaluation.predict(x_train)\n",
    "y_test_predict = blobEvaluation.predict(x_test)\n",
    "print('trainAccracy:',blobEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict))\n",
    "print('testAccracy:',blobEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 0.9977029096477795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       1.00      1.00      1.00        18\n",
      "         4.0       1.00      0.99      0.99       134\n",
      "         5.0       1.00      1.00      1.00      1164\n",
      "         6.0       1.00      1.00      1.00      1763\n",
      "         7.0       1.00      1.00      1.00       696\n",
      "         8.0       1.00      0.99      0.99       138\n",
      "         9.0       1.00      1.00      1.00         5\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      3918\n",
      "   macro avg       1.00      1.00      1.00      3918\n",
      "weighted avg       1.00      1.00      1.00      3918\n",
      "\n",
      "testAccracy: 0.6602040816326531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         4.0       0.45      0.17      0.25        29\n",
      "         5.0       0.71      0.65      0.68       293\n",
      "         6.0       0.63      0.77      0.69       435\n",
      "         7.0       0.68      0.57      0.62       184\n",
      "         8.0       0.74      0.38      0.50        37\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       980\n",
      "   macro avg       0.46      0.36      0.39       980\n",
      "weighted avg       0.66      0.66      0.65       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# 训练随机森林，子属性集属性个数 log2底d，d为特征数\n",
    "blobEvaluation = RandomForestClassifier(n_estimators=20, \n",
    "                                        max_depth=None,\n",
    "                                        criterion='entropy',\n",
    "                                        max_features=0.9,\n",
    "                                        class_weight = \"balanced\")\n",
    "blobEvaluation.fit(x_train, y_train)\n",
    "y_train_predict = blobEvaluation.predict(x_train)\n",
    "y_test_predict = blobEvaluation.predict(x_test)\n",
    "print('trainAccracy:',blobEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict))\n",
    "print('testAccracy:',blobEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:618: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 0.9948953547728433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       1.00      0.94      0.97        18\n",
      "         4.0       1.00      0.97      0.98       134\n",
      "         5.0       0.99      1.00      1.00      1164\n",
      "         6.0       0.99      1.00      1.00      1763\n",
      "         7.0       1.00      0.99      0.99       696\n",
      "         8.0       1.00      0.98      0.99       138\n",
      "         9.0       1.00      1.00      1.00         5\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3918\n",
      "   macro avg       1.00      0.98      0.99      3918\n",
      "weighted avg       0.99      0.99      0.99      3918\n",
      "\n",
      "testAccracy: 0.6602040816326531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         4.0       0.58      0.24      0.34        29\n",
      "         5.0       0.69      0.65      0.67       293\n",
      "         6.0       0.64      0.77      0.70       435\n",
      "         7.0       0.65      0.55      0.60       184\n",
      "         8.0       0.88      0.38      0.53        37\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       980\n",
      "   macro avg       0.57      0.43      0.47       980\n",
      "weighted avg       0.66      0.66      0.65       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# 训练bagging，基学习器为决策树\n",
    "blobEvaluation = BaggingClassifier( base_estimator=DecisionTreeClassifier(class_weight = \"balanced\",\n",
    "                                                                          criterion='entropy'), \n",
    "                                    n_estimators=15, \n",
    "                                    max_samples=0.9, \n",
    "                                    max_features=0.9, \n",
    "                                    bootstrap=True, \n",
    "                                    bootstrap_features=False, \n",
    "                                    oob_score=False, \n",
    "                                    warm_start=False, \n",
    "                                    n_jobs=None, \n",
    "                                    random_state=1, \n",
    "                                    verbose=0)\n",
    "blobEvaluation.fit(x_train, y_train)\n",
    "y_train_predict = blobEvaluation.predict(x_train)\n",
    "y_test_predict = blobEvaluation.predict(x_test)\n",
    "print('trainAccracy:',blobEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict))\n",
    "print('testAccracy:',blobEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "总结1 2018.11.18\n",
    "集成学习中，基于非平衡数据：\n",
    "1.决策树相较于随机森林（均添加类别权重,RF:n=26,max_f=log2）而言：泛化能力较高，对不均衡类的查准率较高；\n",
    "2.决策树相较于以决策树为基学习器的Bagging（均添加类别权重,Baggiing:n=46,max_samples=0.9,max_features=0.9）而言：泛化能力略低，整体相近。\n",
    "\n",
    "总结 2018.11.19\n",
    "随机森林与Bagging决策树对于较难学习的模型-wine相较于单一决策树泛化精确度更高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:618: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 0.5209290454313426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00        18\n",
      "         4.0       0.00      0.00      0.00       134\n",
      "         5.0       0.58      0.44      0.50      1164\n",
      "         6.0       0.50      0.87      0.64      1763\n",
      "         7.0       0.00      0.00      0.00       696\n",
      "         8.0       0.00      0.00      0.00       138\n",
      "         9.0       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      3918\n",
      "   macro avg       0.15      0.19      0.16      3918\n",
      "weighted avg       0.40      0.52      0.44      3918\n",
      "\n",
      "testAccracy: 0.47551020408163264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         4.0       0.00      0.00      0.00        29\n",
      "         5.0       0.51      0.38      0.43       293\n",
      "         6.0       0.47      0.82      0.59       435\n",
      "         7.0       0.00      0.00      0.00       184\n",
      "         8.0       0.00      0.00      0.00        37\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       980\n",
      "   macro avg       0.16      0.20      0.17       980\n",
      "weighted avg       0.36      0.48      0.39       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# 训练bagging，基学习器为神经网络\n",
    "blobEvaluation = BaggingClassifier( MLPClassifier(activation='tanh', \n",
    "                                                  solver='lbfgs',\n",
    "                                                  alpha=1e-5,\n",
    "                                                  hidden_layer_sizes=(20,),\n",
    "                                                  random_state=1),\n",
    "                                    n_estimators=15, \n",
    "                                    max_samples=0.8, \n",
    "                                    max_features=0.8, \n",
    "                                    bootstrap=True, \n",
    "                                    bootstrap_features=False, \n",
    "                                    oob_score=False, \n",
    "                                    warm_start=False, \n",
    "                                    n_jobs=None, \n",
    "                                    random_state=None, \n",
    "                                    verbose=0)\n",
    "\n",
    "blobEvaluation.fit(x_train, y_train)\n",
    "y_train_predict = blobEvaluation.predict(x_train)\n",
    "y_test_predict = blobEvaluation.predict(x_test)\n",
    "print('trainAccracy:',blobEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict))\n",
    "print('testAccracy:',blobEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:618: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 0.4609494640122512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.38      0.33      0.35        18\n",
      "         4.0       0.27      0.24      0.25       134\n",
      "         5.0       0.52      0.55      0.53      1164\n",
      "         6.0       0.54      0.37      0.44      1763\n",
      "         7.0       0.35      0.65      0.46       696\n",
      "         8.0       0.27      0.06      0.10       138\n",
      "         9.0       1.00      0.60      0.75         5\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      3918\n",
      "   macro avg       0.47      0.40      0.41      3918\n",
      "weighted avg       0.48      0.46      0.45      3918\n",
      "\n",
      "testAccracy: 0.44387755102040816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         4.0       0.20      0.21      0.20        29\n",
      "         5.0       0.48      0.50      0.49       293\n",
      "         6.0       0.49      0.35      0.41       435\n",
      "         7.0       0.39      0.70      0.50       184\n",
      "         8.0       0.22      0.05      0.09        37\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       980\n",
      "   macro avg       0.30      0.30      0.28       980\n",
      "weighted avg       0.45      0.44      0.43       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练bagging，基学习器为朴素贝叶斯分类器\n",
    "blobEvaluation = BaggingClassifier( GaussianNB(),\n",
    "                                    n_estimators=9, \n",
    "                                    max_samples=0.9, \n",
    "                                    max_features=1.0, \n",
    "                                    bootstrap=True, \n",
    "                                    bootstrap_features=False, \n",
    "                                    oob_score=False, \n",
    "                                    warm_start=False, \n",
    "                                    n_jobs=None, \n",
    "                                    random_state=1, \n",
    "                                    verbose=0)\n",
    "\n",
    "blobEvaluation.fit(x_train, y_train)\n",
    "y_train_predict = blobEvaluation.predict(x_train)\n",
    "y_test_predict = blobEvaluation.predict(x_test)\n",
    "print('trainAccracy:',blobEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict))\n",
    "print('testAccracy:',blobEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "总结2 2018.11.18\n",
    "使用Bagging时，基于非平衡数据，无论使用决策树还是神经网络作为基学习器效果都非常差——只会预测为一类；\n",
    "上述两种集成学习中将最大样本与最大特征参数修改为0.9——增强了基学习器属性和输入多样性（那么降低了集成学习的总误差），则均能极大改善训练结果，神经网络的Bagging集成效果优于单一神经网络。\n",
    "\n",
    "总结 2018.11.19\n",
    "带有较强主观性的非平衡数据（评分数据），决策树分类效果更佳，集成决策树好于单一决策树，AdaBoost提升效果较小，Bagging决策树和随机森林提升较多；神经网络难以训练以预测较少的非平衡类，训练与泛化准确率都较低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 0.49132210311383356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00        18\n",
      "         4.0       0.00      0.00      0.00       134\n",
      "         5.0       0.49      0.54      0.51      1164\n",
      "         6.0       0.49      0.73      0.59      1763\n",
      "         7.0       0.00      0.00      0.00       696\n",
      "         8.0       0.00      0.00      0.00       138\n",
      "         9.0       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      3918\n",
      "   macro avg       0.14      0.18      0.16      3918\n",
      "weighted avg       0.37      0.49      0.42      3918\n",
      "\n",
      "testAccracy: 0.47551020408163264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         4.0       0.00      0.00      0.00        29\n",
      "         5.0       0.48      0.52      0.50       293\n",
      "         6.0       0.47      0.72      0.57       435\n",
      "         7.0       0.00      0.00      0.00       184\n",
      "         8.0       0.00      0.00      0.00        37\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       980\n",
      "   macro avg       0.16      0.21      0.18       980\n",
      "weighted avg       0.35      0.48      0.40       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# 训练MLP神经网络\n",
    "blobEvaluation = MLPClassifier(activation='tanh', \n",
    "                               solver='lbfgs',\n",
    "                               alpha=1e-5,\n",
    "                               hidden_layer_sizes=(len(x_train.columns)*2+1,))\n",
    "blobEvaluation.fit(x_train, y_train)\n",
    "y_train_predict = blobEvaluation.predict(x_train)\n",
    "y_test_predict = blobEvaluation.predict(x_test)\n",
    "print('trainAccracy:',blobEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict))\n",
    "print('testAccracy:',blobEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       1.00      1.00      1.00        18\n",
      "         4.0       1.00      1.00      1.00       134\n",
      "         5.0       1.00      1.00      1.00      1164\n",
      "         6.0       1.00      1.00      1.00      1763\n",
      "         7.0       1.00      1.00      1.00       696\n",
      "         8.0       1.00      1.00      1.00       138\n",
      "         9.0       1.00      1.00      1.00         5\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      3918\n",
      "   macro avg       1.00      1.00      1.00      3918\n",
      "weighted avg       1.00      1.00      1.00      3918\n",
      "\n",
      "testAccracy: 0.6112244897959184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         4.0       0.35      0.24      0.29        29\n",
      "         5.0       0.68      0.59      0.63       293\n",
      "         6.0       0.64      0.69      0.67       435\n",
      "         7.0       0.53      0.57      0.55       184\n",
      "         8.0       0.42      0.41      0.41        37\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       980\n",
      "   macro avg       0.44      0.42      0.42       980\n",
      "weighted avg       0.61      0.61      0.61       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 训练AdaBoost，基学习器为决策树\n",
    "blobEvaluation = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(class_weight = \"balanced\",\n",
    "                                                                          criterion='entropy',max_features='log2'), \n",
    "                                    n_estimators=15, \n",
    "                                    learning_rate=1,\n",
    "                                    algorithm='SAMME',\n",
    "                                    random_state=1)\n",
    "blobEvaluation.fit(x_train, y_train)\n",
    "y_train_predict = blobEvaluation.predict(x_train)\n",
    "y_test_predict = blobEvaluation.predict(x_test)\n",
    "print('trainAccracy:',blobEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict))\n",
    "print('testAccracy:',blobEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "总结3 2018.11.19\n",
    "运用AdaBoost算法，基学习器为决策树（最大划分选用特征小于100%），训练速度快，相较于单一决策树测试准确率上升（成功识别少类标签），且在CarEvaluation数据集上调参影响较小，除了决策树的最大划分选用特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 0.461204696273609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.29      0.33      0.31        18\n",
      "         4.0       0.27      0.25      0.26       134\n",
      "         5.0       0.52      0.56      0.54      1164\n",
      "         6.0       0.54      0.37      0.44      1763\n",
      "         7.0       0.35      0.66      0.46       696\n",
      "         8.0       0.30      0.04      0.08       138\n",
      "         9.0       0.50      0.20      0.29         5\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      3918\n",
      "   macro avg       0.40      0.34      0.34      3918\n",
      "weighted avg       0.48      0.46      0.45      3918\n",
      "\n",
      "testAccracy: 0.44387755102040816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         4.0       0.20      0.21      0.20        29\n",
      "         5.0       0.49      0.51      0.50       293\n",
      "         6.0       0.49      0.34      0.40       435\n",
      "         7.0       0.39      0.71      0.50       184\n",
      "         8.0       0.17      0.03      0.05        37\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       980\n",
      "   macro avg       0.29      0.30      0.28       980\n",
      "weighted avg       0.45      0.44      0.43       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 训练朴素贝叶斯分类器\n",
    "blobEvaluation = GaussianNB()\n",
    "blobEvaluation.fit(x_train, y_train)\n",
    "y_train_predict = blobEvaluation.predict(x_train)\n",
    "y_test_predict = blobEvaluation.predict(x_test)\n",
    "print('trainAccracy:',blobEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict))\n",
    "print('testAccracy:',blobEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainAccracy: 0.4719244512506381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.38      0.33      0.35        18\n",
      "         4.0       0.30      0.22      0.25       134\n",
      "         5.0       0.54      0.55      0.55      1164\n",
      "         6.0       0.51      0.50      0.51      1763\n",
      "         7.0       0.35      0.39      0.37       696\n",
      "         8.0       0.11      0.08      0.09       138\n",
      "         9.0       0.10      0.20      0.13         5\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      3918\n",
      "   macro avg       0.33      0.32      0.32      3918\n",
      "weighted avg       0.47      0.47      0.47      3918\n",
      "\n",
      "testAccracy: 0.48673469387755103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         4.0       0.33      0.24      0.28        29\n",
      "         5.0       0.53      0.54      0.53       293\n",
      "         6.0       0.52      0.52      0.52       435\n",
      "         7.0       0.43      0.43      0.43       184\n",
      "         8.0       0.18      0.19      0.19        37\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       980\n",
      "   macro avg       0.28      0.27      0.28       980\n",
      "weighted avg       0.49      0.49      0.49       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# 训练AdaBoost，基学习器为朴素贝叶斯分类器\n",
    "blobEvaluation = AdaBoostClassifier(base_estimator=GaussianNB(), \n",
    "                                    n_estimators=7, \n",
    "                                    learning_rate=0.7,\n",
    "                                    algorithm='SAMME',\n",
    "                                    random_state=1)\n",
    "blobEvaluation.fit(x_train, y_train)\n",
    "y_train_predict = blobEvaluation.predict(x_train)\n",
    "y_test_predict = blobEvaluation.predict(x_test)\n",
    "print('trainAccracy:',blobEvaluation.score(x_train,y_train))\n",
    "print(classification_report(y_train,y_train_predict))\n",
    "print('testAccracy:',blobEvaluation.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "总结4 2018.11.19\n",
    "对于朴素贝叶斯分类器，基于非平衡数据car，集成学习（AdaBoost和Bagging）训练准确率都较低，但泛化准确率更高;\n",
    "基于平衡数据，Bagging与单一分类器效果相同，AdaBoost训练准确率更高，三者泛化准确率相近;\n",
    "基于较难学习的非平衡数据wine，Bagging朴素贝叶斯提升不明显，AdaBoost提升较为明显。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_n = 0\n",
    "max_p = 0\n",
    "for n in range(7,25):\n",
    "    blobEvaluation = AdaBoostClassifier(base_estimator=GaussianNB(), \n",
    "                                    n_estimators=n, \n",
    "                                    learning_rate=0.5,\n",
    "                                    algorithm='SAMME',\n",
    "                                    random_state=1)\n",
    "    blobEvaluation.fit(x_train, y_train)\n",
    "    y_train_predict = blobEvaluation.predict(x_train)\n",
    "    y_test_predict = blobEvaluation.predict(x_test)\n",
    "    if max_p < blobEvaluation.score(x_test,y_test):\n",
    "        max_n = n\n",
    "        max_p = blobEvaluation.score(x_test,y_test)\n",
    "max_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7000000000000001"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_p = 0\n",
    "max_x = 0\n",
    "for x in [0.1*x for x in range(1,11)]:\n",
    "    blobEvaluation = AdaBoostClassifier(base_estimator=GaussianNB(), \n",
    "                                    n_estimators=7, \n",
    "                                    learning_rate=x,\n",
    "                                    algorithm='SAMME',\n",
    "                                    random_state=1)\n",
    "    blobEvaluation.fit(x_train, y_train)\n",
    "    if max_p < blobEvaluation.score(x_test,y_test):\n",
    "        max_x = x\n",
    "        max_p = blobEvaluation.score(x_test,y_test)\n",
    "max_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
