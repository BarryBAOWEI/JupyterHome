{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据iris数据集\n",
    "def iris_type(s):\n",
    "    it = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
    "    return it[s]\n",
    "path = u'C:/Users/jxjsj/Desktop/irisDataSet.txt'  # 数据文件路径\n",
    "data = pd.read_csv(path, header = None)\n",
    "data[4] = data[4].apply(lambda x: str(iris_type(x)))\n",
    "dataSet = np.array(data)\n",
    "\n",
    "x, y = np.split(dataSet, (4,), axis=1) # 快速切割array 1切列 0切行\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, random_state=1, train_size=0.8) #随机划分训练集与验证集的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据carEvaluation数据集\n",
    "path = u'C:/Users/jxjsj/Desktop/JupyterHome/carEvaluation.txt'\n",
    "dataSet = pd.read_csv(path, header = None)\n",
    "\n",
    "x_temp, y_temp = np.split(dataSet, (6,), axis=1)\n",
    "\n",
    "x = np.array(pd.get_dummies(x_temp))\n",
    "y = np.array(y_temp)\n",
    "\n",
    "# dataSet = pd.get_dummies(dataSet[[0,1,2,3,4,5]])+dataSet[[6]]\n",
    "# x, y = np.split(dataSet, (21,), axis=1) # 快速切割array 1切列 0切行\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, random_state=2, train_size=0.9) #随机划分训练集与验证集的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unacc': 126, 'vgood': 5, 'acc': 35, 'good': 7}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  数据不平衡\n",
    "y = y_test\n",
    "labelCounts = {}\n",
    "for i in y:\n",
    "    if i[0] not in labelCounts.keys(): \n",
    "        labelCounts[i[0]] = 0\n",
    "    labelCounts[i[0]] += 1\n",
    "print(labelCounts)\n",
    "sum_n = 0\n",
    "for i in labelCounts.keys():\n",
    "    sum_n += labelCounts[i]\n",
    "sum_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel='linear'时，为线性核，C越大分类效果越好，但有可能会过拟合（defaul C=1）。\n",
    "kernel='rbf'时（default），为高斯核，gamma值越小，分类界面越连续；gamma值越大，分类界面越“散”，分类效果越好，但有可能会过拟合。\n",
    "decision_function_shape='ovr'时，为one v rest，即一个类别与其他类别进行划分，\n",
    "decision_function_shape='ovo'时，为one v one，即将类别两两之间进行划分，用二分类的方法模拟多分类的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Confusion_Matrix(y_real, y_hat):\n",
    "    '''\n",
    "    计算多元混淆矩阵\n",
    "    :param y_real : 真实值，一个单行的array或者list\n",
    "    :param y_hat  : 预测值，一个单行的array或者list\n",
    "    :return       : 混淆矩阵，左真实&上预测\n",
    "    '''    \n",
    "    y_type = list(set(y_hat))\n",
    "    confusion_matrix = pd.DataFrame(columns = y_type, index = y_type).fillna(0)\n",
    "    cnt_dict = {}\n",
    "    \n",
    "    # 识别y与y_hat对的类别与频数，保存为字典\n",
    "    for i in range(len(y_hat)):\n",
    "        if (y_real[i],y_hat[i]) not in cnt_dict.keys():\n",
    "            cnt_dict[(y_real[i],y_hat[i])] = 0\n",
    "        cnt_dict[(y_real[i],y_hat[i])] += 1\n",
    "    \n",
    "    # 将字典输入到DataFrame\n",
    "    for key in cnt_dict.keys():\n",
    "        confusion_matrix.loc[key[0],key[1]] = cnt_dict[key]\n",
    "        \n",
    "    # 计算错误率\n",
    "    right_cnt = 0\n",
    "    for y_correct in y_type:\n",
    "        right_cnt += confusion_matrix.loc[y_correct,y_correct]\n",
    "    error_rate = 1 - right_cnt/len(y_real)\n",
    "    \n",
    "    return confusion_matrix,error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################### 求最优正则化常数以及高斯核带宽，尝试阶段，用循环（极慢） ###############################\n",
    "best_C = 0.01\n",
    "best_gamma = 5\n",
    "best_error = 1.01\n",
    "\n",
    "for C in np.linspace(0.01, 5, num=15):\n",
    "    for gamma in np.linspace(5, 25, num=10):\n",
    "        clf = svm.SVC(C=C, kernel='rbf', gamma=gamma, decision_function_shape='ovr')\n",
    "        clf.fit(x_train, y_train.ravel()) #array.ravel()表示Nx1合并为1xN\n",
    "        # 训练集\n",
    "        y_train_hat = clf.predict(x_train)\n",
    "        confusion_matrix_train, error_rate_train = Confusion_Matrix(y_train.ravel(), y_train_hat)\n",
    "        # 验证集\n",
    "        y_test_hat = clf.predict(x_test)\n",
    "        confusion_matrix_test, error_rate_test = Confusion_Matrix(y_test.ravel(), y_test_hat)\n",
    "        total_error = error_rate_train + error_rate_test\n",
    "        if total_error < best_error:\n",
    "            best_error = total_error\n",
    "            best_C = C\n",
    "            best_gamma = gamma            \n",
    "\n",
    "clf = svm.SVC(C=best_C, kernel='rbf', gamma=best_gamma, decision_function_shape='ovr')\n",
    "clf.fit(x_train, y_train.ravel())\n",
    "y_train_hat = clf.predict(x_train)\n",
    "confusion_matrix_train, error_rate_train = Confusion_Matrix(y_train.ravel(), y_train_hat)\n",
    "y_test_hat = clf.predict(x_test)\n",
    "confusion_matrix_test, error_rate_test = Confusion_Matrix(y_test.ravel(), y_test_hat)\n",
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一般地训练SVM以及混淆矩阵&错误率输出\n",
    "clf = svm.SVC(C=2, kernel='linear', decision_function_shape='ovr',class_weight = \"balanced\") # 线性核函数\n",
    "# clf = svm.SVC(C=2, kernel='rbf', gamma=20, decision_function_shape='ovr',class_weight = \"balanced\") # 高斯核函数\n",
    "clf.fit(x_train, y_train.ravel()) #array.ravel()表示Nx1合并为1xN\n",
    "# 训练集\n",
    "y_train_hat = clf.predict(x_train)\n",
    "confusion_matrix_train, error_rate_train = Confusion_Matrix(y_train.ravel(), y_train_hat)\n",
    "# 验证集\n",
    "y_test_hat = clf.predict(x_test)\n",
    "confusion_matrix_test, error_rate_test = Confusion_Matrix(y_test.ravel(), y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "意外发现：\n",
    "使用线性核函数相比于高斯核函数，对于特征向量长度较短（维度低）、数据量大的非平衡数据，且使用不同权重正则化常数后，训练集精确度略微下降但测试集精确度显著上升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vgood</th>\n",
       "      <th>good</th>\n",
       "      <th>unacc</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vgood</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacc</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>988</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vgood  good  unacc  acc\n",
       "vgood     60     0      0    0\n",
       "good       0    62      0    0\n",
       "unacc      0     4    988   92\n",
       "acc        0    17      1  331"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0733118971061093"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>vgood</th>\n",
       "      <th>unacc</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgood</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       good  vgood  unacc  acc\n",
       "good      7      0      0    0\n",
       "vgood     0      5      0    0\n",
       "unacc     0      0    116   10\n",
       "acc       2      0      0   33"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06936416184971095"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accracy: 0.930635838150289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.77      0.94      0.85        35\n",
      "        good       0.78      1.00      0.88         7\n",
      "       unacc       1.00      0.92      0.96       126\n",
      "       vgood       1.00      1.00      1.00         5\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       173\n",
      "   macro avg       0.89      0.97      0.92       173\n",
      "weighted avg       0.94      0.93      0.93       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accracy:',clf.score(x_test,y_test))\n",
    "print(classification_report(y_test,y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
