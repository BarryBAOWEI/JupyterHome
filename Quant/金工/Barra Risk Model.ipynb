{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "读取基准数据\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs300_trade_data = pd.read_csv('D:/DataBaseForBarra/hs300_trade_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "市值相关数据\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MV_materials = pd.read_csv('D:/DataBaseForBarra/database1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "基本面相关数据\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VB_materials = pd.read_csv('D:/DataBaseForBarra/database2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "行业相关数据\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_materials = pd.read_csv('D:/DataBaseForBarra/database3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "历史沪深300行情数据\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_trade_data = pd.read_csv('D:/DataBaseForBarra/database4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "数据处理1\n",
    "行情数据打上停牌标识、填充缺失值\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_trade_data['suspend'] = stock_trade_data['close'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "\n",
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst)\n",
    "\n",
    "def fillnanvalue(df):\n",
    "    df_ = df.copy()\n",
    "    df_ = df_.fillna(method='ffill')\n",
    "    return df_\n",
    "\n",
    "stock_trade_data_tmp0 = applyParallel(stock_trade_data.groupby('code'),fillnanvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "数据处理2\n",
    "行情数据添加收益率数据\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_trade_data_tmp1 = stock_trade_data_tmp0.pivot_table(index='day',values='close',columns='code').pct_change().unstack().reset_index().rename(columns={0:'return'})\n",
    "stock_trade_data_tmp2 = stock_trade_data_tmp0.merge(stock_trade_data_tmp1,on=['code','day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "计算Barra十类风格因子并关联到行情表\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1.市值因子\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MV_materials['Size'] = MV_materials['market_cap'].apply(lambda x: np.log(x))\n",
    "Size_df_tmp = MV_materials[['day','code','Size']]\n",
    "stock_trade_data_tmp3 = stock_trade_data_tmp2.merge(Size_df_tmp,on=['day','code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2.贝塔因子 - 有BUG，是在求beta时使用指数加权解法，不是求得beta后再指数加权\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta_tmp0 = stock_trade_data_tmp3[['code','return','day']]\n",
    "hs300_sub0 = hs300_trade_data[['markbench_return']].reset_index().rename(columns={'index':'day'})\n",
    "beta_tmp1 = beta_tmp0.merge(hs300_sub0,on=['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst)\n",
    "\n",
    "def compute_beta(df):\n",
    "    df = df.copy()\n",
    "    code = df['code'].tolist()[0]\n",
    "    # rolling\n",
    "    wind_len = 252\n",
    "    df_ = df[['day','return','markbench_return']]\n",
    "    save_dict = {}\n",
    "    for start in range(len(df_)-wind_len):\n",
    "        end = start + wind_len\n",
    "        df_sub = df_.iloc[start:end,:]\n",
    "        date = df_sub['day'].tolist()[-1]\n",
    "        try:\n",
    "            X = df_sub['return'].dropna()\n",
    "            y = df_sub['markbench_return'].dropna()\n",
    "            X = sm.add_constant(X)\n",
    "            beta = sm.OLS(y,X).fit().params[1]\n",
    "            save_dict[date] = beta\n",
    "        except:\n",
    "            save_dict[date] = np.nan\n",
    "    save_df = pd.DataFrame.from_dict(save_dict,orient='index').reset_index().rename(columns={'index':'day',0:'beta'})\n",
    "    save_df['code'] = code\n",
    "    return save_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "beta_tmp2 = applyParallel(beta_tmp1.groupby('code'),compute_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst)\n",
    "\n",
    "def compute_ewm_beta(df):\n",
    "    df = df.copy()\n",
    "    df['Beta'] = df['beta'].ewm(halflife=63).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_tmp3 = applyParallel(beta_tmp2.groupby('code'),compute_ewm_beta)\n",
    "\n",
    "stock_trade_data_tmp4 = stock_trade_data_tmp3.merge(beta_tmp3[['Beta','day','code']],on=['code','day'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3.动量因子\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst)\n",
    "\n",
    "def compute_momentum(df):\n",
    "    df = df.copy()\n",
    "    df['return_shift21'] = df['return'].shift(21).apply(lambda x: np.log(1+x))\n",
    "    df['Momentum'] = df['return_shift21'].ewm(halflife=126,min_periods=504).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_tmp0 = applyParallel(stock_trade_data_tmp4.groupby('code'),compute_momentum)\n",
    "\n",
    "stock_trade_data_tmp5 = momentum_tmp0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4.残差波动因子\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dastd\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewa(series,halflife):\n",
    "    x = []\n",
    "    alpha = 1 - np.exp(np.log(0.5) / halflife)\n",
    "    x.append(series[0])\n",
    "    for i in range(1,len(series)):\n",
    "        x.append((1-alpha)*x[i-1]+alpha*series[i])\n",
    "    return x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dastd(df):\n",
    "    df = df.copy()\n",
    "    df['rolling252_mean'] = df['return'].rolling(252).mean()\n",
    "    \n",
    "    code = df['code'].tolist()[0]\n",
    "    # rolling\n",
    "    wind_len = 252\n",
    "    df_ = df[['day','return','rolling252_mean']]\n",
    "    save_dict = {}\n",
    "    for start in range(len(df_)-wind_len):\n",
    "        end = start + wind_len\n",
    "        df_sub = df_.iloc[start:end,:].copy()\n",
    "        date = df_sub['day'].tolist()[-1]\n",
    "        return_mean = df_sub['rolling252_mean'].tolist()[-1]\n",
    "        try:\n",
    "            df_sub['return_'] = df_sub['return'].apply(lambda x: (x-return_mean)**2)\n",
    "            dastd = ewa(df_sub['return_'].tolist(),42)    \n",
    "            save_dict[date] = dastd\n",
    "        except:\n",
    "            save_dict[date] = np.nan\n",
    "    save_df = pd.DataFrame.from_dict(save_dict,orient='index').reset_index().rename(columns={'index':'day',0:'dastd'})\n",
    "    save_df['code'] = code\n",
    "    \n",
    "    return save_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst)\n",
    "\n",
    "dastd_tmp0 = applyParallel(stock_trade_data_tmp5.groupby('code'), compute_dastd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "hsigma\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs300_trade_data['markbench_return'] = hs300_trade_data.pct_change()['close']\n",
    "hsigma_tmp0 = stock_trade_data_tmp5[['code','return','day']]\n",
    "hs300_sub0 = hs300_trade_data[['markbench_return']].reset_index().rename(columns={'index':'day'})\n",
    "hsigma_tmp1 = hsigma_tmp0.merge(hs300_sub0,on=['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hsigma(df):\n",
    "    df = df.copy()\n",
    "    code = df['code'].tolist()[0]\n",
    "    # rolling\n",
    "    wind_len = 252\n",
    "    df_ = df[['day','return','markbench_return']]\n",
    "    save_dict = {}\n",
    "    for start in range(len(df_)-wind_len):\n",
    "        end = start + wind_len\n",
    "        df_sub = df_.iloc[start:end,:]\n",
    "        date = df_sub['day'].tolist()[-1]\n",
    "        try: \n",
    "            X = df_sub['return'].dropna()\n",
    "            y = df_sub['markbench_return'].dropna()\n",
    "            X = sm.add_constant(X)\n",
    "            res = sm.OLS(y,X).fit().resid\n",
    "            hsigma = np.std(res)\n",
    "            save_dict[date] = hsigma\n",
    "        except:\n",
    "            save_dict[date] = np.nan\n",
    "    save_df = pd.DataFrame.from_dict(save_dict,orient='index').reset_index().rename(columns={'index':'day',0:'hsigma'})\n",
    "    save_df['code'] = code\n",
    "    return save_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst,sort=False)\n",
    "\n",
    "hsigma_tmp0 = applyParallel(hsigma_tmp1.groupby('code'), compute_hsigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "crma\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_crma(df):\n",
    "    df = df.copy()\n",
    "    code = df['code'].tolist()[0]\n",
    "    # rolling\n",
    "    wind_len = 252\n",
    "    df_ = df[['day','return']]\n",
    "    save_dict = {}\n",
    "    for start in range(len(df_)-wind_len):\n",
    "        end = start + wind_len\n",
    "        df_sub = df_.iloc[start:end,:].copy()\n",
    "        date = df_sub['day'].tolist()[-1]\n",
    "        try:\n",
    "            df_sub['return_'] = df_sub['return'].apply(lambda x: np.log(1+x))\n",
    "            df_sub['return__'] = df_sub['return_'].expanding().sum()\n",
    "            zmax = df_sub['return__'].max()\n",
    "            zmin = df_sub['return__'].min()\n",
    "            crma = np.log(1+zmax) - np.log(1+zmin)\n",
    "            save_dict[date] = crma\n",
    "        except:\n",
    "            save_dict[date] = np.nan\n",
    "    save_df = pd.DataFrame.from_dict(save_dict,orient='index').reset_index().rename(columns={'index':'day',0:'crma'})\n",
    "    save_df['code'] = code\n",
    "    return save_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst,sort=False)\n",
    "\n",
    "crma_tmp0 = applyParallel(stock_trade_data_tmp5.groupby('code'), compute_crma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "标准化再相加\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "resvol_tmp0 = dastd_tmp0.merge(hsigma_tmp0,on=['code','day'])\n",
    "resvol_tmp1 = resvol_tmp0.merge(crma_tmp0,on=['code','day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standerlize_cross(df):\n",
    "    df = df.copy()\n",
    "    date = df['day'].tolist()[0]\n",
    "    \n",
    "    sub_df = df[['dastd','hsigma','crma','code']].set_index('code')\n",
    "    stder_df = sub_df.apply(lambda x: (x-x.mean())/x.std(),axis=0).reset_index()\n",
    "    stder_df['day'] = date\n",
    "    \n",
    "    return stder_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst,sort=False)\n",
    "\n",
    "resvol_tmp2 = applyParallel(resvol_tmp1.groupby('day'), standerlize_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resvol_tmp3 = resvol_tmp2.copy()\n",
    "resvol_tmp3['Resvol'] = resvol_tmp3.apply(lambda x: x['dastd']*0.74+x['hsigma']*0.0+x['crma']*0.16,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_trade_data_tmp6 = stock_trade_data_tmp5.merge(resvol_tmp3,on=['day','code'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5.非线性市值\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_trade_data_tmp6['nlsize'] = stock_trade_data_tmp6['Size'].apply(lambda x: x**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def regression_cross_nlsize(df):\n",
    "    df = df.copy()\n",
    "    date = df['day'].tolist()[0]\n",
    "    sub_df = df[['nlsize','Size','code']].dropna(how='any',axis=1)\n",
    "    \n",
    "    y = sub_df['nlsize']\n",
    "    X = sub_df['Size']\n",
    "    res = sm.OLS(y,X).fit().resid\n",
    "    \n",
    "    sub_df['Nlsize'] = res\n",
    "    sub_df = sub_df[['Nlsize','code']]\n",
    "    \n",
    "    df = df.merge(sub_df,on=['code'],how='left')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst,sort=False)\n",
    "\n",
    "nlsize_tmp0 = applyParallel(stock_trade_data_tmp6.groupby('day'), regression_cross_nlsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsize_tmp1 = nlsize_tmp0[['code','day','Nlsize']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_trade_data_tmp7 = stock_trade_data_tmp6[['code','open','close','high','low','volume','money',\n",
    "                                               'day','suspend','return','Size','Beta', 'Momentum',\n",
    "                                               'Resvol']]\n",
    "stock_trade_data_tmp8 = stock_trade_data_tmp7.merge(nlsize_tmp1,on=['code','day'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 临时保存\n",
    "stock_trade_data_tmp8.to_csv('D:/DataBaseForBarra/stock_trade_data_tmp8.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
